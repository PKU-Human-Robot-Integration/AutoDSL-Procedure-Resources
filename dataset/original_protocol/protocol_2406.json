{
  "id": 2538,
  "origin_website": "Cell",
  "title": "Protocol for fast scRNA-seq raw data processing using scKB and non-arbitrary quality control with COPILOT",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nFor first-time users, we recommend first running the protocol on toy data following steps 1, 2, 5, and 6. For those who wish to learn how to transform typical raw scRNA-seq data into a normalized and annotated gene-by-cell matrix, please follow steps 1, 3, and 7. For users who would like to try this protocol on scRNA-seq data from a species other than Arabidopsis thaliana, (e.g., human PBMC data), please see steps 4 and 8.\nAlign raw reads to genome via scKB\nTiming: 2 min for toy data. For the full datasets demonstrated in this protocol, the running time ranged between 25 min to 120 min, depending on data size and species\nThis step aligns raw reads to the designated genome and calls transcript UMI counts for each cell barcode and gene. The expected output of this step includes gene-by-cell matrices of spliced and unspliced UMI counts of transcripts, reads/aligning stats of the sample, cell barcodes, and gene ID files. These outputs are COPILOT-compatible and can serve as direct inputs to COPILOT for quality filtering and generation of the summary file.\nExtract intron information with the R package BUSpaRse and make kallisto index. This step is important for kallisto to distinguish spliced and unspliced reads when mapping against the designated genome.",
    "Note: Extraction of intron information is done by running BUSpaRse::get_velocity_files(). Notice that argument “X” should point to the directory of your annotation file. Argument “L” specifies the length of reads, which varies with single-cell technologies. For example, 10x Genomics v1: 98 nucleotides, 10x v2: 98 nucleotides, 10x v3:91 nucleotides, Drop-seq: 50 nucleotides. In this example, we set “L” to 91 since our toy data was generated with 10x v3 chemistry. We should set the argument “style” to “Ensembl” since our gene annotation (.gtf) file is downloaded from Ensembl (https://plants.ensembl.org/index.html[href=https://plants.ensembl.org/index.html]). For details related to get_velocity_files() arguments, please refer to the BUSpaRse manual (https://bioconductor.org/packages/release/bioc/manuals/BUSpaRse/man/BUSpaRse.pdf[href=https://bioconductor.org/packages/release/bioc/manuals/BUSpaRse/man/BUSpaRse.pdf]).\nCritical: After running get_velocity_files(), the working directory should have files “cDNA_introns.fa”, “cDNA_tx_to_capture.txt”, “introns_tx_to_capture.txt”, and “tr2g.tsv”. Preparing intron files for the Arabidopsis thaliana genome takes about 1 min.\n# In R\n>setwd(\"∼/to/where/you/clone/the/repo/scKB\")\n# Load libraries and genome\n>library(BUSpaRse)\n>library(BSgenome.Athaliana.TAIR.TAIR9)\n# Extract intron information\n>get_velocity_files(X = \"./Arabidopsis_thaliana.TAIR10.43.gtf\", L = 91, Genome = BSgenome.Athaliana.TAIR.TAIR9, out_path = \"./\", isoform_action = \"separate\", chrs_only=FALSE, style=\"Ensembl\")\n# Index the intron file with kallisto and exit R\n>system(\"kallisto index -i ./cDNA_introns_10xv3.idx ./cDNA_introns.fa\")\n>quit()\nRun scKB.\nNote: Name the output directory as your sample name and set the number of computational threads/cores available accordingly with argument “t”.\nNote: After running scKB, the output directory (in this case “./col0_toy”) should have 8 files: a “inspect.json”, a “run_info.json”, a “spliced.barcodes.txt”, a “spliced.genes.txt”, a “spliced.mtx”, a”unspliced.barcodes.txt”, a “unspliced.genes.txt” and a “unspliced.mtx”.\nNote: The json files document the sample stats of reads and alignment; the mtx files represent gene-by-cell matrices; the txt files contain cell barcodes and gene IDs information.\nNote: The toy data contain 1 million reads and the run takes about 30 s.\n# In bash\n>cd ∼/to/where/you/clone/the/repo/scKB\n# Run bash script scKB. Please name the output directory as your sample name using \"-n\" flag",
    ">./scKB -f ./toy_data -i ./cDNA_introns_10xv3.idx -d ./ -s 10xv3 -t 16 -w ./10xv3_whitelist.txt -n ./col0_toy\nRun scKB on Arabidopsis thaliana wild-type Columbia-0 (“col0”) full data.\nNote: The col0 full data contains 386 million reads and downloading can take 2–3 h.\nNote: Here, we store the fastq files for the full dataset under the folder named \"col0_data\".\nNote: Notice that if containers were applied, it is recommended to set the output directories of sra files and the fastqs files under the mounted directory “/data/” to avoid potential data loss (see steps 7b and c in the section “install scKB and COPILOT on your machine[href=https://www.wicell.org#sec1.1]”).\nNote: The scKB run takes 22 min.\n# In bash\n>cd ∼/to/where/you/clone/the/repo/scKB\n# Install sra-tools and download sra from sample GSM4626009 (col0 full data)\n>conda install -c bioconda sra-tools\n>prefetch -v SRR12046119 SRR12046120\n# Convert sra to fastqs (sras are downloaded to /home/[USER]/ncbi/public/sra/ by default)\n>fastq-dump --outdir ./col0_data/ --split-files --gzip /home/[USER]/ncbi/public/sra/SRR12046119.sra\n>fastq-dump --outdir ./col0_data/ --split-files --gzip /home/[USER]/ncbi/public/sra/SRR12046120.sra\n#Rename fastq files for scKB compatibility\n>rename 's/_1.fastq.gz/_R1_001.fastq.gz/' ./col0_data/∗.fastq.gz\n>rename 's/_2.fastq.gz/_R2_001.fastq.gz/' ./col0_data/∗.fastq.gz\n>rename 's/_3.fastq.gz/_I1_001.fastq.gz/' ./col0_data/∗.fastq.gz\n# Run scKB on the full data col0 from which the toy_data is subsetted\n>./scKB -f ./col0_data -i ./cDNA_introns_10xv3.idx -d ./ -s 10xv3 -t 16 -w ./10xv3_whitelist.txt -n ./col0\nRun scKB on PBMC dataset generated with 10x v2 technology.\nNote: The codes cover data download, intron file extraction, kallisto index building, and scKB execution.\nNote: Notice that if containers were applied, the data downloaded and the output directory are recommended to be put under the mounted directory “/data/” to avoid potential data loss (see steps 7b and c in the section “install scKB and COPILOT on your machine[href=https://www.wicell.org#sec1.1]”).\nNote: The whole process takes about 120 min (preparing genome and intron files take 85 min, scKB takes 45 min).\n# In bash\n>cd ∼/to/where/you/clone/the/repo/scKB",
    "# Download PBMC dataset from 10x Genomics website\n>mkdir pbmc\n>cd pbmc\n>curl -O https://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_fastqs.tar[href=https://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_fastqs.tar]\n>tar xvf pbmc_1k_v2_fastqs.tar\n>cd ../\n# Download gene annotation file from 10x Genomics website\n>curl -O https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz[href=https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz]\n>tar zxvf refdata-gex-GRCh38-2020-A.tar.gz\n# Activate R and set working directory in R\n>R\n>setwd(\"∼/to/where/you/clone/the/repo/scKB\")\n# Install Human BSgenome object\n>BiocManager::install(\"BSgenome.Hsapiens.UCSC.hg38\")\n# Load libraries and genome\n>library(BUSpaRse)\n>library(BSgenome.Hsapiens.UCSC.hg38)\n# Extract intron information\n>get_velocity_files(X = \"./refdata-gex-GRCh38-2020-A/genes/genes.gtf\", L = 98, Genome = BSgenome.Hsapiens.UCSC.hg38, out_path = \"./\", isoform_action = \"separate\", chrs_only=TRUE, style=\"Ensembl\")\n# Index the intron file with kallisto\n>system(\"kallisto index -i ./cDNA_introns_10xv2.idx ./cDNA_introns.fa\")\n>quit()\n# In bash\n# Run scKB\n>./scKB -f ./pbmc/pbmc_1k_v2_fastqs -i ./cDNA_introns_10xv2.idx -d ./ -s 10xv2 -t 16 -w ./10xv2_whitelist.txt -n ./pbmc_1k_v2\nRun COPILOT for quality filtering\nTiming: between 30 s to 50 min, depending on data size and whether downstream analysis with Seurat is performed\nThis step includes quality filtering on cells, optional doublet removal, and cell type/developmental stage annotation (optional). Notice that if containers were used, the data downloaded and the output directory are recommended to be put under the mounted directory “/data/” to avoid potential data loss (see steps 7b and c under the section “install scKB and COPILOT on your machine[href=https://www.wicell.org#sec1.1]”).\nRun COPILOT for non-iterative quality filtering without doing downstream analysis with Seurat.\nNote: The toy data contain only 1 million reads. Therefore, the argument “min.UMI.low.quality” and “min.UMI.high.quality” are adjusted accordingly for expected low sequencing depth.\nNote: The non-iterative filtering is achieved by setting the argument “filtering.ratio” to 1.\nNote: The run takes about 30 s.\n# In R\n>setwd(\"∼/to/where/you/clone/the/repo/scKB\")\n# Load COPILOT\n>library(COPILOT)\n# Run COPILOT\n>copilot(sample.name = \"col0_toy\", species.name = \"Arabidopsis thaliana\", transcriptome.name = \"TAIR10\", sample.stats = NULL, mt.pattern = \"ATMG\",",
    "mt.threshold = 5, cp.pattern = \"ATCG\", remove.doublet = FALSE, do.seurat = FALSE, do.annotation = FALSE, unwanted.genes = NULL, filtering.ratio = 1, min.UMI.low.quality = 1, min.UMI.high.quality = 3)\nRun COPILOT for iterative quality filtering without downstream analysis.\nNote: The iterative filtering is achieved by setting the argument “filtering.ratio” to 0, which will run until there are no cells more similar to the low-quality cell expression profile than the high-quality cell expression profile.\nNote: The run takes about 2 min.\n# Run COPILOT\n>copilot(sample.name = \"col0_toy\", species.name = \"Arabidopsis thaliana\", transcriptome.name = \"TAIR10\", sample.stats = NULL, mt.pattern = \"ATMG\",\n      mt.threshold = 5, cp.pattern = \"ATCG\", remove.doublet = FALSE, do.seurat = FALSE, do.annotation = FALSE, unwanted.genes = NULL, filtering.ratio = 0, min.UMI.low.quality = 1, min.UMI.high.quality = 3)\nRun COPILOT for non-iterative quality filtering with downstream analysis (do.seurat = TRUE), including doublet removal (remove.doublet = TRUE) and annotation of cell types and developmental stages based on bulk-RNAseq and microarray data (do.annotation = TRUE).\nNote: If users wish to annotate cells based on an established reference profile as described in Shahan et al. (2022)[href=https://www.wicell.org#bib25], example code for label transfer is also provided.\nNote: Notice that the code for label transfer is suitable only for reference objects created by Seurat version 4. Label transfer demonstrated here requires users to have sufficient amount of space storage and memory (128 GB) to host and load the reference object.",
    "Note: Here we also demonstrate how to remove genes from downstream analysis with the argument “unwanted.genes”. In this case, the protoplasting-induced genes are removed from the Arabidopsis data. Protoplasting refers to a process of removing cell walls from plant cells, which alters the expression of a subset of genes (Denyer et al., 2019[href=https://www.wicell.org#bib28]). Therefore, to correct for artificial factors in downstream analysis, genes known to be induced by protoplasting during library preparation are removed. The run takes about 50 min without label transfer and 60 min with label transfer.\n# In R\n>setwd(\"∼/to/where/you/clone/the/repo/scKB\")\n# Load COPILOT\n>library(COPILOT)\n# Load unwanted genes (optional)\n>pp.genes <-as.character(read.table(\"./supp_data/Protoplasting_DEgene_FC2_list.txt\", header=F)$V1)\n# Run COPILOT\n>copilot(sample.name = \"col0\", species.name = \"Arabidopsis thaliana\", transcriptome.name = \"TAIR10\", sample.stats = NULL, mt.pattern = \"ATMG\",\nmt.threshold = 5, cp.pattern = \"ATCG\", remove.doublet = TRUE, do.seurat = TRUE, do.annotation = TRUE, unwanted.genes = pp.genes, filtering.ratio = 1, dir_to_color_scheme = \"./supp_data/color_scheme_at.RData\", dir_to_bulk = \"./supp_data/Root_bulk_arabidopsis_curated.RD\")\n# Label transfer from Shahan et al. (2022)[href=https://www.wicell.org#bib25]\n# After downloading supplementary file Root_Atlas_seu4.rds.gz directly from GEO GSE152766, decompress Root_Atlas_seu4.rds.gz in bash\n>gunzip Root_Atlas_seu4.rds.gz\n# Load Seurat, reference atlas and query data in R\n>R\n>library(Seurat)\n>rc.integrated <- readRDS(\"./Root_Atlas_seu4.rds\")\n>seu <- readRDS(\"./col0/col0_COPILOT.rds\")\n# Find anchors and transfer annotation from reference in Shahan et al.,2022\n>lt.anchors <- FindTransferAnchors(reference = rc.integrated, query = seu, normalization.method = \"SCT\", npcs = 50, dims = 1:50)\n>predictions <- TransferData(anchorset = lt.anchors, refdata = rc.integrated$celltype.anno, dims = 1:50, weight.reduction = \"pcaproject\")\n>seu <- AddMetaData(seu, metadata = predictions)\n>seu@meta.data$celltype.anno <- seu@meta.data$predicted.id\n>predictions <- TransferData(anchorset = lt.anchors, refdata = rc.integrated$time.anno, dims = 1:50, weight.reduction = \"pcaproject\")\n>seu <- AddMetaData(seu, metadata = predictions)\n>seu@meta.data$time.anno <- seu@meta.data$predicted.id\n# Visualize the transferred labels and save them as plots (optional)\n>pdf(\"col0_transferred_celltype_anno.pdf\", height=8, width=8)\n>DimPlot(seu, reduction = \"umap\", group.by = \"celltype.anno\")\n>dev.off()\n>pdf(\"col0_transferred_time_anno.pdf\", height=8, width=8)\n>DimPlot(seu, reduction = \"umap\", group.by = \"time.anno\")",
    ">dev.off()\n# Save the query data with transferred labels\n>saveRDS(seu, file = \"./col0/col0_COPILOT.rds\")\nRun COPILOT on the PBMC dataset generated with 10x v2 technology for non-iterative quality filtering without downstream analysis.\nNote: The run takes about 15 s.\n# In bash\n# Extract mitochondrial gene names from genome annotation file\n>grep chrM ./refdata-gex-GRCh38-2020-A/genes/genes.gtf | awk '{print $10}' | uniq | sed -e 's/\"//g' -e 's/;//g' > mt_genes.txt\n# Activate R and set working directory in R\n>R\n>setwd(\"∼/to/where/you/clone/the/repo/scKB\")\n# Load COPILOT\n>library(COPILOT)\n# Run COPILOT\n>copilot(sample.name = \"pbmc_1k_v2\", species.name = \"Homo sapiens\", transcriptome.name = \"hg38\", sample.stats = NULL, mt.pattern = read.table(\"mt_genes.txt\")$V1, mt.threshold = 5, cp.pattern = NULL, remove.doublet = FALSE, do.seurat = FALSE, do.annotation = FALSE, unwanted.genes = NULL, filtering.ratio = 1, legend.position=c(0.2,0.8))"
  ],
  "subjectAreas": [
    "Rnaseq",
    "Bioinformatics",
    "Systems Biology",
    "Computer Sciences",
    "Single Cell"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics",
    "Bioinformatics & Computational Biology"
  ]
}