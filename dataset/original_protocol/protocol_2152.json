{
  "id": 2267,
  "origin_website": "Cell",
  "title": "Visualizing attention zones in machine reading comprehension models",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nData and code preparation\nTiming: 30 min\nIn this protocol, we use the well-known machine reading comprehension (MRC) dataset, SQuAD (Rajpurkar et al., 2016[href=https://www.wicell.org#bib9]), and English BERT (Devlin et al., 2019[href=https://www.wicell.org#bib6]) (base-cased version) pre-trained language model to train an MRC system.\nDownload source codes.\nThe source codes can be downloaded by the following command.\n> git clone https://github.com/ymcui/mrc-model-analysis[href=https://github.com/ymcui/mrc-model-analysis]\nNavigate into the downloaded folder.\n> cd mrc-model-analysis\nDownload SQuAD Data.\nDownload training data.\n> wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json[href=https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json]\nDownload development data.\n> wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json[href=https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json]\nMove the training and development files into a new folder.\n> mkdir squad\n> mv train-v1.1.json dev-v1.1.json squad\nDownload the BERT-base-cased pre-trained language model.\nThe model can be downloaded by the following command. Note that the model requires approximately 400M disk space, so please be patient to wait until it finishes.\n> wget https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip[href=https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip]\nAfter downloading the model, you should unzip the file by the following command.\n> unzip cased_L-12_H-768_A-12.zip\nThe newly created folder contains the following files, where the files with the prefix “bert_model” are the model files, “vocab.txt” is the vocabulary, and “bert_config.json” is the configuration file.\ncased_L-12_H-768_A-12/\n  |- bert_model.ckpt.meta\n  |- bert_model.ckpt.index\n  |- bert_model.ckpt.data-00000-of-00001\n  |- vocab.txt\n  |- bert_config.json\nTransfer model files to a Google Cloud Storage bucket (path start with “gs://”). In this protocol, we use “gs://temp-bucket” for illustration. Note that using the Google Cloud Storage bucket is mandatory for TPU computing. If you are using CPU/GPU, this step can be omitted.\n> gsutil -m cp cased_L-12_H-768_A-12/∗ gs://temp-bucket/bert\nNote: Although we use an English dataset and pre-trained language model (PLM) to illustrate the protocol, it is also applicable to other datasets and PLMs, such as CMRC 2018 (Cui et al., 2019[href=https://www.wicell.org#bib5]) with Chinese BERT (Devlin et al., 2019[href=https://www.wicell.org#bib6]), as long as they share the same dataset and PLM structure.",
    "Training an English MRC system\nTiming: 30 min\nIn this step, we will train a typical English machine reading comprehension system by using SQuAD dataset and pre-trained BERT model. After the training is complete, we will use the official evaluation script to obtain the system’s performance on how well it solves the natural questions.\nCheck the training script and fill in with proper values.\nOpen the training script.\n> vim train_squad.sh\nThe training script contains the following variables and arguments.\nGS_BUCKET=gs://your-bucket\nTPU_NAME=your-tpu-name\nTPU_ZONE=your-tpu-zone\nMODEL_OUTPUT_DIR=$GS_BUCKET/path-to-output-dir\npython -u run_squad.py \\\n  --vocab_file=$GS_BUCKET/bert/cased_L-12_H-768_A-12/vocab.txt \\\n  --bert_config_file=$GS_BUCKET/bert/cased_L-12_H-768_A-12/bert_config.json \\\n  --init_checkpoint=$GS_BUCKET/bert/cased_L-12_H-768_A-12/bert_model.ckpt \\\n  --do_train=True \\\n  --train_file=./squad/train-v1.1.json \\\n  --do_predict=True \\\n  --predict_file=./squad/dev-v1.1.json \\\n  --train_batch_size=64 \\\n  --predict_batch_size=32 \\\n  --num_train_epochs=3.0 \\\n  --max_seq_length=512 \\\n  --doc_stride=128 \\\n  --learning_rate=3e-5 \\\n  --version_2_with_negative=False \\\n  --output_dir=$MODEL_OUTPUT_DIR \\\n  --do_lower_case=False \\\n  --use_tpu=True \\\n  --tpu_name=$TPU_NAME \\\n  --tpu_zone=$TPU_ZONE\nFill the variables with proper values.\n$GS_BUCKET: This is the path for Google Cloud Storage. As we indicated in the previous section, we use “gs://temp-bucket” here.\n$TPU_NAME: This is the name of TPU, which was created by using “ctpu” or “gcloud compute” commands. We use “t2-1” here.\n$TPU_ZONE: This is the zone of TPU, which was created by using “ctpu” or “gcloud compute” commands. We use “us-central1-f” here.\n$MODEL_OUTPUT_DIR: This is the location where we wish to save our model files. We use “squad-model” here.\nOther parameters are set with default values, and there is no need to change them at this time.\nSave the changes and exit by pressing ESC and typing the following.\n> :wq\nTrain an English MRC system by using the preset training script.\nType the following command to allow the model training to be executed in the background and save the log file into “train.log”.\n> nohup nice bash run.squad.sh &> train.log &",
    "The training script will automatically process the data, pre-train the model and perform task fine-tuning. The whole process takes approximately 30 min. The training may unusually fail due to the TPU issue. Please see troubleshooting 3[href=https://www.wicell.org#troubleshooting] for further illustration.\nEvaluate the system performance with the official script.\nRetrieve the prediction file of the development set from the storage bucket to the current folder.\n> gsutil cp gs://temp-bucket/squad-model/predictions.json.\nType the following command to obtain the performance of the MRC system.\n> python eval_squad.py squad/dev-v1.1.json predictions.json\nAfter running the evaluation script, the performance results will be shown. We can see that the exact match (EM) score is 80.567, and the F1 score is 88.117.\n{\"exact\": 80.56764427625355, \"f1\": 88.11721947565059, \"total\": 10570, \"HasAns_exact\": 80.56764427625355, \"HasAns_f1\": 88.11721947565059, \"HasAns_total\": 10570}\nNote: As the main goal of our previous work (Cui et al., 2022[href=https://www.wicell.org#bib4]) was to provide robust and comprehensive analyses of machine reading comprehension models, we carried out each experiment five times with different random seeds, and their average scores were used. However, to minimize the training time, we only train one model in this protocol, and it can be easily generalized to multiple runs as well by running steps 1–3 multiple times. Additionally, please note that TensorFlow with GPU or TPU suffers from the indeterministic issue, even with a fixed random seed. Please see troubleshooting 4[href=https://www.wicell.org#troubleshooting] for further illustration.\nCollecting data points\nTiming: 2 h\nIn this step, we will collect the data points for visualizations. We will mask each attention zone (4 zones and masking all, resulting in 5 in total) in each transformer layer (12 in total) and obtain their prediction files (5×12=60 in total).\nDecode SQuAD development set multiple times to obtain the prediction files when disabling each attention zone in the different layers.\nOpen the decoding script.\n> vim decode_squad.sh",
    "The decoding script is similar to the training script, with two additional arguments, “--mask_layer” and “--mask_zone” specified. “--mask_layer” indicates the layer to be masked, where the index ranges from 0 to 11 (12 layers in total). If “None” is set, it means that all layers will be masked. “--mask_zone” indicates the attention zone to be masked, where the valid values are “q2”, “q2p”, “p2q”, “p2”, and “all”. The final decoding script is as follows.\nGS_BUCKET=gs://your-bucket\nTPU_NAME=your-tpu-name\nTPU_ZONE=your-tpu-zone\nMODEL_OUTPUT_DIR=$GS_BUCKET/path-to-output-dir\nfor idx in {0..11};\ndo\npython -u run_squad.py \\\n  --vocab_file=$GS_BUCKET/bert/cased_L-12_H-768_A-12/vocab.txt \\\n  --bert_config_file=$GS_BUCKET/bert/cased_L-12_H-768_A-12/bert_config.json \\\n  --init_checkpoint=$GS_BUCKET/bert/cased_L-12_H-768_A-12/bert_model.ckpt \\\n  --do_train=False \\\n  --do_predict=True \\\n  --predict_file=./squad/dev-v1.1.json \\\n  --predict_batch_size=32 \\\n  --max_seq_length=512 \\\n  --doc_stride=128 \\\n  --mask_layer=$idx \\\n  --mask_zone=\"q2\" \\\n  --output_dir=$MODEL_OUTPUT_DIR \\\n  --do_lower_case=False \\\n  --use_tpu=True \\\n  --tpu_name=$TPU_NAME \\\n  --tpu_zone=$TPU_ZONE\ndone\nBy changing the values in “--mask_zone”, we will obtain all prediction files (60 in total).\nThe prediction files will be saved in the “output_dir”. The name will look like “predictions_layer0_q2.json”, indicating its layer number and masked attention zone.\nCollect the prediction files and evaluate their performances.\nCopy the prediction files from the storage bucket to the local file system.\n> mkdir prediction && cd prediction\n> gsutil cp gs://temp-bucket/squad-model/predictions_layers∗.json .\nWe get the performances in each prediction file and write them into a result file (results.csv). Make sure the prediction files are in the “prediction” folder as created in the previous step. In this protocol, we use the exact match (EM) score as the source of data points, while we can also use the F1 score for visualization, which can be simply changed by passing an additional argument “--use-f1” to the “get_results.py” script.\n> python get_results.py prediction results.csv",
    "The following is a snippet of the result file (results.csv), where each row contains the result of each masked attention zone. For example, the third line represents the results in layer 2, yielding 80.028, 80.114, 80.36, 80.388, and 76.424 in all, Q2, Q2P, P2Q, and P2 zones, respectively.\nlayer,all,q2,q2p,p2q,p2\n1,78.344,80.539,80.482,79.991,66.982\n2,80.028,80.114,80.36,80.388,76.424\n3,79.688,80.227,80.293,79.792,78.666\n......\nNote: The decoding time can be saved significantly by using multiple computing devices. For example, one can simultaneously decode each attention zone in step 4.\nNote: The layer index starts from 0 in the pre-trained language model, indicating the first transformer layer. In this protocol, we directly use “layer 1” to indicate the first layer to avoid confusion.\nVisualizing effect of each attention zone\nTiming: 5 min\nIn this step, we will use the result file to visualize the effect when a specific attention zone is disabled.\nDecode SQuAD development set multiple times to get the prediction files when disabling each attention zone in the different layers.\nRun the visualization script by passing the result file as the first argument, the baseline performance as the second argument, and the name of the output figure as the third argument. In this example, the result file is “results.csv”, the baseline performance (EM) is “80.567” (refer to step 6.c), and the output figure name is “squad.pdf”.\n> python visualize_att_zone.py results.csv 80.567 squad.pdf\nThe visualization figure will be saved in the “squad.pdf” file, which is shown as follows."
  ],
  "subjectAreas": [
    "Computer Sciences",
    "Systems Biology",
    "Bioinformatics",
    "Cognitive Neuroscience"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics",
    "Bioinformatics & Computational Biology"
  ]
}