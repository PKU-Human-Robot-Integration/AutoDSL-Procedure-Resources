{
  "id": 3827,
  "origin_website": "Cell",
  "title": "A Poisson generalized linear model application to disentangle the effects of various parameters on neurophysiological discharges",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nData preprocessing\nTiming: A few minutes (with the computer\n      used in Diomedi et al., 2020[href=https://www.wicell.org#bib4], see ‘materials and equipment[href=https://www.wicell.org#materials-and-equipment]’)\n    \n      Generalized linear models (GLMs) are a flexible generalization of ordinary\n      linear regression used for dependent variables that have a distribution\n      other than Gaussian. Indeed, Poisson distribution is the most used for\n      modelling the number of spikes that a neuron generate in a brief time\n      interval (bin) (Triplett and Goodhill, 2019[href=https://www.wicell.org#bib18];\n      Pillow et al., 2008[href=https://www.wicell.org#bib15];\n      Truccolo et al., 2005[href=https://www.wicell.org#bib20];\n      Paninski, 2004b[href=https://www.wicell.org#bib12];\n      Dayan and Abbott, 2001[href=https://www.wicell.org#bib3]). Generally speaking, fitting a\n      Poisson GLM requires a dependent variable of which variations can be\n      explained by the variations of a set of independent variables (hereafter\n      called ‘regressors’). Thus, in our application, before fitting the models,\n      data must be pre-processed to create the vector of spike counts Y (the\n      dependent variable, vector of size [total N° of bins × 1]) and the\n      regressors matrix X (matrix of size [total N° of bins × N° of\n      regressors]). X and Y must have the same number of rows to associate the\n      spike count in each bin to the corresponding values of the regressors.\n    \n      Depending on the aims of the study and the task, the independent variables\n      can be both dummy (i.e., with 0 or 1 values only) or continuous (for more\n      details, see ‘Note’ of this paragraph; Figure 1[href=https://www.wicell.org#fig1],\n      central part). A huge variety of different features can be included in the\n      GLM, based on the inputs processed by the brain area of interest. Indeed,\n      this method has been applied to the visual domain (e.g.,\n      Pillow et al., 2008[href=https://www.wicell.org#bib15]), to the motor domain (e.g.,\n      Goodman et al., 2019[href=https://www.wicell.org#bib6];\n      Takahashi et al., 2017[href=https://www.wicell.org#bib17];\n      Paniski et al., 2004a[href=https://www.wicell.org#bib11], 2004b[href=https://www.wicell.org#bib12])\n      using as regressors kinematics, joint apertures and forces and also to the",
    "decision making (e.g., Park et al., 2014[href=https://www.wicell.org#bib13]). Each\n      application involves different independent variables and consequently a\n      different construction of the X matrix. We suggest to carefully review the\n      literature for each domain since it is not possible to provide here all\n      the details. We will spend just a few words on filtering the variables.\n      Whereas it is fundamental to pass the visual stimuli (i.e., images)\n      through filters (the most used are Gabor-like that simulate the receptive\n      fields of the neurons in the early visual cortices) and fit the neural\n      activity with the result of this convolution (Liu et al., 2016[href=https://www.wicell.org#bib10]), this step is not necessary for models that involve kinematics or motor\n      parameters in general. GLMs with both filtered and non-filtered (Goodman et al., 2019[href=https://www.wicell.org#bib6]; Takahashi et al., 2017[href=https://www.wicell.org#bib17]) features have been used.\n      When filters are applied, the most common are raised cosine functions (Pillow et al., 2008[href=https://www.wicell.org#bib15]; Truccolo et al., 2010[href=https://www.wicell.org#bib19]), but also simple sine and\n      cosine functions (Truccolo et al., 2005[href=https://www.wicell.org#bib20]).\n    \n      It is recommendable to include in the model also the cell previous spike\n      activity that can account for internal computations not directly linked\n      with external, measured variables. The spike history is usually included\n      at different time lags, both filtered with raised cosine functions (Pillow et al., 2008[href=https://www.wicell.org#bib15]) or not (Diomedi et al., 2020[href=https://www.wicell.org#bib4]).\n    \n        Choose the time window of interest (or the entire trial). In the case\n        that neurons have not been recorded simultaneously, align each cell\n        neural activity on the timing of an event of reference.\n      \nNote: the analysis can focus on a fixed\n      time window around the event of alignment or in variable period on a trial\n      basis between two behavioral events. In the latter case, since the time\n      duration could be variable between repetitions, each trial will result in",
    "a different number of bins. For the sake of simplicity, in\n      Diomedi et al. (2020)[href=https://www.wicell.org#bib4], we chose a fixed time interval\n      (from 3000 ms before movement onset to 1720 ms after it, to get an integer\n      number of bins, see below).\n    \n        Choose an appropriate bin width depending on the dynamics of the\n        processes of interest. The choice of the best bin width depends on the\n        focus of the study. To capture fine temporal dynamics such as cell\n        refractory period and correlation between neurons, bin width in the\n        order of a few ms should be used (as small as 1–2 ms,\n        Pillow et al., 2008[href=https://www.wicell.org#bib15]). For ‘slower’ processes (or\n        with an uncertain temporal variability), such as kinematics encoding,\n        wider bin widths have been used (40 ms,\n        Diomedi et al., 2020[href=https://www.wicell.org#bib4]; 20 ms,\n        Goodman et al., 2019[href=https://www.wicell.org#bib6]; 50 ms,\n        Hatsopoulos et al., 2007[href=https://www.wicell.org#bib8]).\n      \n        For each trial:\n        \n            Bin the spike trains within the chosen time frame with the chosen\n            bin width to obtain the spike count Y vector (recommended:\n            histcounts MATLAB function).\n          \n            Average each independent variable (e.g., the eye tracks, kinematics\n            data …) within the same bin edges that the Y vector (recommended:\n            histcounts MATLAB function).\n            \nNote: the spike count of the cell\n              (or even of other units, if recorded in parallel,\n              Truccolo et al., 2010[href=https://www.wicell.org#bib19]) with different time\n              lags can be included among the independent variables, thus adding\n              information about spike history.\n            \n            If needed, build the vectors for the dummy independent variables:\n            for each bin of the Y vector, assign 1 when a particular condition\n            is met, otherwise 0. See the note below for an example. In\n            Diomedi et al. (2020)[href=https://www.wicell.org#bib4], we built a number of\n            dummy variables that contained information about the different task\n            phases (behavioral events): planning, movement, holding phases,\n            etc., toward specific targets.",
    "Concatenate tip-to-tail the spike counts of all trials to obtain a\n        unique Y vector (size: [total N° of bins × 1]) that contains the cell\n        activity. Concatenate also the independent variables vectors and pool\n        them together in a unique X matrix [total N° of bins × N° of\n        regressors].\n      \nNote: To avoid the inclusion in the model\n      of certain continuous variables, it is possible to discretize them in\n      fixed intervals and transform them into a set of dummy variables. This\n      procedure is useful especially in such contexts in which the proper\n      encoding of some variables is unknown. For example, let’s consider a\n      variable A to be included in the model because it is thought to modulate\n      neural activity. It can be a regressor as it is (A), but also, for\n      example, squared (A2) or filtered with a set of Gaussian\n      kernels (varying mean and sigma) producing profoundly different effects on\n      GLM fitting. When understanding the precise type of encoding of the\n      variable is not the focus of the work, the discretization in a bunch of\n      dummy variables can be a solution to avoid annoying, complex data\n      elaboration. This approach has some drawbacks: first, as already\n      mentioned, it does not provide information about the type of encoding;\n      second, it can critically enlarge the dimensionality of the model. For\n      example, if the variable A (range [0 10]) is discretized in dummy\n      variables using fixed intervals with unitary width (i.e., the first will\n      take 1 when A is in the range [0 1), the second will take 1 when A is\n      between [1 2) and so on), we will end up with a set of 10 dummy variables\n      that represent A. To give an experimental example, in\n      Diomedi et al. (2020)[href=https://www.wicell.org#bib4], we discretized the gaze",
    "position version, elevation and vergence in a 3D-grid associating to each\n      little spatial volume a dummy variable that took the value 1 in every bin\n      in which the animal fixates in it (otherwise, 0). In conclusion,\n      discretization of continuous variables can help in such situations in\n      which the type of encoding is unknown and out of the scope of the work,\n      but it should be applied after a careful evaluation of pros and contra.\n    \nCritical:\n        Once the X matrix has been built, it is highly recommendable to\n        standardize (calculating the z-score, i.e., first subtracting the mean\n        and then dividing for the standard deviation;\n        Bring, 1994[href=https://www.wicell.org#bib1]) the continuous variables to get beta\n        coefficients directly comparable. This step is fundamental when one\n        wants to further study the beta coefficients estimated during the\n        fitting, especially when the regressors have different scales and/or are\n        expressed with different units of measurement. Note that dummy variables\n        will be 0 or 1 by definition and unitless, so they can be introduced in\n        the model without further standardization. It would not make much sense\n        to get a beta coefficient that refers to ‘standard deviation’ increments\n        (or decrements) of a dummy variable.\n      \n        Be careful in adding new independent variables since if the sample size\n        (i.e., the number of bins) is too small respect to the number of\n        regressors, the fitting can lead to a poor estimation and unreliable\n        beta coefficients. Although there is not a rule that always applies, you\n        can use the ‘one in ten rule’, a rule of thumb which states that the\n        maximal number of regressors in a model is equal to the number of\n        observations (bins) / 10 (Steyeberg and Harrel, 2004[href=https://www.wicell.org#bib16]; Peduzzi et al., 1996[href=https://www.wicell.org#bib14];\n        Harrel et al., 1996[href=https://www.wicell.org#bib7]).\n      \nFitting procedure\nTiming: A few days (with the computer",
    "used in Diomedi et al., 2020[href=https://www.wicell.org#bib4], see ‘materials and equipment[href=https://www.wicell.org#materials-and-equipment]’; highly depending on the number of cells and complexity of the model,\n      see the note in ‘materials and equipment[href=https://www.wicell.org#materials-and-equipment]’ section)\n    \n      The direct comparisons between beta coefficients in non-linear models are\n      usually not straight-forward and often discouraged since many calculations\n      on them are not statistically correct (for example, when they are input of\n      an exp function, as in this case; see the equation in the paragraph\n      below). For this reason, we suggest grouping the regressors with similar\n      ‘meaning’ (e.g., the variables that indicate the 3D position of gaze in\n      terms of version, elevation and vergence angles or x, y and z; the\n      variables that encode kinematics; the variables that contain information\n      about the decision…) in ‘blocks’. After the fitting of the complete model,\n      each block of regressors will be removed in turn to evaluate its influence\n      in terms of goodness-of-fit (see below; Figure 1[href=https://www.wicell.org#fig1],\n      right).\n    \n      In this protocol, the fitting procedure consists of two stages: 1)\n      selection of most influential regressors via LASSO optimization; 2) GLM\n      fitting of the complete and nested models considering only the regressors\n      previously selected. During this latter stage, the models are not LASSO\n      regularized to get a value of the goodness of fit that is not penalized by\n      LASSO additional term. Moreover, the protocol requires that blocks of\n      regressors are removed ‘manually’ starting from the complete model to\n      build the nested models, whereas if LASSO was used in this step, there\n      would be the possibility that other regressors would be removed\n      ‘automatically’ (by LASSO) besides those removed ‘manually’ in an\n      uncontrollable way.\n    \nNote: The LASSO optimization introduces a\n      penalization term during the fitting procedure that shrinks the beta\n      estimate values and sets the less influent to 0. The weight of this new",
    "term is represented by the hyper-parameter λ and it can be adjusted to\n      avoid overfitting and/or to handle a lower number of selected variables\n      (see Figure 2[href=https://www.wicell.org#fig2]). This optimization is commonly used\n      when a model includes many independent variables and their correlation\n      with the dependent variable is not known a priori.\n    \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/549-Fig2.jpg\n          Figure 2. Example of feature selection using LASSO optimization method\n          on randomly generated data\n        \n          Left: Cross-validated deviance of LASSO fit models as a function of\n          the shrinking parameter lambda (λ). The green dashed line corresponds\n          to the lambda that produce the minimum deviance. Lower lambdas (on the\n          right of the green line) produce a model with too many parameters that\n          suffer of overfitting. Higher lambdas (on the left of the green line)\n          tend to shrink too much the model removing important regressors.\n          Right: Beta coefficients fitted by LASSO as a function of λ. Each\n          coloured line represents the value of the coefficient corresponding to\n          a regressor in the model. The green dashed line corresponds to the\n          lambda that produce the minimum deviance, thus the optimal beta\n          coefficients. Lower lambdas (on the right of the green line) produce a\n          model that retains more features (fewer beta coefficients have a 0\n          estimate). With higher lambdas (on the left of the green line)\n          important features are removed from the model, greatly worsening the\n          fit.\n        \nThe fitting procedure includes the following steps:\n        Fit a cross-validated (10-fold) LASSO GLM with Poisson link function to\n        explain the spike count in Y with the regressors in X (in MATLAB:\n        betas = lassoglm (X, Y, 'poisson', 'CV', 10)). Calling the MATLAB\n        lassoglm function with these inputs, it will automatically vary\n        the shrinking parameter λ to individuate the value that returns the\n        minimal cross-validated deviance of the model (see\n        Figure 2[href=https://www.wicell.org#fig2]).",
    "Remove from the X matrix the independent variables (columns) that\n        correspond to the zero beta coefficients assigned during LASSO fitting\n        (take the betas of the model with the λ that minimizes the deviance).\n      \n        Fit the complete GLM with Poisson canonical link function (no LASSO\n        regularized; fitglm MATLAB function) to explain the spike count\n        in Y with all the remaining regressors in X after the LASSO selection.\n        For each block of variables, fit a nested model (fitglm MATLAB\n        function) with all the remaining regressors in X (non-zero LASSO betas)\n        except those belonging to that block. To avoid overfitting, an\n        additional cross-validation (k-fold or leave-one-out) can be performed\n        during this step, training on a part of the dataset and testing on the\n        other part (see the Note below).\n      \n        Fit also the ‘null’ model that includes no regressors at all. The\n        goodness-of-fit of this last model will be used as reference value (fitglm\n        with (real) Y and a vector of 1s of the same length, as an X\n        placeholder). If the cross-validation was performed during step 7, it\n        must be used here as well to fit the ‘null’ model on the same parts of\n        the dataset.\n      \n      As use case, in Diomedi et al. (2020)[href=https://www.wicell.org#bib4], we grouped the\n      regressors in ‘extrinsic’ blocks (namely EYE POSITION, EYE SPEED/DIR,\n      POSTSACC, DELAY, PREP, PREMOV, MOV, HOLD, PREMOV2, MOV2) that carried\n      information about task phases (and so, likely the ongoing corresponding\n      neural processes); and the ‘intrinsic’ SPIKE HISTORY block that carried\n      information about the previous cell spiking activity. We thus obtained i)\n      1 complete model that included all the regressors blocks, ii) 10 nested\n      models removing a different extrinsic block for each run, iii) 1 ‘only\n      extrinsic’ model using all the extrinsic blocks but not the SPIKE HISTORY,",
    "iv) 1 ‘only intrinsic’ model removing all the extrinsic blocks (i.e., X\n      matrix consisted only of the variables in SPIKE HISTORY) and v) the ‘null’\n      model.\n    \n      Prior to further evaluation (see next section) of the fitting, it is\n      possible to assess the appropriateness of the model at glance by plotting\n      an estimate of the firing rate (predict MATLAB function) vs the\n      real spike rate. Alternatively, the firing rate at time t predicted by the\n      model can be calculated as the exponential of the linear combination of\n      the regressors:\n    \n(Equation 1)\n μ t  =\nexp\n(  β 0 \n+  β 1 \nX\n 1 , t \n+ ... +\n β K \nX\n K , t \n)\n      where\n      \n K \n      is the number of regressors,\n      \n{  β k  }\nk = 1 , ...\nK\n      are the beta coefficients,\n      \n X\n k , t \n      is the value of kth variable at time t and\n      \n β 0 \n      is the intercept of the model. Figure 3[href=https://www.wicell.org#fig3] (left) shows\n      an example of recorded (black line) vs estimated (red line) firing rate of\n      a parietal neuron during a reaching task. The predicted activity closely\n      matches the observed, peaking just after movement onset (time: 0 s) and\n      resulting slightly inhibited respect to baseline during the hold phase.\n    \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/549-Fig3.jpg\n          Figure 3. Neural data recorded from a parietal neuron during a\n          fix-to-reach task in darkness\n        \n          Left: Observed (black line) and estimated (red line) firing rates\n          (non-overlapping 40 ms bins). In the plot, data are cross-validated\n          (for the estimation data never seen by the model are used) and\n          averaged across 10 trials. Right: Bars show the weights (w-values) of\n          the 10 blocks of regressors (the ‘functional fingerprint’ of the\n          neuron) on the neural activity. Asterisks indicate most important\n          w-values for each cell. Adapted from\n          Diomedi et al., 2020[href=https://www.wicell.org#bib4].",
    "Note: Apply this procedure separately for\n      each cell data.\n    \nNote: For non-LASSO regularized models,\n      the cross-validation strategy is not necessary. When dealing with highly\n      variable data such as neural recordings, the approach can be useful to get\n      more robust estimates. In this protocol, we suggest averaging\n      cross-validated models that revealed to be the simplest, but valid\n      solution to finally handle unique values (Zhang and Zou, 2020[href=https://www.wicell.org#bib22]; Jung and Hu, 2015[href=https://www.wicell.org#bib9]).\n    \nStatistical analysis\nTiming: A few minutes (with the computer\n      used in Diomedi et al., 2020[href=https://www.wicell.org#bib4], see above)\n    \n      After the fitting procedure during which we estimated the beta\n      coefficients for all the models detailed above, it is possible to extract\n      information in different ways from the models depending on the aims of the\n      study. Our statistical analyses focused on the goodness-of-fit (GOF) of\n      the complete vs the nested models to get insights about the underlying\n      neural modulations. We will also give some advices on how to treat the\n      beta coefficients of the complete model to get more complementary\n      information.\n    \n        Goodness-of-fit: get the w-values. In the context of non-linear models,\n        the goodness-of-fit is measured as likelihood (or its logarithm). The\n        log-likelihood\n        \n ℓ  , easier to compute, is used by the algorithms to estimate the\n        parameters (betas) through a procedure called Maximum Likelihood\n        Estimation (MLE). In our case, the likelihood is the probability, given\n        a model, to observe a given spike train thus it ranges from 0 to 1,\n        while its logarithm (the log-likelihood) ranges from -∞ to 0.\n        \n            Assess the GOF of all the models. It can be done in two ways:\n            \n                the\n                \n ℓ \n                value is directly provided by the fitting function (in MATLAB;\n                from the GeneralizedLinearModel object in MATLAB obtained with\n                fitglm function.\n              \n                by calculation with the following formula, remembering that the\n                firing rate depends on the beta coefficients\n                \n β",
    "(see Equation 1[href=https://www.wicell.org#fd1]):\n                \n(Equation 2)\nℓ\n( y ,\nβ )\n=\n∑\nt = 1\nT\n y t \nlog\n(\n μ t \n)\n +\n∑\nt = 1\nT\n y t \nlog\n ( Δ ) \n − \n∑\nt = 1\nT\nlog\n(\n y t \n! )\n− Δ\n∑\nt = 1\nT\n μ t \n                where y is the spike count, μ is the firing rate predicted by\n                the model (see above), Δ is the bin width, t is the bin number\n                and T the total number of bins.\n              \n            For higher interpretability, calculate McFadden’s pseudo-R2\n            (Cameron and Windmeijer, 1997[href=https://www.wicell.org#bib2]):\n            \n(Equation 3)\nR pseudo 2\n= 1 −\n ℓ complete \n ℓ null \n            Starting from the log-likelihood of the complete (\n ℓ complete \n ) and null (\n ℓ null \n ) models.\n ℓ null \n            represented the fitting of the simplest possible model and, by\n            definition, it is independent from every regressor (the model\n            includes only a constant term). McFadden’s pseudo-R2 can\n            be interpreted as the more common R2 in ordinary linear\n            regression, ranging from 0 (extremely poor fit) to 1 (perfect fit),\n            but it tends to be remarkably lower (values of 0.2 to 0.4 are\n            considered excellent fit).\n          \n            Select only the units with a\n            \n R pseudo 2 \n> t h r e\ns h o l d\n            to discard noisier cells for which the model failed to capture\n            neural modulations. In Diomedi et al. (2020)[href=https://www.wicell.org#bib4], we\n            set the threshold at 0.05, as in previous works (Goodman et al., 2019[href=https://www.wicell.org#bib6]; Paninski et al., 2004a[href=https://www.wicell.org#bib11]).\n          \n            For each nested model, compute a relative pseudo-R2 as:\n            \n(Equation 4)\nR relativepseudo 2\n=\n ℓ nested \n−\n ℓ null \nℓ\nc o m p\nl e t e\n−\n ℓ null \n            where\n            \n ℓ nested \n            is the log-likelihood of the nested model. This value compares the",
    "log-likelihood (i.e., the goodness-of-fit) of each nested model with\n            the complete model (and the null model).\n          \n            Convert the relative pseudo-R2 in a weight for each\n            nested model:\n            \n(Equation 5)\nw − v a l\nu e = \n1  −\nR\nr e l a\nt i v e\np s e u\nd o\n2\n      This score is directly associated with the importance of the group (block)\n      of variables removed to build the nested model with respect to the\n      complete model. Whether a block of regressors contained important\n      information for the model, its removal causes a great worsening of the\n      fit, the relative pseudo-R2 will decrease (towards 0) and the\n      w-value will increase (towards 1). Vice versa, whether a regressors’ block\n      had little influence on the complete model, its removal will cause a\n      little worsening of the fit, an increase (towards 1) in the relative\n      pseudo-R2 resulting finally in a low w-value (towards 0). The\n      Figure 3[href=https://www.wicell.org#fig3] (right) shows an example ‘functional\n      fingerprint’ of a parietal neuron composed by 10 different w-values. The\n      w-values marked with the asterisks are important to describe the neural\n      modulations (computed as described in the next section, point B.). For\n      more details about the 10 w-values meaning, please see\n      Diomedi et al., 2020[href=https://www.wicell.org#bib4].\n    \nCritical: If the complete, nested and\n      null models have been cross-validated during the fitting (steps 7 and 8 in\n      ‘fitting procedure[href=https://www.wicell.org#sec3.2]’ section), average the\n      log-likelihoods across the different testing partitions of the data to\n      compute all the scores in this section.\n    \n        Goodness-of-fit and analysis of the w-values, a few suggestions. The set\n        of w-values describes a ‘functional fingerprint’ characteristic for each\n        cell and summarizes the neural modulations elicited by the entire blocks\n        of regressors. The ‘functional fingerprints’ can be further analyzed to",
    "investigate the relative weights of the groups of variables on the\n        population, the presence of specialized subpopulations of cells, the\n        dynamics of the encoding… Here we provide a few suggestions following\n        the analyses in Diomedi et al. (2020)[href=https://www.wicell.org#bib4], but the\n        w-values can be hypothetically treated with many other approaches.\n        \n            It is possible to compare directly the distributions of the w-values\n            across the neural population to investigate the relevance of each\n            block of variables on the spiking activity. We suggest the use of\n            the median values and non-parametric tests such as Wilcoxon’s to\n            evaluate the significance of the observed differences (see\n            Figure 4[href=https://www.wicell.org#fig4]A for an application).\n            \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/549-Fig4.jpg\n                  Figure 4. Figure and data adapted from\n                  Diomedi et al. (2020)[href=https://www.wicell.org#bib4] showing the w-values\n                  across the population\n                \n                  (A) Box plot of w-values for each block of regressors across\n                  the population (2 animals separated).\n                \n                  (B) The w-values are plotted in ascending order for each block\n                  of regressors.\n                \n                  (C) The neural population (a dot for each cell) is projected\n                  onto the 3 first principal components (PCs) of the principal\n                  component analysis (PCA) performed on the 10 w-values.\n                \n                  (D) Histogram showing the minimum number of regressors’ blocks\n                  (w-values) necessary for each cell to reach at least the 85%\n                  of its extrinsic w-values total sum (i.e., the blocks of\n                  regressors with a significant effect on cell modulations).\n                \n            It is also possible to assess which regressor blocks significantly\n            influence each cell activity.\n            \nFor each cell, sum all its w-values.\n                Iteratively, add together the w-values in descending order up to\n                reach the 85% of the total sum. The blocks needed to achieve\n                this value are considered significant in modulating cell\n                activity (see Figure 4[href=https://www.wicell.org#fig4]D).\n              \n            The ‘functional fingerprints’ describe single cell activity\n            patterns. However, it might be interesting to move towards a",
    "population analysis starting from the compact view provided by the\n            ‘functional fingerprints’ and to seek functionally specialized\n            sub-populations. This can be done in a few steps:\n            \n                Visualize the N-dimensional data points (N = number of w-values)\n                in a 2D or 3D space performing a Principal Component (PC)\n                Analysis on the matrix [N° of units × N] and plotting the\n                projections of the neurons on the first PCs (2 or 3).\n              \n                It is possible to apply standard clustering algorithms (e.g.,\n                K-means or hierarchical clustering) on the functional\n                fingerprints and identify clusters of units with shared activity\n                patterns.\n              \nFigure 4[href=https://www.wicell.org#fig4]C shows the functional structure of our neural\n      population (Diomedi et al., 2020[href=https://www.wicell.org#bib4]) that was\n      characterized by the lack of units clustered according to their functional\n      fingerprints.\n    \n        Beta coefficients analysis: a few suggestions. Beta coefficients carry\n        information about the effect of each single regressor included in the\n        model on neural activity. However, since the non-linearity of the\n        Poisson GLMs (an additive change in the predictors has a multiplicative\n        effect on the response, see Equation 1[href=https://www.wicell.org#fd1]) and the\n        normalization needed to compare the betas, usually it is not recommended\n        to interpret directly these regression coefficients. Anyway, we here\n        report a couple of indirect analyses that can be performed on beta\n        coefficients of the complete GLM to extract additional information (see\n        Diomedi et al., 2020[href=https://www.wicell.org#bib4]).\n        \n            Correlation analysis to investigate the encoding of variables in the\n            population:\n            \n                For each variable of interest, build a beta vector that\n                represents the population response to that variable extracting\n                from the complete model of each unit the beta value\n                corresponding to the variable. Mathematically, the beta vector\n                for the kth variable will be\n                \n{\nβ\n c , k \n}\nc = 1 ,\n ... M\n                where M is the number of the units in the population.",
    "Compute the correlation coefficient r between beta vectors (Zhang et al., 2017[href=https://www.wicell.org#bib21]). We recommend using Spearman's rank correlation that is best\n                suited to deal with the non-linearity of the modulations rather\n                than standard Pearson coefficient.\n                \nNote: high correlation\n                  coefficients mean high similarity in the population response\n                  to the two tested variables.\n                \n            Clustering: similarly to what suggested for the functional\n            fingerprints, it is possible to run standard clustering algorithms\n            on the beta coefficients in order to eventually identify\n            subpopulations that process information in different ways. For\n            example, in Diomedi et al. (2020)[href=https://www.wicell.org#bib4], we found two\n            separate clusters within our neural population that were differently\n            influenced by their own previous spiking activity."
  ],
  "subjectAreas": [
    "Bioinformatics",
    "Model Organisms",
    "Behavior",
    "Neuroscience",
    "Single Cell"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research",
    "Molecular Biology & Genetics",
    "Ecology & Environmental Biology",
    "Bioinformatics & Computational Biology"
  ]
}