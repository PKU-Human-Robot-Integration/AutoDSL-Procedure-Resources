{
  "id": 2547,
  "origin_website": "Cell",
  "title": "Protocol to use TopNet for gene regulatory network modeling using gene expression data from perturbation experiments",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nPerturb gene expression in mp53/Ras cell populations by stable retroviral transduction and drug selection\nTiming: Two to three weeks\nThis step creates cell populations with expression of desired cDNA or knock-down of desired target gene by shRNA. The derived cells are used for additional experiments described below.\nOne day prior to infection, plate mp53/Ras cells at 33°C.\nUse one plate for each perturbation to be derived, including an empty vector control each time infections are performed.\nMake an additional plate of cells for “mock” infection (no virus added).\nThe mock infection allows monitoring of drug selection. Populations infected with retrovirus should have surviving cells, while the “mock” infected cells should all die in the presence of drug.\nPlate mp53/Ras cells at 250,000 cells / 10 cm collagen-coated dish.\nPrepare polybrene (also known as hexadimethrine bromide) in PBS at desired stock concentration.\nFor 100×, dissolve 800 μg/mL. For 1000×, dissolve 8 mg/mL.\nPolybrene can be stored at 4°C for up to 6 months or can be frozen at –20°C for longer periods.\nOne day after plating cells (18–24 h), aspirate media from plates and pipet collected supernatants containing viruses on to each plate to be infected.\nRetrovirus-containing supernatants should have a 5 mL volume if generated as described in “before you begin[href=https://www.wicell.org#before-you-begin]” steps 20 and 21 above.\nUse only one type of virus per plate of cells.\nFor mock infection, replace media with 5 mL of fresh 33°C media.\nAdd 8 μg of polybrene per mL of supernatant to each dish being infected (i.e., dilute 100× or 1000× stock to 1× final concentration in volume of supernatant on each dish).\nIncubate for 1.5–3 h at 33°C in CO2 incubator.",
    "Aspirate supernatant and replace with second aliquot of supernatant for virus containing the same perturbagen. In other words, the same dish should receive multiple rounds of infection with empty vector or virus harboring a single cDNA or shRNA insert.\nGenerally, we do 2 rounds of infection but YAMC and mp53/Ras cells can tolerate up to 6 rounds of infection before experiencing toxic effects from exposure to polybrene.\nFollowing all desired rounds of infection, replace supernatant with fresh 33°C media.\nAllow cells to recover for 48–72 h prior to beginning drug selection.\nFor drug selection of YAMC or mp53/Ras cells, i.e., elimination of uninfected cells in the population, add the appropriate selective agent to 33°C media at concentrations listed below and depending on the resistance marker present in the retroviral vector used.\nPuromycin: 5 μg/mL media; Selection takes 2–4 days.\nHygromycin: 200 μg /mL media; Selection takes 4–7 days.\nBleomycin: 100–400 μg /mL media; Selection takes up to 2 weeks.\nNeomycin/Geneticin: 100–400 μg /mL media; Selection takes up to 2 weeks.\nOnce perturbed populations are derived, they should be maintained in media with the appropriate selective agent during routine maintenance / cell splitting.\nCritical: Selected cell populations should be used for RNA isolation, tumor formation studies and other experimentation within two weeks of derivation. Long-term culture of perturbed populations can allow for drift in the population and altered cell behavior over time in culture.\nNote: For experiments described in McMurray et al., Cell Reports, 2021, we freshly transduced and selected polyclonal populations for each biological replicate and each perturbation described in the paper.",
    "Note: For double / combined perturbation, derive polyclonal population harboring one perturbation and then repeat above steps for second perturbagen. Be sure to use perturbagens with distinct selectable markers to enable selection of pure populations of perturbed cells harboring both perturbations. When selecting with multiple selective agents, use half the dosage recommended above to avoid non-specific cell killing.\nExtract RNA and measure gene expression in perturbed mp53/Ras cell populations\nTiming: 5–7 days\nThis step involves re-plating perturbed cell populations for short-term growth at 39°C and then starving them of serum to remove the influence of serum-contributed growth factors from the gene expression patterns observed. The temperature switching is unique to the YAMC cells and their derivatives (mp53/Ras cells) used in our exemplar experiments. We measured gene expression of genes downstream of the perturbed gene in the absence of serum to be consistent with our prior work using YAMC and mp53/Ras cells (McMurray et al., 2008[href=https://www.wicell.org#bib4]). For any other cell types or cell lines, it should be determined whether growth in the presence or absence of serum is more appropriate, as serum can have substantial impact on observed gene expression patterns. Following serum starvation, cells are harvested for RNA isolation and reverse transcription to generate cDNA that is used for TaqMan quantitative PCR assays.\nTrypsinize and count perturbed cell populations to be used experimentally. Include an empty vector control in each experiment performed. For mp53/Ras cells, plate 250,000 cells per 10-cm dish.\nPlate cells onto fresh collagen-coated dishes with 39°C media, which excludes interferon gamma and any eukaryotic-selective agents from the media (i.e., should be free of puromycin or similar). The media should contain anti-microbials, here kanamycin and gentamycin.\nAllow cells to adhere and grow in 39°C CO2 incubator for 48 h.",
    "Serum-starve cells by aspirating media from each dish and replacing with fresh 39°C media without serum.\nAllow cells to grow for an additional 24 h in 39°C CO2 incubator.\nHarvest cells following trypsinization. Inhibit trypsin activity using 39°C media with serum, then immediately collect each cell population into 15 mL conical tubes (one per perturbation) and pellet cells by centrifugation at 500 g for 5 min at 4°C.\nAspirate media and trypsin from cell pellets. Re-suspend cells in 5 mL 1× PBS (can be room temperature or ice-cold), then pellet again by centrifugation.\nAspirate PBS from cell pellets. Use immediately for RNA extraction OR snap freeze and store at −20°C.\nCell pellets can be stored at −20°C for up to one month prior to RNA extraction.\nIsolate RNA by following manufacturer’s protocol for the QIAGEN RNeasy Mini kit with On-Column DNase Digestion.\nIsolated RNA can be stored at −20°C for two years or longer if handled in an RNase-free manner and not exposed to repeated freeze-thaw cycles.\nPrepare reverse transcription reactions:\nDenature 10 μg of each RNA sample to be used by incubation on a heat block or in a water bath at 70°C for 10 min.\nPlunge samples into ice to stop denaturation. Then add the components listed in the table below to each, keeping samples on ice.\nFor multiple reverse transcription reactions, all components except for RNA and water can be made into a master mix for the appropriate number of reactions and aliquoted into RNA + water for necessary final concentration.\nOnce all components have been added, incubate samples at 42°C for 60 min.\nHeat inactivate RT enzyme by shifting samples to 70°C for 10 min.\nHold samples on ice and proceed to PCR setup OR store at −20°C for long-term storage.\ntable:files/protocols_protocol_2051_5.csv\ntable:files/protocols_protocol_2051_6.csv",
    "Hold samples on ice and proceed to PCR setup OR store at −20°C for long term storage (step 24).\nPrepare TaqMan qPCR assays reaction mix.\nThe reactions were run on TaqMan Low Density Arrays, 384 well cards with primer pairs and probes pre-loaded into each well.\nEach reaction contained forward and reverse primer at a final concentration of 900 nM each and a TaqMan MGB probe (6-FAM) at 250 nM final concentration.\nFor each sample:\ntable:files/protocols_protocol_2051_7.csv\nLoad mixture into each of 8 ports on the array at 100 μL per port.\nEach individual sample of cDNA sample was processed on a separate card.\nNote: As described below in step 32 and further sections on TopNet modeling, four biological replicates of each perturbation were measured.\nNote: As noted in step 13 of the before you begin[href=https://www.wicell.org#before-you-begin] section, we considered a replicate to be an independently derived population of perturbed cells. Each replicate of a given perturbation had an empty vector control population of cells that was derived in parallel with the perturbed cell populations.\nSeal arrays with a TaqMan Low-Density Array Sealer (Applied Biosystems) to prevent cross-contamination.\nRun real-time amplifications on an ABI Prism 7900HT Sequence Detection System (Applied Biosystems) with a TaqMan Low Density Array Upgrade.\ntable:files/protocols_protocol_2051_8.csv\nAfter real-time amplification is complete, obtain threshold cycle (Ct) values via Sequence Detection Software (SDS, Applied Biosystems) following manufacturer’s instructions.\nSDS is graphical user interface software designed for use by wet-lab biologists. For this protocol, each sample was analyzed individually using this software package.\nExport Ct values into a .csv file for use in the following steps.\nThe Ct values from each sample were merged into a single table with probe sets as rows and perturbed samples or matched vector controls in each column.\nPrepare gene expression data for network modeling",
    "Timing: ∼10 min\nThis step prepares the data for input to the network estimation algorithm.\nRead in gene expression measurements for each perturbation and control experiment.\nAs an example, here we read in Ct values from the crgnet experimental data R package available via github.\nif(!require(remotes)){\n  install.packages(\"remotes\")\n}\nremotes::install_github('mccallm/crgnet')\nlibrary('crgnet')\ndata(\"crgdata\")\nNormalization and missing data imputation\nTiming: ∼1 h\nSelect one or more control features to normalize the data. In this example, we use Becn1 as a control because it appears to track the lower quantile of the distribution of expression across the controls reasonably well (Figure 1[href=https://www.wicell.org#fig1]A) and has relatively low variability across the control samples compared to the other genes (Figure 1[href=https://www.wicell.org#fig1]B). This suggests that normalizing to this house-keeping gene may perform well in these data.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2051-Fig1.jpg\nFigure 1. Rationale for the use of Becn1 to normalize qPCR data\n(A) shows the cycle threshold value (Ct) distribution for all measured genes in each control sample. Each box represents an independently derived cell population transduced with an empty vector.\n(B) shows the median average deviation (MAD) versus the median Ct value for each measured gene across all control samples. The red dot denotes Becn1 in both Panel A & B.\nExamine variability in the distribution of expression across control samples. While some variability might be ascribed to the different control vectors, it is unlikely that the effect would be of this magnitude and consistency. Moreover, note that while there is substantial variability in the location of the expression distribution across the empty vector control samples, the range (e.g., IQR) remains relatively constant (except for one sample with the lowest overall expression that also had noticeably higher variability).\nictl <- which(is.na(crgdata$pGene1))\ncontrolSamples <- assay(crgdata)[ ,ictl]\nboxplot(controlSamples, xaxt=\"n\", xlab=\"Control Samples\")\nbecn1 <- controlSamples[rownames(controlSamples)==\"Becn1\",]\npoints(becn1, pch=20, col=\"red\")\nlegend(\"bottom\", pch=20, col=\"red\", \"Becn1\")",
    "The house-keeping gene, Becn1, appears to track the lower quantile of the distribution of expression across the controls reasonably well (Figure 1[href=https://www.wicell.org#fig1]A). This suggests that normalizing to this house-keeping gene may perform well in these data.\nFurther examine the suitability of Becn1 for normalization by looking at the median absolute deviation (MAD) vs median expression.\ncontrolMedians <- apply(controlSamples, 1, median)\ncontrolMADs <- apply(controlSamples, 1, mad)\nplot(x=controlMedians, y=controlMADs, pch=20, ylab=\"MAD\", xlab=\"Median\")\nind <- which(rownames(controlSamples)==\"Becn1\")\npoints(x=controlMedians[ind], y=controlMADs[ind], pch=20, col=\"red\")\ntext(x=controlMedians[ind], y=controlMADs[ind], \"Becn1\", pos=4)points(becn1, pch=20, col=\"red\")\nlegend(\"bottom\", pch=20, col=\"red\", \"Becn1\")\nBecn1 has relatively low variability across the control samples compared to the other genes (Figure 1[href=https://www.wicell.org#fig1]B).\nPerform normalization and missing data imputation.\nExamine the relationship between the proportion of non-detects (those reactions failing to produce fluorescence values above a certain threshold) and the average observed expression value in the empty vector control samples. When the plot argument is set to TRUE, the model_prep function returns a scatterplot of the proportion of non-detects versus average expression for each gene across all control samples.\ncrgprepL1 <- model_prep(crgdata, plot=TRUE)\nNote: The proportion of non-detects general increases for larger Ct values (lower gene expression). However, if this is not the case, an alternative imputation procedure, such as mean imputation, should be used. Additionally, if there are a large number of non-detects spread randomly across all measured genes, this may indicate poor sample quality.\nAdditionally, the model_prep function converts the data to the qPCRset object format needed to impute the non-detects and returns normalization factors. Specifically, the sampleType field of the sample annotation contains a unique description of each experiment: which gene(s) were perturbed and the direction of perturbation. This is used to define replicates for use in the imputation.",
    "Treat non-detects as non-random missing data and impute using the R/Bioconductor package nondetects (McCall et al., 2014[href=https://www.wicell.org#bib2]). This replaces missing values (non-detects) with an imputed values based on an estimated missing data mechanism as well as the expression values seen in replicate experiments.\nNote: Attempting to measure lowly expressed genes will result in a higher number of non-detects. As the number of non-detects increases, the imputation procedure becomes less reliable. Therefore, while there isn’t a universal threshold for the applicability of the non-detects imputation, there is a trade-off between the ability to measure lowly expressed genes and the reliability of the imputation. Often this can be addressed by increasing the number of replicates such that the number of observed values for each gene is sufficiently large.\ncrgdataImputed <- qpcrImpute(crgprepL1$object, groupVars=\"sampleType\")\nNote: This function takes a while to run.\nNormalize the data. Here, we normalize the data to the house-keeping gene, Becn1.\nlibrary(HTqPCR)\ncrgdataNorm <- normalizeCtData(crgdataImputed, deltaCt.genes=\"Becn1\")\nexprs(crgdataNorm) <- -exprs(crgdataNorm)\nIf we were normalizing to multiple control genes, we would first calculate the mean expression of the control genes then proceed as above.\nNote: After normalization, we have lost the cycle threshold (Ct) interpretation but retained the inverse relationship between expression values (on the Ct scale) and the amount of transcript in the sample. Therefore, we consider the negative ΔCt value as our measure of normalized expression.\nQuantify response to perturbations\nTiming: ∼30 min\nIn the previous sections we have dealt with non-detects (missing values) and normalized the data. We now turn out attention to assessing which genes are up- or down-regulated in response to each perturbation.\nCalculate ΔΔCt values that quantify the change in expression from controls for each perturbation.",
    "Examine whether a given perturbed sample is more similar to the control sample from the same batch then to control samples from other batches by running the check_matched_controls function. If there is a batch-effect, it is advantageous to compare each perturbed sample to the control sample from the same batch.\ncheck_matched_controls(crgdataNorm)\nIn almost all cases, the control sample from the same batch is the most similar to the perturbed sample (Figure 2[href=https://www.wicell.org#fig2]). This suggests that there is a difference between batches and motivates the calculation of paired ΔΔCt values as our measure of normalized change in expression in response to each perturbation. If there were no difference between batches, the distance from a given perturbed sample to its matched control (points in Figure 2[href=https://www.wicell.org#fig2]) would be randomly distributed within the set of pairwise differences. An eyeball test is often sufficient to assess this; however, a permutation-based statistical test could also be used. If a batch effect does not exist, then we can simply compare each perturbed sample to the average of all the control samples to compute unpaired ΔΔCt values.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2051-Fig2.jpg\nFigure 2. Matched control samples capture potential batch effects\nFor each perturbed sample (x-axis), the distribution of Euclidean distances from that the vector of Ct values for that perturbed sample to each control sample is shown. The matched control sample for each perturbed sample is highlighted in red. In general, a perturbed sample is most similar to its corresponding control sample, suggesting that matched control and perturbed samples are similarly affected by potential batch effects.\nCalculate paired ΔΔCt values by computing the difference in expression between each perturbed sample and its corresponding control sample from the same batch by running calculate_ddCt().\nddCt <- calculate_ddCt(crgdataNorm)",
    "One final check of the non-detect imputation procedure from before is to examine the distribution of residuals stratified by the presence of imputed non-detect values. These can exist in either the perturbed sample, the control sample, or both samples.\nresids <- examine_residuals(ddCt, plot=TRUE)\nHere, we see what one would expect: a median of zero and roughly equal spread when there are no non-detects, a median slightly below zero when there is a non-detect in only the perturbed sample, and a median slightly above zero when there is a non-detect in only the control sample (Figure 3[href=https://www.wicell.org#fig3]).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2051-Fig3.jpg\nFigure 3. The effect of non-detects on estimates of gene expression\nThe distribution of residuals stratified by the presence of imputed missing values (non-detects) is shown. Note that on average, a non-detect in the perturbed sample results in slightly negative residuals, while a non-detect in the control sample results in slightly positive residuals.\nCalculate approximate z-scores for each perturbation after removing any control genes. Here, we remove the control gene Becn1.\nddCt_no_ctl <- ddCt[-which(rownames(ddCt)==\"Becn1\"), ]\nzscores <- calculate_zscores(ddCt_no_ctl)\nCalculate the probability of up- / down-regulation in response to each perturbation by fitting a uniform / normal / uniform mixture model.\nprobabilities <- calculate_probs(zscores)\nFilter genes that were measured but are not perturbed in any experiment. While these genes are useful in modeling the missing data mechanism for non-detect imputation and estimating probabilities of up- / down-regulation, they will not be used in the subsequent network modeling and can be removed at this point. Here, we also filter several samples that do not represent the type of perturbation being modeled, a single perturbation back to normal expression levels.\nperts <- gsub(\":.+\",\"\",colnames(probabilities))\nind <- which(!rownames(probabilities) %in% perts)\nprobabilities <- probabilities[-ind, -c(1,9,12,13,20,23)]\n-c(1,9,12,13,20,23)\nFormat the probabilities for input to the network model fitting algorithm.",
    "networkInputData <- format_network_input(probabilities)\nOptional: Connectivity graph analysis. Either the z-scores or probabilities could be thresholded to produce a connectivity graph, in which nodes represent genes and directed edges denote that perturbation of the parent gene results in a change in expression of the child gene. Here, we create a connectivity graph based on the probabilities by thresholding the probabilities at an absolute value of 0.5. In other words, if the probability that perturbation of gene A results in a change in expression of gene B exceeds 0.5 then an edge from gene A to gene B is included in the connectivity graph.\nprobs <- networkInputData$ssObj\ncolnames(probs) <- rownames(probs)\nprobs[which(abs(probs)<0.5, arr.ind=TRUE)] <- 0\ndiag(probs) <- 0\nNext, we use the network package to create and plot the connectivity graph (Figure 4[href=https://www.wicell.org#fig4]). We also add data on tumor inhibition and direction of response.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2051-Fig4.jpg\nFigure 4. A connectivity graph showing the effect of perturbation for 20 CRGs\nArrows originating from a node denote the effect of perturbation of that node. Arrows terminating at a node represent the effect on that node, and the edge color denotes up-regulation (red) or down regulation (blue). The tumor inhibitory effect of each perturbation is encoded by the color of each node, tumor inhibitory (yellow) or not tumor inhibitory (grey).\nlibrary(network)\ncgraph <- network(t(probs), matrix.type=\"adjacency\",\n          ignore.eval=FALSE, names.eval=\"probs\")\ndata(\"tumor_inhibition\")\nset.vertex.attribute(cgraph, \"tumor_inhibition\", tumor_inhibition$TumorEffect)\nset.edge.attribute(cgraph, \"direction\", sign(get.edge.attribute(cgraph,\"probs\")))\nplot(cgraph, displaylabels=TRUE, mode=\"circle\", boxed.labels=TRUE,\n  label.bg=ifelse(get.vertex.attribute(cgraph, \"tumor_inhibition\")==\"Smaller\", \"yellow\", \"grey\"),\n  edge.col=ifelse(get.edge.attribute(cgraph, \"direction\")==1, \"red\", \"blue\"))\nlegend(\"topleft\", c(\"Tumor Inhibitory\",\n  \"Not Tumor Inhibitory\"), title=\"Node Color\",\n  fill=c(\"yellow\",\"grey\"))\nlegend(\"topright\", c(\"Up-regulation\", \"Down-regulation\"), title=\"Edge Color\",\n  col=c(\"red\",\"blue\"), lty=1, lwd=5)\nPerform network modeling\nTiming: ∼5 days\nThis step estimates the network of interactions.",
    "Network modeling. Use a ternary network model that accounts for the dynamic nature of gene regulatory networks and facilitates the evaluation of uncertainty to model a gene regulatory network. Specifically, use a parallel tempering algorithm (Swendsen and Wang, 1986[href=https://www.wicell.org#bib5]) to search the model space for networks that produce attractors that are most similar to the observed steady state data. Pseudocode for the network modeling algorithm is supplied in Methods S1[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2051-Mmc1.pdf], while a reproducible workflow of the analyses in this paper is included as the vignette of the crgnet package.\nNote: Unlike previous approaches, here we have incorporated uncertainty in the differential expression estimates via probabilities of up- / down-regulation. This allows the network model to give more weight to data points with higher certainty. Additionally, the ability to produce non-integer network scores eased transitions between network models and significantly decreased computational time.\nHere, we show example code to fit a network using 1,000,000,000 cycles in parallel across 20 processors with temperatures ranging from 0.001 to 1. These parameters should be chosen such that either the network reaches a score of zero (indicating a fit that perfectly explains the observed data) or until additional cycles do not produce a reduction in the network score. The code used to produce these network fits is shown below:\nlibrary(\"ternarynet\")\ndata(\"crgnet_scores\")\nresults <- parallelFit(experiment_set=crgnet_scores,\n            max_parents=4,\n            n_cycles=1e9,\n            n_write=10,\n            T_lo=0.001,\n            T_hi=1,\n            target_score=0,\n            n_proc=20,\n            logfile=\"tnet-fit.log\"),\n            seed=as.integer(112358)\n)\nNote: The computational time required to generate these network models is substantial: each independent network fit presented in McMurray et al. (2021)[href=https://www.wicell.org#bib3] took approximately 12 h to run in parallel on 20 compute nodes. However, less than 1 GB of RAM was sufficient to fit these network models.\nCreate network summaries and visualization\nTiming: ∼1 h (∼1 month with optional steps included)",
    "This step prepares the data for input to the network estimation algorithm.\nSummary statistics can be computed by calculating the proportion of networks in which a given feature or features are present. One can also examine the transition functions, attractors, and trajectories all stored in the fits object. One of the most common ways to visualize a network model is to present the topology. Here we calculate proportion of networks in which a given gene is a parent of another given gene.\ndata(networkInputData)\ndata(networkFits)\ntopo <- topology(fits)\nrownames(topo) <- rownames(networkInputData$ssObj)\ncolnames(topo) <- rownames(networkInputData$ssObj)\nThis information can be exported to Cytoscape or other network visualization software to create a graphical representation of these results.\nOptional: One question of interest is whether it is significant that one can obtain a low scoring network model. This can be examined by permuting the network input data. For each gene, permute its response to all of the experiments while retaining the number of experiments to which each gene responds. In other words, the number of parents in a connectivity graph remains constant but which other genes are parents’ changes. Then fit a network model to the permuted data using the same parameters as above and repeat this process to generate multiple permuted fits. Here, we load precomputed permuted fits from the crgnet package.\ndata(networkFits)\ndata(permutedNetworkFits)\nreal_scores <- sapply(fits, function(x) x$unnormalized_score)\npermuted_scores <- sapply(pfits, function(x) x$unnormalized_score)\nhist(permuted_scores, breaks=25, main=\"\",\nxlab=\"Network Scores\")\nrug(real_scores, lwd=3)",
    "The network scores based on the real data are less than nearly all the scores based on the permuted data (Figure 5[href=https://www.wicell.org#fig5]; empirical p-value ≤ 0.01). With the current network constraints, we can obtain good scores for the real data but not for the permuted data. This suggests that we are not extensively overfitting these data and that the current network constraints are reasonable.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2051-Fig5.jpg\nFigure 5. Network scores produced by real data are lower than those produced by permuted data\nFor each gene, its response to all of the experiments was permuted while retaining the number of experiments to which each gene responds. In other words, the number of parents in a connectivity graph was held constant but the identities of the parent genes were changed. A network model was then fit to the permuted data using the same parameters as used for the real data, and this process was repeated 100 times to generate multiple permuted fits. A histogram of network scores corresponding to the permuted fits is shown. Tick marks on the x-axis denote the scores produced by the real data network fits.\nOptional: To examine whether we could obtain similar fits with a simpler network model, one can vary the in-degree and compare model fits. As an example, we reran the network modeling algorithm with the max_parents reduced from 4 to 3 and also considered a more complex model by increasing the max_parents parameter to 5. We ran both models on permuted data as well as the real data.\ndata(networkFits)\ndata(networkFitsIndeg3)\ndata(networkFitsIndeg5)\nindeg4_scores <- sapply(fits, function(x) x$unnormalized_score)\nindeg3_scores <- sapply(fits3, function(x) x$unnormalized_score)\nindeg5_scores <- sapply(fits5, function(x) x$unnormalized_score)\ndata(permutedNetworkFits)\ndata(permutedNetworkFitsIndeg3)\ndata(permutedNetworkFitsIndeg5)\nindeg4_permuted_scores <- sapply(pfits, function(x) x$unnormalized_score)\nindeg3_permuted_scores <- sapply(pfits3, function(x) x$unnormalized_score)\nindeg5_permuted_scores <- sapply(pfits5, function(x) x$unnormalized_score)\nplot(x=jitter(rep(c(1:6), c(length(indeg3_scores), length(indeg3_permuted_scores), length(indeg4_scores), length(indeg4_permuted_scores), length(indeg5_scores), length(indeg5_permuted_scores)))),",
    "y=c(indeg3_scores, indeg3_permuted_scores, indeg4_scores, indeg4_permuted_scores, indeg5_scores, indeg5_permuted_scores),\n  ylab=\"Network Score\", xlab=\"\", xaxt=\"n\")\naxis(1, line=1.5, at=c(1.5,3.5,5.5), labels = c(\"In-degree 3\", \"In-degree 4\", \"In-degree 5\"), tick=FALSE, cex.axis=1.25)\naxis(1, at=c(1:6), labels = rep(c(\"Real\", \"Permuted\"), 3))\nNote: Figure 6[href=https://www.wicell.org#fig6] illustrates that increasing the in-degree cap from 3 to 4 results in a sizeable reduction in the model score; however, increasing the in-degree cap to 5 produces only a modest improvement (the in-degree 4 network models already do quite well). Regardless of the in-degree cap, better scores were achieved using the real data (as expected). The separation between real and permuted scores is greatest for an in-degree cap of 4. This lends further support to the choice of a maximum in-degree of four for these data.\nOptional: Comparison between network models generated using different in-degree thresholds. Here, we demonstrate the effect of the maximum in-degree on the resulting network topology. Note that a larger in-degree threshold will produce a network with more edges. Of primary interest is whether the high confidence edges are retained for varying in-degrees.\ndata(networkFits)\ndata(networkFitsIndeg3)\ndata(networkFitsIndeg5)\ntopo_i4 <- topology(fits)\ntopo_i3 <- topology(fits3)\ntopo_i5 <- topology(fits5)\nrownames(topo_i3) <- colnames(topo_i3) <-\n  rownames(topo_i4) <- colnames(topo_i4) <-\n  rownames(topo_i5) <- colnames(topo_i5) <- rownames(networkInputData$ssObj)\npar(mfrow=c(1,2))\nplot(x=topo_i4, y=topo_i3, pch=20,\n  xlab=\"In-degree 4 edge proportions\",\n  ylab=\"In-degree 3 edge proportions\",\n  main=paste0(\"Correlation = \", round(cor(as.vector(topo_i3), as.vector(topo_i4)), digits = 2)))\nabline(v=0.8)\nplot(x=topo_i4, y=topo_i5, pch=20,\n  xlab=\"In-degree 4 edge proportions\",\n  ylab=\"In-degree 5 edge proportions\",\n  main=paste0(\"Correlation = \", round(cor(as.vector(topo_i4), as.vector(topo_i5)), digits = 2)))\nabline(v=0.8)\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2051-Fig6.jpg\nFigure 6. The effect of different in-degree limits on network scores and the ability to distinguish between real and permuted data",
    "The network modeling algorithm was run with in-degree limits of 3, 4, and 5 on both real and permuted data. Larger in-degree limits produce generally better scores, and the real data produce better scores than the permuted data across all three in-degree limits.\nTesting tumor formation capacity of cells with two genetic perturbations based on features of the network model\nTiming: 5–6 weeks\nHere, we describe the process of measuring tumor formation in perturbed mp53/Ras cell populations and linking these measurements to features of the network model. This is done by perturbation of multiple target genes selected from among the network nodes in mp53/Ras cells. Subsequently, the perturbed cell populations are implanted into allogeneic, immune compromised mice and tumor growth is measured by monitoring tumor size over time. We perform these studies in CD-1 nude mice (Crl:CD-1-Foxn1nu, Charles River Laboratories, purchased at 6–8 weeks of age), but a number of other immune compromised mouse strains could be used (e.g., NOD/SCID animals).\nFollow steps 1 through 16 in the step-by-step method details[href=https://www.wicell.org#step-by-step-method-details] section to generate cell populations with desired perturbation of combinations of target genes selected based on network modeling results.\nTrypsinize cells following 48 h of growth at 39°C. Pellet cells, wash with 1× PBS (as in step 17 above) BUT DO NOT FREEZE.\nRe-suspend cell pellets in 500 μL of RPMI with no additives and keep on ice. Count cells with an automated cell counter or hemacytometer.\nDilute cells to 5 × 105 per 100 μL in RPMI 1640 media with no additives.\nImplant 100 μL of re-suspended cells into each flank of each experimental animal (i.e., two implantations per animal).\nAnimals should be implanted with only one type of cell population – vector control or a single gene perturbation per animal.",
    "For experiments in McMurray et al. (2021)[href=https://www.wicell.org#bib3], six implantations were done using cells from each perturbed cell population. In parallel, six implantations were done with cells from a freshly derived empty vector control population included in each experiment.\nNote: At implantation, mark or number animals in some manner (ear punch, tattoo or alternative method) to keep track of tumor growth per animal per week.\nAt 7, 14, 21 and 28 days post-implantation, measure tumor diameter by caliper at two distinct points of each tumor for each animal on both flanks independently.\nUse tumor diameter data to calculate tumor volume using the standard formula for volume of a sphere (volume=(4/3)πr3).\nExamine and quantify the association between predicted gene interactions and phenotypic outcomes (here tumor size)."
  ],
  "subjectAreas": [
    "Bioinformatics",
    "Systems Biology",
    "Cancer",
    "Cell Culture",
    "Cell Biology",
    "Genetics",
    "Molecular Biology",
    "Gene Expression"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research",
    "Molecular Biology & Genetics",
    "Bioinformatics & Computational Biology",
    "Bioengineering & Technology"
  ]
}