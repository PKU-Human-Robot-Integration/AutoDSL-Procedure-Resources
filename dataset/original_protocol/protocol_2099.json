{
  "id": 2213,
  "origin_website": "Cell",
  "title": "Protocol to decode representations from EEG data with intermixed signals using temporal signal decomposition and multivariate pattern-analysis",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nTemporal signal decomposition in RIDE\nTiming: 20 s per dataset, depending on computing power\nIn this step, we apply the RIDE algorithm to EEG data. First, we import epoched, single-trial EEG data in Matlab using the EEGLAB toolbox and prepare the data for RIDE. Second, we extract the trial-specific reaction times (RT). Third, we set the configuration for the decomposition and run RIDE. Fourth, we extract single-trial decomposed data from the RIDE toolbox output. Finally, we convert the single-trial data into a data format that can be used by the ADAM toolbox and MVPA-Light toolbox.\nNote: If preferred, open “Example code/star_protocol_RIDE.m” in Matlab to follow this section while using the deposited data. Sample datasets for this step are in the folder “Example_data/RIDE”. This folder contains input data for RIDE.\nImport EEG data. RIDE requires epoched single-subject and single-trial data as input. Each dataset should contain trials of one condition and one subject only.\nCritical: Use datasets that are free of any artifacts and are baseline corrected. All channels containing non-brain activity must be discarded beforehand.\nNote: The trials are stimulus-locked. The RIDE toolbox requires data in a 3-dimensional matrix, where the first dimension is sampling points, the second is channels, the third is trials (sample x channel x trial).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx6.jpg\nImport data in BrainVision Core Data Format 1.0 (exported from Brain Vision Analyzer using EEGLAB and EEGLAB bva-io plugin.\nPermute the data matrix into the required input format sample x channel x trial as described above.\nExtract reaction times.",
    "Note: To separate the R component related signal, a vector containing the trial-specific reaction times (RTs) in milliseconds must be passed to RIDE. The length of this vector must be equal to the size of the third dimension (i.e., trial dimension) of the EEG data matrix.\nExtract the RTs from the event information variable available in EEGLAB after importing the EEG data.\nCritical: In EEGLAB, the locking point in each trial is coded by “TLE” in the ‘EEG.event.type’ field. The script looks for the first occurrence of a response-type event representing the response (i.e., “S1” or “S2” for left or right keypress). The trial-specific RTs are computed using the number of data points between the specific TLE event and the response event.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx7.jpg\nConfigure and run RIDE. All parameters used for RIDE are passed in a struct variable ‘cfg’. See the essential parameters below. For a comprehensive list, please refer to the RIDE manual available on the RIDE website (http://cns.hkbu.edu.hk/RIDE.htm[href=http://cns.hkbu.edu.hk/RIDE.htm]).\nConfigure the parameters.\ncfg.comp.name: A cell variable specifying the components to be extracted. Decompose the signal into three components ‘S’, ‘C’ and ‘R’. ‘S’ refers to ERP component clusters that are locked to the stimulus onset and ‘R’ refers to component clusters locked to the RT. ‘C’ refers to a central component cluster not locked to either stimulus or response. For details, please refer to Ouyang et al. (2015b)[href=https://www.wicell.org#bib14].",
    "cfg.comp.twd: Ouyang et al. (2015b)[href=https://www.wicell.org#bib14] uses time window functions to optimize the decomposition of the components. For each component, a time window in ms must be specified that constrains the decomposition to the time window where the specific component is supposed to occur. The latencies of the typical event-related potentials as determined by visual inspection of the data provide a good orientation here. The S-component time window should cover ERPs associated with perceptual and attentional processes. The C-component time window should span response selection-associated potentials. The time window of the R-component covers processes directly associated with the response and is specified relative to the trial-specific RT.\nNote: Specify the time windows as used by Petruo et al. (2021)[href=https://www.wicell.org#bib15].\ncfg.comp.latency: The RIDE decomposition aims to estimate the latency of the C-component. Therefore, the C-component is specified as ‘unknown’ here. The latencies of the S-component are assumed to be 0, the latencies of the R component are given by the RTs.\ncfg.samp_interval: The temporal resolution of the data in ms, which is the temporal difference between two consecutive data points.\ncfg.epoch_twd: The time window of each trial in ms, which is the time of the first and last sample point in each trial.\nCreate the RIDE configuration by calling the function ‘RIDE_cfg’ and passing the ‘cfg’ struct variable.\nStart the decomposition by calling the function ‘RIDE_call’ and passing the ‘data’ matrix variable and the ‘cfg’ configuration variable.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx8.jpg\nExtract single-trial, decomposed component data. The output variable of RIDE_call (‘results’) contains, among others, the fields ‘s’, ‘c’, ‘r’. These represent the decomposed, latency-corrected and averaged S-, C- and R-components.",
    "Critical: For later MVPA analysis, we need data on the single-trial level, which is not part of the default RIDE output. The single-trial data can be extracted with the RIDE toolbox function ‘move3’. This function shifts every single trial 3-D data (sample x channel x trial) by a relative lag.\nSubtract the move3 transformed C and R component data from the undecomposed single-trial data (to yield the S cluster data). The output is single-trial, decomposed data.\nNote: In contrast to the averaged ‘RIDE_call’ output, we do not apply latency shift here.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx9.jpg\nSave single-trial data in EEGLAB format.\nUse the original EEGLAB ‘EEG’ variable.\nOverwrite the ‘data’ field with the specific RIDE decomposed component data.\nNote: In the following example, move the C-component data matrix back into the original EEG variable and save the EEG variable as EEGLAB .set file.\nRepeat this step also for S and R component data.\nApply a baseline correction to the data before exporting.\nThe reason for this is that the data may not be properly baseline-aligned after the RIDE decomposition. For MVPA, applying baseline correction is highly recommended. In the example, we use the EEGLAB function ‘pop_rmbase’ with a time window of -200 to 0 ms relative to the locking point.\nOptional: The ADAM toolbox also provides several preprocessing functions, including baseline correction.\nCritical: During the detection of the RTs, make sure to detect the correct response event. Depending on the type of experimental paradigm or segmentation, multiple response events may exist or response events may be missing for specific trials (e.g., if the segmentation contains hit trials but also miss trials).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx10.jpg\nMVPA in ADAM\nTiming: 30 min per dataset, depending on the computing performance",
    "In this step, we conduct a set of diagonal decoding (i.e., classification across time) and temporal generalization analyses on the decomposed EEG data by using the ADAM toolbox (Fahrenfort et al., 2018[href=https://www.wicell.org#bib4]). After the RIDE decomposition, single-trial data are available for RIDE S-, C- and R-component. In the following section, we analyze the C-component data. First, we import the RIDE-decomposed datasets into FieldTrip format. Second, we describe how to run first- and second-level analyses in ADAM. The code example below is based on examples provided by Fahrenfort et al. (2018)[href=https://www.wicell.org#bib4] and uses the same parameters as the ones deposited by Petruo et al. (2021)[href=https://www.wicell.org#bib15].\nNote: We only present an exemplary analysis of certain classes/conditions of the RIDE C-component here. Except for folder names, none of the other aspects of the following steps is specific to a given RIDE component type. Thus, the order of the different components used for MVPA is irrelevant. Similarly, if RIDE was defined with a lower (i.e., without R-component) or higher number (i.e., two C-components) of components, that should also work just as described in the current example. That is, an iteration with the R-component data can be left out or the C-component can be run twice (first with C1-component and then with C2-component).\nImport the RIDE-decomposed data.\nNote: Matlab users can open “Example code/star_protocol_concatenate.m” to follow this section while using the deposited data. Sample datasets as input for this step are in the folder “Example_data/Concatenate”.",
    "Critical: ADAM requires single-trial datasets in EEGLab or FieldTrip format as input (Fahrenfort et al., 2018[href=https://www.wicell.org#bib4]). All experimental conditions that should be analyzed using MVPA must be stored in one dataset. Since each RIDE output file contains only trials of one experimental condition, we need to concatenate the datasets first. To be able to associate each trial with its condition, we add a trial information field [1 × number of trials], coding each trial with a condition-specific numerical value. For example, the first condition is coded as 1, the second as 2, and so on. In ADAM it is possible to define classes based on several numeric codes defined in this step.\nImport the RIDE decomposed output into FieldTrip data format using the FieldTrip function ‘ft_preprocessing’.\nAppend the datasets using the function ‘ft_appenddata’.\nAdd information on the trial-class association by adding a FieldTrip ‘trialinfo’ field (dimension number of trials x 1) to the FieldTrip EEG dataset.\nThe aggregated dataset is saved as a Matlab file. Sample datasets for this step can be found in the folder “Example_data/Concatenate”.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx11.jpg\nPerform the first-level analysis. Configure the first-level analysis, i.e., single-subject level, in ADAM.\nNote: Sample data as input for the following steps can be found in the folder “Example_data/ADAM”. Matlab users can run the code star_protocol_ADAM. Check the toolbox paths in the startup file of ADAM beforehand.\nDefine the input files:\nSpecify the datasets for subjects 1–4. More subjects can be added by adding additional lines.\nNote: Exemplary datasets of N=20 subjects are available for this stage. Subject IDs are arbitrarily given between 001 and 023 during recruitment. In case of no-shows, incomplete task performance, equipment failure, etc., the ID number was skipped and not re-used.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx12.jpg\nDefine the classes.",
    "Define the relevant conditions as classes. This is essential to train a classifier to differentiate between experimental conditions based on the decomposed EEG data. In this example, we classify C-component data by differentiating between Task repetition trials in the cued block and Task repetition in the memory block:\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx13.jpg\nNote: Similarly, the cue versus memory block effect can be computed for Task repetition. The code examples below specify all the sub-conditions and their combinations. We recommend using the smallest meaningful units (conditions) in the experiment to define the classes. This can be used later for secondary analyses, sanity checks, troubleshooting, etc.\nOptional: All the class names below refer to the data type (“_stC” as single-trial C-component data). This might seem redundant since in our case, C-component, S-component, and R-component datasets were created separately for each subject. We have also kept the three component types separately when the segmented file formats were created as input files for ADAM. Therefore, it is not possible to mix up data and classes from different components. However, in this case, a redundant naming convention can be useful to easily recognize different parts of the code that would be otherwise largely indistinguishable.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx14.jpg\nConfigure the first-level analysis. Define the general configuration parameters in this step. Non-essential parameters are marked as “optional”.\nCreate an empty variable ‘cfg’.\ncfg.class_spec: Specify classes. In the example code below, we will classify the observed EEG activity as (1) belonging to a cued task repetition or (2) a memory-based task repetition.\ncfg.datadir: Specify input files location. In our example, input files were stored separately for each component type.\ncfg.filenames: Specify input file names. In this example, the input files were specified in the variable ‘filenames’ in a previous step.\ncfg.outputdir: Specify output folder for the results of the first-level analysis.",
    "cfg.model (optional): Specify the selected MVPA model.\nNote: The ‘BDM’ backward decoding model is used to predict the experiment’s condition (class) based on the neurophysiological pattern. To build the predictive model, ADAM employs Linear Discriminant Analysis (LDA) as a default setting. Another option for model selection would be the forward encoding model (FEM). From the application point of view, BDM should be used to investigate a categorical relationship between EEG data and classes, while FEM should be used in case of a continuous relationship between classes and the neurophysiological data. In the current protocol, the aim is to classify behaviors of Task repetition and Task switching by differentiating between cued and memory-induced situations. Response selection prompted by a cue or by an internal memory are discrete categories, therefore, BDM was selected. To perform FEM in ADAM, see (Fahrenfort, 2020[href=https://www.wicell.org#bib3]). BDM is the default setting in ADAM, therefore, this line is optional in the code.\ncfg.raw_or_tfr (optional): Perform classification on time-domain data (‘raw’) or on time-frequency data (‘tfr’). The default setting in ADAM is ‘raw’. If ‘tfr’ is selected, ADAM will perform a time-frequency decomposition prior to the classification using the FieldTrip toolbox. The current protocol does not cover this type of analysis, in case of interest, please refer to (Fahrenfort et al., 2018[href=https://www.wicell.org#bib4]). Of note, choosing ‘tfr’ will significantly increase the processing time required for classification.",
    "cfg.nfolds (optional): Define the number of folds. Using a value of 5, the classifier will be trained on 80% of the data, and tested on the remaining 20% of the data, iterating this process until all data points have been tested (5-fold training). The average of the consecutive test folds will be used as a final performance index. The number of folds can be increased up to the number of trials in the input file, however, it is not a common practice to use more than ten folds. The default setting is 10, that is, the classifier will be trained on 90% of the data and tested on the remaining 10% of the data. In the current protocol, a 5-fold configuration yielded good classification accuracy and stable generalization patterns. We recommend testing this parameter for every research project.\nNote: It is not possible to provide an optimal number for the different research applications. As a general recommendation, if a lower number of folds yields classification around the chance level, try to use more folds.\ncfg.class_method (optional): Select the performance metric. Here, we choose the area under the curve (AUC). AUC is the default setting in ADAM, therefore, this line can be skipped. However, since this parameter is essential for interpreting the results, we recommend keeping this line for clarity. This measure originates from signal detection theory and refers to the area under the receiver operating characteristic. That is, when cumulative true positive rates are plotted against the cumulative false-positive rates, the total area covered will determine the AUC value. AUC is the default setting in ADAM. Other included options are accuracy, d’, hit rate, and false alarm rate (Fahrenfort et al., 2018[href=https://www.wicell.org#bib4]).",
    "cfg.crossclass: Compute temporal generalization. If ‘yes’ is specified, a complete matrix will be computed between training and testing time points. If this parameter is ‘no’ (default setting), only a subset of this data will be available (i.e., when testing and training on the same time point).\nNote: It is recommended to set cfg.crossclass to ‘yes’, since this step does not increase computing time significantly, however, it provides more options for subsequent analyses (Fahrenfort et al., 2018[href=https://www.wicell.org#bib4]). In the current protocol, performing a temporal generalization analysis on RIDE decomposed data was the main goal, therefore, the whole matrix was calculated.\ncfg.channelpool (optional): Select number and types of channels. ‘ALL NOSELECTION’ selects all available channels for decoding, which is also the default setting. The number of channels will partially determine the number of features in decoding. Generally, a larger number of features can increase the success of classification. Features that contribute to the classification will receive a larger weight than features with a low contribution. However, if it is assumed that certain areas should contribute more to the model, the relevant channels can be preselected in this step, which in turn, can further boost the classification performance. In the case of task switching, there was no such hypothesis, therefore, ‘ALL NOSELECTION’ was used to allow the model a non-biased channel weighting and to keep the number of features on maximum, at least for the channels. Of note, results of the first-level analysis will be saved in a folder named after the channel selection. That is, the results of the first-level analysis will be located in a new subfolder called ‘ALL NOSELECTION’.",
    "cfg.resample (optional): Perform resampling. To reduce computation time, we down-sample the data to 55 Hz. Importantly, lowering the sampling rate inevitably leads to information loss, which might affect the accuracy of the classification. We have tested this possibility and re-calculated some of our results on 256 Hz. Since there was no observable difference between the models of 55 Hz and 256 Hz data, we have kept the 55 Hz results (Petruo et al., 2021[href=https://www.wicell.org#bib15]). For new research projects, we recommend a similar approach. Initial exploration on low-resolution data and a subsequent validation with a higher resolution can provide the optimum between computation time and classification accuracy. The default setting is ‘no’.\ncfg.erp_baseline (optional): Perform baseline correction. Here, baseline correction was applied already in a previous step. The default setting is ‘no’. To run baseline correction in ADAM, add this parameter to the provided code and specify the beginning and the end of the baseline time window in seconds. For example, a 200 ms baseline period before the stimulus presentation would be cfg.erp_baseline = [-.2, .0].\nNote: Baseline correction is a linear transformation, users can freely choose when to apply it (before or during ADAM).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx15.jpg\nPause point: Double-check the configuration.\nStart the classification by running the function ‘adam_MVPA_firstlevel’. The output i.e., results of the first-level analysis are stored in the specified output folder.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx16.jpg\nPerform the second-level analyses. First, calculate the group-level decoding performance when training and testing were performed on the same time points. This is also known as diagonal decoding. Training and testing data are separated and iterated according to the ‘cfg.nfolds’ settings in Configure and run first-level analysis. Second, perform a temporal generalization analysis, which tests the generalizability of the classifier to other time points. In secondary or group-level analyses.",
    "Note: ADAM applies t-tests across the individual datasets to compare classification performance against a reference level (Fahrenfort et al., 2018[href=https://www.wicell.org#bib4]). Classification performance was defined during the first-level analysis in ‘cfg.class_method’. Here, we use AUC, therefore, the reference is the chance level of a binary choice (AUC = 0.5). For more details about AUC and alternative performance metrics, see ‘cfg.class_method’ in the step Configure and run first-level analysis. Input files are provided in “Example_firstlevel_results_ADAM”. The related code in the depository is star_protocol_ADAM.m.\nPerform diagonal decoding.\nEvaluate the success of the decoding process by calculating AUC values on the group level. Specifically, the ‘adam_compute_group_MVPA’ function extracts the results of the first level analyses and calculate the available group statistics on them.\nDefine the input folder with the parameter ‘cfg.startdir’.\nNote: In our example, C-component results of the first-level analysis contrasting Cue and Memory block Task Repetition classes (“Example_firstlevel_results_ADAM/Task repetition”). Running the code example below opens a pop-up window that allows the selection of subfolders. Choose the folder that contains the “ALL_NOSELECTION” subfolder. The subfolder “All_NOSELECTION” was generated according to the ‘cfg.channelpool’ setting. Importantly, if the files of the first level results need to be moved, make sure that they are still located directly in a folder that is named according to the used ’cfg.channelpool’ setting. Troubleshooting[href=https://www.wicell.org#troubleshooting]: Problem 3[href=https://www.wicell.org#sec5.5]: Cannot load data in the second-level analysis of ADAM.\nSpecify the time window of the analysis in the field ‘cfg.timelim’ (optional). For the sample data, select the entire trial length, starting from the baseline period (-200 ms–1,000 ms). Time intervals have to be defined as milliseconds.\nCritical: This step is important if the input files contain larger segments than the interest of the group-level analysis. If the entire segment lengths in the input data are to be analyzed, this line can be skipped.",
    "Specify correction method for multiple comparisons. Importantly, any group-level analysis is subject to the multiple comparison problem. ADAM has two methods for controlling multiple comparisons: cluster-based permutation testing and False Discovery Rate (FDR). In the first option, significant t-tests in adjacent time points constitute a cluster that is equivalent to the sum of the individual t-values in that cluster. This process is then iterated according to the ‘cfg.iterations’ setting. After the iteration, observed cluster sizes can be compared against the null distribution of cluster sizes under random permutation, which then allows the computation of the corrected p-values. If FDR was chosen, the correction takes into account the expected proportion of false discoveries (for details, see Fahrenfort et al., 2018[href=https://www.wicell.org#bib4]). Previous MVPA studies that used RIDE-decomposed EEG data all used cluster-based permutation testing, therefore, for the example datasets, select ‘cluster_based’ in ‘cfg.mpcompcor_method’.\nNote: The selection of correction methods should depend on the consideration of the researcher. There is no known aspect of classifying RIDE data that would necessitate either cluster-based or FDR correction.\nSet the number of iterations (optional). Since the default value is also 1000, the command line of ‘cfg.iterations’ can be left out completely without changing the group-level results.\nNote: Generally, high iteration numbers lead to more accurate cluster-based p-values, however, more iterations would significantly increase computation time. Therefore, if initial explorations are needed with the parameters of the decoding analysis, iterations between 250-500 can be used to obtain an estimate of the group-level classification performance. After the parameter space has been set, the final results can be evaluated with 1,000 or more iterations. If the results show spurious clusters, the iteration number might need to be increased above 1000.",
    "Specify the time dimensions for training and testing. The parameter ‘cfg.reduce_dims’ should be used to specify our interest within the matrix of training and testing time points. In the example below, ‘diag’ limits the group-level extraction of decoding performance to the case when the classifier was trained and tested on the same points (i.e., the diagonal axis of the testing X training time points matrix). Results are saved in a structure array type of variable and named as ‘mvpa_stats’ in our example (see section expected outcomes[href=https://www.wicell.org#expected-outcomes]).\nVisualize the results with adam_plot_MVPA. This command will prompt a pop-up window in which group-level AUC values (y-axis) are depicted along with the analyzed time window (x-axis, as earlier defined in cfg.timelim) and compared with the corrected significance level. Customized plots can also be generated in ADAM (for details, see Fahrenfort et al., 2018[href=https://www.wicell.org#bib4]).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx17.jpg\nTemporal generalization.\nApply the group-level analysis to the whole matrix of testing and training time points. This method is called temporal generalization and its function is to test the generalizability of the classifier to other time points (Fahrenfort et al., 2018[href=https://www.wicell.org#bib4]; Grootswagers et al., 2016[href=https://www.wicell.org#bib6]; King and Dehaene, 2014[href=https://www.wicell.org#bib10]).\nNote: It is also possible to specify a time window and/or frequency range for training and testing data. These functions are out of the scope of the current protocol, for their description, see Fahrenfort et al. (2018)[href=https://www.wicell.org#bib4].\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx18.jpg\nAlternative: MVPA in MVPA-Light\nTiming: 30 min per dataset, depending on the computing performance",
    "The classification across time and temporal generalization analyses on the decomposed EEG data can be alternatively performed using the MVPA-Light toolbox (Treder, 2020[href=https://www.wicell.org#bib23]). MVPA Light has a larger selection and customization of classifiers and numerous options of performance metrics than ADAM. Furthermore, it includes the option of a searchlight analysis, which is useful for the source estimation of the classification results. Since this is not a feature of ADAM, we recommend MVPA Light for research questions that concern neural source localization.\nNote: Similar to ADAM, single-trial single-subject data is required for MVPA-Light. All MVPA analyses (classification across time, temporal generalization) are performed in two levels: single-subject level (level 1) and group level (level 2). In the following section, use the same example of ADAM which classifies C-component data by differentiating between task repetition trials in the cued block and task repetition trials in the memory block. The following steps include single-subject level classification across time, temporal generalization, and corresponding group-level statistics and visualization. To classify S-component and R-component data and to differentiate other conditions, please replace the dataset with the respective RIDE-decomposed dataset and follow the same steps.\nOptional: Use “Example code/star_protocol_MVPALight.m” and “Example_data/MVPALight.\nCritical: The steps 9, 10, and 11 must be performed for all subjects, which can best be done using loops.\nImport the RIDE-decomposed data. MVPA-Light uses a 3-D [trials × features × time points] array as data input, where features represent electrode channels or voxels. The trials of all classes must be concatenated in a single variable. The condition associated with a certain trial of the aggregated dataset is coded by a numeric value (1 for the first condition, 2 for the second condition) in the trialinfo field (number of trials × 1).",
    "Critical: Some classifiers (e.g., Support Vector Machine) rely on the value of these class labels (e.g., 1 as positive, -1 as negative) to evaluate the classification performance. Labels with other numerical codes rather than 1 and 2 cause distortion of classification performance.\nImport the RIDE decomposed output into FieldTrip data format using the FieldTrip function ‘ft_preprocessing’.\nAppend the datasets using the function ‘ft_appenddata’.\nAdd information on the trial-class association by adding the field ‘trialinfo’ to the FieldTrip EEG dataset.\nUse the FieldTrip function ‘ft_timelock’ with the parameter cfg.keeptrials set to ‘yes’ to permute the data to a 3-D matrix. This function can also be used to make a channel or time window selection (parameter ‘cfg.channel’ and ‘cfg.latency’).\nNote: For classification across time and temporal generalization, all-time points and all electrode channels are recommended to be included in further MVPA.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx19.jpg\nSet parameters for first-level analysis. A set of parameters need to be specified in MVPA-Light to perform first-level analysis, i.e., single-subject level analysis. These parameters determine the preprocessing steps, classification algorithms, and the expected outcome metrics. All parameters are assigned to a structure variable ‘cfg’.\nNote: We only describe a few parameters that are necessary or frequently used in the single-subject level MVPA. For further parameters and hyperparameters please refer to Treder (2020)[href=https://www.wicell.org#bib23].\ncfg.preprocess: MVPA-Light provides different pre-processing procedures to adapt datasets before training the classifiers, such as sample averaging, over-/under-sampling to balance the trial numbers of different conditions.\nNote: It is recommended to preprocess the data with undersampling or oversampling if the numbers of trials in the two conditions strongly differ.",
    "cfg.classifier: This is the most important configuration which decides the algorithm used for MVPA. MVPA-Light provided numerous classifiers with flexible customizing settings for each of them. The default classifier is ‘lda’ (linear discriminant analysis), which is especially time efficient. For noisy datasets, the more robust classifier ‘svm’ is recommended. For each classifier, its hyperparameters can also be specified in the field ‘cfg.hyperparameter’.\nNote: It is strongly recommended to try out different classifiers and hyperparameters to finally decide the proper classifier which fits the specific research goal.\ncfg.metric: Specify the measures for classification output.\nNote: ‘Accuracy’ represents the fraction correctly predicted the class in each participant. Another important one is ‘auc’ that represents the area under the curve. Notably, ‘auc’ is only used for binary classification. Other metrics such as ‘confusion’, ‘precision’ can also be used as the output. Several metrics can be included in one calculation through a configuration resembling this: ‘cfg.metric’ = {‘accuracy’, ‘auc’,’confusion’}.\ncfg.cv: Specify the type of cross-validation. Cross validation is also provided in MVPA-Light through configuring ‘cv’ and other related parameters. The parameter ‘cfg.cv’ specifies the cross-validation type which can be chosen from ’kfold’,’holdout’, and so on.",
    "Note: When cfg.cv=’kfold’, all data are split into k folds (the number of k is defined in ‘cfg.k’ with a default value of 5). In each iteration, one fold is held out and used as testing set, the rest folds are training set. This process is iterated until every fold serves as testing set for once. When cfg.cv=’holdout’, a fraction of data is held out and used as testing data and the rest are used as training data.The number of fraction is defined by setting ‘cfg.p’. Cross validation can also be repeated with new randomly assigned folds when setting ‘cfg.repeat’ and the final result is the average of all repetitions.\nRun the first-level analyses. After the parameters and class labels have been properly specified, the first-level analysis for each subject can be performed. MVPA-Light provides different analyses using the function ‘mv_classify’.\nUse the function ‘mv_acrosstime’ directly for binary classification.\nUse the function ‘mv_timextime’ for temporal generalization.\nCritical: Both functions should be applied on datasets of single subjects, thus the returned result is individual classification performance.\nNote: For the convenience of further statistical analysis, it is recommended to run this function in a loop and store all individual results in a cell array as shown in the code below.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx20.jpg\nRun the statistical analyses. Statistical analyses can be done in MVPA-Light for all MVPA tasks to evaluate the classification performance. Different statistical methods can be employed through configuration to fit the results generated from the subject-level MVPA.\nSelect a metric from the classification outcome. Here we use ‘auc’ for statistics.\nSpecify statistical methods and requirements in ‘cfg_stat.test’ and corresponding parameter settings. Statistical analyses should be done in all timepoints for binary classification and temporal generalization.",
    "Select a cluster-based permutation test to identify time points where significant classification performance occurred. For each time point, the statistic design follows the purpose of the experiment design and classification goal.\nChoose a within-subject design and compare the ‘auc’ of the group with the chance level 0.5 to evaluate the classification performance of the classifier. The following code example shows one way to statistically analyze the classification performance.\nNote: This code can be applied to both results of subject-level binary classification and temporal generalization.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx21.jpg\nPlot the results. Use the MVPA-Light’s provided built-in functions to visualize the classification performance and corresponding statistics.\nCalculate a grand average among all subjects using selected metrics.\nUse the function ‘mv_combine_results’\nSelect the proper metric via function ‘result_average’.\nSpecify parameters for plotting. The grand average classification performance can be plotted through ‘mv_plot_result’ for classification across time and temporal generalization using two parameters: the averaged results and timepoints for labeling x-axis.\nNote: If visualization of statistical results is required, another parameter ‘mask’ from the variable ‘stat_level2’ is also needed. The example of plotting the grand average classification performance and statistics for each MVPA task is shown in the following code example.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1688-Fx22.jpg"
  ],
  "subjectAreas": [
    "Bioinformatics",
    "Neuroscience",
    "Behavior",
    "Cognitive Neuroscience"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research",
    "Ecology & Environmental Biology",
    "Bioinformatics & Computational Biology"
  ]
}