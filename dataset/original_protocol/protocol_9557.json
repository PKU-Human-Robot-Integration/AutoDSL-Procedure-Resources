{
  "id": 9968,
  "origin_website": "Jove",
  "title": "4D Light-sheet Imaging of Zebrafish Cardiac Contraction",
  "procedures": [
    "Approval for this study was granted by the Institutional Animal Care and Use Committee (IACUC) of the University of Texas at Dallas, under protocol number #20-07. Tg(myl7:nucGFP) transgenic zebrafish larvae12 were used for the present study. All data acquisition and image post-processing were carried out using open-source software or platforms with research or educational licenses. The resources are available from the authors upon reasonable request.\n1. Zebrafish breeding and embryo microinjection\nTiming: 2 days\nMaintain and breed adult zebrafish through standard care and breed procedures. For detailed methods, refer to previous report13.\nPerform microinjection following established protocol14. For the present study, microinjection was performed at the 1-2 cell (zygote) stage.\n\t​NOTE: It is crucial to accurately identify this stage for effective microinjection and to ensure developmental consistency. During the one-cell stage, a small dome forms atop the yolk, and this stage typically lasts approximately 12 min. Upon progressing to the two-cell stage, two adjacent domes become visible, and this stage endures for about 45 min post-fertilization15. More detailed information of system construction can be found in other reports or protocols12,16,17. \n2. Zebrafish embryos/larvae preparation and mounting\nTiming: 7 days\nTransfer embryos at 1 day post fertilization (dpf) to E3 water with 0.2 mM 1-Phenyl-2-thiourea (PTU) (see Table of Materials) to prevent pigment formation.\nReplace the medium with fresh E3 water with PTU every day until LSM imaging.\nImage embryos or larvae with the stereo microscope to record their development at the desired timepoints between 0 and 7 dpf.\nPrepare segmented fluorinated ethylene propylene (FEP) tubes with 2 mm inner diameter for embedding zebrafish larvae under the LSM system12.\n\tNOTE: The FEP tube is utilized to secure the sample with refractive index matching materials that closely resemble the surrounding medium, such as water.",
    "Starting from 3 dpf, transfer fish to a 150 mg/L tricaine (MS-222) solution (see Table of Materials) to immobilize fish before imaging.\nPrepare 0.8 % low-melting agarose with 150 mg/L tricaine and use a transfer pipette to move anesthetized fish to the agarose once it has cooled to room temperature18.\nUse another transfer pipette to mount the fish with agarose in FEP tubes (Figure 1).\n\tNOTE: To ascertain the minimal stress in the developing embryos, pre- and post-fixation examinations of cardiac activity, such as heart rate, were conducted under microscopic observation. These assessments aimed to identify any significant differences before and after tricaine anesthesia. An additional examination of the skin and musculature for irregularities in cardiac structure, such as edema, could also be conducted post-fixation. The concentration of tricaine also plays a crucial role in cardiac imaging19, and therefore the 150 mg/L concentration tricaine solution was utilized for the imaging of contraction in zebrafish larvae in this project. While the present retrospective synchronization allows us to address the irregular heartbeats20, a comprehensive solution for the 4D imaging of cardiac arrhythmias and long-term imaging in zebrafish is still under development.\n3. Light-sheet imaging system setup and configuration\nTiming: 3-14 days\nConstruct an in-house LSM system based on a cylindrical lens using continuous-wave diode-pumped solid-state (DPSS) laser systems at specific wavelengths such as 473 nm and 532 nm as illumination sources (Figure 2A).\nCustomize LabVIEW (see Table of Materials) control codes for the synchronization of translational sample stage, light-sheet illumination, and exposure of sCMOS camera to capture image sequences.\n\t​NOTE: More detailed information of system construction can be found in other reports or protocols12,16,17. We encourage research groups to seek collaborative opportunities with laboratories that possess established expertise in optical imaging during system construction.\n4. Zebrafish imaging preparation and data collection",
    "Timing: 1 day\nCalibrate LSM system spatial resolution and minimize opacity variation at varying depths by measuring fluorescence beads.\n\t\nFirst, dilute fluorescent beads (see Table of Materials) having the diameter of 0.53 µm to a concentration of 1: 1.5 x 105 using 0.8 % low-melting agarose and transfer the solution to the segmented FEP tube.\nSecond, use the LSM system to image the beads and measure the point spread function (PSF) across the entire sample, validating the spatial resolution and system alignment12.\n\t\tNOTE: In this system, the analysis of representative results for the full width at half maximum (FWHM) indicates lateral and axial resolutions of 1.26 ± 0.15 and 2.48 ± 0.15 µm (n = 60 beads), respectively. This suggests a consistent spatial resolution throughout the imaging depth.\nAttach the FEP tube with mounted zebrafish larva securely to the 6-axis (x, y, z, pitch, yaw, and roll) motorized sample stage, and submerge the tubes into the sample chamber filled with E3 water. To avoid the light scattering by the yolk sac and better locate the position of the heart, rotate the zebrafish larva to take image from the ventral side (Figure 2B). In this case, most captured images would include both the ventricle and atrium (Figure 2C).\n\tNOTE: Given that the current imaging procedures typically lasted less than one hour per fish and were conducted in a controlled room temperature environment, the chamber temperature control and oxygen level regulation are deemed optional for this project. However, for longer-term time-lapse imaging studies, particularly those focused on developmental processes, continuous temperature monitoring and regulation at 27 °C within the sample chamber is suggested to ensure the physiological environment of the zebrafish and to prevent any potential developmental abnormalities.",
    "Connect the motorized sample stage to the workstation and configure all necessary parameters, including the desired moving mode.\nEstablish a connection between the sCMOS camera and the workstation. Adjust all essential settings, such as an exposure time of 5 ms and the desired region of interest.\nConfigure the number of image sequences and frames within the customized LabVIEW control program.\nPower on the laser and initiate LSM imaging of the sample. Maintain the process until all image sequences have been successfully recorded.\nRecord 300 frames as a 2D image sequence to cover 3-5 cardiac cycles of the larva with a framerate of 200 frames/second. The recording captures cardiac contractility at the selective plane illuminated by the light-sheet.\nMove the larva at the step size of 1 µm across the light-sheet illumination to virtually slice the sample.\n\tNOTE: The step size of the sample stage should be set based on the axial resolution of the light-sheet system, following the Nyquist-Shannon sampling theorem12.\nRepeat step 7 to record another image sequence of the new sample slice until the whole heart is covered. Generally, 100-200 image sequences with the step size of 1 µm ensure the coverage of the entire heart of a zebrafish larva (Figure 2D).\n\t​NOTE: Step 4.7-4.9 are controlled by the LabVIEW program and automatically performed by the LSM system (Figure 3). Given the extensive volume of image data generated, a standardized naming convention is recommended for image sequences. For example, designate folders with names such as \"z-1\", \"z-2\", etc., to categorize data across various image sequences. Within each sequence, the images should be named sequentially (e.g., \"1\", \"2\", ...) to denote distinct time points. The total time for mounting fish, adjusting the imaging angle, and collecting all the data for one zebrafish larva is around 1 h.",
    "5. 4D image reconstruction with parallel computation\nTiming: 1 day\nNOTE: The 4D reconstruction algorithm developed by our group and sample data are publicly accessible21. This method allows one to reconstruct the 4D heart image from the image sequences collected in previous steps (Table 1).\nOpen the file test_Parallel.m in MATLAB (see Table of Materials). Specify the folder location where the raw image sequences are stored in the variable \"baseDir\".\nAssign the variable \"numOfSlice\" with the total number of image sequences (typically 100-150) and the variable \"numOfImage\" with the number of images (typically 300-500) in each sequence.\nInspect the image sequence that shows the middle plane of the zebrafish heart (for example, the 51st sequence out of 101 total sequences). Identify the frame numbers of the first and fourth systoles in this sequence and assign them to the variables systolicPoint_1st and systolicPoint_4th.\nClick on Run to start the process.\n\tNOTE: The length of the cardiac cycle in each image sequence will first be identified by the MATLAB program through a comparison of the similarity (sum of squared differences) between images at different time points. Subsequently, the cardiac cycle will be estimated using the average of the cycle lengths from all image sequences. Next, the starting points of image sequences at different axial locations will be aligned by the program through an iterative comparison of the image similarity from the first image sequence to the last image sequence.\nCheck the results in the output folder. The program will save the images as \".tif\" files with time stamps. Each \".tif\" file is a 3D heart image at a specific time point. The time interval between two 3D images is equal to the exposure time that is set.",
    "​NOTE: Reconstruct the acquired images from the previous steps to depict the 4D (3D spatial + 1D temporal) cardiac contractions. To enhance proficiency in high-throughput investigations during the retrospective synchronization, this approach enables simultaneous computational operations on a GPU by leveraging multiple CPU cores through the MATLAB parallel computing toolbox and transforming images into the gpuArray format.\n6. 3D cell segmentation and cell tracking\nTiming: 1 day\nDownload 3DeeCellTracker package (see Table of Materials) and set up the Python environment22.\nDownload ITK-SNAP annotation software23 (see Table of Materials) and use it to manually label the 3D heart image in two selected timepoints, one at the ventricular diastole and the other at the ventricular systole, to create the training and validation datasets.\n\tNOTE: Other labeling software may also be applicable.\nIn Python, run the 3DeeCellTracker training program and initialize the noise_level(100 in this case), folder_path and model parameters in TrainingUNet3D function to set the predefined 3D U-Net model.\nIn MATLAB, use imageDimConverter.m program to convert and rename the training and validation dataset to the proper format for loading.\nIn Python, load the training and validation datasets by using trainer.load_dataset() and trainer.draw_dataset() functions.\nIn Python, run the first part of 3DeeCellTracker tracking program and initialize the parameters.\n\tNOTE: This includes defining image parameters to characterize image dimensions, segmentation parameters to select the machine learning model applied for cell segmentation, and tracking parameters to select the pre-trained deep neural network models employed for cell registration. For the first time use, employing the U-Net model for cell segmentation and FFN+ PR-GLS for cell registration is recommended. It is needed to store data, model, and results in folders that will be automatically created in this step.",
    "In MATLAB, use imageDimConverter.m program to convert and rename all the 3D heart images to the proper format and transfer them to the data folder created in the last step.\nIn Python, run the second part of 3DeeCellTracker program to start segmentation.\nOnce the first 3D image is segmented, compare the segmentation result with the raw image, and perform manual correction if any incorrect segmentation is found. Move the corrected segmentation to the created \"/manual_vol1\" folder.\nIn Python, run the third part of 3DeeCellTracker program to segment all the images.\nUse Amira (see Table of Materials) to perform a visual assessment of tracking outcomes by comparing the positions of tracked cells with their corresponding raw images. If test results are not satisfying, recommence the procedure from step 6.6, employ an alternative machine learning model for segmentation or cell registration, and then re-initiate the tracking process.\n\t​NOTE: After the segmentation, the data of cell labels is stored as an 8-bit image (0 to 255) by default, which means only 256 scales are provided as labels for cell classification. There are two solutions for addressing this issue when additional classes are needed. One solution is to set the format of data of cell labels as a 16-bit image in the tracking program, which will cause an exponential increase in the processing time, more than two days in the present case. The other solution is to use the \"separateTrackingResults.py\" program to post-process the cell labels, which will separate cells with the same labels based on their physical location and assign each cell a different label. This process takes around 10 min in this case.\n7. Cardiac contractility analysis in the virtual reality mode\nTiming: 1 day\nAcquire the cell tracking outcome from previous steps.",
    "Manually validate the data and select cells with consistent image intensity across all volumes (about 500 cells out of approximately 600).\nUse cellLabelsToObj.ipynb script21 to generate a surface mesh for each individual cell through 3D Slicer software24 (see Table of Materials) and assign a unique color code to each cell.\nExport each 3D model, consisting of all cells in a single time point, as a single .obj file consisting of multiple sub-objects accompanied by a .mtl file to describe the cell label.\nImport the models into Unity using the educational license, a development engine used for extended reality.\nApply the customized scripts consisting of functions written in C# to the models and user-interface elements to allow for 4D visualization and interactive analysis. Perform VR interaction following step 7.7.\nInteract with the models in virtual reality (VR) using the following functions (Figure 4):\n\t\nCell selection: Select up to two cells at a time and view their trajectories, velocities, volumes, surface areas, and relative distances.\nTime point selection: Choose a specific time point in the data to analyze the outputs of the selected cells, such as at t = 0 ms during diastole, or at t = 200 ms during systole.\nTime pause: Freeze the dynamic model to focus on the selected cells and their outputs.\nContrast: Modulate the contrast between the selected cells and surrounding cells in the model.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Bioengineering"
  ],
  "bigAreas": [
    "Bioengineering & Technology"
  ]
}