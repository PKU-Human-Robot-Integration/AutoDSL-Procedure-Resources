{
  "id": 11810,
  "origin_website": "Jove",
  "title": "Measuring the Kinematics of Daily Living Movements with Motion Capture Systems in Virtual Reality",
  "procedures": [
    "All experimental procedures described here were approved by the Institutional Review Board of Hanyang University, according to the Declaration of Helsinki (HYI-15-029-2). 6 healthy controls (4 males and 2 females) and 6 MCI patients (3 males and 3 females) were recruited from a tertiary medical center, Hanyang University Hospital.\n1. Recruit Participants\nRecruit MCI patients (i.e., impaired IADL capabilities) and healthy controls (i.e., normal IADL capabilities) aged between 70 - 80 years.\nWith the help of a neurologist with more than 10 years of clinical experience, review the patients' medical histories, and exclude patients with a history of neurological/psychiatric diseases or brain surgery.\n\tNOTE: Use the following neuropsychological tests: Mini Mental State Examination-Dementia Screening, Korean Instrumental Activities of Daily Living, Free and Cued Selective Reminding Test, Digit Span Test-Forward/Backward, Trail Making Test-A/B13, and the criteria of Albert et al.14 to diagnose MCI.\n2. Install VR Software and Connect Computers\nSetup the hardware in the dedicated room similar to Figure 1. Perform this protocol in a room-sized immersive virtual environment (4 x 2.5 x 2.5 m3) containing 4 computers, 4 stereoscopic three-dimensional (3D) projectors, and 8 motion tracking cameras to track the position and orientation of the dominant hand and head during the two IADL tasks.\n\tNOTE: The VR technologies used in this article are computer hardware and software that offer immersive and interactive 3D experiences, by which realistic objects and events can be presented in a virtual environment. The details of the hardware and software are described in the Materials Table.\nEnsure all the computers are equipped with the required software (Visual Studio 2012 redistributable package (x86), DirectX, and MiddleVR, or equivalent). For MiddleVR, i.e., middleware software, check the website15 to obtain the latest versions of the libraries for the input devices, stereoscopy, clustering, and interactions.",
    "Connect computers to stereoscopic 3D projectors. Graphical settings are 1920 x 1080 pixel resolution.\nCreate a Windows 10 HomeGroup to connect the 4 computers to a home network. On the primary computer, create a folder and share it with other HomeGroup computers.\nOn the primary computer, initiate the middleware software. Click \"Cluster\" button. Set the primary computer as a server and other computers as clients. This will synchronize the state of all devices. Click \"3D Nodes\" button. Specify the position, orientation, and size of the virtual environment screen.\nComplete the settings based on the website15 and save the configuration file.\n3. Set Up Motion Capture Systems in a Virtual Environment\nMount 8 motion tracking cameras in a virtual environment to fully cover the capture volume. Fix cameras securely so that they remain stationary during capture. Ensure objects in a virtual environment will be visible by at least 2 cameras at all times.\nInstall OptiTrack Motive software, i.e., motion capture software, on the primary computer using the installation manual16. Connect the primary computer with the motion capture systems with Category 6 Ethernet cables.\nCalibrate the motion capture systems with the following steps, as detailed in the software manual16.\n\t\nRemove all extraneous reflections or unnecessary markers from the capture volume.\nClick the \"Mask Visible\" button to mask unwanted reflections or ambient interference.\nClick the \"Start Wanding\" button. Use the calibration wand to support the capture of sample frames in order to compute respective positions and orientations in 3D space.\nClick the \"Calculate\" button to calibrate the system using collected samples.\nCheck the calibration results (in order from worst to best): Poor, Fair, Good, Great, Excellent, and Exceptional. If the result is better than Great, click the \"Apply\" button. If not, click the \"Cancel\" button and repeat the wanding process.",
    "Place the calibration square inside the 3D space where you want the origin to be located. Click \"Set Ground Plane\" button to establish a tracked 3D coordinate system origin.\nSelect associated reflective markers for the dominant hand and head. Click the \"Rigid Body\" button and then click the \"Create From Selected Markers\" button.\nOn the motion capture software, open the \"Streaming\" menu. Verify that the port number listed is 3883, and select the \"Broadcast frame data\" box in the \"VRPN Streaming Engine\" category. Click \"Ctrl\" + \"S\" to save the calibration file.\nOn the primary computer, initiate the middleware software. Click the \"Devices\" button. Add a VRPN Tracker to obtain tracking data from the motion capture system, and then save the configuration file.\n4. Prepare a Virtual Environment for Use\nRemove all reflective objects (i.e., watches, rings, earrings, metals, etc.) from the virtual environment.\nTurn on computers, stereoscopic 3D projectors, and motion capture systems (360 frames per second).\nOnce 4 computers are running, launch the VRDaemon software. For example, double click on \"VRDaemon.exe\" which located in \"C:\\Program Files (x86)\\MiddleVR\\bin.\"\nOn the primary computer, initiate the motion capture software. Click the button near the top menu labeled \"Open Existing Project.\" Load the camera calibration file.\nOn the primary computer, initiate the middleware software. Click the \"Simulations\" button. Load the appropriate simulation and configuration files from a shared folder.\nOn the middleware software, press the \"Run\" button to execute an immersive virtual application with the selected simulation and configuration files.\n5. Familiarize the Participant with the Virtual Environment\nProvide the participant with stereoscopic glasses weighing around 50 g. The display frequency of the stereoscopic glasses is 192 Hz. Ensure that the stereoscopic glasses are comfortably placed over the eyes and ears; see Figure 2A.",
    "Attach reflective markers weighing less than 1 g to the participant's dominant hand and head. Be careful to attach the reflective markers tightly; see Figure 2B. Inform the participant that they can freely move or rotate in the virtual environment using head movement and can click virtual objects with the dominant hand. A virtual hand appears in the virtual environment to mimic the position of the participant's index finger; see Figure 3.\nAsk the participant to freely move (i.e., stand up, sit down, go left, and go right) in the virtual environment for 5 min to familiarize themselves with the VR environment. Then ask the participant to click virtual buttons for 5 min in order to become familiar with how to interact with virtual objects with the dominant hand. Provide another 10 min training session if the participant asks for one.\nCheck whether the participant is immune to VR sickness with a simulator sickness questionnaire17.\n\tCAUTION: The synchronized motion tracking on the stereoscopic display can cause VR sickness, which can result in discomfort, headache, stomach awareness, nausea, vomiting, pallor, sweating, fatigue, drowsiness, disorientation, and apathy. If the participant complains of fatigue or the simulator sickness score is too high, stop the protocol.\n6. Perform \"Task 1: Withdraw money\"\nCAUTION: Counterbalance the sequences of Task 1 and Task 2 to remove the carry-over effect.\nExplain to the participant the details of the task and provide the 8 action steps to complete the task in the virtual environment. The steps are (1) insert the card into the ATM, (2) select the 'withdraw' menu, (3) select the amount to withdraw, (4) select the bill type, (5) enter the PIN (personal identification number), (6) select the receipt option, (7) remove the card, and (8) take the money from the ATM (see Figure 4).",
    "On the primary computer, initiate the middleware software. On the \"Simulations\" tab, select a simulation file for Task 1 and a configuration file. Press the \"Run\" button; \"Task 1: Withdraw money\" will run in the virtual environment.\n\tNOTE: For the Task 1 file, see the attached \"Task 1 Withdraw Money.zip\" file in Supplemental File 1. Note that the virtual task was developed with the Unity 3D engine.\nIf the \"Task 1: Withdraw money\" runs in the virtual environment, instruct the participant to perform as follows: \"Please withdraw 70,000 KRW (equivalent to around 60 USD) from the ATM for shopping. Select two different types of notes, one 50,000 KRW note for 50,000 KRW and two 10,000 KRW notes for 20,000 KRW. The password for your transaction is today's date. For instance, if the experiment is carried out on the 11th of November, then the PIN is 1111. Please keep the receipt for further reference.\"\nOnce the task is finished, check the saved kinematic data in CSV files (comma-separated values) for further analysis from a shared folder.\n\tNOTE: Using the motion capture systems, during \"Task 1: Withdraw money\" record the position and orientation of the dominant hand when conducting a task with a recording frequency of 1 ms.\nGive about 5 min break to the participant before starting \"Task 2: Take a bus.\"\n7. Perform \"Task 2: Take a bus\"",
    "Explain to the participant the details of the task and provide instructions on how to complete \"Task 2: Take a bus\" as follows: \"Please wait at the bus stop and take the target bus. The target bus information will be given on the VR screen by a specific line number, color, and destination. When the target bus arrives, be sure to walk out of the bus stop and to the front door of the target bus. 8 different target buses will be randomly generated and presented.\" See Figure 5.\nOn the primary computer, initiate the middleware software. On the \"Simulations\" tab, select a simulation file for Task 2 and a configuration file. Press the \"Run\" button, then \"Task 2: Take a bus\" will run in the virtual environment.\n\tNOTE: For the Task 2 file, see the attached \"Task 2 Take a Bus.zip\" file in Supplemental File 2. Note that the virtual task was developed with the Unity 3D engine.\nIf the \"Task 2: Take a bus\" runs in the virtual environment, instruct the participant to wait in the bus stop. Click the \"Spacebar\" key on the keyboard to make buses arrive at the bus stop.\nOnce the task is finished, check the saved kinematic data in CSV files for further analysis from a shared folder.\n\tNOTE: Using the motion capture systems, during \"Task 2: Take a bus\" record the position and orientation of the head when conducting the task with a recording frequency of 1 ms.\nThe protocol is complete. Help the participant remove the stereoscopic glasses and detach the reflective markers from the dominant hand and head.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}