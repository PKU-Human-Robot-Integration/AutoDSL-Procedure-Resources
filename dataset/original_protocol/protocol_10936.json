{
  "id": 11494,
  "origin_website": "Jove",
  "title": "Using the Visual World Paradigm to Study Sentence Comprehension in Mandarin-Speaking Children with Autism",
  "procedures": [
    "This study has been approved by the Ethics Committee of the School of Medicine at Tsinghua University. Informed consent has been obtained from all individual participants included in the study.\n1. Participant Screening and Study Preparation\nRecruit Mandarin-speaking preschool children with autism.\n\tNOTE: Their diagnoses should be confirmed by pediatric neurologists at hospitals using DSM-IV-TR40 or DSM-541 and, ideally, the number of participants should be no less than 15. The present study recruited 25 participants with confirmed diagnoses.\nEvaluate each participant independently using gold-standard diagnostic instruments like the Autism Diagnostic Observation Schedule42.\nMeasure the verbal IQ of participants using the Wechsler Preschool and Primary Scale of Intelligence-IV (CN), a standardized IQ test designed for Mandarin-speaking children between the ages of 2-6 and 6-1143.\n\tNOTE: The verbal IQ scores of the children with autism in the present study were all above 80. They were all high-functioning children with autism.\nCalculate each participant's mean length of utterance (MLU) by dividing the total number of words by the number of utterances in each speech sample. Record 100 utterances for each participant from either their interactions with parents or with teachers. Then, calculate the MLU by dividing the total number of words in each participant's utterances by 100.\n\tNOTE: MLU indicates the participant's sentence complexity levels.\nRecruit TD children. Ideally match the TD children to the children with autism for age (TD group 1), MLU (TD group 2), and verbal IQ (TD group 3).\n\tNOTE: The present study recruited 50 TD children (25 boys and 25 girls) from local kindergartens. 25 matched to the children with autism for age and 25 matched to the children with autism for both MLU and verbal IQ.\n2. Warm-up Session",
    "Invite the participants for a warm-up session before the actual test. Introduce the participant to the research environment and interact with him or her to establish a good rapport.\n\tNOTE: This can be done on the same day as the testing session or organized on a different day. In the warm-up session, two experimenters are typically involved and interact with the participant using toys and props.\n3. Conditions and Experimental Design\nConstruct the test stimuli. Create 12 target items, each comprised of a visual stimulus, and two spoken sentences containing the morphological markers BA and BEI, respectively. Construct the spoken sentences using the same structure: morphological marker + noun phrase (NP) + adverb + verb phrase (VP) (see Examples 1a and 1b below).\n\tNOTE: The marker BA indicates that the following NP is the recipient of the holding event (see 2a), and BEI indicates that the following NP is the initiator of the event (see 2b). The subject NP of a sentence in Mandarin can often be omitted when the referent of the NP is contextually available.\nExample:\n\t(1) a. BA shizi qingqingdi bao-le      qilai.\n\t         BA  lion   gently       hold         up\n\t         Meaning: Someone gently holds the lion.\n\t     b. BEI shizi qingqingdi bao-le      qilai.\n\t         BEI lion   gently       hold          up\n\t         Meaning: Someone is gently held by the lion.\n\t(2) a. BA + [NP]Recipient\n\t     b. BEI + [NP]Initiator\nUse Pixelmator (or another image editor) to create visual images. Open Pixelmator. Click on the Pixelmator icon. Create a visual image from a template. Click Show Details in the template chooser. Double-click the template to open it. Adjust the width, height, resolution, and color depth from the pop-up menus. Enter the relevant parameters. Click OK.",
    "Use Praat (or another audio editor) to construct spoken sentences. Set up the microphone. Open Praat. Click on the Praat icon. Select Record Mono sound from the New menu. Set the recording conditions by clicking the sample rate option of 44100. Click the Record button.\nRecord the spoken sentences by asking a native Beijing Mandarin-speaker to produce the sentences in a child-directed manner. Save the recordings by clicking Save.\n\t\tNOTE: Typically, 12 to 16 target items are constructed for sentence comprehension studies with children. Test stimuli can be created using other image and audio editors for a visual world study.\nConstruct visual images, each containing two pictures. The two pictures depict the same event involving the same characters. Reverse the event roles (initiator or recipient) of the two characters in the two pictures. Make one picture compatible with the construction containing BA (BA-target event) and one with the construction containing BEI (BEI-target event). An example is provided in Figure 1.\n\tNOTE: This figure has been reprinted with permission from Zhou and Ma (2018)19.\nCounterbalance and randomization: divide the target trials into two experimental lists, with a participant seeing each visual stimulus but listening to only one of the recorded sentences for the stimulus. Counterbalance the spoken sentences containing BA and BEI across the two experimental lists, with 6 constructions containing BA and 6 containing BEI. Add 12 filler items to each experimental list and arrange the target and filler trials in a random order. Randomly assign the participants to the two lists.\n4. Experimental Procedure\nEye-tracking procedure.",
    "Invite the participants to sit comfortably in front of the display monitor of the remote eye tracker. Set the distance between the participants' eyes and the monitor around 60 cm. Perform the standard calibration and validation procedures by asking the participants to fixate on a grid of five fixation targets in random succession.\nPresent the participants with a spoken sentence while they are seeing a visual image, as done in the standard visual world paradigm10,44. Use the monocular eye-tracking option by tracking the eye that is on the same side as the illuminator of the eye tracker. Record the participant's eye movements using the eye tracker.\n\t\tNOTE: The eye tracker used in the present study allows remote eye-tracking with a sampling rate of 500 Hz.\nTesting and measuring.\n\t\nTest the participants individually. Simply tell the participants to listen to the spoken sentences while they are viewing the pictures. Ask one experimenter to monitor the participant on the computer and one to stand behind the participant and gently rest her hands on the participant's shoulders to minimize the participant's sudden movements.\nMeasure the participant's eye movements that arise as automatic responses to the linguistic input using the eye tracker.\n\t\tNOTE: The task does not ask participants to make any conscious judgments about the spoken sentences to minimize their computational burden. The eye tracker automatically records the eye movements.\nMonitoring during the test: use the live viewer mode on the computer screen, exhibited by the eye tracker during the test, to observe the participant's looking behavior. Ask the experimenter who monitors data collection via the live viewer mode to signal to the experimenter who stands behind the participant to reorient the participant if his or her eye gaze wanders off the computer screen.\n5. Data Treatment and Analysis",
    "Code the participants' fixations in two interest areas. Use Data Viewer to draw the two interest areas: BA-target event area and BEI-target event area (see Figure 1). Open Data Viewer. Select one of the interest area shape icons on the tool bar. Use the mouse to drag a box around the region you want to define as an interest area. Save the interest area in the Interest Area Set folder. Apply the interest area to other visual images.\n\tNOTE: The depicted event in the upper panel of Figure 1 matches the BA-construction, hence the BA-target event, and the event depicted in the lower panel matches Figure 1b, hence the BEI-target event. The software used for data coding is Data Viewer, which comes with the eye tracker used in the study. Other data analysis software is also available.\nAnalyze the eye gaze patterns using Data Viewer.\n\t\nOpen Data Viewer. Choose the sample report function from the menu to set the time windows for analysis (e.g., every 200 ms for the time window in the present study). Use the same function to time lock the fixation proportions in the interest areas to the onset of the marker for each trial. Export the raw data into an excel file using the export function from the menu.\nUse the excel functions to average the fixation proportions following the onset of the marker for each area. Use the excel functions to compute the fixation proportions in each time window of 200 ms over a period of 5200 ms (the mean length of the target sentences + 200 ms) from the onset of the marker for the two areas. Apply linear mixed-effects models to the eye movement data, detailed in Representative Results below.",
    "NOTE: The use of 200 ms as a time window is based on the standard procedure for analyzing child eye gaze data in the literature12,13,18,19,45,46,47, and it is generally assumed that it takes about 200 ms to observe the effects of linguistic markers on eye movements48.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}