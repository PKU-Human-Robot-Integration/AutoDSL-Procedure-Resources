{
  "id": 10549,
  "origin_website": "Jove",
  "title": "Automated Rat Single-Pellet Reaching with 3-Dimensional Reconstruction of Paw and Digit Trajectories",
  "procedures": [
    "All methods involving animal use described here have been approved by the Institutional Animal Care and Use Committee (IACUC) of the University of Michigan.\n1. Setting up the reaching chamber\nNOTE: See Ellens et al.14 for details and diagrams of the apparatus. Part numbers refer to Figure 1.\nBond clear polycarbonate panels with acrylic cement to build the reaching chamber (15 cm wide by 40 cm long by 40 cm tall) (part #1). One side panel (part #2) has a hinged door (18 cm wide by 15 cm tall) with a lock. If the rat will be tethered to a cable, cut a slit (5 cm wide by 36 cm long) into the chamber ceiling to accommodate it (part #12). The floor panel has 18 holes (1.75 cm diameter) (part #13) cut into it and is not bonded to the rest of the chamber.\nMount and align infrared sensors (part #3) in the side panels 4.5 cm from the back of the chamber and 3.8 cm from the floor. The behavioral software has an indicator (‘IR Back’) that is green when the infrared beam is unbroken and red when the beam is broken. Once the software is set up, this can be used to check sensor alignment.\nMount a mirror (15 cm x 5 cm, part #4) 10 cm above the reaching slot (part #14). Angle the mirror so the pellet delivery rod is visible to the camera.",
    "Place the chamber on a sanitizable support box (59 cm wide by 67.3 cm long by 30.5 cm tall, part #5). The chamber rests above a hole in the support box (12 cm wide by 25 cm long) that allows litter to fall through the floor holes (part #13) and out of the reaching chamber. Cut a second hole (7 cm wide by 6 cm long, part #15) into the support box in front of the reaching slot, which allows a pellet delivery rod to bring pellets to the reaching slot.\nMount two mirrors (8.5 cm wide x 18.5 cm tall, part #6) to the floor with magnets on either side of the chamber so that the long edge of the mirror is touching the side panel 3 cm from the front of the reaching box. Angle the mirrors so that the camera can see into the box and the area in front of the reaching slot where the pellet will be delivered.\nMount the high-definition camera (part #7) 17 cm from the reaching slot, facing the box.\nMount black paper (part #18) on either side of the camera so the background in the side mirrors is dark. This enhances contrast to improve real-time and off-line paw detection.\nMount the linear actuator (part #16) on a sanitizable frame (25 cm wide by 55 cm long by 24 cm tall, part #8) with screws. The actuator is mounted upside down to prevent pellet dust from accumulating inside its position-sensing potentiometer.",
    "Insert a foam O-ring into the neck of the pellet reservoir (funnel) (part #9) to prevent dust from accumulating in the assembly. Mount the funnel below a hole (~6 cm diameter, part #17) in the top of the frame by slipping the edges of the funnel above three screws drilled into the underside of the frame top. Insert the guide tube (part #10) into the neck of the funnel.\nAttach the plastic T connector to the end of the steel rod of the actuator. Insert the tapered end of the pellet delivery rod into the top of the connector and the cupped end through the guide tube into the pellet reservoir.\nPlace the linear actuator assembly under the skilled reaching chamber so that the pellet delivery rod can extend through the hole (part #15) in front of the reaching slot.\nPlace the entire reaching apparatus in a wheeled cabinet (121 cm x 119 cm x 50 cm) ventilated with computer fans (the interior gets warm when well-lit) and lined with acoustic foam.\nBuild five light panels (part #11) by adhering LED light strips on 20.3 cm by 25.4 cm support panels. Mount diffuser film over the light strips. Mount one light panel on the ceiling over the pellet delivery rod area. Mount the other four on the sides of the cabinets along the reaching chamber.\n\tNOTE: It is important to illuminate the area around the reaching slot and pellet delivery rod for real-time paw identification.\n2. Setting up the computer and hardware\nInstall the FPGA frame grabber and digital extension cards per the manufacturer’s instructions (see the Table of Materials).\n\tNOTE: We recommend at least 16 GB of RAM and an internal solid-state hard drive for data storage, as streaming the high-speed video requires significant buffering capacity.",
    "Install drivers for the high-definition camera and connect it to the FPGA framegrabber. The behavioral software must be running and interfacing with the camera to use the software associated with the camera.\n\tNOTE: The included code (see supplementary files) accesses programmable registers in the camera and may not be compatible with other brands. We recommend recording at least at 300 frames per second (fps); at 150 fps we found that key changes in paw posture were often missed.\nCopy the included code (project) in “SR Automation_dig_ext_card_64bit” to the computer.\n3. Behavioral training\nPrepare rats prior to training.\n\t\nHouse Long-Evans rats (male or female, ages 10–20 weeks) in groups of 2–3 per cage on a reverse light/dark cycle. Three days before training, place rats on food restriction to maintain body weight 10–20% below baseline.\nHandle rats for several minutes per day for at least 5 days. After handling, place 4–5 sugar pellets per rat in each home cage to introduce the novel food.\nHabituate the rat to the reaching chamber (1–3 days)\n\t\nTurn on the LED lights and place 3 sugar pellets in the front and back of the chamber.\nPlace the rat in the chamber and allow the rat to explore for 15 min. Monitor if it eats the pellets. Repeat this phase until the rat eats all of the pellets off of the floor.\nClean the chamber with ethanol between rats.\n\t\tNOTE: Perform training and testing during the dark phase. Train rats at the same time daily.\nTrain the rat to reach and observe paw preference (1–3 days).\n\t\nTurn on the lights and place the rat in the skilled reaching chamber.",
    "Using forceps, hold a pellet through the reaching slot at the front of the box (Figure 1, Figure 2). Allow the rat to eat 3 pellets from the forceps.\nThe next time the rat tries to eat the pellet from the forceps, pull the pellet back. Eventually, the rat will attempt to reach for the pellet with its paw.\nRepeat this 11 times. The paw that the rat uses most out of the 11 attempts is the rat’s “paw preference”.\n\t\tNOTE: An attempt is defined as the paw reaching out past the reaching slot. The rat does not need to successfully obtain and eat the pellet.\nTrain the rat to reach to the pellet delivery rod (1–3 days)\n\t\nAlign the pellet delivery rod with the side of the reaching slot contralateral to the rat’s preferred paw (use a guide to ensure consistent placement 1.5 cm from the front of the reaching chamber). The top of the delivery rod should align with the bottom of the reaching slot (Figure 2B). Place a pellet on the delivery rod.\n\t\tNOTE: Positioning the delivery rod opposite the rat’s preferred paw makes it difficult for the rat to obtain the pellet with its non-preferred paw. We have not had issues with rats using their non-preferred paw. However, in certain models (e.g., stroke) this may still occur and a restraint on the non-preferred reaching limb can be added.",
    "Bait the rat with a pellet held using forceps, but direct the rat towards the delivery rod so that its paw hits the pellet on the rod. If the rat knocks the pellet off of the rod, replace it. Some rats may not initially reach out far enough. In this case, move the pellet delivery rod closer to the reaching slot and then slowly move it further away as the rat improves.\nAfter about 5–15 baited reaches the rat will begin to reach for the pellet on the delivery rod spontaneously. Once the rat has attempted 10 reaches to the delivery rod without being baited, it can advance to the next phase.\nTrain the rat to request a pellet (2–8 days).\n\tNOTE: Although we have had 100% success training rats to reach for pellets, about 10% of rats fail to learn to request a pellet by moving to the back of the chamber.\n\t\nPosition the pellet delivery rod based on the rat’s paw preference and set it to position 2 (Figure 2A). Set height positions of the pellet delivery rod using the actuator remote. Holding buttons 1 and 2 simultaneously moves the delivery rod up, while holding buttons 3 and 2 moves the delivery rod down. When the delivery rod is at the correct height, hold down the desired number until the light blinks red to set.\nPlace the rat in the chamber and bait the rat to the back with a pellet. When the rat moves far enough to the back of the chamber that it would break the infrared beam if the automated version was running, move the pellet delivery rod to position 3 (Figure 2B).",
    "Wait for the rat to reach for the pellet and then move the pellet delivery rod back to position 2 (Figure 2A). Place a new pellet on the delivery rod if it was knocked off.\nRepeat these steps, gradually baiting the rat less and less, until the rat begins to: (i) move to the back to request a pellet without being baited, and (ii) immediately move to the front after requesting a pellet in the back. Once the rat has done this 10 times, it is ready for training on the automated task.\n4. Training rats using the automated system\nSet up the automated system.\n\t\nTurn on the lights in the chamber and refill the pellet reservoir if needed.\nPosition the pellet delivery rod according to the rat’s paw preference. Check that the actuator positions are set correctly (as in Figure 2A).\nTurn on the computer and open the Skilled Reaching program (SR_dig_extension_card_64bit_(HOST)_3.vi). Enter the rat ID number under Subject and select the paw preference from the Hand drop-down menu. Specify the Save Path for the videos.\nSet Session Time and Max Videos (number of videos at which to end the session at). The program will stop running at whichever limit is reached first.\nSet Pellet Lift Duration (duration of time that the delivery rod remains in position “3” after the rat requests a pellet). Enable or disable Early Reach Penalty (delivery rod resets to position “1” and then back to “2” if the rat reaches before requesting a pellet).\nTake calibration images. The 3-D trajectory reconstruction uses a computer vision toolbox to determine the appropriate transformation matrices, which requires identifying matched points in each view. To do this, use a small cube with checkerboard patterns on each side (Figure 3).",
    "Place the helping hand inside the reaching chamber and poke the alligator clip through the reaching slot. Hold the cube in front of the reaching slot with the alligator clip.\nPosition the cube so that the red side appears in the top mirror, the green side in the left mirror, and the blue side in the right mirror. The entire face of each of the three sides should be visible in the mirrors (Figure 3).\nIn the behavioral program, make sure ROI Threshold is set to a very large value (e.g., 60000). Click the run button (white arrow). Once the Camera Initialized button turns green, press START. Note that the video is being acquired.\nClick Cal Mode. Then, take an image by clicking Take Cal Image. The image directory path will now appear under “.png path” with the .png filename formatted as “GridCalibration_YYYYMMDD_img#.png”.\nMove the cube slightly, and take another image. Repeat again for a total of 3 images.\nStop the program by clicking STOP and then the stop sign button. Remove the helping hand and cube from the box.\nBe careful not to bump anything in the behavioral chamber after calibration images have been taken that day. If anything moves, new calibration images need to be taken.\nRun the automated system.\n\tNOTE: Determine “ROI Threshold” settings (described below) for each mirror before running rats for actual data acquisition. Once these settings have been determined, pre-set them before beginning the program and adjust during acquisition if necessary.\n\t\nPlace the rat in the skilled reaching chamber. Click on the white arrow to run the program.",
    "Before clicking START, set the position of the ROI for paw detection by adjusting x-Offset (x-coordinate of the top-left corner of the ROI rectangle), y-Offset (y-coordinate of the top-left corner of the ROI), ROI Width and ROI Height.\nPosition the ROI in the side mirror that shows the dorsum of the paw, directly in front of the reaching slot (Figure 2C). Be sure that the pellet delivery rod does not enter the ROI and that the ROI does not extend into the box to prevent the pellet or the rat’s fur from triggering a video when the rat is not reaching.\nClick START to begin the program.\nAdjust the “Low ROI Threshold” value until the “Live ROI Trigger Value” is oscillating between “0” and “1” (when the rat is not reaching). This value is the number of pixels within the ROI with intensity values in the threshold range.\nSet the ROI Threshold. Observe the Live ROI Trigger Value when the rat pokes its nose into the ROI and when the rat reaches for the pellet. Set the ROI threshold to be significantly greater than the “Live ROI Trigger Value” during nose pokes and lower than the “Live ROI Trigger Value” when the rat reaches. Adjust until videos are consistently triggered when the rat reaches but not when it pokes its nose through the slot\n\t\tNOTE: This assumes the paw is lighter colored than the nose; the adjustments would be reversed if the paw is darker than the nose.",
    "Monitor the first few trials to ensure that everything is working correctly. When a rat reaches before requesting a pellet (delivery rod in position “2”), the “Early Reaches” number increases. When a rat reaches after requesting a pellet (delivery rod in position “3”), the “Videos” number increases and a video is saved as a .bin file with the name “RXXXX_YYYYMMDD_HH_MM_SS_trial#”.\n\t\tNOTE: The default is for videos to contain 300 frames (i.e., 1 s) prior to and 1000 frames after the trigger event (this is configurable in the software), which is long enough to contain the entire reach-to-grasp movement including paw retraction.\nOnce the session time or max videos is reached, the program stops. Press the stop sign button.\nClean the chamber with ethanol and repeat with another rat, or if done for the day proceed to converting videos.\nConvert .bin files to .avi files.\n\tNOTE: Compressing videos during acquisition causes dropped frames, so binary files are streamed to disk during acquisition (use a solid state drive because of high data transfer rates). These binary files must be compressed off-line or the storage requirements are prohibitively large.\n\t\nOpen the “bin2avi-color_1473R_noEncode.vi” program.\nUnder “File Path Control” click the folder button to select the session (e.g., R0235_20180119a) you want to convert. Repeat for each session (up to six).\nClick the white arrow (run) and then “START” to begin. You can monitor the video compression in the “Overall Progress (%)” bar. Let the program run overnight.\nBefore you begin training animals the next day, check that the videos have been converted and delete the .bin files so there is enough space to acquire new videos.\n5. Analyzing videos with DeepLabCut",
    "NOTE: Different networks are trained for each paw preference (right paw and left paw) and for each view (direct view and left mirror view for right pawed rats, direct view and right mirror view for left pawed rats). The top mirror view is not used for 3D reconstruction—just to detect when the nose enters the slot, which may be useful to trigger interventions (e.g., optogenetics). Each network is then used to analyze a set of videos cropped for the corresponding paw and view.\nTrain the DeepLabCut networks (detailed instructions are provided in DeepLabCut documentation on https://github.com/AlexEMG/DeepLabCut).\n\t\nCreate and configure a new project in DeepLabCut, a machine learning algorithm for markerless pose estimation13.\nUse the program to extract frames from the skilled reaching videos and crop images to the view to include (direct or mirror view) in the program interface. Crop frames large enough so that the rat and both front paws are visible.\n\t\tNOTE: Networks typically require 100–150 training frames. More training frames are needed when the paw is inside as compared to outside the chamber because of lighting. Tighter cropping reduces processing time, but be careful that the cropped regions are large enough to detect the paw’s full trajectory for each rat. It should be wide enough for the rat’s entire body to fit in the frame (direct view), and to see as far back into the chamber as possible and in front of the delivery rod (mirror view).\nUse the program GUI to label body parts. Label 16 points in each frame: 4 metacarpophalangeal (MCP) joints, 4 proximal interphalangeal (PIP) joints, 4 digit tips, the dorsum of the reaching paw, the nose, the dorsum of the non-reaching paw, and the pellet (Figure 4).",
    "Follow the DeepLabCut (abbreviated as DLC henceforth) instructions to create the training dataset, train the network, and evaluate the trained network.\nAnalyze videos and refine the network.\n\t\nBefore analyzing all videos with a newly-trained network, analyze 10 videos to evaluate the network’s performance. If there are consistent errors in certain poses, extract additional training frames containing those poses and retrain the network.\nWhen analyzing videos, make sure to output .csv files, which will be fed into the code for 3D trajectory reconstruction.\n6. Box calibration\nNOTE: These instructions are used to determine the transformation matrices to convert points identified in the direct and mirror views into 3-D coordinates. For the most up to date version and more details on how to use the boxCalibration package, see the Leventhal Lab GitHub: https://github.com/LeventhalLab/boxCalibration, which includes step-by-step instructions for their use.\nCollect all calibration images in the same folder.\nUsing ImageJ/Fiji, manually mark the checkerboard points for each calibration image. Save this image as “GridCalibration_YYYYMMDD_#.tif” where ‘YYYYMMDD’ is the date the calibration image corresponds to and ‘#’ is the image number for that date.\n\t\nUse the measurement function in ImageJ (in the toolbar, select Analyze | Measure). This will display a table containing coordinates for all points marked. Save this file with the name “GridCalibration_YYYYMMDD_#.csv”, where the date and image number are the same as the corresponding .tif file.\nFrom the boxCalibration package, open the ‘setParams.m’ file. This file contains all required variables and their description. Edit variables as needed to fit the project’s specifications.",
    "Run the calibrateBoxes function. Several prompts will appear in the command window. The first prompt asks if whether to analyze all images in the folder. Typing Y will end the prompts, and all images for all dates will be analyzed. Typing N will prompt the user to enter the dates to analyze.\n\tNOTE: Two new directories will be created in the calibration images folder: ‘markedImages’ contains .png files with the user defined checkerboard marks on the calibration image. The ‘boxCalibration’ folder contains .mat files with the box calibration parameters.\nRun the checkBoxCalibration function. This will create a new folder, ‘checkCalibration’ in the ‘boxCalibration’ folder. Each date will have a subfolder containing the images and several .fig files, which are used to verify that box calibration was completed accurately.\n7. Reconstructing 3D trajectories\nAssemble the .csv files containing learning program output into the directory structure described in the reconstruct3Dtrajectories script.\nRun reconstruct3Dtrajectories. This script will search the directory structure and match direct/mirror points based on their names in the leaning program (it is important to use the same body part names in both views).\nRun calculateKinematics. This script extracts simple kinematic features from the 3-D trajectory reconstructions, which can be tailored to specific needs.\n\tNOTE: The software estimates the position of occluded body parts based on their neighbors and their location in the complementary view (e.g., the location of a body part in the direct camera view constrains its possible locations in the mirror view). For times when the paw is occluded in the mirror view as it passes through the slot, paw coordinates are interpolated based on neighboring frames.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}