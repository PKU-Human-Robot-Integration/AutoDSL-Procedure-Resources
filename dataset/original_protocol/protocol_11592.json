{
  "id": 12854,
  "origin_website": "Jove",
  "title": "Conscious and Non-conscious Representations of Emotional Faces in Asperger's Syndrome",
  "procedures": [
    "Ethics Statement: Procedures involving human participants have been approved by the human participant research ethics committee/Institutional Review Board at the Academia Sinica, Taiwan.\n1. Stimuli and Experimental Program Preparation\nPrepare a pool of more than 60 emotional face photographs29 categorized into three facial expressions (angry, happy, and neutral). Use graphics software to mask out hair and ear parts in the photographs with black background as shown in Figure 1A so that participants can concentrate on the facial features in the photographs.\n\t\nOpen a photograph in the graphics software. Use the selection toolbox to draw an elliptical region and adjust the region size so that the ears and most hair do not fall in the ellipse.\nInvert the selected region. Click \"delete\" to remove the unwanted region of the photograph and replace it with the black background color.\nimgsrc://cloudfront.jove.com/files/ftp_upload/53962/53962fig1.jpg\nFigure 1. Examples of emotional face stimuli. (A) photograph faces where the hair and ears have been masked out in the black background color, and (B) line-drawing faces that are edited from (A) by graphics software. The faces show neutral, happy, and angry emotions respectively from the top to bottom rows. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/53962/53962fig1large.jpg]\nCreate a pilot study. Recruit pilot participants for selecting suitable stimuli from the photograph pool.\n\tNote: The pilot participants should not participate in the EEG experiment.\n\t\nConfigure the stimulus presentation program beginning with the first computer screen presenting the task instruction, followed by 5 familiarization trials. Begin each trial with a fixation cross, followed by a face stimulus, and by an emotionality evaluation task. See Supplemental Code File for an example program.\n\t\tNote: The real pilot trials immediately follow the familiarization trials by selecting face photographs in a random order from the pool.",
    "Create an experimental program, including the instruction screens and a central eye-fixation screen. Create the face stimulus screen as illustrated in Figure 2 by configuring the photograph size to be 18.3 x 24.4 cm2 (width x height) with black background color, given a computer screen size 41 x 25.6 cm2 with resolution 1,680 x 1,050. See Supplemental Code File for an example program.\nCreate a scoring system for emotionality evaluation in the program as illustrated in Figure 3. Place a horizontal line ranging from -100 to +100 in a continuous scale in the center of the screen without any tick-marks, except for the central and endpoints. Prepare the program such that participants can freely evaluate the emotionality of a photograph face by dragging the scoring cursor to the left for very angry (-100) and to the right for very happy (+100), and press the GO button.\n\t\t\tNote: The scoring line is designed without any tick-marks because patients with AS can easily get stuck in placing the cursor between ticks during emotionality evaluation. Therefore, a continuous scale is preferred for patients.\nMake sure the program records a participant's behavioral results (e.g. reaction time and emotionality scores), which are used as criteria for choosing photographs from the pool (see step 1.3.1).\nRecruit pilot participants (5 control and 5 AS pilot participants). Diagnose clinical patients according to Gillberg30 and DSM-IV criteria26 and administer the clinical derived short-form of Wechsler Adult Intelligence Scale (WAIS-III)31. Match the controls to their AS counterparts as closely as possible on gender, and on verbal/performance IQ scores.",
    "Run the experimental procedure in the pilot study for each individual participant. After completing the emotional face recognition task, interview each pilot AS participant on the reasonable duration of the central-eye fixation and stimulus presentation periods, difficulty of the task, ease of using the scoring system and the maximum number of trials for keeping his/her concentration, based on which the program can be reconfigured for the EEG experiment (see step 1.3.2)\nimgsrc://cloudfront.jove.com/files/ftp_upload/53962/53962fig2.jpg\nFigure 2. A screenshot of a face stimulus in the program. The size of the face is configured to fit the height of the screen. The empty area is filled in with the black color. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/53962/53962fig2large.jpg]\nimgsrc://cloudfront.jove.com/files/ftp_upload/53962/53962fig3.jpg\nFigure 3. A screenshot of the scoring system for emotionality evaluation. The scoring bar is designed to have no tick mark. The participant needs to drag the mouse to select the score assigned to a face and press the GO button to finish the task. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/53962/53962fig3large.jpg]\nProgram for Task 1: Photograph Session.\n\t\nSelect from the pool 30 photographs, comprising 10 each for happy, angry, and neutral facial expressions (5 male and 5 female faces for each type of expressions), that give the most comparable mean reaction times and mean emotionality scores between the 5 AS and 5 control pilot participants.\nUpdate the experimental program configurations by incorporating feedback from the pilot patients, such as the optimal central eye-fixation period (i.e., 1,000 msec), duration of stimulus presentation (i.e., 1,000 msec), inter-stimulus interval (i.e., randomly assigned in-between 4 and 7 sec), and scale of the scoring system (i.e., -100 to 100). Add five familiarization trials prior to the 30 experimental trials in the program.",
    "Change the number of stimuli and time intervals in an external configuration text file associated with the experimental program.\n\t\t\tNote: The text file can be modified to fit different experimental conditions without intervention of software engineers.\nDo not count the five photographs for familiarization trials to the 30 selected photographs. Do not use the EEGs and the behavioral data recorded in familiarization trials in data analysis.\nProgram for Task 2: Line-drawing Session.\n\t\nCreate line-drawing pictures of the 35 photographs (5 for familiarization trials, 30 for experimental trials) used in Task 1 by tracing the edges of each face. Use graphics software to modify the grey scale photographs into black-and-white line-drawings as shown in Figure 1B.\n\t\tNote: Steps below for photograph editing is one of the possible solutions for making line-drawings.\n\t\t\nIn the graphics software, adjust the brightness/contrast of the photograph so that the original grey scale intensity in the majority pixels falls in either black or white.\nApply \"sketch effect\" in the \"effect\" or \"filter\" menu of the software to a grey scale photograph so that only contour of the high spatial frequency part is preserved, and apply \"distress effect\" to increase the dilation of the contour lines.\nUse any brush tool to enhance the contours and use an eraser tool to clean up unwanted parts. Make sure to keep important facial features by checking back and forth between the original photograph and its line-drawing counterpart.\nMake a copy of the program of Task 1 in step 1.3 to create a program for Task 2 and replace the 35 photographs in Task 1 with the corresponding line-drawings.\n2. EEG Recording Procedure\nPreparations\n\t\nRecruit 10 healthy controls and 10 patients with AS for EEG experiments based on the guidelines of the local human participant research ethics committee/Institutional Review Board.",
    "Administer the short-form of WAIS-III31 to the patients with AS individually prior to the experiments, and find the controls who match the patients as closely as possible on gender and on the verbal/performance IQ scores.\nEEG Recording\n\t\nSeat the participant in a comfortable chair in a sound insulated (dimly lit) chamber and adjust the chair position so that the computer screen is 60 cm in front of the participant. After a tutorial on the experimental procedure, have the participant fill out the consent forms along with a few questions on his/her handedness.\nUse an EEG cap with 132 Ag/AgCl electrodes (including 122 10-10 system EEG, and the bipolar VEOG, HEOG, EKG, EMG electrodes, along with six facial-muscle channels) to record EEGs. Connect the cap to two 64-channel amplifiers with 0.1-100 Hz analog band-pass filter to digitize raw EEGs at 1,000 Hz sampling rate.\nFit the standard 128-channel EEG cap to each participant's head. Adjust the cap so that the electrode labeled \"reference\" is placed at the \"Cz\" position, which is located relative to the anterior/posterior midline landmarks (i.e., middle of the nasion to inion distance), and to the left/right landmarks (i.e., middle of the left/right tragis), according to the EEG international 10/10 system.\nGently use a blunt needle to inject conductive gel into all the electrodes. Stir with the needle slowly inside the electrode to ensure good gel contact between the scalp and the electrode (i.e., to keep the impedance below 5 kΩ). Constantly check the condition of gel contact at the electrodes labeled \"reference\" and \"ground\" on the EEG cap to make sure the impedance measurement is correct.",
    "Observe the electrode impedance by viewing the electrode impedance screen supported by the EEG recording software (e.g. SCAN 4.5 in this study) that usually goes with the EEG system. On the screen, the electrodes are shown in colors, and different colors indicate the levels of impedance.\nPlace one HEOG electrode at the canthus of one eye (positive site), and the second electrode at the canthus of the other eye (negative site), one VEOG electrode above and the other one below the left eye, bipolar EKG electrodes on the back of the left and right hands, and bipolar EMG electrodes in the area between the thumb and index finger of the right hand, and the six facial electrodes around the eyebrow and cheek.\nRecord in a notebook those bad channels in which the impedance is higher than 5 kΩ, or directly save the screen showing impedance at all electrodes. Use this as future reference for discarding bad channels at the stage of EEG data processing.\nRecord resting-state EEGs after instructing the participant to close eyes for 12 min. During this time, doubly check the quality of the instant EEG stream shown on the screen supported by the EEG recording software.\n\t\tNote: There should be clear alpha waves distributed in the occipital channels during the eyes-closed condition compared with the eyes-open condition. If the alpha waves are too noisy (ignoring the bad channels) or distorted, return to step 2.2.4 and adjust the gel contact.\nStart the two experimental tasks in a counter-balanced order across participants. Record EEGs by clicking the record icon on the screen supported by the recording software.",
    "After reading the task instruction shown on the screen, have each participant perform the 5 familiarization trials, followed by the 30 task trials. Use the same procedure for both photograph and line-drawing tasks. In the task instruction, encourage participants to assign a score to emotionality of a face stimulus as quickly as possible.\nIMPORTANT: Check programs prepared in steps 1.3.2 and 1.4.2 for correctly sending events time-locked to the onset of central eye-fixation, face stimulus presentation, and pressing of the GO button to the recording software during emotionality evaluation. Those onset times are coded as numeric and can be checked on the screen supported by the recording software.\n\t\t\tNote: The participant can take a break in between the two tasks. There is no EEG recording during the break.\nUse a digitizer (e.g. the Polhemus FASTRAK 3D digitizer in this study) to record the 3D positions of electrodes and save it in a file (e.g. .3dd or .dat file) for co-registering EEG caps across participants in data analysis.\nAfter the EEG experiment, have the participant fill out a 35 question inventory on his/her behaviors and feelings during the EEG experiment (e.g., have negative emotions, almost fell into sleep), and provide them payment for participating in the experiment.\nBring the participant to the washroom to clean/dry his/her hair.\nClean and sterilize the EEG cap according to clinical instructions.\n3. Processing EEG Data\nNote: The software commands provided in this section are specific for EEGLAB.\nFilter the EEG signals using a high-pass filter of 1 Hz and a low-pass filter of 50 Hz by calling the pop_eegfilt.m function32.\n\tNote: Use a low-pass filter of 40 Hz for some countries that have 50 Hz electrical grid frequency",
    "Discard bad channels with impedance higher than 5 kΩ after checking the electrode impedance recorded in step 2.2.6. Discard those bad channels with very different power spectrum compared with the neighboring channels by visual inspection of the power spectrum features (e.g., the maximum value, the curvature, etc.) in each channel.\n\t\nCalculate and plot the power spectrum of the EEG signal by calling the pop_spectopo.m function32.\nRe-reference the EEG signals with the average of brain channels without the bad channels by calling the pop_reref.m function.\nSegment EEGs into stimulus-locked epochs, each of which ranges from -2.0 sec pre- to 1.5 sec post-stimulus onset. Correct for baseline (-2.0 to -1.2 sec before the stimulus onset) by removing the average of baseline values from each epoch.\n\t\nCall the pop_epoch.m and pop_rmbase.m functions, respectively. Choose the interval of baseline prior to the central eye-fixation period and the onset of the face stimulus.\nMark bad epochs that appear to contain artifacts. Discard the bad epochs while reserving the epochs contaminated by eye blinks. The epochs with artifacts usually look noisy or have extremely high peak value (e.g. higher than 100 µV) compared with typical epochs.\n\t\nCall the pop_rejmenu.m function to launch a semi-automatic procedure. An interaction window will pop out to re-confirm auto-selected bad epochs by the user via visual inspection. Though a majority of epochs are contaminated by eye blinks, these epochs can be tentatively reserved for later removal by independent component analysis (ICA)33 in step 3.8.\nAfter discarding bad channels and bad epochs, run ICA on the pruned EEG data using the pop_runica.m function.\nAmong the estimated independent components (ICs), identify artifacts resulting from eye movement/blink, muscle activity, heartbeat, and line noise32.",
    "Note: A significantly high correlation (R2 >0.9) between IC scores of a component and those of all reference channels (VEOG, HEOG, EKG, and facial channels) indicates that this component is mainly contributed by artifacts. The estimated IC scores explained by the artifacts can be cleaned up using multiple regression analysis.\nRemove artifact ICs and estimate the clean EEGs which are derived by the product of the ICA mixing matrix and artifact-cleaned IC score matrix. Save the clean EEGs for further analysis.\n\t\nKeep the residuals of predicting artifact ICs (R2 >0.9) from the reference VEOG, HEOG, EKG and facial channels in the IC score matrix. Remove other artifact ICs by the pop_subcomp.m function. The function returns the artifact-cleaned EEGs.\n4. Statistical Analysis\nPartition EEG channels into eleven homogeneous regions to reduce the number of statistical comparisons in ERP and ERSP analyses, that is, left- (10 channels), midline- (14), and right-frontal (10); left- (13) and right-temporal (13); left- (9), midline- (14) and right-central (9); left- (9), midline- (12) and right-occipital parietal (9) as shown in Figure 4. These regions are defined according to the functional anatomy of cortex34. Functional homogeneity of EEG signals in these regions has been validated in different experiments13,35,36.\nimgsrc://cloudfront.jove.com/files/ftp_upload/53962/53962fig4.jpg\nFigure 4. The channel partition. The channels are divided into eleven regions. LF: left-frontal (10 channels), MF: midline-frontal (14), RF: right-frontal (10), LT: left-temporal (13), RT: right-temporal (13), LC: left-central (9), MC: midline-central (14), RC: right-central (9), LP: left-occipital parietal (9), MP: midline-occipital parietal (12), RP: right-occipital parietal (9). Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/53962/53962fig4large.jpg]\nLoad the clean EEGs in step 3.8. Compute the channel ERP by averaging signals across epochs in each channel, and regional ERP by averaging ERPs within the same region.",
    "Note: When EEGs are loaded using the pop_loadset.m function in EEGLAB, the signals are stored in the structure variable \"EEG.data\" in a channel-by-time-by-epoch array.\n\t\nIn the Matlab command window, compute the channel ERP by averaging EEG.data across epochs for every channel (e.g., channelERP = mean(EEG.dat,3)). Compute the regional ERP by averaging the channel ERPs within each region according to the partition in 4.1 (e.g., regionalERP = mean(channelERP(index,:),1), where \"index\" stands for the channel indices in a given region).\nCompute the channel ERSPs by applying a time-frequency transform (e.g. Wavelet transform) to epoch signals in each channel, and regional ERSPs by averaging channel ERSPs in the same region.\n\t\nPerform the time-frequency transform by calling the pop_newtimef.m function.\n\t\tNote: In this study, the \"wavelet cycles\" entry is set to [1, 0.5] and \"baseline\" is set to [-2,000 to -1,200] msec. The resulting channel ERSPs will be stored in a frequency-by-time-by-channel array.\nIn the Matlab command window, compute the regional ERSP by averaging ERSPs across channels within each region according to the partition in 4.1 (e.g., regionalERSP = mean(channelERSP(:,:,index),3), where \"channelERSP\" is the output from the pop_newtimef.m function, and \"index\" stands for the channel indices in a given region).\nCalculate mean values in different time intervals (e.g. 50-150, 150-250, 250-350, 350-450 msec) for regional ERPs. Calculate mean values in different time-frequency intervals (e.g. 50-150, 150-250, 250-350, 350-450, 450-800 msec in 1-7 Hz, and 200-800 msec in 8-30 Hz) for regional ERSPs.\nApply MANOVA in statistical software (e.g. IBM SPSS ) to the mean values of regional ERPs and ERSPs to evaluate main effects for the task (photograph vs. line-drawing), region (eleven scalp regions), and group (AS vs. control), as well as the interaction effects among the task, region, and group.",
    "In the statistical analysis, consider gender (male vs. female) as a covariate, and estimate the main and interaction effects by holding the gender effect constant.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}