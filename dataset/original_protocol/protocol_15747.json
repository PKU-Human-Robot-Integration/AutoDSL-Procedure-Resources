{
  "id": 19573,
  "origin_website": "Jove",
  "title": "A Standardized Pipeline for Examining Human Cerebellar Grey Matter Morphometry using Structural Magnetic Resonance Imaging",
  "procedures": [
    "NOTE: The data used in this study were part of a project approved by the Monash University Human Research Ethics Committee (project 7810). Participants provided written informed consent. While the pipeline can be run on Mac, Windows, or Linux operating systems, ACAPULCO, SUIT, and the QC pipelines have explicitly been tested on Linux (Ubuntu) and Mac (Catalina, Big Sur v11.0.1) operating systems.\n1. Module 1: ACAPULCO (anatomical parcellation)\nData collection\n\t\nCollect 3D T1-weighted MRI images of the whole brain at a resolution of 1 mm3 or less. Isotropic voxel dimensions (typically 1 mm x 1 mm x 1 mm), and a 3-Telsa (or greater) scanner are recommended. Consult with an imaging specialist at their radiography center to set up and acquire data that meet these specifications.\n\t\tNOTE: T2-weighted images are sometimes useful for volumetric analyses; however, the pipeline presented here relies on T1-weighted data only, and some of the tools used are exclusive to this type of data. As such, T2-weighted images cannot be used.\nUndertake a visual quality assessment of images to exclude gross cerebellar malformations (e.g., large lesions) or substantial motion artifacts that prevent identification of major cerebellar landmarks (e.g., the major anatomical fissures). Do not automatically exclude atrophied cerebella, even if substantial.\nFor group studies, also consider quantitative quality assessments using freely-available, standardized tools such as MRIQC46 to further identify problematic data.\nConvert all data to NIFTI-GZ format using a tool such as dcm2niix47.\nRecommended data organization\n\t\nObtain all necessary software as listed in the Table of Materials. Ensure Docker48 or Singularity49, Matlab50, and SPM1251 are installed prior to running the pipeline.\n\t\tNOTE: Extensive written and video tutorials describing the pipeline are also available (see the Table of Materials).",
    "Once all necessary software is installed, create folders in the working directory and label them 'acapulco,' 'suit,' and 'freesurfer.' Do this using the mkdir command from the command line.\nIn the 'acapulco' directory, create an output folder. In the output folder, create a directory for each subject in the study containing the T1-weighted image in NIFTI-GZ format.\n\t\tNOTE: It is recommended to keep a copy of the original data elsewhere.\nAnatomical cerebellar parcellation using ACAPULCO\n\t\nGo to the Table of Materials and download the relevant scripts and containers required to run ACAPULCO (under acapulco pipeline files). In the 'acapulco' directory, place the (i) ACAPULCO Docker OR Singularity container ('acapulco_0.2.1.tar.gz' or '.sif', respectively), (ii) contents of the QC_scripts archive (3 files: 'QC_Master.R,' 'QC_Plots.Rmd,' and 'QC_Image_Merge.Rmd'), and (iii) 'R.sif' (singularity) OR 'calculate_icv.tar' (docker) file.\nOpen a terminal, and from the command line, run the ACAPULCO container on a single image (replace <<subject>> in the following). Wait for ~5 min for processing to complete.\n\t\t\nUsing Docker, type the command:\ndocker load --input acapulco_0.2.1.tar.gz\ndocker run -v $PWD:$PWD -w $PWD -t --user $(id -u):$(id -g) --rm acapulco:latest -i output/<<subject>>/<<subject>>.nii.gz -o output/<<subject>>\nUsing Singularity, type the command:\nsingularity run --cleanenv -B $PWD:$PWD acapulco-0.2.1.sif -i output/<<subject>>/<<subject>>.nii.gz -o output/<<subject>>\nLoop across all subjects/scans in the cohort. See the Table of Materials for a link to the ENIGMA Imaging Protocols website for downloading the pipeline (under ENIGMA Cerebellum Volumetrics Pipeline) and the tutorial manual containing examples of how to create a for-loop for processing multiple subjects serially.\nAfter processing, look for the following files generated in the subject-specific folders:\n\t\t\nIdentify \"<subject>_n4_mni_seg_post_inverse.nii.gz\": parcellated cerebellum mask in original (subject space).\nIdentify \"<subject>_n4_mni_seg_post_volumes.csv\": volumes (in mm3) for each of the 28 subunits generated by acapulco;\nIdentify representative images (in 'pics' directory): sagittal, axial, and coronal.",
    "Statistical outlier detection and quality control (QC)\n\t\nFrom the terminal and in the 'acapulco' directory, ensure that the contents of QC_scripts are in the 'acapulco' directory. To run the QC scripts:\n\t\t\nUsing Docker, type the command:\ndocker load calculate_icv.tar\n\t\t\tdocker run -v $PWD:$PWD -w $PWD --rm -it luhancheng/calculate_icv:latest Rscript\nQC_Master.R output/\nUsing Singularity, type the command:\nsingularity exec -B $PWD:$PWD R.sif Rscript /path/to/QC_Master.R /path/to/acapulco/output\nExamining the QC images generated by ACAPULCO\n\tNOTE: There is a 3-step process for quality checking the ACAPULCO parcellated images.\n\t\nOpen the 'QC_Images.html' in a web browser and quickly (~10 s per subject) scroll through the images to identify obvious failures or systematic issues. Note the subject IDs of failed or suspect parcellated images for follow-up.\n\t\tNOTE: See Figure 3 for a guide on the neuroanatomy of the cerebellar lobules and Figure 4, Figure 5, and Figure 6 in the representative results section below for examples of 'good' parcellations, 'subtle mis-parcellations,' and 'global failure' parcellations.\nOpen the 'Plots_for_Outliers.html' to check the boxplots for quantitative statistical outliers. Look for outliers (2.698 s.d above or below the mean) above or below the whiskers of the box plots. Hover over the data points to display the Subject ID. Identify the outliers denoted by a '1' in the relevant column in the 'Outliers.csv' file, and note the total number of segments identified as outliers for each subject in the final column in 'Outliers.csv.'\nManually inspect each image having one or more outliers. CRITICAL: Using a standard NIFTI image viewer (e.g., FSLEyes or MRICron), overlay the ACAPULCO mask onto the original T1w image to check the quality of the parcellation slice-by-slice.\n\t\t\nTo generate overlays for detailed QC from the command line using FSLEyes, i) change the directory to the 'acapulco' directory, ii) specify the subject to view (replace <subject>):\n\t\t\tsubj=<subject_name>",
    "Copy/paste the following code to the terminal (without manually changing {subj} as this has been set by the previous line:\nt1_image=output/${subj}/${subj}.nii.gz\n\t\t\tacapulco_image=output/${subj}/${subj}_n4_mni_seg_post_inverse.nii.gz\n\t\t\tfsleyes ${t1_image} ${acapulco_image} --overlayType label --lut random_big --outline --outlineWidth 3 ${acapulco_image} --overlayType volume --alpha 50 --cmap random\n\t\t\tNOTE: A determination will need to be made whether to include the abnormal segment or not, i.e., is there a parcellation error, or is it just normal variability in the individual's anatomy? Each parcellated region is considered individually, so a few regions can be excluded for an image, while the remainder can be retained if correct.\nDo one or more parcellated regions need to be excluded from the final dataset?\n\t\t\tIf Yes (outlier is confirmed), exclude this parcellation(s) from the analysis by replacing the volume estimate with NA in the corresponding cell of the 'Cerebel_vols.csv' file for that subject.\nDo parcellation errors result in some of the cerebellum being excluded from the mask?\n\t\t\tIf Yes, (for example, if particular cerebellar lobules are missing from the mask or appear 'cut off'), immediately exclude the subject from further analyses (i.e., do not proceed to run the SUIT module on those subjects).\n2. Module 2: SUIT cerebellum-optimized voxel-based morphometry\nVoxel-based morphometry analyses using SUIT\n\tCRITICAL: This pipeline requires the ACAPULCO module to have already been run, as it relies on the generation of a subject-specific cerebellar mask for optimization of the registration and normalization of the cerebellum to the SUIT template. If the subject-specific mask generated by ACAPULCO does not include the whole cerebellum, this warrants exclusion from the SUIT module. For instructions on running SUIT standalone, see52.",
    "Obtain all necessary software listed in the Table of Materials. Ensure the SPM12 folder and all subfolders are in the MATLAB path. Ensure enigma_suit scripts are saved in 'spm12/toolbox' directory and added to the MATLAB path. To check the MATLAB path, type pathtool in the MATLAB command window, then click Add with subfolders to add the relevant folders.\nRun the SUIT pipeline for one or more subjects. Wait for ~15-20 min (if using the graphical user interface [GUI]) and ~5-7 min if running from the terminal (bash/shell) for processing to complete.\n\t\t\nTo use the GUI (subjects will be run in serial), from the MATLAB command window, type the command:\nsuit_enigma_all\nIn the first pop-up window, select the subject folders from the 'acapulco/output' directory to include in the analysis. Click on the individual folders on the right side of the window, or right-click and Select All. Press Done. In the second pop-up window, select the SUIT directory, where the analyses will be written.\nOR Call the function from the MATLAB command line for a single subject, type the command:\nsuit_enigma_all('/path/to/acapulco/output/subjdir','/path/to/suitoutputdir')\nOR Call the function from the terminal window, outside of MATLAB, for a single subject by typing the command:\nmatlab -nodisplay -nosplash -r \"suit_enigma_all('/path/to/acapulco/output/subjdir','/path/to/suitoutputdir'), exit\"\nSee the Table of Materials for a link to the ENIGMA Imaging Protocols website for downloading the pipeline (under ENIGMA Cerebellum Volumetrics Pipeline) and the tutorial manual containing examples of how to create a for-loop for processing multiple subjects serially.\nLook for the following points regarding the script.\n\t\t\nEnsure that the script copies the N4 bias-corrected, MNI-aligned (rigid-body) T1 image and the ACAPULCO cerebellum mask into the output directory.\nEnsure that the script segments the grey and white matter of the cerebellum.",
    "Ensure that the script corrects for overinclusion errors in the parcellation using the ACAPULCO mask.\nEnsure that the script DARTEL normalizes and reslices the data into SUIT space with Jacobian modulation so that the value of each voxel is proportional to its original volume.\nCheck each subject's folder for the following final outputs: 'wd<subject>_seg1.nii' (grey matter) and 'wd<subject>_seg2.nii' (white matter).\nStatistical outlier detection and quality control\n\t\nVisually inspect the normalized, modulated images (wd*) for major failures. In MATLAB, type the command:\nspm_display_4D\nManually select the 'wd*seg1' images from the suit subfolders, or navigate to the 'suit' directory; insert '^wd.*seg1' in the Filter box (no quotations) and press Rec button. Press Done.\nScroll through the images to ensure they are all well-aligned. See Figure 7 for correctly normalized images from healthy controls (A,B) and an individual with a heavily atrophic cerebellum (D).\n\t\tNOTE: At this stage, the between-subject anatomy is very similar (as they have been registered to the same template), and volume differences are instead encoded by differing voxel intensities. Major failures will be obvious, e.g., blank images, large areas of missing tissue, unusual intensity gradients (i.e., bright voxels all at the top, dark voxels all at the bottom). These images should be excluded from subsequent steps.\nCheck spatial covariance for outliers. In MATLAB, type the command:\ncheck_spatial_cov\nSelect the 'wd*seg1' images as per the previous step. When prompted, select the following options: Prop scaling: Yes; Variable to covary out: No; Slice (mm): - 48 , Gap: 1.",
    "Look at the boxplot displaying the mean spatial covariance of each image relative to all others in the sample. Identify data points that are >2s.d. below the mean in the MATLAB command window. For these, inspect the \"<subj>_n4_mni.nii.gz\" image in the SUIT folder for artifacts (motion, anatomical abnormalities), image quality issues, or preprocessing errors.\nIf the image quality and preprocessing are acceptable and visual inspection of the modulated images in the previous step does not indicate an issue with segmentation and normalization, retain these data in the sample. Otherwise, exclude these data.\n3. MODULE 3 (optional): Intracranial Volume (ICV) estimation using FreeSurfer\nNOTE: This module will use the FreeSurfer pipeline to calculate ICV. It does not need to be re-run if there are existing Freesurfer outputs for the cohort (any version).\nSetting up FreeSurfer\n\t\nEnsure FreeSurfer is downloaded and installed53. Go to the Table of Materials and download the relevant scripts to run this Module (under ICV pipeline files). When working with FreeSurfer, set the following variables:\nexport FREESURFER_HOME=<freesurfer_installation_ directory>\n\t\tsource $FREESURFER_HOME/SetUpFreeSurfer.sh\nReplace <path> in the following:\nexport SUBJECTS_DIR=<path>/enigma/Freesurfer\nRunning Freesurfer autorecon1\n\t\nFor a single subject, from inside the 'freesurfer' directory (processing time ~20 min), type the command:\ncd <path>/enigma/freesurfer\n\t\trecon-all -i ../input/<subject>.nii.gz -s <subject> -autorecon1\nSee the tutorial manual for examples of how to create a for-loop for processing multiple subjects serially.\nCalculation of ICV\n\t\nData organization\n\t\t\nIn the 'freesurfer' directory, place the (i) Docker OR Singularity container used in Module 1 ('calculate_icv.tar' or 'R.sif,' respectively) and (ii) xfm2det script (see the Table of Materials). Then, do a git clone to clone the required ICV script:\n\t\t\tgit clone https://github.com/Characterisation-Virtual-Laboratory/calculate_icv\nRunning ICV extraction (processing time ~5 min)\n\t\t\nFrom 'freesurfer' directory, with singularity ('R.sif') container, type:\nsingularity exec --cleanenv -B $PWD:$PWD R.sif calculate_icv/calculate_icv.py --freesurfer_dir=/path/to/freesurfer --acapulco_dir=/path/to/acapulco/QC/Cerebelvolsfile --output_csv_name=Cerebel_vols.csv calculate_icv",
    "From 'freesurfer' directory, with docker container, type:\ndocker run -v $PWD:$PWD -w $PWD -rm -it luhancheng/calculate_icv:latest\n\t\t\tcalculate_icv/calculate_icv.py --freesurfer_dir=/path/to/Freesurfer --\n\t\t\tacapulco_dir=/path/to/acapulco/QC/Cerebelvolsfile --output_csv_name=Cerebel_vols.csv\n\t\t\tcalculate_icv\nRunning script without container-see the Table of Materials for additional required software and dependencies. From the 'freesurfer' directory, type:\n./calculate_icv/ calculate_icv.py ---freesurfer_dir=/path/to/freesurfer --\n\t\t\tacapulco_dir=/path/to/acapulco/QC/Cerebelvolsfile --\n\t\t\toutput_csv_name=Cerebel_vols.csv calculate_icv\n\t\t\tNOTE: This will calculate the ICV for each subject and append a column with ICV to the end of the 'Cerebel_vols.csv' file.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Neuroscience"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research"
  ]
}