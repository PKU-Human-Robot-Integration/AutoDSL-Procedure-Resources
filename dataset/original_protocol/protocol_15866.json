{
  "id": 19692,
  "origin_website": "Wiley",
  "title": "DIAMOND+MEGAN: Fast and Easy Taxonomic and Functional Analysis of Short and Long Microbiome Sequences",
  "procedures": [
    "Microbiome projects employing second-generation, short read sequencing technologies, such as provided by Illumina or Ion-Torrent, typically involve tens or hundreds of sequencing datasets, each containing millions of reads. Here we discuss how to apply the core analysis pipeline to such data.\nWe will illustrate the necessary steps using a published dataset (Hu et al., 2018[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0014]; SRA accession: PRJNA490628) collected from gastric wash samples isolated from six patients with advanced gastric adenocarcinoma (GC) and from five patients with superficial gastritis (SG). The data can be obtained by following the Support Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-prot-0002], step 1, “Data acquisition.” Every sample is represented by two files of reads (forward and reverse reads), and thus the total dataset consists of 22 files of Illumina paired-end reads, each containing 16 million reads of length 150 bp, on average. In this protocol, we apply the preprocessing steps described in Support Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-prot-0002] to the example dataset. Whether preprocessing is necessary depends on the data quality, whether the data is host associated, and on the availability of sufficient computational resources.\nMaterials\nHardware\nA server (typically Linux) with a good number of cores, 24 or more, with at least 64 GB of main memory and sufficient disk space (multiple TB)\nSoftware\nDIAMOND (http://www.diamondsearch.org[href=http://www.diamondsearch.org])\nMEGAN (http://megan.husonlab.org[href=http://megan.husonlab.org])\nUnicycler (https://github.com/rrwick/Unicycler#installation[href=https://github.com/rrwick/Unicycler#installation])\nMedaka (https://github.com/nanoporetech/medaka[href=https://github.com/nanoporetech/medaka])\nNOTE: DIAMOND is designed to align a large set of short read sequences against a large protein reference database (Buchfink et al., 2015b[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0010]). This typically involves aligning hundreds of millions of reads against the NCBI-nr database (Benson et al., 2005[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0004]) of non-redundant protein reference sequences, which currently contains approximately 180 million entries. The program is typically run on a Linux server, from the command line.\n1. Build a DIAMOND index.\nIn preparation of using DIAMOND to align sequences, you must first build a DIAMOND index.",
    "From the command line, download the latest NCBI-nr database as follows:\n         \nwget https://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/nr.gz\nThen, run DIAMOND to build the DIAMOND index, as follows:\n         \ndiamond makedb --in nr.gz --db nr\nThis will create a file called nr.dmnd that contains the DIAMOND index.\nThe parameters supplied here to DIAMOND are the command makedb requesting that an index be built, followed by --in nr.gz, specifying the input file, and -db nr, specifying the name of the index (or database) file, in this case nr (the resulting file will end on the suffix.dmnd).\nWhen using the command line, any program that is not in your path of executables, or any file that is not in your current directory, must be prefixed by a path to it. So, for example, if you installed DIAMOND in a directory called /home/me/software and are working in a different directory, then in the above line, replace diamond by /home/me/software/diamond.\nAlso, note that in microbiome analysis, the rule is to never decompress or unzip any of the data files being processed. Most programs are able to read and write compressed files. In particular, above, to compute the DIAMOND index, we do not unzip the file nr.gz. Below, to align reads, we do not unzip the sequencing files.\n2. Align short reads.\nWhen running DIAMOND to align sequences, we have to provide a number of command-line parameters:\n         \nFirst, specify the command blastx, which requests alignment of translated reads against the reference database.\nUse -d nr to determine the index file to use. This refers to the index file nr.dmnd, but must be specified without the file suffix.\nUse -q (input file.) to specify the input file. The file must be in FastA or FastQ format, and can be compressed (suffix .gz).",
    "Use -o (output-file) to specify the output file. Use .daa as file suffix.\nUse -f 100 to specify that the output be written in DAA (DIAMOND alignment archive) format, which is required for processing with MEGANIZER and MEGAN.\nTo run DIAMOND on an input file in compressed FastQ format, for example on the first sample of the example dataset after preprocessing, type the following:\n         \ndiamond blastx -d nr -q SRR7828855_merged.fastq -o SRR7828855_merged.daa -f 100\nAgain, use paths to programs, and to files that are not in your current directory.\nDIAMOND can only be applied to a single input file per run, and so this command has to be repeated on all individual files of the sample.\nThe resulting DAA file, in binary format, contains all information about the aligned sequences and their alignments. The DIAMOND view command can be used to post-process a DAA file, for example, to filter reads and alignments or to export the alignments in a different format.",
    "DIAMOND has several parameters that control its performance and the amount of memory it uses. -b sets the “block size,” that is, how many sequences are processed at a time. This options scales roughly linearly, with 1.0 approximating to 6 GB in memory. The option -c sets the number of “index-chunks,” for which the default is 4. Settings this parameter to a lower number (e.g., 1) increases the speed of DIAMOND, while consuming more memory. Thus, on a compute server with high amount of RAM, it is useful to set -b to a higher number and -c to a lower number (e.g., -b 12 -c 1). Additionally, the parameter -t sets the directory where DIAMOND writes temporary files. If the server on which DIAMOND is run has a virtual filesystem, such as /dev/shm, setting the temporary directory for DIAMOND to this filesystem will also make it perform significantly better, as the IO operations will not be limited by slow network filesystems (e.g., -t /dev/shm).\nPlease see http://www.diamondsearch.org[href=http://www.diamondsearch.org] for more details.\n3. Meganization.\nA DAA file computed by DIAMOND contains aligned sequences and their alignments. This data can be used to perform taxonomic and functional binning of the sequences.\nThe term meganization refers to the process of first analyzing all sequences and alignments in a DAA file, so as to perform taxonomic and functional binning or classification of the sequences, and then placing the result of this analysis in an additional block at the end of the DAA file (see Fig. 2[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0002]). For short reads, taxonomic binning is performed using the naïve LCA algorithm (Huson et al., 2007[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0017]), whereas functional binning is performed using the best-hit approach (Huson et al., 2011[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0018]).",
    "MEGAN supports a number of different classifications. Taxonomic classification is performed using the NCBI taxonomy and the GTDB taxonomy (Parks et al., 2020[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0035]). Functional classification is currently performed using EC (Barrett, 1992[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0003]), eggNOG (Powell et al., 2012[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0037]), InterPro (Mitchell et al., 2015[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0030]), or SEED (Overbeek et al., 2013[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0032]). Functional classification using KEGG (Kanehisa & Goto, 2000[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0021]) is available in the Ultimate Edition of MEGAN. Other classifications will be added in future releases. The mappings of reference protein accessions to classes in the supported classifications are provided in an SQLite database.\nTo prepare for meganization, download and unzip the database file from: https://software-ab.informatik.uni-tuebingen.de/download/megan6[href=https://software-ab.informatik.uni-tuebingen.de/download/megan6]. The current version is megan-map-Jan2021.db.\nA DAA file containing the alignments computed by DIAMOND in the previous step can be meganized either using a command-line program or through the graphical user interface of MEGAN. The command-line MEGANIZER program daa-meganizer is installed with MEGAN and is found in the megan/tools sub-directory of the MEGAN installation directory.\nTo run MEGANIZER on the input file in DAA format called SRR7828855_merged.daa, from the previous step, execute the following:\n         \ndaa-meganizer -i SRR78288555_merged.daa -mdb megan-map-Jan2021.db\nAgain, use paths to programs, and to files that are not in your current directory.\nThe MEGANIZER program offers a number of additional options, which can be listed by running:\n         \ndaa-meganizer -h\nThe daa-meganizer program can be run individually on each file in the dataset, similar to DIAMOND, or can also be run on a list of input files that are separated by spaces.",
    "As an example of an additional feature, consider the task of contamination filtering. For human-associated microbiome samples, one might consider all reads with significant alignments to proteins from Metazoa (animals) as contamination. Or, as another example, in low biomass samples, laboratory contaminants might make up a significant fraction in the sample, and these can be identified using a tool like decontam (Davis, Proctor, Holmes, Relman, & Callahan, 2018[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0011]).\nFor example, to perform meganization with contaminant filtering for all animals, first create a text file contaminants.txt that contains a list of NCBI taxon names or numerical ids, then pass this to the MEGANIZER program using the option -cf, as shown here:\necho \"Metazoa\" > contaminants.txt\ndaa-meganizer -i input.daa -mdb megan-map-Jan2021.db -cf contaminants.txt\nWith this feature turned on, in the case of short reads, any read that has a significant alignment to any contaminant taxon (recursively including all descendants) will be assigned to the Contaminants node in every classification. Contaminants can also be specified later, during an update of the analysis, as described below.\nDAA files produced by DIAMOND can also be meganized using the graphical user interface (GUI) of the MEGAN program. To initiate this, launch MEGAN in GUI mode.",
    "Once MEGAN is running, select the File → Meganize DAA File… menu item to open the meganization dialog (Fig. 3A[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0003]). This dialog has multiple tabs. On the first tab, Files, enter all the DAA files that you want to meganize (Fig. 3B[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0003]). These will be processed one-by-one. On the second tab, Taxonomy, use the button Load MeganMapDB mapping file to select the mapping file megan-map-Jan2021.db (Fig. 3C[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0003]). By default, all classifications supported by the selected mapping file will be activated. Thus, there will generally be no need to explicitly turn on any of the classifications. The last tab, LCA Params, can be used to adjust the classification parameters (Fig. 3D[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0003]).\nTo run meganization on all selected files, press the Apply button. When the computation is completed, the meganized DAA files can be opened in MEGAN using the File → Open… menu item (Fig. 3E[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0003]).\nMeganization does not change the initial content of a DAA file and a DAA file can be re-meganized any number of times. Meganization can take several hours on larger datasets, and so for large datasets, we recommend running the daa-meganizer command-line program on a server.\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/c2f892f8-00e5-41fb-9957-e7a3d8924b8d/cpz159-fig-0002-m.jpg</p>\nFigure 2\nMeganization. DIAMOND produces a DAA file that has three blocks of data, containing reference protein header lines, all aligned reads, and all alignments. The MEGANIZER program (or the meganize dialog in MEGAN) uses this data to compute taxonomic and functional classifications of all reads based on the data, with the help of a database that maps reference headers to classes in the classifications. The computed classifications, together with an indexing of all reads, are appended to the bottom of the DAA file so as to produce a “meganized” DAA file, which can be opened in MEGAN.\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/a127996d-55f3-4db8-858c-2d1ef644b3f2/cpz159-fig-0003-m.jpg</p>\nFigure 3",
    "Meganization dialog. (A) Open the dialog using the Meganize DAA Files menu item. (B) Add all DAA files to be meganized. (C) Load the Megan mapping database file. (D) Optionally, change the LCA parameters. Press Apply. Once meganization has completed, open the files using the Open menu item.\n4. Open and update DAA files in MEGAN.\nUsually, MEGAN is run interactively on a desktop or laptop. If your files were meganized on a server, then you must first copy them onto your local computer.\nAt startup, MEGAN displays a main taxonomy viewer and a message window, on which all commands are echoed and errors are reported. The File → Open… menu item can be used to open one or more meganized DAA files (Fig. 3E[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0003]).\nOnce a file has been opened, the main taxonomy viewer displays the taxonomic classification of the sequences based on the NCBI taxonomy. Viewers for the other supported classifications can be opened as discussed below. The status bar at the bottom of the taxonomy viewer provides some information on the number of taxa displayed, the number of aligned and assigned reads, and the parameters used during meganization.\nNote that the file chooser only allows selection of DAA files that have file extension .daa and that have been successfully meganized.\nTo re-meganize a DAA file, for example, to use a more recent mapping database, you can do so using the MEGANIZER program or MEGAN's meganization dialog, as described above.\nThe parameters used for the initial taxonomic and functional analysis of a DAA file can be interactively modified, and then the analysis can be rerun using the Change LCA Parameters dialog, which is opened using the Options → Change LCA Parameters… menu item (see Fig. 4[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0004]).",
    "In more detail, the alignments considered during taxonomic and functional analysis can be filtered by minimal bit score (Min score), e-value (Max Expected), or minimal percentage identity (Min Percent Identity). In addition, the Top Percent parameter (default: 10%) filters all alignments whose bitscore does not lie within the specified percentage of the best score seen for a given read.\nTwo alternative parameters, Minimum Support Percent and. Min Support, determine the percent or number of assigned reads, respectively, that must be assigned to a taxon (and its descendants) so that the taxon appears in the taxonomic tree. For any taxon that does not meet this criterion, the read counts are passed up the tree (toward the root) until a taxon is reached that has a sufficiently high read count.\nThe LCA Algorithm parameter can be used to select between the naïve LCA, the “weighted LCA,” (Buchfink, Huson, & Xie, 2015a[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0009]), or the “long reads LCA” (Huson et al., 2018[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0016]). For the latter two algorithms, the Percent to cover parameter is used to set the percent of weight to cover, or percent of coding sequence to cover, respectively.\nOn the advanced tab of the dialog, one can select a contaminants file and thus rerun the analysis so as to assign contaminant sequences to the “contaminants” node.\nIn this protocol, we focus on how to meganize DAA files and then work with them in MEGAN. However, the program can also import a wide range of other formats, including alignments in BLAST, xml, tab-delimited, or text files, in SAM format, and classifications in csv text files and BIOM format. As with DAA files, this can be done both either using command-line tools, such as blast2rma or sam2rma, or directly in MEGAN.\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/fe2d69d6-9f06-47b7-bea6-60b99e84f88e/cpz159-fig-0004-m.jpg</p>\nFigure 4",
    "LCA parameters dialog. Accessed from the Options menu, the LCA dialog can be used to update the parameters used for taxonomic and functional analysis of a dataset, in particular supplying a list of contaminant taxa.\n5. Taxonomic inspection.\nBy default, upon loading a meganized DAA file into MEGAN, the program will open the main taxonomy viewer that provides an overview of the assignment of all sequences to taxa or nodes in the NCBI taxonomy (Fig. 5A[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0005]). By default, each node or taxon is represented by a circle whose area is proportional to the number of reads assigned to the taxon. Selection of a node will display two numbers, labeled Assigned and Summed, reporting the number of reads assigned to the given node, or to the given node and any of its descendants, respectively, as illustrated for Pseudomonas in Figure 5B[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0005]. Display of these values can also be turned on using the Tree → Show Number of Assigned and Tree → Show Number of Summarized menu items.\nThe taxonomy viewer displays a subtree of the NCBI taxonomy that contains all taxa to which a read has been assigned. The tree is drawn from left to right, from the root towards the leaves of the taxonomy. To facilitate viewing of the tree at different levels of detail, the user can “collapse” selected nodes so as to have them drawn as a leaf node, suppressing the subtree that lies below the selected node(s), using the Tree Collapse menu item, or expand them using Tree → Uncollapse. There are a number of other related menu items, such as Tree → Uncollapse All or Tree → Uncollapse Subtree, which uncollapses all nodes, or all nodes below any select nodes, respectively.",
    "The user can also collapse all nodes at a given taxonomic rank, such as phylum, class, order, etc., using the Tree → Rank… menu item or corresponding toolbar item (Fig. 5B[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0005]).\nThe GTDB taxonomy (Parks et al., 2020[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0035]) encompasses both bacteria and archaea and is based on marker gene similarity. In addition to taxonomic analysis using the NCBI taxonomy, MEGAN also provides a binning of reads based on the GTDB taxonomy. This alternative taxonomic view can be opened using the Window → Open GTDB Viewer… menu item. The GTDB viewer provides the same functionality as MEGAN's main taxonomic viewer.\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/5e2023e3-29e6-47cc-8a8c-1ea08cf095d2/cpz159-fig-0005-m.jpg</p>\nFigure 5\nInteractive exploration of a taxonomic analysis. (A) The main window associated shows a rooted tree representing the NCBI taxonomy and nodes are scaled to indicate the number of sequences assigned. (B) The user can select the level of resolution, that is, which taxonomic rank is to appear at the leaves of the tree. (C) Rarefaction analysis applies to the taxa at the leaves of the tree. (D) The user can select nodes in the viewer and then choose between a number of different charts for representing the read assignment to the selected taxa.\n6. Taxonomic Charts.\nMEGAN provides a number of different charts that can be used to summarize in-sample diversity or between-sample diversity (as discussed further below). To use a chart, first select all nodes of interest in the taxonomy viewer and then open the desired chart using Window → Charts… menu item or Show → Chart tool bar item (Fig. 5D[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0005]).\n7. Functional inspection.",
    "During meganization, functional classification of reads is performed, and reads are assigned to functional classes using a number of different classifications systems, currently using EC (Barrett, 1992[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0003]), eggNOG (Powell et al., 2012[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0037]), InterPro (Mitchell et al., 2015[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0030]), or SEED (Overbeek et al., 2013[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0032]). Functional classification using KEGG (Kanehisa & Goto, 2000[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0021]) is available in the Ultimate Edition of MEGAN. Other classifications will be added in future releases. Functional classification is performed using the “best hit” algorithm (Huson et al., 2011[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0018]), and so reads are usually assigned to the leaves of each functional analysis.\nEach classification is represented by a rooted tree in MEGAN, which can be opened in a separate viewer, using the Window Open EGGNOG → Viewer… menu item to open the eggNOG viewer, for example, and then interactively explored in a manner similar to that described above for MEGAN's taxonomic viewers (Fig. 6[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0006]).\nIn addition, the functional viewer provides a side bar on the left that contains two tabs, one presenting the full functional classification as a drop-down tree and the other containing a table listing the number of reads assigned to each leaf of the currently displayed tree (Fig. 6A[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0006]).\nFunctional nodes can be collapsed and expanded, as discussed above for the taxonomic inspection. However, as functional classifications do not have taxonomic ranks, collapse to a specific rank is not supported. However, the user can use the Tree → Collapse at Level… menu item to collapse a functional classification at a given “level” or distance from the root (Fig. 6A[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0006], bottom).",
    "MEGAN's charts can also be used to visualize functional assignments. To use a chart, first select all nodes of interest in the functional viewer and then open the desired chart using the Window → Charts… menu item or Show → Chart tool bar item (Fig. 6B[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0006]). In the depicted example, all functional nodes at level 2 were selected and then displayed as a pie chart.\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/29bd1e09-3a39-4269-a7d7-c751a0c7270b/cpz159-fig-0006-m.jpg</p>\nFigure 6\nEggNOG functional viewer. (A) The eggNOG functional classification displayed as a rooted tree from left to right. The classification can be collapsed at a prescribed level, for example 2. (B) Functional assignments can be selected and then displayed using different charts.\n8. Read-level analysis (optional).\nMEGAN allows the user to drill down to inspect individual reads and their alignments, explore the alignment of reads against a given reference sequence, and perform gene-centric assembly on specific genes or functional classes (Fig. 7[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0007]).\nThe read inspector dialog can be used to view the assignment of reads to selected taxa or functional classes, and to inspect the reads and their alignments. To load taxonomic or functional nodes into the viewer, select them and then use choose Options → Inspect… menu item or corresponding node context menu item (Fig. 7A[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0007]).\nWhen performing a detailed analysis of specific genes in a microbiome sample, it may be desirable to investigate how reads align against specific reference sequences. To allow this, MEGAN provides an alignment viewer that can be opened by selecting the functional node of interest and then choosing the Window → Show Alignment… menu item or corresponding node context menu item (Fig. 7A[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0007]).\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/153b34e6-a7b9-403d-b109-1bb51c4f2574/cpz159-fig-0007-m.jpg</p>\nFigure 7",
    "Analyzing reads. (A) Use the inspector viewer to drill down to individual reads and their alignments. (B) View short reads aligning to a reference protein. (C) Run gene-centric assembly on all reads assigned to a specific gene or functional class. (D) Resulting contigs can be uploaded to NCBI and aligned there using BLAST, from within MEGAN.\n9. Gene-centric assembly (optional).\nGenome assembly of short read microbiome shotgun data is challenging (Boisvert et al., 2012[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0006]), and metagenome assembled genomes (MAGs) often consist of large collections of small contigs (Kang, Froula, Egan, & Wang, 2015[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0022]). An alternative approach is to attempt to assemble individual gene families into contigs corresponding to genes from different genomes (Huson et al., 2017[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0019]).\nTo apply gene-centric assembly in MEGAN, open the function viewer of interest and uncollapse all nodes (as described above). Further, select a leaf of interest, for example acetolactate synthase in the eggNOG viewer, and then use the File → Export → Gene-Centric Assembly… menu item or corresponding node context menu item to open the gene-centric assembly dialog (Fig. 7C[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0007]). Press Apply to launch the assembly process.\nUpon completion of gene-centric assembly, MEGAN will report basic assembly statistics, and the user will be presented with a dialog that can be used to launch a BLAST alignment of the resulting gene sequences on NCBI (Fig. 7D[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0007]). The contigs and resulting alignments can be opened as a new MEGAN document in RMA format.\n10. Comparison of DAA files.\nMost microbiome projects involve multiple samples, and these must be analyzed in a comparative manner. To address this, MEGAN uses the concept of a comparison document that contains the result of the taxonomic and functional analysis of multiple individual samples, but not the corresponding reads and alignments (Fig. 8[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0008]).",
    "A comparison document is usually created from a set of meganized DAA files (e.g., for all samples SRR7828855-SRR7828865) using the compare dialog, which is opened by selecting the File → Compare… menu item (Fig. 8A[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0008]).\nThe dialog provides buttons to choose whether the comparison is to be based on absolute counts or relative counts (normalized to the smallest sample size in the input), with the option to ignore all reads that are unassigned. Upon pressing Apply, a new comparison document will be created.\nA newly computed comparison document can be saved to a file (extension .megan) using the File → Save As… menu item and reopened using the File → Open… menu item. The file is a small text file and thus can easily be shared, e.g., via e-mail.\nA comparison document is displayed using the same taxonomy and functional viewers as for a single meganized DAA file (Fig. 8B[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0008]).\nEach sample in a microbiome project has associated metadata, reflecting technical parameters such as DNA extraction protocol, sequencing run, etc., and biological attributes, such as disease state, age, gender, etc., for human-associated samples. Metadata can be used both in visualization and statistical analysis.\nMetadata should be prepared in a text file in tsv (tab-separated value) format. The first line starts with the special tag #SampleID followed by the names of all attributes (such as “Patient,” “Tumor type,” etc.). Then, there should be one row for each sample, with each row starting with the name of the sample (file name without path or suffix), then followed by the values for all the named attributes.\nMetadata can be imported into a comparison document (but also into an individual meganized DAA file) using the File → Import → Metadata… menu item (Fig. 8C[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0008]).",
    "MEGAN provides a “Samples Viewer” that provides access to the imported metadata, and allows one to color, label, style, or group samples by attributes (Fig. 8D[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0008]). The samples viewer is opened using the Window → Samples Viewer… menu item or the corresponding toolbar button.\nFor example, to color samples by a specific attribute, perform a context click on the table header for the given attribute, use the context menu to select all values, and then select the Use to Color Samples context menu item.\nThe samples viewer also provides methods for computing new comparison documents based on sub-selections or grouping of the samples. For example, the Options → Compute Core Biome… can be used to compute a new document containing those taxa that are present in large proportion of the samples at a high enough proportion or abundance.\nFor a comparison document, each taxonomic (or functional) node is displayed as a pie chart, coxcomb chart, bar chart, or heatmap, so as to indicate how many reads from each sample are assigned to the node (Fig. 8B[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0008]). The displayed counts can be scaled linearly, by square root, or logarithmically. These aspects of the visualization are selected using the corresponding Layout menu items or tool bar items.\nTaxonomic charts can be opened in the same way as described above. For example, in Figure 9A[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0009], we show a stacked bar chart displaying the percent of reads assigned to nodes of the taxonomic rank of class. In part D of the same figure, we show a plot that correlated a set of metadata attributes, subject age, height, and weight, with read counts assigned at the taxonomic rank of class.",
    "Alpha diversity, or within-sample diversity, can be computed in MEGAN by selecting either the Options → Shannon-Weaver Index menu item or the Options → Simpson-Reciprocal Index menu item. Either measure will be calculated on the set of currently selected nodes, and the results will be written to the message window (Fig. 9B[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0009]).\nBeta diversity, or between-sample diversity, can be calculated using a number of different measures. To calculate such measures on a comparison document in MEGAN, open the cluster analysis viewer using the Window → Cluster analysis… menu item. MEGAN provides implementations of the Bray-Curtis ecological index (Bray & Curtis, 1957[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0008]), Jensen-Shannon divergence (JSD), euclidean distances, and a number of other measures, which can be selected from the cluster analysis viewer's Options menu.\nThe measures are computed based on the currently selected nodes in the corresponding taxonomic (or functional) viewer, and the resulting distances are used to generate a PCoA (principal coordinate analysis) plot, a hierarchical clustering, an unrooted tree, an unrooted phylogenetic network, and a simple matrix, each displayed in a different tab.\nThe PCoA plot can be customized in a number of ways; one can select between two and three dimensions, select which principal components to display, and turn on both bi-plot and tri-plot vectors. For example, in Figure 9C[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0009], the bi-plot (shown in green) indicates that Helicobacter pylori is a main cause of differences between samples, whereas the tri-plot (show in orange) displays metadata-correlated variation.\nNote that using euclidean distances and PCoA together is mathematically equivalent to performing a PCA (principal component analysis) calculation.",
    "The naïve LCA and other similar algorithms used for taxonomic binning assign reads to taxa on different ranks of the NCBI taxonomy (Fig. 9D[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0009]). As a consequence, the number of reads assigned at any given rank of the taxonomy might be much lower than the total number of assigned reads. This problem can be addressed, to a degree, using taxonomic projection, a simple algorithm that maps all read counts on a taxonomy to a selected rank. It operates by pushing all counts down the tree, from the root toward the selected rank, passing down counts to children in proportion to the number of reads assigned to a given child, or one of its descendants. This method is run using the Options → Project Assignments to Rank….\nA functional comparison of multiple samples is very similar to the described taxonomic comparison (Fig. 10[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0010]). The same visualizations, charts, and alpha- and beta-diversity are provided for all functional viewers.\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/42ede39d-40b3-4fbc-b1c2-8dad0b5f61cd/cpz159-fig-0008-m.jpg</p>\nFigure 8\nWorking with multiple samples. (A) Use the compare dialog to setup a comparison document for multiple samples. (B) The comparison document can be explored using the taxonomic and functional viewers. (C) Metadata for all samples can be imported. (D) The sample viewer can be used to view metadata, for coloring and styling samples, and for extracting new comparison documents.\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/8d7e444b-37f2-4749-9697-a9c7ca2e12f2/cpz159-fig-0009-m.jpg</p>\nFigure 9\nTaxonomic diversity plots. (A) A stacked bar chart displaying percent assigned at the taxonomic rank of class. (B) Alpha diversity calculated for rank of species. (C) PCoA plot at rank of species, using Bray-Curtis distances. (D) A plot correlating subject age, height, and weight with assigns at the taxonomic rank of class.\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/5c27ae23-6ce0-4860-be61-cfc2f25493c8/cpz159-fig-0010-m.jpg</p>\nFigure 10",
    "Functional comparison (A) A functional viewer (eggNOG) for a comparison document, using heatmaps to indicate different samples. (B) PCoA plot for a functional viewer (eggNOG), using Bray-Curtis distances.\n11. Exporting data (optional).\nData computed in MEGAN can be exported in a number of different ways, so as to allow additional analysis using other tools. The File → Export submenu provides 18 different menu items for exporting data, many of which support multiple formats. The taxonomic or functional classification of reads can be exported in a large number of different ways, in csv or tsv format. This is done by first selecting all nodes of interest in a taxonomic or functional viewer, and then selecting the File → Export → Text (CSV)….\nIn Figure 11A[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0011] we show how to export the number of reads assigned to a particular taxon, the latter to be reported as a path from the root of the taxonomy down to the specific taxon.\nAny chart can be exported as an image using the File → Export Image menu item, and using the File → Export Legend… menu item for its legend. The data displayed in a chart can be exported using the File → Export Data… menu item (Fig. 11B[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0011]).\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/7daddeb8-b277-4cdc-a0b7-678302fceea5/cpz159-fig-0011-m.jpg</p>\nFigure 11\nData export. (A) How to export the number of reads assigned to a specific taxonomic path. (B) How to export a chart and the corresponding data used to create it.",
    "Before you can run the core DIAMOND+MEGAN analysis pipeline, there are a number of preprocessing steps to be considered. You may need to acquire public sequencing data. Usually, you will perform quality control, quality trimming, and contamination filtering on your input data.\n1. Data acquisition.\nThe Sequence Read Archive (SRA) is a major source of microbiome sequencing datasets. The SRA Toolkit is a collection of tools that can be used to access the stored data in an efficient manner. For example, the program fastq-dump can be used to download sequences in fastq format. To download the data used in this protocol, we ran the command on all identifiers assigned to the referenced project (SRR7828855-SRR7828865):\n         \nfastq-dump -I --split-files --gzip (identifier)\nThe --split-files option needs to be omitted for long read and single-end short read sequencing datasets, and the option --table SEQUENCE should usually be specified for long read datasets.\nDetails of all parameters can be found on the fastq-dump website.\n2. Quality control.\nThe first step of any data analysis is to take a look at the data to check for obvious problems (the example dataset used in Basic Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-prot-0001] does not have any particular problems). FastQC is widely used form Illumina short reads. It can be run as follows:\n         \nfastqc -f fastq -o (output directory)\n--extract -d (temporary directory) (input files)\nThe output is a collection of files in HTML format. These can be opened and viewed using a web browser and will provide an analysis of the quality of the sequencing data.\n3. Quality trimming and contamination filtering.\nIt is not uncommon to analyze microbiome sequencing data without performing quality trimming and contamination control, especially if sequence assembly is not performed and the data is not host associated.",
    "Because the example data is human-associated, here we illustrate this process using the tool KneadData ? (https://github.com/biobkery/kneaddata[href=https://github.com/biobkery/kneaddata])? for quality trimming and host-associated contamination filtering. This first uses trimmomatic (http://www.usadellab.org/cms/?page=trimmomatic[href=http://www.usadellab.org/cms/?page=trimmomatic]) (Bolger, Lohse, & Usadel, 2014[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0007]) to trim poor-quality bases from the ends of the sequencing reads. It then uses bowtie2 (Langmead & Salzberg, 2012[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0026]) to compare all reads against the human genome to remove human reads.\nKneadData requires a bowtie2 index of the host genome (here, human genome) to be filtered. This is downloaded using the command:\n         \nkneaddata_database --download human_genome bowtie2\nBased on the information given in the respective publication, the tool was applied with the following parameters for the example dataset of Basic Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-prot-0001]:\n         \nkneaddata --input SRR7828855_1.fq --input SRR7828855_2.fq -db human-genome-db\n--output (output directory)\n-t 32 --trimmomatic-options=\"SLIDINGWINDOW:4:20 MINLEN:50\"\n--bowtie2-options=\"-very-sensitive -dovetail\"\n--output-prefix SRR7828855_kneaddata\nThe example dataset consists of overlapping read pairs, and so a tool may be applied to merge the pairs. Here we used the program fastq-join. It can be installed via conda using the command:\n         \nconda install -c bioconda fastq-join\nThe program is executed on the output of KneadData for the example dataset as follows:\n         \nfastq-join SRR7828855_kneaddata_1.fastq SRR7828855_kneaddata_2.fastq -o fastq-join/SRR7828855_%.fastq\nThe program fastq-join produces four output files, each replacing the “%” placeholder in the -o argument (fastq-join/SRR7828855_%.fastq for the above command, fastq-join being the directory where the files will be written). For example, the file SRR782885_join.fastq contains reads that were successfully merged, and SRR782885_un1.fastq and SRR782885_un2.fastq contain the reads that were not merged for the first and second read pairs, respectively. Before carrying out downstream analysis, we concatenate these three files in order to not lose any information, as follows:\n         \ncat fastq-join/SRR7828855*.fastq > fastq-join/SRR7828855_merged.fastq\nIn Basic Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-prot-0001], we use only the files that are output of the cat command (quality trimmed, contamination filtered, overlapping read-pairs merged).",
    "This protocol describes the analysis of a typical single sample from a long read microbiome shotgun sequencing project, obtained using a third-generation sequencer, such as an ONT (Oxford Nanopore Technologies) MinION or a PacBio (Pacific Biosciences) sequencing device.\nThe analysis described here is built around the core pipeline depicted in Figure 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0001]. For long reads, we add two steps. In a preprocessing step, all reads are assembled. The assembly of long read datasets, although more error-prone, results in some complete or near-complete, often circular chromosomes, and some contigs. The assembled, longer sequences make the task of accurate taxonomic binning easier, as well as making it possible to obtain a more complete and meaningful annotation of the genomes. In an optional post-processing step, contigs are subjected to protein-reference-based frame-shift correction, and then taxonomic bins are analyzed for completeness, contamination, and strain heterogeneity using a tool such as CheckM (Parks, Imelfort, Skennerton, Hugenholtz, & Tyson, 2014[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0034]).\nLong read sequencing data differ from short read sequencing data in terms of length, of course, but also in other aspects, including being more error-prone, even after assembly, and showing a high variability of sequence length.\nLong reads and long read assemblies can contain many insertion and deletion errors, which cause problems when performing sequence alignment against the NCBI-nr protein reference database. To address this, we employ DIAMOND in frame-shift-aware alignment mode and use a long read version of the LCA algorithm for taxonomic binning in MEGAN (Huson et al., 2018[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0016]). To address the length variability of long reads and contigs, instead of reporting the number of reads assigned to each taxonomic node, we report the number of aligned bases.",
    "In this protocol, we will illustrate the necessary steps using a published dataset (Arumugam et al., 2019[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0002]) that was collected from an enrichment bioreactor seeded with waste-water treatment sludge. The total dataset consists of ∼695, 000 long reads with an average length of 9 kb, totaling approximately 6 Gb of sequence.\nTo download the sequencing dataset, please follow Support Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-prot-0002] using the SRA accession SRR8305972.\n1. Assembly.\nDe novo assembly of genomes from microbiome shotgun sequencing data is a long-standing, difficult problem. Short reads generated by second-generation sequencers are usually not informative enough to resolve repeats and conserved regions in genomes, resulting in disappointingly short contigs and scaffolds (Boisvert et al., 2012[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0006]). Long reads obtained by third-generation sequencing technologies overcome the problem of resolving repeats and conserved regions in metagenomes, and allow the assembly of complete, circular microbial genomes (Arumugam et al., 2019[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0002]; Moss, Maghini, & Bhatt, 2020[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0031]).\nIn this protocol step, we describe the use of the long read assembly pipeline Unicycler (Wick et al., 2017[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0046]). There are a number of other tools for the assembly of long read metagenomic datasets, such as Flye (Kolmogorov, Rayko, Yuan, Polevikov, & Pevzner, 2019a[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0023]) and Canu (Koren et al., 2017[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0025]), each with specific advantages and drawbacks (Wick & Holt, 2019[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0045]).\nUnicycler is a bacterial genome assembly pipeline that can run on long-reads-only datasets, as well as on hybrid (long read and short read) datasets. Here we describe the use of long-reads-only mode. In long-reads-only mode, the Unicycler pipeline consists of minimap2 (Li, 2018[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0028]) and miniasm (Li, 2016[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0027]) for assembly, racon (Vaser et al., 2017[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0043]) for building consensus, and tBLASTn (Altschul et al., 1997[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0001]) for detecting the origin of replication in circular genomes.",
    "Unicycler requires only two parameters in long-reads-only mode: -l for the input reads (fastq file, can be gzipped) and -o for the output directory. The additional parameters we use are -t for setting the number of CPU threads, and --keep 3 to retain intermediate files generated by the pipeline, which can be useful for inspecting the assembly later on. It is run like this for the example dataset:\n         \nunicycler -l SRR8305972.fastq.gz -o unicycler_asm -t (threads)\n--keep 3\nAdditionally, the assembly mode can be selected by the parameter --mode, which can take three values as input: conservative, normal, and bold, setting the trade-off between generating longer contigs and a higher risk of misassembly. We use the default setting, normal, in this protocol.\nUnicycler places all output in the specified output directory, which is unicycler_asm in the example command. The final assembly is written to a file called assembly.fasta. Other produced files include assembly.gfa, which contains the assembly graph, and 001_string_graph.gfa, which contains the raw string graph. Such GFA files can be visualized and explored using the Bandage program (Wick, Schultz, Zobel, & Holt, 2015[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0047]).\n2. Correcting errors in draft assemblies.\nLong-read-only assemblies of microbiome sequencing data can consist of long continuous, and even circular and complete sequences. However, the sequences will usually lack accuracy, which is due to systematic errors in sequencing, rather than random errors. Before continuing with the downstream analysis, these errors in the assembled contigs need to be corrected as much as possible. Racon (Vaser et al., 2017[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0043]), a fast consensus algorithm, is one of the error-correction tools commonly used after assembling error-prone long read datasets. Unicycler, the assembly pipeline employed here, already performs three rounds of error-correction by Racon.",
    "To improve the quality of the sequences further, we apply the tool medaka (ONT, 2020[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0033]), which is a neural-network based correction algorithm designed for sequences obtained using an ONT device.\nThe medaka_consensus executable, which runs the pipeline of medaka, takes as input the draft assembly (-d) (assembly.fasta in the Unicycler output directory), the raw reads (-i), and a model name describing both the flow-cell used and the version of the employed base-calling algorithm (-m). It requires an output directory to be specified (-o). The software is run as follows for the example dataset:\n         \nmedaka_consensus -i SRR8305972.fastq.gz -d assembly.fasta -o unicycler_medaka -t (threads)\n-m r941_min_high_g330\nIf medaka needs to be run again (e.g., due to an error), the -f option can be specified to override the output directory; otherwise medaka will use the existing files in the output directory. The -b (batch size, default: 100) option can be used to control the memory usage of medaka, e.g., -b 1000, to increase its performance by using 10 times more memory than the default.\nThe available models can be listed with the command: medaka tools_list models and new model files can be downloaded using the command medaka tools download_models. The model names follow the notation: chemistry_device_accuracy_basecaller. For the model used for the example dataset (r941_min_high_g330), that is, R 9.4.1 chemistry, MinION, High accuracy base calling, and guppy version 3.3.0.\nMedaka outputs the error-corrected assembly to a file called consensus.fasta in the specified output directory.\n3. DIAMOND comparison.\nDespite being error-corrected multiple times with several methods, long-read-only assemblies still contain errors, mostly insertions and deletions of single or a few bases. This causes problems for translated alignment algorithms such as BLAST×, because erroneous insertions and deletions cause frame-shifts that break alignments.",
    "To address this, DIAMOND provides a frameshift-aware alignment mode (Buchfink et al., 2015b[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0010]; Huson et al., 2018[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0016]), which is activated by specifying a frameshift penalty using the -F option. We use a penalty of 15, which appears to strike a good balance between producing long alignments without excessive switching of frames.\nBy default, DIAMOND reports a set of high-scoring alignments for a given query sequence, regardless of their position along the query. Applied to long reads or contigs, this usually results a list of alignments that cover only a small, highly conserved region of the query. Hence, for the alignment of long reads and contigs, DIAMOND provides an alternative reporting mode, range culling, that reports alignments that are high-scoring in comparison only with other alignments that cover the same region of the query. This feature is activated using the flag --range-culling, and we also set the parameter --top 10 to instruct the program to reports all alignments whose bit-score lies within 10% of the best score of competing alignments.\nUsing the final polished assembly file as input file (consensus.fasta in the medaka output directory), we run DIAMOND as follows for the example dataset:\n         \ndiamond blastx -q consensus.fasta -d nr.dmnd -o SRR8305972_unicycler.daa -F 15 -f 100 --range-culling --top 10 -p (threads)\nThe output file must have the file extension .daa.\n4. Taxonomic and functional binning.\nTo perform taxonomic binning of long reads or contigs, MEGAN provides an enhanced LCA approach called the interval-union LCA algorithm (Huson et al., 2018[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0016]). This algorithm considers alignments along the whole sequence and assigns the sequence to the most specific taxon that covers a high percentage of the aligned regions of the sequence.",
    "In more detail, the interval-union LCA algorithm works by first attempting to detect genes on the query sequence. This is done by grouping alignments based on their locations on the query sequence, and defining intervals where a gene starts and ends. The alignments are filtered locally within intervals, by their bit-score. The query sequence is then assigned to the taxon whose alignments cover at least the value of the Percent to cover parameter, or the taxon that is the lowest common ancestor of all taxa that are above this value.\nTo perform functional binning on each such interval, MEGAN sorts the alignments by bit score and assigns function of the first alignment in the sorted list that has a functional classification to the read. Thus, a query sequence can be classified into multiple functional categories, where each interval (each gene) is classified into a functional category.\nIn addition to using the interval-union LCA algorithm, when processing long reads or contigs, MEGAN reports the number of aligned bases, rather than number of reads, assigned to a given taxon or functional class.\nA DAA file produced by DIAMOND with the appropriate parameters discussed in the DIAMOND comparison paragraph can be meganized either using command-line tool daa-meganizer or using the meganize dialog of MEGAN, very much as described above for short reads.\nTo meganize the DAA file from the previous section, use this command:\n         \ndaa-meganizer -i SRR8305972_unicycler.daa -mdb megan-map-Jan2021.db --longReads",
    "Alternatively, DAA files for long reads can be meganized using the GUI. The meganize dialog in MEGAN is opened using the File → Meganize DAA File… menu item. After supplying the list of DAA files to be meganized, check the Long Reads box on the Files tab (Fig. 12A[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0012]). This will activate the interval-union LCA algorithm and the reporting of aligned bases, rather than read count. You can verify this by inspecting the LCA tab. Here, the LCA algorithm will show longReads (this refers to the interval-intersection LCA) and the Read Assignment mode will show alignedBases (Fig. 12C[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0012]). The Percent to cover will be set to 51%, by default. As described above for short reads, on the Taxonomy tab, select the mapping file (Fig. 12B[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0012]).\nMeganized DAA files can be inspected and analyzed the same way as in Basic Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-prot-0001] for short reads. Below we describe the functionality that is specific to long reads.\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/3fb38f6e-0ecc-49f0-b8a2-92cc35fe6d66/cpz159-fig-0012-m.jpg</p>\nFigure 12\nMeganize dialog for long reads. (A) Select the long reads check box. (B) Load the MEGAN mapping database. (C) Optionally, change the parameters for the employed LCA algorithm.\n5. Long read inspection.\nMEGAN provides a long read inspector that can be used to explore the alignments to reference proteins along a given long read or contig. To open this viewer for a specific taxon or functional class, select the node in the corresponding viewer and the choose the Inspect Long Reads… context menu item.\nThe long read inspector displays each sequence assigned to a given node in a separate row, listing the sequence name, length, taxonomic assignment, % coverage and number of alignments, together with an overview visualization of the sequence and its alignments to reference proteins (Fig. 13A[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0013]). Alignments are represented by arrows in the direction of translation.",
    "The visualization can be extended to show annotations of the aligned reference sequences, using the Layout drop-down menu item to select which classifications to use. The sliders on the right side and at the bottom of the window can be used to control the height of the rows and the zoom level of the layout of the alignments along the length of the sequence, respectively. Clicking on an arrow will select it, causing the corresponding alignments to be displayed in the message window. The context menu item Select Similar can be used to select all other arrows that represent alignments to the same taxon (Fig. 13B[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-fig-0013]).\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/cdec2041-b852-41b1-b976-3f1b1293b536/cpz159-fig-0013-m.jpg</p>\nFigure 13\nLong read inspector. (A) Overview visualization of all sequences assigned to a specific taxon, in this example Candidatus Competibacter phosphatis. (B) More detailed visualization showing the taxonomic assignment of aligned reference proteins, with all alignments to Candidatus Competibacter phosphatis selected.\n6. Exporting data.\nAll the methods for exporting data that are described above for short read microbiome sequences can also be applied to long read sequencing datasets. Here we describe two additional methods. The first can be used for short reads, too, whereas the second only makes sense for long read data.\nMEGAN allows the user to export all reads to taxonomic or functional class-specific files. To use this feature, select all nodes of interest in a taxonomic or functional viewer and then use the File → Extract Reads… menu item to open a new dialog to specify the filename to use for output. During saving, any occurrences of the special placeholders %t or %i in the filename will be replaced by the name of the class, or the class integer id, respectively, thus ensuring that the reads assigned to each selected class are written to a different file.",
    "As discussed above, even after multiple rounds of error correction, sequences assembled from long-reads-only datasets may contain many insertions and deletions, which leads to problems during translated alignment, thus significantly reducing the performance of tools like CheckM and Prokka (Seemann, 2014[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0041]) on assembled long reads.\nTo address this, MEGAN implements a heuristic that aims at reducing the number of erroneous insertions and deletions by inserting an additional N at locations where the DIAMOND alignments suggest that a base is missing (causing a frame-shift of +1 in the alignments), or two additional Ns where the DIAMOND alignments indicate that the sequence contains a superfluous base (causing a frame-shift of −1 in the alignments) (Huson et al., 2018[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0016]).\nTo save frame-shift-corrected sequences, select all nodes of interest in a taxonomic or functional viewer and then use the File → Export → Frame-Shift Corrected Reads… menu item to open a new dialog to specific the filename to use for output. Again, any occurrences of the special placeholders %t or %i in the output filename will be replaced by the name of the class, or the class integer id, respectively, during export.\nBoth export procedures described above can also be carried out on the command line, using the program read-extractor that can be found in MEGAN's tools sub-directory. The program takes as input a meganized DAA file (option -i), the name of an output file (option -o), which may contain occurrences of the special placeholders %t and %i that are replaced as discussed above, a classification name (option -c), such as Taxonomy or GTDB, and the flag -fsc, if frame-shift correction is desired.\nThe program is run like this for the example dataset:\n         \nread-extractor -i SRR8305972_unicycler.daa -o %t_%i.fasta -c classification\n-fsc",
    "Here, classification can be either Taxonomy or GTDB, and the output files will be written into the current directory with the format described above using the placeholders. The output can also be written into a directory, such as -o bins/%t_%i.fasta.gz. The -gz option can be used to compress the output files.\nThe alignment of reference proteins to long reads or contigs can be used to produce a crude annotation of the sequences, and this is implemented in MEGAN. To use this feature, select all nodes of interest in a taxonomic or functional viewer and then use the File → Export → Annotations in GFF Format… menu item to export the annotated sequences. The exported GFF file can then be visualized in an annotation viewer (Rutherford et al., 2000[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0040]; Thorvaldsdóttir, Robinson, & Mesirov, 2013[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0042]) or used in downstream analysis.",
    "As discussed above, MEGAN places all reads into taxonomic bins, using both the NCBI taxonomy and the GTDB taxonomy. In either case, these bins are candidates for being “metagenome assembled genomes” (MAGs). These putative MAGs can be exported from MEGAN in FastA format using the above-described export of frame-shift corrected sequences. The quality of these bins can optionally be assessed using a tool such as CheckM, as discussed below.\n1. Completeness and contamination analysis using CheckM.\nTo determine which of these output bins can be considered a high-quality MAG, we need to assess the level of completeness and level of contamination of each file.\nThe program CheckM (Parks et al., 2014[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0034]) takes as input a collection of putative taxonomic bins and provides measures of completeness and contamination of each bin, based on the detection analysis of clade-specific, single-copy marker genes.\nCheckM requires an input directory containing one FASTA file per bin, such as exported by MEGAN, as described above. The command to execute the standard pipeline is:\n         \ncheckm lineage_wf --tmpdir tmp -t (threads)\n--pplacer_threads (threads)\n-x fasta --tab_table -f SRR8305972_checkm.txt bins/ checkm_out/\nHere, option --tmpdir specifies a temporary directory for use by the program, -t and --pplacer_threads sets the number of threads used by the program and during pplacer calculations, -x specifies the extension of the input files (e.g., fasta, fa, or fna), --tab_table makes the output tab-delimited, which is written into the file specified after -f, the directory called bins/ here is the input directory with all input files (e.g., the output of read-extractor from the Basic Protocol 2[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-prot-0003], step 6., “Exporting data”), whereas all intermediate and output files are written to the specified output directory (here checkm_out).",
    "In Table 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-tbl-0001], we present the CheckM results for all taxonomic bins exported from the GTDB taxonomy that show at least 50% completeness.\nHighlighted in gray, for each taxonomic bin (column Bin Id), we list the reported percentage of completeness (Compl.), contamination (Cont.), and strain heterogeneity (SH). These values are inferred from lineage-specific marker genes. The Marker lineage column reports the most specific lineage CheckM could detect for the bin, whose marker genes were used for the analysis. The # Genomes column contains the number of genomes in the lineage used, while the # Markers and #Marker Sets columns contain number of marker genes and co-located marker gene sets for the lineage, respectively. The columns #0, #1, and #2 contain the number of genes found within the bin with the given number of copies. As CheckM uses single-copy marker genes, for a complete and uncontaminated genome, each marker gene should be found exactly once. Completeness and contamination are calculated based on the copy numbers of marker genes, whereas strain heterogeneity is an estimate of how much of the detected contamination is from a closely related organism.\nTable 1.\n                CheckM results for the example dataset\ntable:\n﻿Bin ID,Marker lineage,#G,#M,#MS,#0,#1,#2,Compl.,Cont.,SH\nBacteroidetes bacterium OLB12,k Bacteria (UID2570),433,274,183,13,261,0,95.28,0.0,0.0\nCandidatus Accumulibacter,c Betaproteobacteria (UID3971),223,422,210,24,395,3,95.19,1.11,0.0\nGammaproteobacteria,c Gammaproteobacteria (UID4266),1097,270,172,13,243,14,95.07,4.99,0.0\nChlamydiia,k Bacteria (UID2982),88,230,148,12,215,3,94.6,1.58,0.0\nRhodospirillaceae,o Rhodospirillales (UID3754),63,336,201,16,319,1,94.12,0.5,0.0\nBacteroidetes bacterium OLB8,p Bacteroidetes (UID2591),364,302,202,14,286,2,94.04,0.99,0.0\nChlorobi bacterium OLB5,k Bacteria (UID2570),433,273,183,25,246,2,90.87,0.66,0.0\nunclassified Thauera,f Rhodocyclaceae (UID3972),30,540,241,89,443,8,85.47,1.9,62.5\nBacteroidetes,p Bacteroidetes (UID2591),364,303,203,43,238,22,83.16,5.61,4.55\nunclassified Nitrospira,k Bacteria (UID3187),2258,181,110,36,138,7,82.75,4.77,0.0\nSphingobacteriales bacterium 44-15,p Bacteroidetes (UID2591),364,302,203,85,211,5,74.54,2.46,12.5\nChloroflexi bacterium,k Bacteria (UID1452),924,163,110,63,74,23,59.06,17.09,3.12\nCandidatus Competibacter phosphatis,k Bacteria (UID203),5449,104,58,69,32,3,53.45,4.31,33.33\nChloroflexi,k Bacteria (UID1452),924,163,110,73,72,15,52.67,19.09,16.67",
    "aA given bin, we report the percent completeness (Compl.), contamination (Cont.), and strain heterogeneity (SH) estimated by CheckM. In addition, we report the marker lineage used by CheckM to analyze the bin, and for that lineage, the number of genomes (#G), markers (#M), and marker sets (#MS), as well as the number of marker genes found 0, 1, or 2 times (columns #0, #1 or #2, respectively).\n2. Alternative assembly using Flye.\nFlye (Kolmogorov, Yuan, Lin, & Pevzner, 2019b[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0024]; Kolmogorov et al., 2019a[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0023]) is a long read assembly program, which also supports Nanopore-only assemblies of microbiome samples. It can be used as an alternative to the Unicycler pipeline. Flye performs better than Unicycler in terms of recovering plasmids and generating slightly more reliable assemblies, whereas Unicycler is better at achieving higher rates of complete, circular assemblies (Wick & Holt, 2019[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-bib-0045]). Flye can be installed through conda with the command:\n         \nconda install -c bioconda flye\nFor the example dataset from Basic Protocol 2[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.59#cpz159-prot-0003], it can be run as:\n         \nflye --nano-raw SRR8305972.fastq.gz -g 4m -o SRR8305972_flye_asm --plasmids --meta -t (threads)",
    "The nano-raw option specifies the location of the raw base-called fastq file for Nanopore data. Alternatively, the --nano-corr option can be used for input reads that have undergone a preliminary error-correction step. The assembler also supports long reads generated by PacBio sequencers, using the options --pacbio-raw, --pacbio-corr, and --pacbio-hifi for raw, error-corrected, and HiFi reads, respectively. Flye expects an estimate of the genome size with the -g option (e.g., 4m); however, this option has very little effect in metagenome mode (it is nevertheless required, here we set it to 4m). The option -o specifies output directory. The flag --plasmids instructs Flye to look for plasmids in the dataset. The flag --meta turns on the metagenome assembly mode. The option -t sets the number of threads to use.\nFlye outputs the assembled contigs in a file called assembly.fasta in the output directory, as well as the assembly graph in assembly_graph.gfa and assembly_graph.gv files."
  ],
  "subjectAreas": [
    "Bioinformatics"
  ],
  "bigAreas": [
    "Bioinformatics & Computational Biology"
  ]
}