{
  "id": 2317,
  "origin_website": "Cell",
  "title": "Extraction of CRISPR-targeted sequences from the metagenome",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nPreprocess raw paired FASTQ files\nTiming: 1–2 h\nThis process is quality control of the input sequences.\nAlternatives: A pipeline script for preprocessing, assembling, and spacer collection is provided in the repository[href=https://doi.org/10.5281/zenodo.6621424] (pipeline_scripts/assembly_pipeline.sh).\nTrim poor-quality bases, adapters, and PhiX spikes.\n$ bbduk.sh -Xmx100g t=8 in1=r1.fastq.gz in2=r2.fastq.gz out=trimmed.fastq.gz ftm=5 qtrim=rl trimq=20 ftl=15 ref=adapters,phix ktrim=r k=23 mink=11 hdist=1 tpe tbo maq=20\nRemove human-derived reads.\n$ bbmap.sh -Xmx100g t=8 ref={path to the human reference FASTA file} in=trimmed.fastq.gz outu=decontaminated.fastq.gz interleaved=t minratio=0.9 maxindel=3 bwr=0.16 bw=12 fast=t minhits=2 qtrim=r trimq=10 untrim=t idtag=t printunmappedcount=t kfilter=25 maxsites=1 k=14\nNote: We used the human genome reference FASTA file posted by the author of BBtools[href=https://www.seqanswers.com/forum/bioinformatics/bioinformatics-aa/37175-introducing-removehuman-human-contaminant-removal].\nCorrect errors in the reads.\n$ tadpole.sh threads=8 -Xmx100g interleaved=t in=decontaminated.fastq.gz out=ecc.fastq.gz mode=correct\nCritical: This output FASTQ file is analysis-ready and used for assembly and spacer extraction.\nMetagenome assembly\nTiming: 1–12 h (Varies strongly depending on library)\nAssemble metagenome contigs from the preprocessed FASTQ files.\nAssemble preprocessed FASTQ file using SPAdes.\n$ spades.py -t 8 -m 100 --meta --only-assembler --12 ecc.fastq.gz -o {path to spades output directory}\nNote: We skipped the error-correction step in the SPAdes program to avoid the occasional endlessly running problem. Please refer to the troubleshooting[href=https://www.wicell.org#troubleshooting] section for detail.\nAssign unique identifiers to all assembled contigs.\n$ cd {path to spades output directory}\n$ id=$(openssl rand -hex 12)\nawk -v id=${id} '/ˆ>/ {n++; print \">contig_\"id\"_\"n;} !/ˆ>/{print}' scaffolds.fasta > scaffolds.renamed.fasta\nCritical: Assigning unique identifiers is important to avoid conflicts in the later analyses. Here, we used randomly generated strings; however, any unique readable identifier, such as sample IDs, could be used instead.\nOptional: We recommend removing contigs shorter than 1k bases to reduce the file size.\nNote: The pre and assembling processes are independently conducted for each paired FASTQ file.",
    "Optional: We advise that the system has sufficient disk space to store all preprocessed FASTQ and assembled FASTA files. The rest of the files, including intermediate and temporary files, can be deleted to save the disk space.\nExtraction of CRISPR direct repeats from the assembled contigs\nTiming: 1–2 h\nFrom the assembled contigs, discover CRISPR consensus direct repeats.\nRun CRISPRDetect to discover consensus CRISPR direct repeats.\n$ CRISPRDetect.pl -q 0 -f scaffolds.renamed.fasta -o crispr_detect_output -array_quality_score_cutoff 2\nFrom the output gff file, extract direct repeats, and convert them into a FASTA file.\n$ grep 'repeat_region' crispr_detect_output.gff | cut -f 9 | tr ';' '∖n' | egrep 'ˆNote=' | cut -f 2 -d '=' | awk '{n++; printf(\">DR_%i∖n%s∖n\", n, $0)}' > crispr_dr.fasta\nNote: Again, these direct repeat extractions are independently conducted for each assembled FASTA file.\nAfter discovering all direct repeats from each assembled FASTA file, we merge them into a single file, assign unique identifiers, and remove redundancy.\n$ cat {all crispr dr fasta files} > merged_crispr_dr.fasta\n$ awk '/ˆ>/ {n++; print \">dr_\"n; } !/ˆ>/ {print}' merged_crispr_dr.fasta > merged_crispr_dr.renamed.fasta #giving new unique identifiers\n$ cd-hit-est -S 1 -c 1 -i merged_crispr_dr.renamed.fasta -o merged_crispr_dr.repr.fasta\nOptional: We provided the direct repeat sequences extracted from the human gut metagenomes in the previous study. The sequences are stored in a FASTA formatted file located in the supplementary folder (supplementary_data/crispr/drs/all_dr.clustered.fasta).\nExtraction of CRISPR spacers from the preprocessed reads\nTiming: 1 h\nAlternatives: A pipeline script for the spacer collection is provided in the repository[href=https://doi.org/10.5281/zenodo.6621424] (pipeline_scripts/collect_spacers.sh).\nHere, we return to the preprocessed FASTQ files. From them, we extract CRISPR spacers from reads containing CRISPR direct repeats.\nExtract direct repeat-containing reads. This initial filtering step significantly reduces the number of reads, effectively speeding up the following spacer extraction processes.\n$ bbduk.sh in=ecc.fastq.gz ref=merged_crispr_dr.repr.fasta outm=dr_containing_reads.fastq.gz interleaved=t k=21 hdist=1 rename=t",
    "Second filter to mask the direct repeats in the reads.\n$ bbduk.sh in=dr_containing_reads.fastq.gz ref=merged_crispr_dr.repr.fasta kmask=R k=19 hdist=1 out=dr_masked.fastq mink=15\nExtract spacers from the masked reads using our python script.\n$ {path to the virome_scripts directory}/pipeline_scripts/extract_spacers.py -s {sample name} dr_masked.fastq > spacers.fasta\nNote: The python script used above is available from our repository[href=https://doi.org/10.5281/zenodo.6621424] (pipeline_scripts/extract_spacers.py).\nOptional: The python program used above does not output short (<20 bp) and long (>50 bp) sequences by default. These parameters can be changed by options (-s and -l).\nNote: Spacer extraction is conducted for each preprocessed FASTQ file.\nMerge all discovered spacers, assign unique identifiers, and remove redundancy.\n$ cat {all spacer fasta files} > all_spacers.fasta\n$ awk '/ˆ>/ {sub(/ˆ[ˆ[:space:]]+[[:space:]]/, \"\"); n++; printf(“>spacer_\"n\"∖t\"$0);} !/ˆ>/ {print}' all_spacers.fasta > all_spacers.renamed.fasta #giving new unique identifiers\n$ cd-hit-est -T 8 -M 10000 -d 0 -sf 1 -s 0.9 -c 0.98 -i all_spacers.renamed.fasta -o all_spacers.repr.fasta\nOptional: It is highly advisable to make each spacer and direct repeat trackable to the original samples, contigs, and/or associated direct repeats. This can be achieved using FASTA descriptions in each record.\nOptional: We provided the spacer sequences extracted from the human gut metagenomes in the previous study. The sequences are stored in a FASTA formatted file located in the supplementary folder (supplementary_data/crispr/spacers/all_spacers.clustered.removed_short.fasta).\nProtospacer discovery\nTiming: 1–2 h\nHere, we discover protospacers by aligning the spacer sequences to CRISPR-masked contigs.\nSearch CRISPR direct repeats from the contigs.\n$ makeblastdb -dbtype nucl -in scaffolds.renamed.fasta\n$ blastn -evalue 1e-5 -task ‘blastn-short’ -outfmt 6 -num_threads 8 -query merged_crispr_dr.repr.fasta -db scaffolds.renamed.fasta > dr.blastn\nMask sequences around direct repeat aligned regions.\n$ samtools faidx scaffolds.renamed.fasta",
    "$ awk ‘BEGIN{FS=\"∖t\"; OFS=\"∖t\"} $10<$9{t=$9; $9=$10; $10=t} {print $2,$9–1,$10}' dr.blastn | sort -k1,1 -k2,2n | bedtools merge -i /dev/stdin -d 60 | bedtools slop -b 60 -i /dev/stdin -g scaffolds.renamed.fasta.fai | bedtools maskfasta -bed /dev/stdin -fi scaffolds.renamed.fasta -fo crispr_masked.fasta\nAlign spacers to the masked contigs.\n$ makeblastdb -dbtype nucl -in crispr_masked.fasta\n$ blastn -evalue 1e-5 -perc_identity 93 -task ‘blastn-short’ -outfmt 6 -num_threads 8 -query all_spacers.repr.fasta -db crispr_masked.fasta > spacers.blastn\nNote: Protospacer search is conducted for each assembled FASTA file.\nMerge all discovered protospacers into a single BED-formatted file.\n$ cat {all spacer blastn output files} | awk ‘BEGIN{FS=\"∖t\"; OFS=\"∖t\"} $10<$9{t=$9; $9=$10; $10=t} {print $2,$9–1,$10,$1}' | sort -k1,1 -k2,2n > all_protospacers.bed\nOptional: We provided the protospacers discovered from the assembled human gut metagenome contigs in the previous study. The protospacers are stored in a BED-formatted file located in the supplementary folder (supplementary_data/targeted_sequences/protospacers/all_protospacers.bed).\nSpacer clustering based on co-occurrence\nTiming: 2–4 h\nHere, we cluster spacers using a co-occurrence network calculated from the spacer alignment result. From this network, we discover the graph communities, representing subsets of spacers that corresponding protospacers co-occur together across the assembled contigs. We extract the protospacer-enriched regions using these graph communities, i.e., spacer clusters. This process effectively reduces the false-positive ratio by excluding lone or randomly scattered protospacers.\nInitial clustering is based on distance.\n$ bedtools cluster -d 50000 -i all_protospacers.bed | awk ‘BEGIN{FS=\"∖t\"; OFS=\"∖t\"} {print $1\"_cluster_\"$5,$2,$3,$4}' > initial_cluster.bed\nCalculate a weighted graph from the spacer co-occurrence and generate an abc formatted file.\n$ {path to the virome_scripts directory}/graph_clustering/generate_abc_edgefile.py initial_cluster.bed > protospacers.abc\nNote: The python script used above is available in our repository[href=https://doi.org/10.5281/zenodo.6621424] (graph_clustering/generate_abc_edgefile.py).\nConvert the abc file into an mci format.\n$ mcxload -abc protospacers.abc --stream-mirror -write-tab data.tab -o protospacers.mci\nRun an mcl program to discover graph communities.\n$ mcl protospacers.mci -I 4 -pi 0.4 -te 8",
    "Convert the mcl output to a tabular format.\n$ mcxdump -icl out.protospacers.mci.I40pi04 -tabr data.tab > protospacers_cluster.tab\nCritical: Each tab-delimited line within this output file consists of a spacer cluster.\nMark CRISPR-targeted regions using the clustering result and the merged protospacer bed file.\n$ {path to the virome_scripts directory}/graph_clustering/mark_crispr_targeted.py all_protospacers.bed protospacers_cluster.tab > crispr_targeted.bed\nNote: The python script used above is available in our repository[href=https://doi.org/10.5281/zenodo.6621424] (graph_clustering/mark_crispr_targeted.py).\nNote: The fourth column in the output file is formatted as {cluster id}:{protospacer count in the region}.\nMerge the regions to rescue the fragmented clusters.\n$ sort -k1,1 -k2,2n crispr_targeted.bed > crispr_targeted.sorted.bed\n$ bedtools merge -d 1000 -i crispr_targeted.sorted.bed -o collapse -c 4 > crispr_targeted.merged.bed\nExtract CRISPR-targeted regions from the assembled contigs.\n$ samtools faidx scaffolds.renamed.fasta\n$ cut -f 1,2 scaffolds.renamed.fasta.fai | sort -k 1,1 | join -t $'∖t' - <(sort -k 1,1 crispr_targeted.merged.bed) | awk 'BEGIN{OFS=\"∖t\"; FS=\"∖t\"} $4>$2{$4=$2} {print $1,$3,$4,$5}' | bedtools getfasta -fi scaffolds.renamed.fasta -bed /dev/stdin -fo crispr_targeted.fasta\nNote: The extraction of CRISPR-targeted sequences is conducted for each assembled FASTA file.\nOptional: We provided the CRISPR-targeted terminally redundant sequences extracted from the assembled human gut metagenome contigs in the previous study. The sequences are stored in a FASTA formatted file located in the supplementary folder (supplementary_data/targeted_sequences/tr/tr_sequences.fasta)."
  ],
  "subjectAreas": [
    "Genomics",
    "Sequence Analysis",
    "Bioinformatics",
    "Systems Biology",
    "Crispr"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics",
    "Bioinformatics & Computational Biology"
  ]
}