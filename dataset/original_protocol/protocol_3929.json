{
  "id": 4133,
  "origin_website": "Cell",
  "title": "Processing single-cell RNA-seq data for dimension reduction-based analyses using open-source tools",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nSingle-cell read alignment and dropEst library quantification\nTiming: 5 h, for 120 million reads on a compute node with 12 cores and 48 GB of memory. 1.5 h for example subset dataset (GSM4804820) with the same specifications. Processing time decreases linearly with the number of cores available.\nThis section encompasses the library demultiplexing, read alignment, droplet count matrix estimation, and preliminary quality assessment with the DropEst library, the STAR aligner, and the scRNABatchQC R package, respectively (Dobin et al., 2013[href=https://www.wicell.org#bib5]; Liu et al., 2019[href=https://www.wicell.org#bib15]; Petukhov et al., 2018[href=https://www.wicell.org#bib18]). First, dropTag takes paired-end, raw .fastq files and tags them in the context of unique molecular identifiers (UMIs) and cellular barcodes for the demultiplexing process. This is dependent on the scRNA-seq platform’s barcode whitelist; in this case we use the inDrop V1 and V2 barcodes. Before running the actual alignment process, a genome index must first be generated with respect to the reference and annotation files. STAR is a fast, scalable RNA-seq aligner which has splice awareness and takes the multiple tagged fastq.gz files generated by dropTag and aligns them using a reference genome index. The sorted .bam file generated by STAR alignment is used as an input to dropEst, which generates a barcode by gene count matrix, or droplet matrix, from the STAR aligned transcripts. Finally, scRNABatchQC is used to provide summary statistics and a quality assessment of the generated droplet matrix. This droplet matrix is further filtered in the heuristic droplet filtering[href=https://www.wicell.org#sec3.2] and automated droplet filtering with dropkick[href=https://www.wicell.org#sec3.3] section variants.\nNote: This protocol serves as a reference for an order-of-operations and their parameters in our open-source pipeline; organized and executable scripts, with proper file and directory references, are available at: https://github.com/KenLauLab/STAR_Protocol/[href=https://github.com/KenLauLab/STAR_Protocol/].",
    "Critical: The dropEst repository should be made locally available to explore its configurations and files by cloning from https://github.com/hms-dbmi/dropEst[href=https://github.com/hms-dbmi/dropEst]. This repository is also fully available within the provided Singularity container, whose configs can be displayed with the following command:\nsingularity exec -e star_dropest_star_protocols_pipeline.sif ls /usr/share/dropEst/configs\nConfig files of interest can then be copied from the container to the local directory with the following, where <example.xml> is the file of interest:\nsingularity exec -e star_dropest_star_protocols_pipeline.sif cp /usr/share/dropEst/configs/<example.xml> .\nRun DropTag with the following:\nsingularity exec -e star_dropest_star_protocols_pipeline.sif droptag -c /usr/share/dropEst/configs/indrop_v1_2.xml reads_R1.fastq reads_R2.fastq\nThe following parameter is required:\nc, config filename: The file path to the .xml file containing estimation parameters within the Singularity container, which includes platform-specific information. Further parameters contained within this .xml file are described by Petukhov, et al. (Petukhov et al., 2018[href=https://www.wicell.org#bib18]): https://github.com/hms-dbmi/dropEst/blob/master/configs/config_desc.xml[href=https://github.com/hms-dbmi/dropEst/blob/master/configs/config_desc.xml]\n<reads_R1>, <reads_R2>: These are positional arguments which should be replaced with the paths to the fastq files representing the R1 and R2 reads respectively; set to “reads_R1.fastq” and “reads_R2.fastq” in this example. R1 corresponds to the barcode read and R2 corresponds to the gene read.\nPause point: The output of step 1 is saved as multiple tagged .fastq files, further detailed in the expected outcomes[href=https://www.wicell.org#expected-outcomes] section.\nCreate a directory for operations to be performed and generate the index file:\nmkdir STAR_index && singularity exec -e star_dropest_star_protocols_pipeline.sif \\ STAR --runThreadN 16 --runMode genomeGenerate \\\n--genomeDir STAR_index --genomeFastaFiles \\ primary_assembly.fa --sjdbGTFfile \\ annotation.gtf --sjdbOverhang 99\nTo create a genome index, the user must provide the reference genome (.fasta file) and the corresponding annotation file (.gtf) and run STAR with following parameters:\nrunMode: Mode to run, example set to “genomeGenerate”",
    "runThreadN: The number of threads to generate the index file with, this step speeds up with higher values and is limited by the CPU used. Set to “16” in the example.\ngenomeDir: Path to directory where files will be stored, set in example to “STAR_index”\ngenomeFastaFiles: Path to genome .fasta file, set in example to “primary_assembly.fa”\nsjdbGTFfile: Path to annotation .gtf file, set in example to “annotation.gtf”\nsjdbOVerhang: The number of bases to concatenate from donor and acceptor sides of splice junctions. Set in example as “99”.\nCritical: Step 2 must be re-run for different reference genome and annotation file versions, as the generated genomic index will be unique to each version.\nPause point: The output of step 2 is saved as a genomic index file, further detailed in the expected outcomes[href=https://www.wicell.org#expected-outcomes] section.\nRun the single-cell alignment process with STAR, using our Singularity container:\nsingularity exec -e star_dropest_star_protocols_pipeline.sif STAR \\\n--genomeDir STAR_index \\\n--readFilesIn reads.tagged.1.fastq.gz \\\n--outSAMmultNmax 1 --runThreadN 16 --readNameSeparator space \\\n--outSAMunmapped Within --outSAMtype BAM SortedByCoordinate \\\n--outFileNamePrefix reads \\\n--readFilesCommand gunzip -c\nThe following parameters are required:\ngenomeDir: The path to the directory containing the STAR index file. Set in example as “STAR_index”\nreadFilesIn: The path to the tagged .fastq file(s), where multiple tagged .fastq files can be input, set as “reads.tagged.1.fastq.gz” in example.\noutSAMmultNmax: Maximum number of multiple alignments for a read that will be output to the .sam/.bam files, example set to “1”\nrunThreadN: Number of threads, example set to “12”, increase value to speed up performance.\nreadNameSeparator: Characters separating the part of the read names that will be trimmed in output, example set to “space”\noutSAMunmapped: Output unmapped reads within the main ,sam file, example set to “Within”\noutSAMtype: Output formatting of .bam file, example set to “BAM SortedByCoordinate”",
    "outFileNamePrefix: Output file name prefix, set here as “reads”\nreadFilesCommand: Command to decompress fastq.gz files, example set to “gunzip –c”\nCritical: Ensure that there is sufficient memory overhead for this step, with a minimum of 32 GB allotted, as spikes in memory usage may prematurely end the alignment process.\nPause point: The output of step 3 is saved as a .bam, with several attributes, further detailed in the expected outcomes[href=https://www.wicell.org#expected-outcomes] section.\nRun DropEst, configured here for an inDrop library, with the following:\nsingularity exec -e star_dropest_star_protocols_pipeline.sif dropest -m -V -b -F -o sample_name -g annotation.gtf -L eiEIBA -c /usr/share/dropEst/configs/indrop_v1_2.xml readsAligned.sortedByCoord.out.bam\nThe following arguments are used in this step:\nm, merge-barcodes: Merge linked cell tags\nV, verbose: Output verbose logging messages\nb, bam-output: Print tagged bam files\nF, filtered-bam: Print tagged bam file after the merge and filtration\no, output-file filename: The output file name, example set to “sample_name”\ng, genes filename: Gene annotation file (.bed or .gtf), example set to “annotation.gtf”\nL: This is parameter has several options which denote the inclusion of count UMIs with reads that correspond to specific parts of the genome. Set to “eiEIBA” in the example.\ne: UMIs with exonic reads only\ni: UMIs with intronic reads only\nE: UMIs, which have both exonic and not annotated reads\nI: UMIs, which have both intronic and not annotated reads\nB: UMIs, which have both exonic and intronic reads\nA: UMIs, which have exonic, intronic and not annotated reads\nc, config filename: XML file with estimation parameters, example set to “./configs/indrop/v_1_2.xml”, further details can be found at: https://github.com/hms-dbmi/dropEst/blob/master/configs/config_desc.xml[href=https://github.com/hms-dbmi/dropEst/blob/master/configs/config_desc.xml]\n<readsAligned.sortedByCoord.out.bam>: Positional argument for the input bam file. Set in example as “readsAligned.sortedByCoord.out.bam”.\nCritical: Like step 3, this is a memory-intensive step. Ensure that there is sufficient memory overhead for this step, with a minimum of 32 GB allotted.",
    "Pause point: The output of step 4 is saved as a .bam and a .rds file, both with several attributes, further detailed in the expected outcomes[href=https://www.wicell.org#expected-outcomes] section.\nFrom the output of DropEst, generate sparse count matrices with the code as follows:\nsingularity exec -e star_dropest_star_protocols_pipeline.sif R --vanilla --slave -f /R_scripts/RDS_to_sparesematrix.r --args sample_name.rds\nThe following arguments are used in this step:\n--args: Path to the output .rds file, set in example as “sample_name.rds”.\nNote: The source of the invoked R script can be viewed from within singularity container using vi. This script simply loads the .rds file, its contained data, and writes matrix files that are interoperable between different processing pipelines:\nsingularity exec -e star_dropest_star_protocols_pipeline.sif vi /R_scripts/RDS_to_sparesmatrix.r\nPause point: The output of step 5 is saved as three files representing the droplet matrix, feature labels, and barcode labels, which are further detailed in the expected outcomes[href=https://www.wicell.org#expected-outcomes] section.\nFinally, generate a quality assessment report:\nsingularity exec -e star_dropest_star_protocols_pipeline.sif R --vanilla --slave -f /R_scripts/scRNABatchQC.r --args hsapiens sample_name.rds_cm.csv\nThe following arguments are used in this step:\n--args: Consists of two parts, positionally, the species and target .csv file. In this example, set as “hsapiens” and “sample_name.rds_cm.csv”.\nPause point: The output of step 6 is saved as an .html file, further detailed in the expected outcomes[href=https://www.wicell.org#expected-outcomes] section.\nVariant 1. Heuristic droplet filtering\nTiming: 15 to 30 min, depending on the size of the droplet matrix and cores available for certain parallelized functions.",
    "This section and its variant describe the barcode filtering of the droplet matrix, and can be used modularly if the user has a pre-computed matrix, either from the single-cell read alignment and DropEst library quantification[href=https://www.wicell.org#sec3.1] section of this protocol or an external source, so long as the rows represent cell barcodes and columns represent genes. The output for this section will be a cell matrix, differing from a droplet matrix in that it only contains gene read counts from only high-quality, intact single cells. Primarily, this section will be performed interactively with Jupyter Notebooks running within a Conda environment, making extensive use of the AnnData Python class and scanpy library. First, a data-driven cutoff, by means of finding the inflection point in a cumulative sum curve of ranked barcode counts, is generated and used to minimize information-spars barcodes. Second, a distribution of uniquely detected genes per droplet is automatically thresholded through Otsu’s method, separating the remaining information-rich and information-sparse droplets and generating a binary metadata label. Third, tissue-specific gene expression signatures are visualized after DR to pinpoint cell populations of interest for downstream analysis. Fourth, unsupervised clustering is performed to discretize the single-cell transcriptional landscape. Finally, by heuristically integrating these metrics and expression signatures, populations of intact single-cells and their respective high-quality transcriptomes can be selected and saved to an independent file.\nCritical: This section is performed entirely within a Jupyter Notebook available through Github at https://github.com/KenLauLab/STAR_Protocol/[href=https://github.com/KenLauLab/STAR_Protocol/]. To use this notebook, follow the instructions described in the python environment preparation[href=https://www.wicell.org#sec1.3] section of before you begin[href=https://www.wicell.org#before-you-begin]. For further information on how to navigate Jupyter Notebooks, see its documentation page: https://jupyterlab.readthedocs.io/[href=https://jupyterlab.readthedocs.io/].\nPrepare DropEst outputs from the single-cell read alignment and DropEst library quantification[href=https://www.wicell.org#sec3.1] section for analysis in an interactive Jupyter Notebook:\nimport scanpy as sc\nimport numpy as np\nimport QCPipe",
    "adata = QCPipe.qc.read_dropest(“<dir>”)\nadata.write_h5ad(“<filename.h5ad>”,compression=’gzip’)\nThis step uses the arguments:\n<dir>: The directory where the DropEst results are stored, specifically from step 5, set in example as “dir”\n<filename.h5ad>: Filename for the output .h5ad file, set in example as “filename.h5ad”\nPause point: The output of step 7 is saved as a compressed .h5ad file, further detailed in the expected outcomes[href=https://www.wicell.org#expected-outcomes] section.\nNote: For the heuristic droplet filtering[href=https://www.wicell.org#sec3.2], automated droplet filtering with dropkick[href=https://www.wicell.org#sec3.3], and post-processing and dimension reduction structure preservation analysis[href=https://www.wicell.org#sec3.4] sections of this protocol, adata is a common variable, which represents the AnnData object that scanpy methods operate on. adata is typically the parameter used for each function’s first positional argument.\nRestart the notebook kernel and reload the data, from file, as an AnnData object:\nimport scanpy as sc\nimport QCPipe\nimport numpy as np\nadata = sc.read_h5ad(“<filename.h5ad>”)\nadata.raw = adata #set the raw attribute\nadata.var[‘Mitochondrial’] = adata.var.index.str.startswith(<mitochondrial nomenclature>) #set the mitochondrial variable attribute\nsc.pp.calculate_qc_metrics(adata, qc_vars=[‘Mitochondrial’], use_raw=True, inplace=True)\nThe parameters in this code are as follows:\n<filename.h5ad>: The filename of the .h5ad file generated in step 7\n<mitochondrial nomenclature>: The mitochondrial nomenclature of the dataset, given the gene symbol. This will vary depending on the gene nomenclature and species. For example, human mitochondrial gene symbols are designated with “MT-”, whereas mouse symbols are preceded by “mt-”.\nNote: The following steps assume that the notebook kernel activated in step 8 is not subsequently deactivated or restarted; thus, library import statements are not detailed further.\nPerform the first-pass inflection point-based filtering:\nInflection_estimate = QCPipe.qc.find_inflection_point(adata)\nsc.pp.filter_cells(adata, min_counts=adata[Inflection_estimate].obs[‘total_counts’])\nAlternatively, the user can set a manual cutoff using an estimated number of encapsulated cells:\nsc.pp.filter_cells(adata, min_counts=adata[<estimated number of cells encapsulated>].obs[‘total_counts’])\nThe parameter in this code is as follows:",
    "<estimated number of cells encapsulated>: This number represents the estimated number of cells encapsulated during the library generation process and is based on the flow time and rate of the process.\nCritical: If the droplet matrix to be used in this step was generated through an external pipeline, ensure that it is ordered, starting with barcodes associated with the most to the least detected reads. Step 9 will fail if the data are not ordered as such. This ordering, however, is automatically performed in the DropEst output preparation in step 7.\nAutomatically identify cells with relatively high transcriptional diversity:\nadata = QCPipe.qc.relative_diversity(adata)\nNormalize, log-like transform, and scale the data in preparation for dimensionality reduction:\n#Droplet matrix is normalized to the median number of counts per barcode\nsc.pp.normalize_total(adata)\n#Droplet matrix is log-like transformed with np.arcsinh, without adding a pseudocount\nadata.X = np.arcsinh(adata.X).copy()\n#Droplet matrix centered and scaled through a Z-score transformation\nsc.pp.scale(adata)\nOptional: Perform feature selection with highly_variable_genes or nvr after installing the required packages. These methods can be run in a Jupyter Notebook:\nsc.pp.highly_variable_genes(adata)\nAlternatively, install nvr through the command line:\npip install nvr\nRun NVR:\nimport nvr\nadata = nvr.nvr_feature_select(adata)\nNote: Only one of these feature selection methods should be used at a time. Also, ensure that the data’s stage of normalization and transformation complies with the requirements of these feature selection methods.\nPerform the initial dimensionality reduction with PCA:\nsc.pp.pca(adata,highly_variable_genes=False)\nThe parameter for running the PCA is as follows:\nhighly_variable_genes: This parameter is used to indicate whether to use feature selected variables, set in this example as “False”.\nGenerate a K-nearest neighbors graph (KNN) from the PCA-based distance matrix. This is run with a K of approximately the square root of the total number of barcodes, balancing the influence of local and global distances:\nk_neighbors = np.sqrt(adata.n_obs).astype(int)",
    "sc.pp.neighbors(adata,n_neighbors = neighbors)\nPerform Leiden community detection:\nsc.pp.leiden(adata,resolution=1)\nThe parameter for running this Leiden clustering is as follows:\nresolution: The clustering resolution, where a higher number leads to more, smaller clusters, and a lower number leads to fewer, larger clusters. The example is set to “1”.\nProject the data into 2 dimensions with UMAP:\nsc.tl.umap(adata,min_dist=0.25)\nThe parameter for running this UMAP is as follows:\nmin_dist: The minimum distance allowed for each cell or data point in the 2-dimensional projection. The example is set as “0.25”. Lower min_dist values cause the data points to be more compact in 2D space, and vice versa for higher values.\nVisualize factors useful in the heuristic determination of high-quality cell barcodes:\nsc.pl.umap(adata,color=[‘gene’,’leiden_labels’,’pct_counts_Mitochondrial’,’pct_counts_in_top_200_genes’,’relative_transcript_diversity_threshold’],use_raw=False)\nThe parameter for running this UMAP is as follows:\ncolor: The values stored in the AnnData object which are to be visualized in on a 2-dimensional projection, in this example we visualize some “gene”, “leiden_labels”, “pct_counts_Mitochondrial”, “pct_counts_in_top_200_genes”, and “relative_transcript_diversity_threshold”. These factors are used in the heuristic selection of clusters.\nuse_raw: Whether to visualize normalized and scaled values or the raw count values within the AnnData object droplet matrix. Set to “False” in this example.\nCritical: By priority, clusters of droplet barcodes should be selected based on these criteria in step 18:\nMarker gene expression and specificity: These genes will vary between the biological system of interest as well as the heterogeneity of cell input. Colorectal tumors, for example, will have a mixture of epithelial and immune cells, and markers would be used accordingly.\nThe number of uniquely expressed genes: This is a strong predictor of encapsulated cells, and empty droplets are unlikely to contain a biologically relevant diversity of gene transcripts. This should be maximized unless there is a particular cell type that is known to express very few unique transcripts.",
    "Mitochondrial gene count percentage: This is important because encapsulated cells undergoing lysis will contain a high percentage of mitochondrial reads, effectively adding noise to a droplet due to the removal of more informative genes from a limited read count pool.\nAmbient gene expression: This is akin to the mitochondrial gene count percentage, as the encapsulation substrate may contain the remnants of lysed cells, often consisting of mitochondrial genes, but may vary per cell type. This should be minimized.\nTotal counts: As the number of transcripts detected represents the amount of raw transcriptional information contained within a droplet. This should also be maximized unless there is a particular cell type that is known to express very few unique transcripts.\nSelect and visualize the cells based off the heuristic criteria using discretized Leiden clusters:\nadata.obs[‘Cell_Selection’] = np.isin(adata.obs[‘leiden_labels’],[<cluster selection>]).astype(bool)\nsc.pl.umap(adata,color=[‘leiden_labels','Cell_Selection'],legend_loc='on data',legend_fontoutline=True,legend_fontsize=10)\nThe parameters in this case are:\n<cluster selection>: The set of Leiden clusters to be selected and passed as a list of characters such as [‘1’,’2’, … ‘n’].\nlegend_loc: This parameter indicates where the cluster legends will be displayed, set as “on data” in this example.\nlegend_fontoutline: This parameter is used to render an outline on the cluster legends for readability, set as “True” in this example.\nlegend_fontsize: This parameter designates the size of the font, set to 10 in this example.\nEnsure that the selected cells comply with the heuristic criteria by reviewing the outputs of steps 17 and 18; then save this selection to a .h5ad file.\ndata_out = QCPipe.qc.subset_cleanup(adata,selection='Cell_Selection')\ndata_out.write_h5ad(“<Filtered_Data.h5ad>”,compression=’gzip’)\nThe parameters in this case are:\nselection: The observation attribute used to subset the data, as defined earlier, this example is set as “Cell_Selection”\n<Filtered_Data.h5ad>: The filename to save the compressed .h5ad as, set in this example as “<Filtered_Data.h5ad>”.",
    "Pause point: The output of step 19, a filtered cell matrix, is saved as an .h5ad file, further detailed in the expected outcomes[href=https://www.wicell.org#expected-outcomes] section.\nVariant 2. Automated droplet filtering with dropkick\nTiming: 5 to 10 min, depending on the size of the droplet matrix.\nThis variant serves the same function as the heuristic droplet filtering[href=https://www.wicell.org#sec3.2] section. For automated droplet filtering in Python, dropkick is a machine learning tool that builds a probabilistic model of single-cell barcode transcriptome quality and returns a score for all barcodes in the input scRNA-seq droplet matrix (see step 7 for generating .h5ad from DropEst files) (Heiser et al., 2020[href=https://www.wicell.org#bib11]). dropkick can be run from the command line or interactively in a Jupyter Notebook. A command line interface exists for its two primary modules designed for QC reporting and filtering, whose usages are outlined as follows.\nInstall dropkick through pip, or from source code at https://github.com/KenLauLab/dropkick[href=https://github.com/KenLauLab/dropkick]:\npip install dropkick\nRun the dropkick qc function to generate a quality overview report, which is saved to the current working directory as a .png image file:\ndropkick qc <path/to/counts[.h5ad|.csv]>\nThe required parameter for this function is:\n<path/to/counts[.h5ad|.csv]>: The file path to the droplet matrix file of interest, which can be either .h5ad or .csv file.\nNote: If the input counts are in .csv format, ensure that the file is in cells by genes configuration with labels for gene identities as column headers. The output from the step 7 can be used here directly.\nRun the dropkick filtering algorithm with the run function:\ndropkick run <path/to/counts[.h5ad|.csv]> -j 5\nThe required parameters for this function are:\n<path/to/counts[.h5ad|.csv]>: The file path to the droplet matrix file of interest, which can be either .h5ad or .csv file.",
    "j: The number of jobs used to parallelize the training and cross-validation of the dropkick model. We recommend adjusting the `-j` flag according to the number of available CPUs. If using a machine with more than five cores, `-j 5` is optimal for the five-fold cross validation performed by dropkick, and model training is usually completed in less than two minutes.\nNote: All available user parameters can be found by running `dropkick run -h`. Default parameters are typically fast and robust for most datasets across encapsulation platforms, tissues, and levels of ambient background, see the troubleshooting[href=https://www.wicell.org#troubleshooting] section for further points of optimization.\nPause point: The output of step 22 is a .h5ad file, saved to disk, containing the input droplet matrix with additional metadata consisting of cell quality scores and binary labels. This is further detailed in the expected outcomes[href=https://www.wicell.org#expected-outcomes] section.\nIn a Jupyter Notebook, as described in step 19, load the dropkick-generated .h5ad file with the appropriate libraries and generate the filtered cell matrix:\ndata_out = QCPipe.qc.subset_cleanup(adata,selection='dropkick_label')\ndata_out.write_h5ad(“<Dropkick_Filtered_Data.h5ad>”,compression=’gzip’)\nThe parameters in this case are:\nselection: The observation attribute to use to subset the data, as defined earlier, this example is set as “dropkick_label”.\n<Filtered_Data.h5ad>: The filename to save the compressed .h5ad as, set in this example as “<Dropkick_Filtered_Data.h5ad>”.\nNote: It is good practice to ensure that the selected cells also comply with the heuristic cell selection criteria as discussed in step 17. The entirety of the heuristic droplet filtering[href=https://www.wicell.org#sec3.2] section can also be performed with a dropkick-labeled droplet matrix (the output from step 22), further augmenting cluster selection heuristics with learned metadata.\nPause point: The output of step 23, a filtered cell matrix, is saved as an .h5ad file, further detailed in the expected outcomes[href=https://www.wicell.org#expected-outcomes] section.\nPost-processing and dimension reduction structure preservation analysis",
    "Timing: 15–30 min depending on the complexity and heterogeneity of the data at hand.\nThe final phase of this pipeline is centered around generating a representative two-dimensional projection of a filtered cell matrix to accurately visualize the global and local populational heterogeneity within dataset. Using scRNA-seq data to address hypotheses necessitates robust visualizations to counteract stochasticity inherent to several popular non-linear dimensionality algorithms. This stochasticity is often unaccounted for during downstream and may interfere with the representation of cellular relationships along the transcriptomic landscape, warping the perceived distances between cell types in 2D space. This section walks through the quantitative evaluation of two popular embedding techniques, t-SNE (van der Maaten and Hinton, 2008[href=https://www.wicell.org#bib30]) and UMAP (McInnes et al., 2018[href=https://www.wicell.org#bib29]), to determine the more reliable visualization strategy for a particular dataset. First, each latent space, or non-linearly projected, representation of the cell matrix is generated. Second, after identifying putative cell types in the data, discrepancies between these latent and native, or linearly transformed, spaces are calculated on global and local scales. Finally, rearrangements in subpopulation adjacencies are calculated on a graphical basis, allowing for users to choose the latent representation which minimizes discrepancies in latent-native space distances as well as in subpopulation adjacencies; both factors may greatly influence the biological interpretation of the data.\nRefer to the normalization, transformation, scaling, and DR guidelines in steps 11–15, as this section uses the same processes. Ensure that the cell count matrix has been processed, up to the Leiden clustering calculation, before proceeding.\nUsing a calculated 50-component PCA, calculate a t-SNE representation of the cell count matrix.\nk_neighbors = np.sqrt(adata.n_obs).astype(int)\nsc.tl.tsne(adata, use_rep=”X_pca”, perplexity=k_neighbors)\nThe parameters in this case are:\nuse_rep: The representation of the single-cell data to use to initialize t-SNE nonlinear embedding, set as “X_pca”, or the 50-dimensional PCA representation in this example.",
    "perplexity: This is the effective nearest neighbors that are utilized in the t-SNE embedding, set to the square-root (rounded-down) of the total number of cells being examined.\nNext, generate a coarse-grained similarity graph using communities detected through the Leiden algorithm:\nsc.tl.paga(adata)\nProject the data into 2 dimensions using UMAP, but unlike in the heuristic droplet filtering[href=https://www.wicell.org#sec3.2] and automated droplet filtering with dropkick[href=https://www.wicell.org#sec3.3] section variants, initialize this projection with the PAGA similarity values:\nsc.tl.umap(adata, init_pos=”paga”)\nThe parameters in this case are:\ninit_pos: The representation of the data that is used for the initialization of the UMAP visualization, the example is set as “paga”, as calculated in step 26.\nRun the structure_preservation_sc function to calculate global latent-native space discrepancies:\ncorr, EMD, knn = QCPipe.fcc.structure_preservation_sc(adata=adata, latent=\"X_tsne\", native=\"X_pca\", k=neighbors)\nThe parameters in this case are:\nlatent: The target latent representation of the data to be evaluated, in this example we start with “X_tsne”, this parameter can be replaced with “X_umap” to evaluate UMAP representations (Figures 6[href=https://www.wicell.org#fig6]C and 6D)\nnative: The native space representation of the data to compare the latent representation with, set as “X_pca” in the example due to the linear nature of its decomposition.\nk: The k number of nearest neighbors for use in structure preservation analysis, set to the square-root (rounded-down) of the total number of cells being examined calculated in step 25.\nPerform differential gene expression (DE) testing to derive transcriptional signatures from the detected subpopulations of cells, whose local latent-native distance discrepancies should be quantified:\nsc.tl.rank_genes_groups(adata, groupby=”leiden”)\nThe parameters in this case are:\ngroupby: The dataset labels between which to perform DE testing, in this case we use the “leiden” clusters.",
    "Critical: Ensure that all detected Leiden clusters can be reasonably identified through their gene expression signatures as described in literature. Unless a particular subpopulation is expected to be novel, cluster-to-cluster comparisons will not be biologically meaningful unless properly annotated. Note that the annotation of gene expression signatures is out of the scope of this protocol and will vary for each tissue of interest.\nSubset single-cell cluster(s) of interest to perform latent-native discrepancy evaluation on a cluster-by-cluster basis (defined through the detection of known marker genes and the signature detection of step 29):\nQCPipe.fcc.subset_uns_by_ID(adata, uns_keys=[\"X_pca_distances\",\"X_tsne_distances\",\"X_umap_distances\"], obs_col=\"leiden\", IDs=[<cluster id_c>])\nThe parameters in this case are:\nuns_keys: The distances of interest to be subset, which are stored in the unstructured (.uns) attribute of the AnnData object. Set in the example as “X_pca_distances”, “X_tsne_distances”, and “X_umap_distances”\nobs_col: This parameter indicates which observation attribute to use to subset the data, as defined earlier, this example is set as “leiden”\nIDs: The observational IDs in which subsets of cells, Leiden cluster IDs in this example, are selected.\nPerform the latent-native discrepancy calculations and visualize them using the distance_stats, SP_plot, joint_plot_distance_correlation, and plot_cumulative_distributions functions:\npca_dist_c, tsne_dist_c, corr_stats_c, EMD_c =QCPipe.fcc.distance_stats(pre=adata.uns[<\"X_pca_distances_c\">], post= adata.uns[\"X_tsne_distances_c\"])\nQCPipe.fcc.SP_plot(pre_norm=pca_dist_c, post_norm=tsne_dist_c, labels=[\"PCA (50)\",\"t-SNE\"], figsize=(4,4)).joint_plot_distance_correlation()\nQCPipe.fcc.SP_plot(pre_norm=pca_dist_c, post_norm=tsne_dist_c, labels=[\"PCA (50)\",\"t-SNE\"], figsize=(3,3)).plot_cumulative_distributions()\nThe parameters in this case are:\npre: The calculated distances before generating the latent space representation of the data, which is are the “X_pca” distances in this example.\npost: The calculated distances after generating the latent space representation of the data, which is are the “X_tsne” distances in this example. For comparisons between these latent space representations, users can replace “tsne” with “umap” to test the latter embedding (Figures 7[href=https://www.wicell.org#fig7]A, 7B, 7F, and 7G).",
    "pre_norm: A flattened vector of normalized, unique cell-cell distances before transformation, as output by “distance_stats”. This is calculated for the PCA representation in the example.\npost_norm: A flattened vector of normalized, unique cell-cell distances after transformation, as output by “distance_stats”. This is calculated for the t-SNE representation in the example.\nlabels: The labels for the pre- and post- transformation data, set as “PCA (50)” and “t-SNE” in this example.\nfigsize: The size of the figure, in terms of width and height. Set as “(4,4)” and “(3,3)” respectively in this example.\nNote: Step 32 should be repeated as necessary with each latent space representation of interest. Here we recommend also running it with the UMAP representation calculated in step 27.\nCompare these distances between subpopulations of cells, being clusters c1, c2, and c3 in this example as defined in step 30:\ncorr_tSNE, EMD_tSNE =QCPipe.fcc.cluster_arrangement_sc(\n  adata= adata,\n  pre= adata.obsm[\"X_pca\"],\n  post= adata.obsm[\"X_tsne\"],\n  obs_col=\"leiden\", IDs=[\"c1\",\"c2\",\"c3\"],\n  ax_labels=[\"PCA (50)\",\"t-SNE\"],\n  figsize=(4,4),\n)\nThe parameters in this case are:\npre: The coordinates of each single-cell before transformation, “X_pca”, or the 50-dimensional PCA are used in this case.\npost: The coordinates of each single-cell after transformation, “X_tsne”, or the 50-dimensional PCA are used in this case. For comparisons between these latent space representations, users can replace “tsne” with “umap” to test the latter embedding (Figures 7[href=https://www.wicell.org#fig7]C, 7D, 7H, and 7I).\nobs_col: This parameter indicates which observation attribute to highlight by color, this example is set as “leiden”\nIDs: The observational IDs in which subsets of cells, Leiden cluster IDs in this example, are selected.\nax_labels: The labels for the pre- and post- transformation data, set as “PCA (50)” and “t-SNE” in this example, to be plotted as axis labels.",
    "figsize: The size of the figure, in terms of width and height. Set as “(4,4)” and “(3,3)” respectively in this example.\nNote: Step 3.9 should also be repeated as necessary with each latent space representation of interest. Here we recommend also running it with the UMAP representation calculated in step 27. Further, additional comparisons between other Leiden clusters should be performed to evaluate all potential subpopulations of interest, and these clusters should incorporate signatures highlighted in step 29.\nGenerate a minimum-spanning tree (MST) to investigate global subpopulation arrangements and structure:\nQCPipe.fcc.find_centroids(adata, use_rep=\"X_pca\", obs_col=\"leiden\")\nQCPipe.fcc.find_centroids(adata, use_rep=\"X_tsne\", obs_col=\"leiden\")\nQCPipe.fcc.find_centroids(adata, use_rep=\"X_umap\", obs_col=\"leiden\")\nThe parameters in this case are:\nuse_rep: The representation of the single-cell data to find centroids within, set as “X_pca”, “X_tsne”, and “X_umap” in this example.\nobs_col: This parameter indicates which observation attribute to find centroids within, as defined earlier, this example is set as “leiden”\nNote: Step 33 should also be repeated as necessary with each latent space representation of interest, like in step 32.\nDetermine the edge differences from native (PCA) to latent (t-SNE and UMAP) spaces by counting edge inconsistencies in a minimum spanning tree:\ntsne_set = set(adata.uns[\"X_tsne_centroid_MST\"].edges).difference(set(adata.uns[\"X_pca_centroid_MST\"].edges))\numap_set = set(adata.uns[\"X_umap_centroid_MST\"].edges).difference(set(adata.uns[\"X_pca_centroid_MST\"].edges))\nThe parameters in this case are:\nLatent MST: The MST calculated based on the latent representation of the data, being “X_tsne” and “X_umap” in these two calculations.\nNative MST: The MST calculated based on the native representation of the data, being “X_pca” in these two calculations.\nPlot these calculated edge differences:\nQCPipe.fcc.DR_plot(dim_name=\"t-SNE\").plot_centroids(adata=a, obs_col=\"leiden\", use_rep=\"X_tsne\", highlight_edges=tsne_set)\nQCPipe.fcc.DR_plot(dim_name=\"UMAP”).plot_centroids(adata=a, obs_col=\"leiden\", use_rep=\"X_umap\", highlight_edges=umap_set)\nThe parameters in this case are:\ndim_name: The name of the latent representation to be plotted, being “X_tsne” and “X_umap”.\nobs_col: This parameter indicates which observation attribute to highlight by color, this example is set as “leiden”",
    "use_rep: The representation of the single-cell data to plot, set as “X_tsne” and “X_umap” in this example.\nhighlight_edges: Which differing edges to highlight, representing a rearrangement of coarse cluster neighbors. “tsne_set” and “umap_set” in this example, calculated earlier."
  ],
  "subjectAreas": [
    "Rnaseq",
    "Bioinformatics"
  ],
  "bigAreas": [
    "Bioinformatics & Computational Biology"
  ]
}