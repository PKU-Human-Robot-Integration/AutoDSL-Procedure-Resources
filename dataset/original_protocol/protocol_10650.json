{
  "id": 11061,
  "origin_website": "Jove",
  "title": "Defining the Role Of Language in Infants' Object Categorization with Eye-tracking Paradigms",
  "procedures": [
    "All methods described here have been approved by the Northwestern University Institutional Review Board.\n1. Stimuli Creation\nNOTE: The visual stimuli (see Figure 1) used in the representative design reported below were originally developed in Havy and Waxman (2016)18 and are available for download at https://osf.io/n6uy8/.\nTo create a new continuous category, first design a pair of novel digital images. Next, morph the pair of images together, using software (see, e.g., Table of Materials) to form a continuum of exemplars between the two original images. Create at least two categories in this way so that one can serve as the category to be learned while the other provides the novel category exemplar for the test trial.\nSelect the familiarization exemplars at evenly spaced intervals from across each learned category’s continuum (e.g., the 0%, 20%, 40%, 60%, 80%, and 100% exemplars). Select an appropriate number of exemplars (e.g., six). Commensurate with the difficulty of the category and age of the participants.\nTo create the exemplars for the test phase, select the midpoints of the familiar category’s continuum and the novel category’s continuum (i.e., the 50% exemplar). Then match the color of the novel exemplar to that of the familiar exemplar using an image manipulation program (see, e.g., Table of Materials).\nRecord auditory stimuli produced by a female native English speaker in a soundproof booth. If possible, use the same speaker for both labeling phrases (i.e., “Look at the modi”) and non-labeling phrases (i.e., “Look at that!”).\n\t\nInstruct the speaker to produce all utterances in infant- or child-directed speech.\nSelect utterances which are approximately the same length across conditions, likely around 1,500 ms per phrase.\n2. Apparatus",
    "Use an appropriate eye-tracker. To collect adequate eye-tracking data for a familiarization-test measure, most widely available eye-trackers will suffice: the objects occupy large portions of the screen, and the data analysis investigates performance over a long window, rather than individual, rapidly occurring eye movements such as saccades.\nBecause this task requires eye-tracking infants, ensure that the system conforms to several requirements.\n\t\nFirst, use an ­eye-tracker with a remote tracking mode, which does not require infants to place their heads on a chin-rest. Ensure that the eye-tracker can tolerate relatively large head movements or readjustments.\nSecond, use a relatively large screen to display the images to infants, (e.g., 57 x 45 cm).\nThird, use an extendable arm mount for the eye-tracker to facilitate data collection by allowing the researcher to adjust the height of the eye-tracker to each infant.\nFourth, make the eye-tracking equipment unobtrusive, focusing infants’ attention solely on the display screen. For instance, some systems integrate the eye-tracking equipment with the display monitor or mount the equipment directly below the monitor.\nNote that this task can also be completed by hand-coding high-quality video data of the infants’ looking behavior. While hand-coding techniques may pose some challenges for using the more fine-grained time-course analyses, hand-coded data are entirely sufficient for the aggregate looking analyses.\n3. Task Design\nIn the eye-tracker’s associated software (see, e.g., Table of Materials), create four different conditions: Fully Supervised, Unsupervised, Semi-supervised, and Reversed Semi-supervised. Ensure these conditions are separate, so that each infant will see only one condition.\nGenerate at least two pseudo-random orders of the learning exemplars, with the constraint that no more than two exemplars from the same side of the continuum (0-40% or 60-100%) can be shown consecutively.",
    "Create familiarization videos that pair the auditory stimuli with the visual stimuli as appropriate for each condition.\n\t\nCombine the visual and auditory stimuli in video editing software (see, e.g., Table of Materials). Present all images on the same background. Set the onset of the auditory stimulus to an appropriate range, between 500 ms and 1,500 ms after the onset of the visual stimulus. Use this short delay to ease infants’ processing load 19.\nFor instance, in the Fully Supervised condition, pair each familiarization exemplar with a labeling phrase.\nIn the Unsupervised condition, pair each familiarization exemplar with a non-labeling phrase.\nIn the Semi-supervised condition, pair only the first two exemplars in each order with labeling phrases but the rest with non-labeling phrases.\nFor the Reversed Semi-supervised condition, pair the final two exemplars with labeling phrases but the first four with non-labeling phrases (see Figure 1).\nUpload these videos into the eye-tracker software, ordering the familiarization videos as determined by the pseudo-randomized order.\nUpload a short (10 s or less) attention-grabbing animation displayed in the center of the screen after familiarization: this will ensure that most infants are looking to the center of the screen when the test phase begins.\nFinally, for each learning category, design two test trials, each featuring two exemplars displayed side-by-side. Ensure that for both test trials, one exemplar will represent the midpoint of the now-familiar category while the other represents the midpoint of the novel category.\n\t\nCounterbalance the trials so that the left/right positioning of the novel exemplar in the test trial is reversed across videos.\nUpload these test trials to the eye-tracker software, positioning them after the post-familiarization attention-getter. Counterbalance these trials’ presentation so each infant has an equal chance of seeing a left-novel or right-novel test trial.",
    "Ensure that test trials last at least 5 s, and up to 20 s, in order for children initially looking away to accumulate sufficient looking.\n[Place Figure 1 here]\n4. Study Procedure\nBefore the infant arrives, set up the eye-tracker.\n\t\nRandomly assign the infant to a condition and an order.\nOpen the eye-tracker software and select the assigned condition/order pair.\nNow enter the participant number for this recording.\nAfter performing the consent process, bring the infant and the caregiver to the eye-tracking room. Ensure the room is moderately lit without any distracting decorations on the walls.\nPlace a chair in front of the eye-tracker at an appropriate distance for the model of eye-tracker being used. Seat the caregiver in this chair and the infant on the caregiver’s lap. If the infant does not wish to sit in the caregiver’s lap, they may sit on their own, or they may sit in a car seat.\nIf the infant is sitting on the caregiver’s lap, instruct the caregiver not to bias infants’ behavior in any way but to try to keep the infant centered on the caregiver’s lap. Provide caregivers with a pair of blacked-out sunglasses to wear so they cannot see the stimuli.\nAsk the infant to look at the eye-tracker screen; consider displaying an engaging image or video to attract their attention. Position the screen so that infants’ eyes are within the calibration window.\nPerform the eye-tracker’s calibration procedure. Use a five-point calibration if possible, but less comprehensive calibrations are also likely to be adequate. Infants often respond better when the calibration image is an animation with auditory accompaniment.\nIf the infant passes calibration, then begin the experiment. If not, recalibrate until they are successful. Any infants who cannot be calibrated are excluded.",
    "If multiple experiments are run consecutively, or if a single experiment is quite long, consider re-calibrating after each section.\n5. Data Analysis\nUse data analysis software to perform this analysis (e.g., see Table of Materials).\nCreate areas of interest (AOIs) around the exemplar positions on the left and right sides of the screen.\nFor familiarization trials, use the appropriate AOI to assess the time infants spent looking to the exemplar displayed on each trial. Exclude any infant who does not show sustained looking for a majority of the exemplars (e.g., require that infants attend to 4 of a possible 6 familiarization exemplars for at least 25% of those trials).\nFor the test trial, include only infants’ first 5 s of accumulated looking. For younger infants, from 3 to 12 months of age, consider using a longer window such as 10 seconds of accumulated looking. Consider excluding infants who show insufficient sustained looking at test (e.g., accumulating less than 2.5 s of looking) or who fail to look to both of the exemplars.\nNow create a preference score for each infant’s test trial by dividing the amount of time spent looking to the novel exemplar by the total amount of time looking to both exemplars. To analyze these proportions, transform them first with an empirical logit or arc-sin square-root to make them suitable for analysis with linear models.\nFor a time-course analysis of infants’ looking behavior at the test, separate data into small bins (e.g., between 10 and 100 ms), and calculate a preference score within each bin for each infant.",
    "Perform an analysis of the time-course data, testing whether infants’ pattern of looking throughout the test trial varies by condition. Note that multiple forms of analysis may answer this question, including a cluster-based permutation analysis20, as demonstrated here, and growth curve modeling.21\nFor a cluster-based permutations analysis, select a t-value threshold, corresponding to the desired alpha level (recommended alphas range from .01 to .20; note that this alpha value does not represent the overall test’s alpha level, merely the level required for individual time-bins to exceed the threshold). Sum the t-statistics for every consecutive time-bin that surpasses the chosen t-threshold; these cumulative t-statistics indicate the size of the divergences between conditions in the data.\nTo determine if these divergences are greater than expected by chance, perform at least 1,000 simulations with the condition labels randomly shuffled. Evaluate the unshuffled data’s divergences against this chance-based distribution.\n\t\tNOTE: It is this comparison of the original divergence against the chance-based distribution that determines the false-positive rate of the analysis, rather than the number of time-bins in which t-tests were conducted or even the t-value threshold selected for those initial t-tests. As a result, this analysis provides a conservative alternative to directly reporting the results from multiple t-tests across pre-specified time-bins (e.g., conducting tests every 500 ms).\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}