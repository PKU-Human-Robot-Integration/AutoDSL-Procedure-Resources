{
  "id": 12148,
  "origin_website": "Jove",
  "title": "Morphology-Based Distinction Between Healthy and Pathological Cells Utilizing Fourier Transforms and Self-Organizing Maps",
  "procedures": [
    "1. Protocol Requirements\nObtain high-resolution deconvolved three-dimensional (3D) microscopy data deconvolved in compliance with the Nyquist criterion with a sampling interval at least twice the highest spatial frequency of the specimen to obtain a high resolution image.\nUse 3D rendering software for the surface reconstruction and export.\nUse 3D animation software capable of running Python scripts (the Python script can be downloaded from the github repository: https://github.com/zcseresn/ShapeAnalysis) to create 2D projections.\nUse Fiji13 to analyze 2D projections and extract the DFT components.\n\t\nUse the current Fiji distribution. If there already exists an installed version of Fiji, make sure that the installed version is the latest. This can be easily achieved by running the Help |Update option.\nUse the Active Contour plugin15, which can be downloaded from http://imagejdocu.tudor.lu/doku.php?id=plugin:segmentation:active_contour:start and should be copied into the plugins folder.\nDownload the SHADE Fiji plugin from the github repository and copy into the plugins folder.\nUse computational mathematics software capable of calculating Self-Organizing Maps.\n2. Reconstruct the 3D Image.\nNOTE: For testing purposes, an example dataset is provided in the github repository (see above).\nStart the 3D reconstruction software and open the 3D image data.\nCreate a 3D Surface of (all) object(s).\n\t\nSelect the 3D view option and click on Surfaces. Click on the Next button (blue circle with a white triangle) to proceed with the surface creation wizard.\nSelect the image channel for the surface reconstruction.\nApply a smoothing function to avoid porous surfaces.\n\t\t\nChoose a smoothing value that does not hide the details of the surface but avoids porous surfaces.\nSelect a thresholding method to find the surfaces.\n\t\t\nUse an absolute intensity threshold when the objects are well-separated from the background and have an approximately uniform brightness level.",
    "Apply a local contrast threshold when the objects vary in their intensity but can still be separated from the local background and from the other objects surrounding them. Set the local threshold search area according to the value of the expected diameter of the reconstructed objects.\nFilter the reconstructed surfaces according to morphological parameters of interest, e.g., volume, sphericity, surface-to-volume ratio, etc., and finish the surface reconstruction.\nSave and export the generated surfaces in a format that is compatible with the 3D animation software that will be used in the next step.\n3. Transform the 3D reconstructed surfaces into 2D projections\nStart Blender and go to the output tab in the right-side window. Select the TIFF format from the dropdown menu and set the color depth to 8 bit RGBA.\nSwitch into Scripting Mode and open the provided script file \"GUI_AutoRotate.py\" from the repository provided with this work (https://github.com/zcseresn/ShapeAnalysis).\nClick on Run Script. Choose the folder of the wrl files when prompted for input.\nIf needed, create more rotations when working with more complex surfaces: go to the GUI and set the box Rotations to a value above 6.\n\tNOTE: A rotation of 6 different angles can be sufficient to distinguish the different cell populations. It is not recommended to create less than six rotations per surface, because of potential information loss.\nRun the script by clicking on the Rotate button in the GUI. Save the projections of the individual surfaces in the same folder that was used as the input folder (step 2.3). By default, the images are saved in an 8 bit Tiff format (see step 2.1), which is the format required by the Fiji plugin SHADE.\n4. Find the periphery and calculate the Fourier components using Fiji.",
    "Open Fiji and select SHADE in the Plugins menu. Start with the default values and fine-tune the parameters later on. Click OK when ready to run the program.\n\t\nChoose a Gradient Threshold value for the thresholding of the input image.\nChoose the Number of Iterations. The higher the Number of Iterations value, the more precise the reconstruction of the periphery. For simpler shapes, a lower number is usually sufficient.\nUse the Number of Dilations parameter to determine how much larger the starting mask is compared to the actual cell. Usually more complex shapes need more dilation steps for proper periphery finding.\nCheck the Dark Background checkbox if the projected shapes are brighter than the background.\nActivate the Show Intermediate Results checkbox only when using a small test dataset to determine the performance of SHADE. Activating this option for larger datasets lowers the computational efficiency and could possibly halt a system with low video memory.\nCheck the Save Result Tables checkbox to use the results of SHADE as an input for step 5. If the box is checked, all results are saved in individual csv files. A summary of the output data is always generated in a file called \"Result_collection_of_all_DFT_calculations.csv\".\nSelect the input data folder that contains the TIFF files that were created in step 3.\nProvide the output data folder.\nClick OK to start the plugin.\n5. Self-Organizing Maps\nNOTE: SOM networks are only able to classify data when they are trained on a large dataset which contains input from all expected cell types and conditions. For demonstration purposes, such a dataset is provided and can be found in our repository (“AllCells_summary_normalised.csv” from https://github.com/zcseresn/ShapeAnalysis\nFollow these guidelines if there is no trained SOM available yet for the input data; otherwise proceed to step 5.2.",
    "Start a computational mathematical software capable of performing neural network classifications.\nSelect a data file to be used for training the SOM network. This dataset should contain all experimental conditions in order to train the SOM on the particular cell types and experimental conditions.\n\t\tNOTE: It is also possible to use the provided AllCells_summary_normalised.csv for testing the system.\nStart the training and wait till the training is completed before proceeding. By default, the script is set to run 2000 iterations (\"Epochs\").\n\t\tNOTE: The number of iterations depends on the learning rate of the SOM. Depending on the input data it is advisable to test both higher and lower number of epochs and observe the stability of the pattern of the SOM. When using the script provided, the number of iterations can be changed under line 32. The network size can be changed in line 34 (by default it is set to 12 by 12).\nAfter the training is finished, examine the network’s topology (neighbor distances, input planes, sample hits, etc.). The network is now trained and can be saved for future use.\nLoad in the SOM, when using an already trained map (this can come either from Step 5.1 or from other sources) in order to cluster a dataset.\n\t\nImport the csv file that is to be tested with the preloaded trained SOM. Select the csv output of the SHADE Plugin from step 4 when using data prepared by the SHADE plugin.\n\t\tNOTE: It is also possible to use the example data files “InteractingCells_summary_normalised.csv”, “MobileCells_summary_normalised.csv” or “PhagocytosingCells_summary_normalised.csv” that are provided via github.\nAfter the classification is finished, evaluate the results of the SOM as in step 5.1.5.",
    "Examine the hitmap generated from the csv file. Each cell of the map shows how many times the dataset \"hits\" that particular cell of the trained SOM. When a group of cells are clustered in a small area of this map, this indicates that the dataset is fairly homogenous. Multiple clusters will indicate that subgroups likely exist in the dataset.\nExamine the neighborhood weight distances. Areas of this map that are well separated correspond to groups of objects that behave very differently from the SOM's point of view. With DFT components as input data, this means that these cell groups have very dissimilar shapes of the corresponding 3D surfaces.\nExamine the weight planes for information about the contribution by each element of the feature vector. In case of using the 20 DFT components as described earlier, 19 maps will appear here. When using the provided example dataset, the first 5 or 6 weight planes will be different, but the rest of them will appear fairly similar. In this case it can be concluded that it would be enough to use approximately 7 DFT components."
  ],
  "subjectAreas": [
    "Cancer Research"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research"
  ]
}