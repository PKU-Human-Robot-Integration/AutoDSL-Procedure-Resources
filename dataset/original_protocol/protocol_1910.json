{
  "id": 2022,
  "origin_website": "Cell",
  "title": "Speech-to-Speech Synchronization protocol to classify human participants as high or low auditory-motor synchronizers",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nWe focus on two versions of the Speech-to-Speech Synchronization test: the Implicit Fixed and the Explicit Accelerated. Below we detail the steps necessary to carry out both versions. When neither version is mentioned, the particular step does not differ between them. Both versions can be conducted in-lab or remotely/online. The in-lab experimental scripts, as well as the wav files described below are available at https://zenodo.org/badge/latestdoi/407612860[href=https://zenodo.org/badge/latestdoi/407612860] (MATLAB version) whereas the online scripts to conduct the experiment can be found at https://app.gorilla.sc/openmaterials/290032[href=https://app.gorilla.sc/openmaterials/290032].\nFor the general setup of the experiment, participants should sit in front of a computer close to a microphone and wear headphones. Wearing headphones represents a crucial aspect of the design, for two main reasons: (i) recording should not be contaminated by the auditory stimulus and (ii) participants own voice feedback should be masked by the external stimulus (i.e., participants should not be able to listen to their own vocal production). The microphone can be externally connected to the computer; the computer’s internal microphone can also be used. Participants are instructed to maintain a short distance (below 30 cm) between their mouth and the microphone throughout the test. When the test is conducted in-lab, instructions are given verbally at the start of the experiment and appear written on the computer screen before the beginning of each step.\nPart one\nVolume adjustment\nTiming: approximately 2 min (15 s of volume adjusting + 1.5 min for instructing the participant)\nNote: In case of applying the test remotely/online, two additional steps are added to ensure that the participant is wearing headphones and that the microphone is working properly (Woods et al., 2017[href=https://www.wicell.org#bib12]).",
    "Have participants listen to a train of synthesized syllables played backwards (i.e., the same audio wav used as stimulus in the main task, made of 16 syllables randomly concatenated, but reversed in time) while asking them to whisper the syllable “tah”.\nAsk participants to gradually increase the volume until they cannot hear their own whisper while still being at a comfortable level.\nOnce they select the volume level, instruct them not to change the volume throughout the task.\nCritical: The maximal volume reached by the used device and stimuli in our case was 100 dB, stated by the WHO as a safe sound level if listened for 15 min each day (World Health Organization, 2015[href=https://www.wicell.org#bib13]).\nCritical: Crucially, all included participants should report not hearing their own voice.\nNote: The volume selected by the participants does not distinguish between high and low synchronizers (Mann–Whitney–Wilcoxon test, two-sided P = 0.69; highs: n = 15, meanVol = 95.16 dB, s.d. = 3.84 dB, and lows: n = 16 meanVol = 95.67 dB, s.d. = 4.07 dB).\nPart two\nTraining\nTiming: approximately 30 s\nHave participants passively listen to a 10-s rhythmic train of syllables.\nSyllables are presented at 4.5 Hz for the Implicit Fixed Version and 4.3 Hz for the Accelerated Explicit Version (example_45 Hz.wav and example_43 Hz.wav, respectively).\nOnce the rhythmic train ends, ask participants to whisper the syllable “tah” at the same pace for 10 s.",
    "Critical: In the implicit version tell participants that this step is for them to get an idea of how they are supposed to be whispering continuously during the main task. More precisely, give the following instructions: “First, you will be presented with an example audio of how to continuously and repeatedly whisper the syllable 'tah.' Pay attention to it and once it ends it will be your turn to practice the whispering.”\nPart three\nMain task\nTiming: approximately 1.5 min (60 s for the main task run + 30 s for the two-alternative forced choice questions only in the Implicit Fixed Version)\nFor the Implicit Fixed version, ask participants to pay attention to the perceived syllables while continuously whispering the syllable ‘tah’. Explain to them that after the presentation, they will be required to identify a subset of the presented syllables and that the point of the continuous ‘tah’ whispering is to make more challenging the syllables recall. Do not disclose that the objective of the whispering is to measure their speech-to-speech synchrony. For the Explicit Accelerated Version, ask participants to synchronize the repeated whispered syllable to the rate of the auditory stimulus.\nHave participants listen to a 60-s audio comprising a rhythmic train of syllables (stimulus_fix.wav for the Implicit Fixed version, stimuls_acc.wav for the Explicit Accelerated).\nHave participants continuously whisper the syllable “tah” while looking at a fixation cross in the center of the screen during the whole audio presentation and record participants' vocalizations.\nOnly for the Implicit Fixed Version, once the audio presentation ends. Ask participants to answer four two-alternative forced choice questions about whether a particular syllable was presented or not (e.g., “Did you hear the syllable /bah/?”). Have them respond with the keyboard by pressing Y for yes or N for no.",
    "Note: The purpose of this assessment is to direct the participant’s attention to the syllable detection task and to avoid having them intentionally synchronizing their whisper to the auditory stimulus. There is no useful information in the participants’ responses, it has been shown that lows and high synchronizers have equal poor performance on this task (Assaneo et al., 2019a[href=https://www.wicell.org#bib1]).\nNote: The test consists of two runs, therefore Part two and three are repeated.\nPart four\nAnalysis\nTiming: approximately 3 min\nVisualize and listen to the recorded audio signals. We suggest using the software praat (Boersma and Weenink, 2001[href=https://www.wicell.org#bib5]). If none of the exclusion criteria are reached (see below for details regarding exclusions), each participant is labeled as a high or low synchronizer, following the analysis described below."
  ],
  "subjectAreas": [
    "Clinical Protocol",
    "Neuroscience",
    "Behavior",
    "Cognitive Neuroscience"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research",
    "Ecology & Environmental Biology"
  ]
}