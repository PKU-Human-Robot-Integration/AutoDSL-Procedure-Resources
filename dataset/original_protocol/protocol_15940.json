{
  "id": 19770,
  "origin_website": "Wiley",
  "title": "Heritability Estimation Approaches Utilizing Genome-Wide Data",
  "procedures": [
    "This GREML protocol can be broadly categorized into three steps—(1) create genetic relatedness matrix (GRM); (2) remove one of the cryptically related individual pairs; (3) run restricted maximum likelihood (REML). GCTA allows multi-threading that can be enabled by using the flag --thread-num or -threads.\nSoftware and files needed for GREML\nSoftware\nGCTA (Yang et al., 2010[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0096]; Yang, Lee, et al., 2011[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0097]; https://yanglab.westlake.edu.cn/software/gcta/#Download[href=https://yanglab.westlake.edu.cn/software/gcta/#Download])\nData file\nThe Northern Finland Birth Cohort (Sabatti et al., 2009[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0060]; https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000276.v2.p1[href=https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000276.v2.p1])\n1. Create GRM using plink format files (test.bed, test.bim, and test.fam).\nDepending upon the requirements of the analysis, GRMs can be created in different ways, such as by using only autosomes, using each chromosome separately, using the X chromosome alone, or using a subset of SNPs.\n         \naUsing autosomes only:\n               \ngcta64 --bfile test --autosome --make-grm-bin --out test_grm --thread-num 4;\nbBased on each chromosome separately:\n               \ngcta64 --bfile test --chr 1 --make-grm-bin --out test_grm_chr1 --thread-num 4;\ngcta64 --bfile test --chr 2 --make-grm-bin --out test_grm_chr2 --thread-num 4;\n. . .\ngcta64 --bfile test --chr 22 --make-grm-bin --out test_grm_chr22 --thread-num 4;\ncUsing X chromosome.\n               \ngcta64 --bfile test --make-grm-xchr --out test_grm_xchr --thread-num 4;\ndCreate GRM with a subset of SNPs (test_snplist.txt—one SNP on a line)\n               \ngcta64 --bfile test --extract test_snplist --make-grm-bin --out test_grm_subset --thread-\nnum 4;\n2. Remove one individual from each cryptically related pair using kinship coefficient cutoff (0.05):\n         \ngcta64 --grm test_grm --grm-cutoff 0.05 --make-grm-bin ---out test_grm_0.05 --thread-num 4;\n3. Run REML with kinship matrix (test_grm_0.05.grm.bin, test_grm_0.05.grm.N.bin, and test_grm_0.05.grm.id) and phenotype file (test.phen):\n         \ngcta64 --grm test_grm_0.05 --pheno test.phen --reml --out test_greml --thread-num 4;\nThe phenotype file typically has three columns—Family ID, Individual ID, and Phenotype. However, more than one phenotype can also be provided and assigned to a specific column (phenotype) for formula:\n$h_{SNP}^2$\n estimation by providing an additional option --mpheno [(column-number) - 2] in the above command.",
    "REML can also be run in various alternative ways such as using GRMs created by a subset of SNPs, using multiple GRMs, adjusting for covariates and using discrete outcomes e.g., case-control status in phenotype file:\n         \nRun REML using GRM created by a subset of SNPs (test_grm_subset.grm.bin, test_grm_subset.grm.N.bin, and test_grm_subset.grm.id):\n               \ngcta64 --grm test_grm_subset --keep test_grm_0.05.grm.id --pheno test.phen --reml --out\ntest_greml_subset --thread-num 4;\nRun REML using multiple GRMs (grm_chrs.txt is a text file with list of GRM names—one GRM name on a line):\n               \ngcta64 --mgrm grm_chrs.txt --pheno test.phen --reml --out\ntest_greml_chrs --thread-num 4;\nAdjust for covariates (--covar and --qcovar for discrete and continuous covariates, respectively):\n               \ngcta64 --reml --grm test_grm_0.05 --pheno test.phen --covar sex.txt --qcovar PCs.txt --out\ntest_greml_adj --thread-num 4;\nsex.txt is a list of individuals’ sexes (discrete variable) and PCs.txt is a file with first 10-20 principal components (continuous variable). Similar to the phenotype files, covariate files also have the first two columns as family id and individual id followed by covariate columns.\nRun REML for case control data (test_cc.phen—phenotype file with case-control information). Let us assume that the prevalence of the disease is 0.1 in the general population. The option --prevalence is used to specify the disease prevalence and transformation of formula:\n${\\rm{\\hat{h}}}_{{\\rm{SNP}}}^2$\n from observed discrete (0-1) scale to unobserved continuous liability scale.\n               \ngcta64 --reml --grm test_grm_0.05 --pheno test_cc.phen --prevalence 0.1 --out\ntest_greml_cc --thread-num 4;\nUsually, GCTA runs REML in a constrained manner such that 0 < formula:\n${\\hat{h}}^2$\n < 1. If there are multiple matrices each with a small contribution to formula:\n${\\hat{h}}^2$\n, one or more random effects may hit the boundary. REML stops if more than half of the total components hit the boundary. To avoid such situation, --reml-no-constrain can be used to run REML in an unconstrained manner.",
    "As seen in the previous example, SNP-heritability attributable to each chromosome can be estimated by simultaneously fitting GRMs based on each chromosome in to REML. Similarly, GREML can be run in various other stratified ways, for example, using GRMs created by a subset of SNPs stratified by either minor allele frequency (MAF) bins alone or both linkage disequilibrium (LD) and MAF bins. These variations of GREML were developed to adjust for the influence of MAF and local LD on the estimated SNP-heritability, and known as the GREML-MAF Stratified (GREML-MS) and GREML-LD and MAF Stratified (GEML-LDMS) approach, respectively. Like original GREML, stratified GREML is also performed in three major steps: (1) create GRM, (2) remove one of the cryptically related individual pairs, and (3) run REML. However, GREML-LDMS includes an additional step—calculation of LD scores (summation of r2 values between a SNP and all SNPs in a given genomic region) prior to creating GRMs. It is noteworthy that multiple GRMs are created and fitted in REML based on the stratification criteria in stratified GREML.\nSoftware and files needed for Stratified-GREML\nSoftware\nGCTA (Yang et al., 2010[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0096]; Yang, Lee, et al., 2011[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0097])) (https://yanglab.westlake.edu.cn/software/gcta/#Download[href=https://yanglab.westlake.edu.cn/software/gcta/#Download])\nR/R-Studio (R Team, 2019[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0070]; R Team, 2020[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0071]; https://www.R-project.org[href=https://www.R-project.org])\nData file\nThe Northern Finland Birth Cohort (Sabatti et al., 2009[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0060]; https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000276.v2.p1[href=https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000276.v2.p1])\nGREML-MS (Based on MAF bins only)\n1a. Create GRMs:\n         \ngcta64 --bfile test --autosome --maf 0.01 --max-maf 0.1 --make-grm-bin --out\ntest_maf0.1_grm --thread-num 4;\ngcta64 --bfile test --autosome --maf 0.1 --max-maf 0.2 --make-grm-bin --out\ntest_maf0.2_grm --thread-num 4;\n. . .\ngcta64 --bfile test --autosome --maf 0.4 --max-maf 0.5 --make-grm-bin --out\ntest_maf0.5_grm --thread-num 4;",
    "2a. Remove one of the cryptically related individual pairs: REML can be run with unrelated individuals by adding a flag --keep [list of individuals with kinship coefficient < threshold e.g. 0.05]. A list of individuals with kinship coefficient less than a set threshold can be created using the protocol provided in GCTA. Alternatively, the test_grm_0.05.grm.id file created in the GREML protocol can directly be used. It is noteworthy that stratified REML analysis is performed with multiple GRMs listed in a text file (one GRM name in a line).\n3a. Run REML:\n         \ngcta64 --mgrm greml_ms_grm_list.txt --pheno test.phen --reml --out test_greml_ms --thread-num 4;\nGREML-LDMS (based on LD and MAF bins)\n1b. Calculate LD scores:\nLD scores are calculated using option --ld-score-region [window size]. GCTA uses default window size of 200 Kb with 100Kb overlapping regions between two segments:\n         \ngcta64 --bfile test --autosome --ld-score-region 200 --out test_ld --thread-num 4;\nImport the output of the above command (test_ld.score.ld) to R and create quartiles based on either ldscore_SNP or ldscore_region. Save SNPs corresponding to each quartile as test_ld_q*.txt, where * is 1/2/3/4. Different bins are created on the basis of LD score quartiles and MAF ranges. For example, SNPs within each MAF range such as 0.01 < MAF ≤ 0.1, 0.1 < MAF ≤ 0.2,, 0.2 < MAF ≤ 0.3,, 0.3 < MAF ≤ 0.4 and 0.4 < MAF ≤ 0.5 can be binned on the basis of quartiles of regional or SNP LD scores.\n2b. Create GRM:\n         \nfor i in $(seq 1 4); do\ngcta64 --bfile test --autosome --extract test_ld_q${i}.txt --maf 0.01 --max-maf 0.1 --make-\ngrm-bin --out test_q${i}_maf0.1_grm --thread-num 4;\ndone;\nfor i in $(seq 1 4); do\ngcta64 --bfile test --autosome --extract test_ld_q${i}.txt --maf 0.1 --max-maf 0.2 --make-\ngrm-bin --out test_q${i}_maf0.2_grm --thread-num 4;\ndone;\n. . .",
    "for i in $(seq 1 4); do\ngcta64 --bfile test --autosome --extract test_ld_q${i}.txt --maf 0.4 --max-maf 0.5 --make-\ngrm-bin --out test_q${i}_maf0.5_grm --thread-num 4;\ndone;\n3b. Remove one of the cryptically related individual pairs: One individual from the cryptically related pairs can be removed using the command provided in the GCTA protocol. Alternatively, an already filtered list of unrelated individuals can be used as in GREML-MS.\n4b. Run REML:\n         \ngcta64 --mgrm greml_ldms_grm_list.txt --pheno test.phen --reml --out test_greml_ldms --thread-num 4;",
    "This LDAK protocol can be divided into five steps—(1) Thinning of SNPs; (2) calculating weights of thinned SNPs based on the pair-wise LD with all nearby SNPs in a bin (e.g., 100 kb); (3) creating kinship matrix; (4) removing one of the cryptically related individual pairs; (5) running REML. In the following protocols, we use a default setting of α = −0.25; the user may change this depending on the desired model. Like GCTA, LDAK also allows multi-threading for most of the analyses which can be enabled by using the option --max-threads.\nSoftware and files needed for LDAK\nSoftware\nLDAK (Speed et al., 2012[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0066], 2017[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0065]) (http://dougspeed.com/downloads[href=http://dougspeed.com/downloads]) for the first-time users and (http://dougspeed.com/downloads2[href=http://dougspeed.com/downloads2]) for the returning users\nData file\nThe Northern Finland Birth Cohort (Sabatti et al., 2009[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0060]; https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000276.v2.p1[href=https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000276.v2.p1])\n1. Thinning of SNPs:\nThinning of SNPs means removing one of the SNP pairs that are in strong LD with each other from the analysis. LDAK uses r2 = 0.98 and 100 Kb window size as default values:\n         \nldak5.1.linux --thin --bfile test --chr AUTO --window-prune .98 --window-kb 100;\nawk '{print $1, 1}' thin.in > weights.thin;\nAll thinned SNPs in the file weights.thin are assigned equal weight, i.e., 1, and are used for calculation of kinship matrix using LDAK-Thin model.\n2. Calculate weights of thinned SNPs:\nAll the thinned SNPs are weighted equally for the LDAK-Thin model, whereas variant specific weights are calculated for the LDAK model. Prior to calculation of variant specific weights, LDAK cuts the thinned SNPs into multiple sections. We save these sections and corresponding SNP weights for each chromosome in a sub-directory ./sections/section${j}, where j represents chromosome number 1-22.\n         \nawk 'NR==FNR{x[$1] = $0; next} $2 in x{print $1 \":\" $2 \":\" $4 \":\" $6 \":\" $5}' thin.in test.bim > extend_thin.in;",
    "awk 'NR==FNR{x[$1] = $0; next} $2 in x{print $1 \":\" $2 \":\" $4 \":\" $6 \":\" $5}' thin.out test.bim > extend_thin.out;\nfor j in $(seq 1 22); do\nmkdir -p ./sections/sections$j/;\nawk -v var=$j '{split($1, a, \":\"); if(a[1] == var) print a[2]}' extend_thin.in >\n./sections/sections$j/thin.in;\ndone;\nfor j in $(seq 1 22); do\nawk -v var=$j '{split($1, a, \":\"); if(a[1] == var) print a[2]}' extend_thin.out >\n./sections/sections$j/thin.out;\ndone\nfor j in $(seq 1 22); do\nldak5.1.linux --cut-weights ./sections/sections$j --bfile test --chr $j --no-thin DONE --\nmax-threads 4;\nldak5.1.linux --calc-weights-all ./sections/sections$j --bfile test --chr $j --max-threads\n4;\ndone;\ncat ./sections/sections{1..22}/weights.short > ./sections/weights.short;\nThinned SNPs in the file weights.short have SNP-specific weights and are used to calculate kinship matrix using the LDAK model. weights.short usually has a smaller number of SNPs than initially thinned SNPs because many of the thinned SNPs have zero weight and are not included in the calculation of kinship matrix.\n3. Create kinship matrix.\n         \na.Calculate Kinship matrix using same weight for all thinned SNPs (LDAK-Thin model):\n               \nldak5.1.linux --calc-kins-direct test_grm_ldak_thin --bfile test --chr AUTO --weights\nweights.thin --power -0.25 --max-threads 4;\nb.Calculate Kinship matrix using SNP specific weights (LDAK Model):\n               \nldak5.1.linux --calc-kins-direct test_grm_ldak --bfile test --chr AUTO --weights\n./sections/weights.short --power -0.25 --max-threads 4;\n4. Remove one of the cryptically related individual pairs.\n         \na.LDAK-Thin model:\n               \nldak5.1.linux --filter test_ldak_thin_0.05 --grm test_grm_ldak_thin --max-rel 0.05 --max-\nthreads 4;\nb.LDAK model:\n               \nldak5.1.linux --filter test_ldak_0.05 --grm test_grm_ldak --max-rel 0.05 --max-threads 4;\nThe above commands produce two files—test_ldak_thin_0.05.keep and test_ldak_thin_0.05.lose or test_ldak_0.05.keep and test_ldak_0.05.lose—depending on the selected model. While running REML we can use .keep file by adding a flag --keep [keep-file]. However, we use the same set of individuals (test_grm_0.05) as used in the GCTA approach to maintain uniformity across different approaches.\n5. Run REML.\n         \na.LDAK-Thin model:\n               \nldak5.1.linux --reml test_ldak_thin --pheno test.phen --pheno --grm test_grm_ldak_thin --",
    "keep test_grm_0.05.grm.id --constrain YES --max-threads 4;\nb.LDAK model:\n               \nldak5.1.linux --reml test_ldak --pheno test.phen --pheno --grm test_grm_ldak --keep\ntest_grm_0.05.grm.id --constrain YES --max-threads 4;",
    "A stratified version of LDAK can be run using already calculated weights of thinned SNPs (see LDAK protocol). Unlike, GCTA, LDAK does not allow –min-maf or –max-maf option along with –calc-kins-direct. Therefore, markers based on MAF bins should be extracted from ‘test.bim’ files and the list should be used to extract the set of markers while creating kinship matrix (–extract list-of-SNPs.txt). Since, we are using pre-computed weights and advise one uses already pruned set of individuals (see LDAK protocol), we provide rest two steps here – i) create kinship matrix; ii) Run REML.\nSoftware and files needed for Stratified LDAK\nSoftware\nLDAK (Speed et al., 2012[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0066], 2017[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0065]) (http://dougspeed.com/downloads[href=http://dougspeed.com/downloads]) for the first-time users and (http://dougspeed.com/downloads2[href=http://dougspeed.com/downloads2]) for returning users\nData file\nThe Northern Finland Birth Cohort (Sabatti et al., 2009[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0060]; https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000276.v2.p1[href=https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000276.v2.p1])\nLDAK-Thin-MS model\n1a. Create Kinship Matrix:\n         \nldak5.1.linux --calc-kins-direct test_maf0.1_ldak_thin_grm --bfile test --chr AUTO --\nextract test_maf0.1.txt --weights weights.thin --power -0.25 --max-threads 4;\nldak5.1.linux --calc-kins-direct test_maf0.2_ldak_thin_grm --bfile test --chr AUTO --\nextract test_maf0.2.txt --weights weights.thin --power -0.25 --max-threads 4;\n. . .\nldak5.1.linux --calc-kins-direct test_maf0.5_ldak_thin_grm --bfile test --chr AUTO --\nextract test_maf0.5.txt --weights weights.thin --power -0.25 --max-threads 4;\n2a. Run REML:\n         \nldak5.1.linux --reml test_ldak_thin_ms --pheno test.phen --mgrm ldak_thin_ms_grm_list.txt\n--keep test_grm_0.05.grm.id --max-threads 4;\nLDAK-MS Model\n1b. Create Kinship Matrix:\n         \nldak5.1.linux --calc-kins-direct test_maf0.1_ldak_weights_grm --bfile test --chr AUTO --\nextract test_maf0.1.txt --weights ./sections/weights.short --power -0.25 --max-threads 4;\nldak5.1.linux --calc-kins-direct test_maf0.2_ldak_weights_grm --bfile test --chr AUTO --\nextract test_maf0.2.txt --weights ./sections/weights.short --power -0.25 --max-threads 4;\n. . .\nldak5.1.linux --calc-kins-direct test_maf0.5_ldak_weights_grm --bfile test --chr AUTO --\nextract test_maf0.5.txt --weights ./sections/weights.short --power -0.25 --max-threads 4;\n2b. Run REML:\n         \nldak5.1.linux --reml test_ldak_ms --pheno test.phen --mgrm ldak_ms_grm_list.txt --keep\ntest_grm_0.05.grm.id --max-threads 4;",
    "The threshold GRM approach uses two GRMs corresponding to one genetic component: a first GRM is the same as that created in GREML (without threshold) and a second GRM is created with a threshold by setting the off-diagonals that are <0.05 to 0. Here, we do not need to remove samples based on the GRM threshold. SNP-heritability attributable to the first kinship matrix is same as the SNP-heritability estimated by GREML. Overall, the estimate represents pedigree-based heritability, and h2 attributable to second GRM (formula:\n${\\rm{h}}_{{\\rm{Ped}}}^2 - {\\rm{h}}_{{\\rm{SNP}}}^2$\n) represents h2 attributable to shared environment. Frist, a GRM is created using commands in the GREML protocol (except, removing one of the cryptically related individuals), and then the following steps can be used to estimate SNP and pedigree-based heritability.\nSoftware and files needed for Threshold GREML\nSoftware\nGCTA (Yang et al., 2010[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0096]; Yang, Lee, et al., 2011[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0097]; https://yanglab.westlake.edu.cn/software/gcta/#Download[href=https://yanglab.westlake.edu.cn/software/gcta/#Download])\nData file\nThe Northern Finland Birth Cohort (Sabatti et al., 2009[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0060]; https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000276.v2.p1[href=https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000276.v2.p1])\n1. Create GRM with threshold:\n         \ngcta64 --grm test_grm --make-bK 0.05 --out test_grm_bK --thread-num 4;\n2. Run Threshold GREML:\n         \ngcta64 --mgrm threshold_grm_list.txt --reml --pheno test.phen --out test_Threshold --\nthread-num 4;",
    "LDSC allows formula:\n${\\rm{h}}_{{\\rm{SNP}}}^2$\n, the SNP heritability, to be directly estimated from the summary results by regressing the observed χ2 test statistic against LD score of genome-wide SNPs. Estimation of formula:\n${\\rm{h}}_{{\\rm{SNP}}}^2$\n using LDSC can be broken down into four simple steps: i) installing the program, ii) obtaining the summary results from the study in question, iii) formatting summary results for use in LDSC, and iv) running the program to estimate common SNP heritability.\nSoftware and files needed for LDSC Regression\nSoftware\nLDSC (Bulik-Sullivan et al., 2015[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0013]; Bulik-Sullivan et al., 2015[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0014]; https://github.com/bulik/ldsc[href=https://github.com/bulik/ldsc])\nData files\nSummary Results for height and BMI (Yengo et al., 2018[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0102]; https://portals.broadinstitute.org/collaboration/giant/index.php/GIANT_consortium_data_files[href=https://portals.broadinstitute.org/collaboration/giant/index.php/GIANT_consortium_data_files])\nLD Scores calculated in 1000 Genomes reference data (Bulik-Sullivan et al., 2015[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0013]; https://alkesgroup.broadinstitute.org/LDSCORE[href=https://alkesgroup.broadinstitute.org/LDSCORE])\n1. Installation and activation.\nLDSC can be installed from the resource provided earlier using following command:\n         \ngit clone https://github.com/bulik/ldsc.git;\nLDSC is a python package and an Anaconda environment (environment.yml) present in the original package must be created before using LDSC. It installs a list python dependency for LDSC: \n         \nconda env create --file environment.yml;\nBefore running LDSC an Anaconda environment is installed as above and must be activated as below:\n         \nsource activate ldsc\n2. Download summary results.\nThe next step is to download the summary results that can be downloaded from the resource provided above directly or using command line via wget.\n3. Convert to LDSC recognized format.",
    "LDSC accepts a specific format of summary statistics with six columns—a unique identifier (rs id), allele 1 (effect allele), allele 2 (other allele), sample size, p-value and a signed summary-statistics (effect, odds ratio, log odds ratio, Z score). Sometimes sample size is not provided in the summary results. In that case, a uniform sample size can be provided by using a flag --N [sample size]. In the case of unsigned effects, LDSC assumes allele 1 to be a risk increasing/positively associated allele and processes summary result accordingly. Although summary results can be formatted manually, LDSC recommends using the python script munge_sumstats.py provided in the original package because it checks for several things besides converting summary result to LDSC format. In addition, it is recommended to use SNPs from summary results that are common in the HapMap3 dataset, particularly if the summary result is obtained from imputed data.\nHapMap SNPs (w_hm3.snplist.bz2) can be downloaded from https://data.broadinstitute.org/alkesgroup/LDSCORE/[href=https://data.broadinstitute.org/alkesgroup/LDSCORE/] either directly or using command line via wget.\n         \nMunge_sumstats.py --sumstats [summary-result] --out [sumstats-ldsc] --merge-alleles\nw_hm3.snplist.txt;\n4. Estimate heritability.",
    "To estimate heritability attributable to common variants present in summary result, χ2 values from the output of above command (sumstats-ldsc.gz) is regressed on the ld scores (sum of r2 values for a SNP with surrounding SNPs in a predefined window) calculated in a reference population such as the 1000 Genomes Project or UK Biobank. LD scores can be downloaded from the link provided in the resource. Assuming the GWAS included European population, LD scores should be used from European population, for example eur_w_ld_chr. In addition to LD scores, LDSC requires a regression weight file that includes r2 values for the SNPs used in the regression, i.e., GWAS SNPs. Generally, LDSC is not very sensitive to regression weights. Therefore, it is currently recommended to use the same LD scores for both flags. For partitioned h2 estimation, one may choose a subset of GWAS SNPs to calculate LD scores using 1000 Genomes data separately, and use them as regression weight.\n         \nldsc.py --h2 [sum-stats-file.gz] --ref-ld-chr eur_w_ld_chr/ --w-ld-chr eur_w_ld_chr/--out\nout_h2;\nIf the original GWAS already controlled for population stratification and cryptic relatedness, the intercept can be constrained by adding a flag --intercept-h2 [threshold] or --no-intercept which constrains the intercept to 1.",
    "SumHer is integrated into LDAK software; therefore, no extra software needs to be installed. Unlike LDSC, one must modify summary results to SumHer-compatible format manually. A compatible summary stats file has 5 or 6 columns (column names are case sensitive) with core columns: ‘Predictor’, ‘A1’, ‘A2’, ‘n’; then, there are three options to choose additional 1-2 columns. The last column could be ‘Z’, or last two columns could be ‘Direction’, ‘Stat’ or ‘Direction’, ‘P’. Predictor should be in ‘chr:position’ format.\nSoftware and files needed for LDSC Regression\nSoftware\nLDAK (Speed et al., 2012[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0066], 2017[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0065]; http://dougspeed.com/downloads[href=http://dougspeed.com/downloads]) for first-time users and (http://dougspeed.com/downloads2[href=http://dougspeed.com/downloads2]) for returning users\nData files\nSummary Results for height and BMI (Yengo et al., 2018[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpz1.734#cpz1734-bib-0102]; https://portals.broadinstitute.org/collaboration/giant/index.php/GIANT_consortium_data_files[href=https://portals.broadinstitute.org/collaboration/giant/index.php/GIANT_consortium_data_files])\nLD Scores calculated in 2000 Great Britain samples from UK Biobank dataset; http://dougspeed.com/pre-computed-tagging-files[href=http://dougspeed.com/pre-computed-tagging-files])\nThere are several tagging files available. Based on the recommendation of SumHer authors, we used BLD-LDAK tagging file (GBR population, HapMap SNPs) in our analysis.\n1. Convert summary result to SumHer compatible format.\nLet us assume height summary results were downloaded from GIANT consortium and unzipped to height_raw.txt using gunzip -c [summary-result.gz] > height_raw.txt. This file can be formatted to get height summary results with specific columns needed for SumHer.\n         \nawk 'BEGIN{print \"Predictor A1 A2 Direction P n\"}\n (NR > 1 && ($2 == \"A\" || $2 == \"C\" || $2 == \"G\" || $2 == \"T\")\n&& ($3 == \"A\" || $3 == \"C\" || $3 == \"G\" || $3 == \"T\")){print $1, $2, $3, $5, $7, $8}'\nheight_raw.txt > height.txt;\nThen, download the list of HapMap3 SNPs with chromosome and position information (https://www.dropbox.com/s/xabjdu6squ6u56r/hapmap3.snps[href=https://www.dropbox.com/s/xabjdu6squ6u56r/hapmap3.snps]) and format the first column of height.txt:\n         \nawk '(NR == FNR){a[$1] = $2; b[$1] = $3$4; next} (FNR ==1){print $0}($1 in a && ($2$3 ==",
    "b[$1] || $3$2 == b[$1])){$1 = a[$1]; print $0}' hapmap3.snps height.txt > height_hm3.txt;\n2. Estimate heritability.\nSNP tagging information must be downloaded prior to estimating heritability. LDAK has SNP tagging files pre-calculated using LDAK-Thin, BLD-LDAK, and BLD-LDAK-Light+Alpha models in different populations. These files can be downloaded from the link provided in the resource, depending on the population used in the original GWAS. It is noteworthy that alpha values should be downloaded from (https://www.dropbox.com/s/o7xphugm4mln9xa/pow.txt[href=https://www.dropbox.com/s/o7xphugm4mln9xa/pow.txt]) for using BLD-LDAK-Light+Alpha model. This model is useful for gene enrichment analysis. Once SNP tagging information is downloaded, SNP-heritability can be estimated using the flag --sum-hers.\n         \nldak5.1.linux --sum-hers height --summary height_hm3.txt --tagfile\nbld.ldak.hapmap.gbr.tagging --check-sums NO;\n--Check-sums is a mandatory flag that tells the pipeline not to match the number of SNPs in summary result to those in the reference tagging file because, generally, all tag SNPs are not present in GWAS summary result."
  ],
  "subjectAreas": [
    "Human Genetics"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics"
  ]
}