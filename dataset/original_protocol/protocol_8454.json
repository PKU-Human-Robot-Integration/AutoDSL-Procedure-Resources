{
  "id": 8865,
  "origin_website": "Jove",
  "title": "SwarmSight: Real-time Tracking of Insect Antenna Movements and Proboscis Extension Reflex Using a Common Preparation and Conventional Hardware",
  "procedures": [
    "1. Catch and Harness Honey Bees\nFollow the Protocol steps 1 through 3.1.1 of Smith and Burden59.\n2. Preparing the Animal Harness and Video Camera\nHide the legs by applying tape over the top of the harness tube, visually inspecting that legs cannot be seen moving from the top.\nRestrain the head by applying heated wax to the back of the insect head. Visually inspect that the head is fixed and not moving. At this point, the antennae and the mandibles should be the only appendages free to move.\nMaximize contrast between the antennae and the video background by placing a white sheet of paper underneath the insect harness. To minimize the need to later adjust the camera, mark the location of the insect harness on the paper, and then place new individuals at the same location.\nFix the camera position using a tripod or a webcam holder to place the camera above the insect's head. Using the camera software, preview the video, and zoom in to magnify the head image, allowing for a ~20 - 30% clearance on all sides of the video.\n\t\nEnsure that the only moving objects in the camera view are the antennae or the proboscis/mandibles and reposition the camera or the animal if necessary.\n\t\tNOTE: SwarmSight checks for movement in pixels surrounding the head. Extraneous motion in the immediate vicinity of the head caused by objects such as legs, shadows, fans, or humans may confuse the software, and introduce additional noise.\nMinimize antenna shadows by adjusting ambient lighting.\n\tNOTE: The software can tolerate some shadows, but for best results, they should be kept to a minimum.",
    "Prevent automatic camera exposure adjustments by using camera shutter speed software to keep the camera exposure time constant throughout the video. Using the software, adjust the shutter speed to maximize contrast (video scene not too light or too dark), by adjusting the 'Exposure slider' under 'Webcam Settings.'\n\tNOTE: The above instructions are specific to the webcam and software used. These will need to be adapted if other webcams are used.\nPlace the odor delivery source and ensure that it does not obstruct the camera view by inspecting the camera video feed. Ensure that a vacuum source is placed on the opposite side to remove the stimulus odors.\nPlace an LED, or some other visual indicator that changes brightness to indicate odor delivery, within the camera view.\n\tNOTE: The LED brightness value is saved by the software and can be used to determine the exact frames when the odor delivery begins and ends.\n3. Film Each Individual under Experimental Conditions\nFilm each individual insect and test condition in separate video files by either recording each individual test combination separately or using video editing software to split a long video file into smaller files.\n\tNOTE: The software requires the user to locate the position of the head in each video, and for the head to remain fixed. If the head moves, additional noise will be introduced. The Batch Processing feature of SwarmSight allows the user to rapidly set the location of the head for multiple videos and assumes that the insect head remains fixed for the duration of each video file. Instructions on how to split long video files can be found online60.\n4. Video Analysis\nDownload and install the 'Antenna Tracking' module by following the steps provided online58.",
    "NOTE: Video tutorials describing how to use the software are available on the website as well.\nOpen a video file showing a filmed animal by using the 'Browse' button.\nPositioning the antenna sensor and treatment sensor\nOnce the video loads, position the rectangular \"Antenna Sensor\" widget over the animal's head, using the rotation and scale icons to align the widget with the head (see Figure 1D for example).\nPosition the circular \"Treatment Sensor\" widget over the LED that indicates when the odor or stimulus is being presented.\n\t\tNOTE: The Treatment Sensor will record the brightness value of the pixel at the center of the widget for every frame.\nStarting video processing\nPress the \"Play\" button (black triangle) in the bottom left corner to start the analysis of the frames.\n\t\tNOTE: The detected likely antenna and proboscis points will be highlighted yellow. The yellow rings will show the location of the tips of the appendages. The angles (where 0 is directly in front of the animal) of the antenna and the proboscis extension length will be shown in the \"Model\" widget in the lower left corner (see Figure 1D). The \"Dominant Sectors\" widget in the lower right corner will show the relative intensity of the five 36-degree sectors where the most antenna points have been detected. The darkest sectors contain the most points, while the lightest have the fewest. The sector number (1 - 5) with the most points will be shown in the lower corners of the widget (see Figure 1D).\nAdjusting filter thresholds and adding exclusion zones\nTo change the sensitivity of the filters, adjust sliders in the \"Filters\" section, on the right panel.",
    "NOTE: Depending on the lighting conditions and general movement speed of the appendages, different filter sensitivities will be optimal. The user can find the optimal values by adjusting the values and observing the highlighted areas in the Antenna Sensor widget. When an ideal set of sensitivities is found, only the appendages will be highlighted. It is recommended to fast forward to other parts of the video to ensure the filter sensitivities are optimal there, too.\nOptionally, to ignore extraneous objects, on the right panel, expand the \"Antenna Sensor\" section, click the \"Add Exclusion Zone\" button (see Figure 1D), and click on a set of points to form a red polygon, the contents of which will be ignored by the software.\n\t\tNOTE: If the video contains extraneous motion, and the motion is within the Antenna Sensor widget's zone (e.g., moving legs, strong shadows, lab equipment, etc.), the software may mistake it for appendage movement. The extraneous objects can be ignored by drawing red polygons or \"Exclusion Zones.\"Â Anything inside a red polygon will not be used for tracking.\nSaving results\nOnce the filters and widgets have been set up, stop the video, restart it from the beginning, and play it to the end.\n\t\tNOTE: Once the whole video has played, the positions of the appendages for all video frames will be stored in the memory.\nTo save the appendage position data to a file, expand the \"Save\" section on the right, and click the \"Save to .CSV\" button. Then choose a folder to save the file.",
    "NOTE: The \"Save to .CSV\" button will save the processing results to a .csv file. By default, the user will be offered to save the .csv file in the same folder as the video file and will have a date and time as part of the file name. The resulting .csv file will contain a set of columns that contain information about the position of the appendages, including the antenna angles and dominant sectors, as well as orientation and position of the head. The description of each column is provided online61.\nOptionally, use the Columns(s) and Value(s) fields in the Save section to create an extra column (or more if separated by commas) in the .csv file to record information, such as subject ID or the name of an experimental condition.\n\t\tNOTE: The value in the Column(s) box will appear in the header of the first column and the value in the Value(s) box will be repeated in all rows of the first column.\nBatch processing\n\tNOTE: The software can process multiple video files in a batch. However, the user must provide the head location information for each video before starting the batch.\n\t\nIn the right panel, in \"Video Files\" section, click the \"Batch Processing\" button to open a window that allows creating a list of video files to be processed sequentially by the software.\nUse the \"Add More Video Files to Batch\" button to select one or more video files to be included in the batch list.\nOptionally, use the \"CTRL\" or \"SHIFT\" keys to select multiple videos that will use the same set of widget parameters.\n\t\tNOTE: Good candidates for parameter reuse are sets of videos of the same animal that has not been moved between different experimental conditions.",
    "Start setting the widget parameters to be used for the selected videos by clicking the \"Set Sensor Positions for Selected\" button.\nAdjust parameters in the Antenna Sensor, Treatment Sensor, Filters, or Save sections, and click \"Save Parameters to Batch\" when done.\nOnce the parameters for each video have been selected, start the batch process by clicking the \"Start Processing\" button.\n\t\tNOTE: The software will load the video files in the order in which they appear in the batch list, process them, and save their corresponding .csv files to the same folder where the video files are located. A progress bar at the top will provide an estimated finish time after the first video has been completed."
  ],
  "subjectAreas": [
    "Neuroscience"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research"
  ]
}