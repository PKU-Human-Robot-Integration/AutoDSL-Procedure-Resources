{
  "id": 2694,
  "origin_website": "Cell",
  "title": "Protocol to explain graph neural network predictions using an edge-centric Shapley value-based approach",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nEdgeSHAPer is applicable to a trained GNN model. We show how to derive a four-layer graph convolutional network (GCN)6[href=https://www.wicell.org#bib6] and then use EdgeSHAPer to explain predictions for an input graph of choice. Initially, we present a step-by-step guide on how to use EdgeSHAPer on chemical compounds encoded as SMILES strings7[href=https://www.wicell.org#bib7] and the resulting molecular graphs to which the method was originally applied. Then, we show how to import the module into any Python program for custom data and tasks.\nData preparation\nTiming: 15 min\nThe first step consists of data preparation. A specific format is required and must be generated (manual step).\nThe data need to be formatted as a comma separated value (.csv) file, in which the SMILES string and label of each compound must be present (any other attribute will be ignored by the program) (Figure 1[href=https://www.wicell.org#fig1] provides an example):\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2184-Fig1.jpg\nFigure 1. Excerpt of a suitable input file\nThe columns in this file simply indicate the SMILES field and the label field. Custom names instead must be specified in the scripts. In our case study, we have binary labels stating the compound to be active (0) or inactive (1) (consistent with standard programming indexing) against a target of interest (in this case, the dopamine D2 receptor). If additional columns are present, they are ignored (not used in the code).\nCreate a .csv file with the required format containing all the molecules.\nPlace the file in a folder of interest.\nOpen the parameters.yml file which contains configurable parameters for the trainer and explainer scripts. Edit this file based on needs.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2184-Fig2.jpg\nFigure 2. Excerpt of a file for the specification of training, validation, and test sets\nAll three files have the same format (SMILES strings separated by a new line).",
    "Optional: It is also possible to create .txt files listing compounds used as training, validation, and test sets. Here, the molecules are identified by their SMILES strings, separated by a new line. An exemplary file is shown in Figure 2[href=https://www.wicell.org#fig2] (having same format for training, validation, and test sets).\nNote: The repository contains data from the original publication,1[href=https://www.wicell.org#bib1] which can be used to test the algorithm.\nGraph neural network training\nTiming: 5 min\nThis step is required for training a GNN. We provide a script to derive a four-layer GCN. However, this step can be omitted if a GNN model is already available. In this case, please, refer to the use of EdgeSHAPer via custom code as an alternative execution (see below).\nRun the script for model training:\nOpen a terminal in the repository root folder.\nIf not already active, activate the conda environment:\n>conda activate edgeshaper_env\nTroubleshooting 3[href=https://www.wicell.org#sec7.5].\nRun the trainer_script.py:\n>python trainer_script.py\nThe script will load the arguments contained in the configuration file parameters.yml. This file may be subject to change with future developments, so please, refer to the GitHub repository for an up-to-date version. The current editable and main parameters include:\nDATA_FILE: your dataset in .csv format.\nTRAIN_DATA_FILE (optional): .txt file with training samples.\nVALIDATION_DATA_FILE (optional): .txt file with validation samples.\nTEST_DATA_FILE (optional): .txt file with test samples.\nSAVE_FOLDER_DATA_SPLIT (optional): the folder path where to save the data split into training, validation, and test sets. Three .txt files will be generated if this option is used.\nSMILES_FIELD_NAME: column name for the SMILES field in DATA_FILE.\nLABEL_FIELD_NAME: column name for the label field in DATA_FILE.\nMODEL_SAVE_FOLDER: location in which the trained model will be saved.\nHIDDEN_CHANNELS: number of hidden channels used for the neural network.\nBATCH_SIZE: batch size used for neural network training.",
    "EPOCHS: number of epochs for which the network will be trained.\nSEED (optional): seed for the random number generator.\nNote: At the time of writing, the default values found in the parameters.yml file are the ones used in Mastropietro et al.1[href=https://www.wicell.org#bib1]\nNote: If training, validation, and test data are not provided, the complete dataset will be divided into training, validation, and test sets according to an 80%:10%:10% ratio. In this case, it might be useful to specify the parameter SAVE_FOLDER_DATA_SPLIT in order to save the resulting data split. The generated files have the same format as the file in Figure 2[href=https://www.wicell.org#fig2].\nEdgeSHAPer explanation execution\nTiming: 1–1.5 min per molecule\nThe last step facilitates the execution of the EdgeSHAPer explainability module. The user is required to submit a .txt file containing the names of the compounds whose predictions should be explained, separated by a new line.\nCritical: The molecules to be explained should not be contained in the training or validation sets according to standard machine learning practice.\nRun the explainer script:\nWith a terminal opened in the repository root folder, run:\n>python explainer_script.py\nThe parameters read from the parameters.yml file include:\nMODEL: model file to load.\nDATA_FILE: your dataset in .csv format.\nMOLECULES_TO_EXPLAIN: .txt file with the SMILES strings of the molecules to explain.\nTARGET_CLASS: class label for which the explanation should be computed.\nSMILES_FIELD_NAME: column name for the SMILES field in DATA_FILE.\nLABEL_FIELD_NAME: column name for the label field in DATA_FILE.\nMINIMAL_SETS: Boolean flag stating whether to compute minimal informative sets (full details are provided in the original publication).\nSAVE_FOLDER_PATH: folder path where to save the explanations, along with additional information.\nHIDDEN_CHANNELS: number of hidden channels in the network to be loaded.\nSAMPLING_STEPS: number of Monte Carlo sampling steps.",
    "VISUALIZATION: Boolean flag specifying whether to generate visualizations for the generated explanations (which will be saved in SAVE_FOLDER_PATH).\nTOLERANCE (optional): permitted deviation between the predicted probability and sum of Shapley values approximation.\nSEED (optional): seed for the random number generator.\nAlternatives: The previous step is used to run the EdgeSHAPer algorithm from a script. However, EdgeSHAPer can also be imported into a project, enabling customizable applications. To use EdgeSHAPer as a component of custom Python code, proceed as follows:\nfrom edgeshaper import edgeshaper\nmodel = YOUR_GNN_MODEL\nedge_index = YOUR_GRAPH_EDGE_INDEX\nx = YOUR_GRAPH_NODES_FEATURES\ndevice = \"cuda\" # or \"cpu\"\ntarget_class = YOUR_TARGET_CLASS\nedges_explanations = edgeshaper(model, x, edge_index, M = 100, target_class = TARGET_CLASS, device = device)\nThe edgeshaper function returns a Python list containing Shapley values for the edges in the same order as in the provided edge_index. This allows a user to freely execute EdgeSHAPer in custom code, providing high flexibility and the possibility of explaining predictions in applicability domains other than cheminformatics. The parameter model denotes the pre-trained GNN model used for the prediction, x and edge_index are the respective features of the graph nodes and the edge index indicating the links among nodes. M is the number of Monte Carlo sampling steps to perform and target_class is the class label for which the explanation is performed. Finally, device indicates whether the model should run on GPU for hardware acceleration or on CPU. Further details concerning additional accepted parameters are provided in the GitHub repository. A second alternative is the use of the provided Edgeshaper class, which offers additional functionalities. First, instantiate an Edgeshaper object, then call its methods:\nfrom edgeshaper import Edgeshaper\nedgeshaper_explainer = Edgeshaper(model, x, edge_index, device = device)",
    "edges_explanations = edgeshaper_explainer.explain(M = 100, target_class = TARGET_CLASS, P = None, deviation = TOLERANCE, log_odds = False, seed = SEED)\nThe method explain applies the EdgeSHAPer algorithm and returns a list of the Shapley values calculated for each edge (the order is consistent with the one in edge_index). P is a parameter used for the generation of the random graphs (indicating the edge existence probability) for Monte Carlo sampling; passing None will use the graph density of the explained graph as the default probability (more details are reported in the original publication1[href=https://www.wicell.org#bib1]). The parameter deviation can be used to set a permitted deviation of the sum of the Shapley values from the predicted probability. The default setting is None, corresponding to no predefined deviation and performing the requested Monte Carlo sampling steps M. Further parameters include log_odds and seed. The former is a Boolean flag set to use log odds instead of probability as the target for the Shapley value approximation. The latter represents the optional seed for the random number generator. Additional methods provided by the Edgeshaper class are compute_pertinent_positivite_set and compute_minimal_top_k_set, which return the minimal informative sets from the explanations along with Infidelity and Fidelity scores, respectively. Let us consider the following example:\npert_positive_set, infidelity_score = edgeshaper_explainer.compute_pertinent_positivite_set()\nminimal_top_k_set, fidelity_score = edgeshaper_explainer.compute_minimal_top_k_set()\nThen, after computing explanations for the compound and optionally minimal sets, they can be visualized with the method visualize_molecule_explanations:\nedgeshaper_explainer.visualize_molecule_explanations(smiles, save_path = SAVE_PATH, pertinent_positive = True, minimal_top_k = True)\nThis method relies on several parameters. The first parameter is smiles, which contains the SMILES strings of the molecule to be explained and the second one is save_path, which indicates the folder where to save the generated images. Finally, the parameters pertinent_positive and minimal_top_k_sets determine whether visualizations are also created for the minimal informative sets.",
    "Note: The GitHub repository is continuously maintained and updated. Hence, settings and scripts are modified periodically to improve the algorithm and enhance the number of features provided. However, to ensure reproducibility, we keep an active branch in the repository named protocol, representing a snapshot of the protocol presented here. A README file states if the main branch is up-to-date or if it has recently been edited. Apart from such updates, general use instructions will remain valid including the main up-to-date branch."
  ],
  "subjectAreas": [
    "Computer Sciences",
    "Chemistry",
    "Bioinformatics"
  ],
  "bigAreas": [
    "Bioinformatics & Computational Biology"
  ]
}