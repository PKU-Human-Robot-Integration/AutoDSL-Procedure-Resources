{
  "id": 10793,
  "origin_website": "Jove",
  "title": "Integrating Visual Psychophysical Assays within a Y-Maze to Isolate the Role that Visual Features Play in Navigational Decisions",
  "procedures": [
    "All experimental protocols were approved by the Institutional Animal Care and Use Committee of the Environmental Laboratory, US Army Engineer and Research and Development Center, Vicksburg, MS, USA (IACUC# 2013-3284-01).\n1. Sensory maze design\nConduct the experiment in a watertight poly methyl methacrylate Y-maze platform (made in-house) set atop of a transparent support platform in a dedicated room. Here the platform is 1.9 cm thick and is supported by 4 7.62 cm beams of extruded aluminum that is 1.3 m in width, 1.3 m in length, and 0.19 m in height.\nConstruct the holding and decision areas to be identical in construction (Figure 1A). Here, the Y-maze arms are 46 cm in length, 23 cm in width, and 20 cm in depth with a central decision area approximately 46 cm in diameter.\nAdhere white project-through theater screen at the bottom of the Y-maze for projecting visual stimuli into the domain.\nCoat the sides of the Y-maze with white vinyl to limit external visual stimuli.\nInstall a remotely controlled clear gate (via clear monofilament) to partition the holding area from the central decision area to release subjects into the maze after acclimation.\nPlace additional blinds to prevent the fish from viewing lights, housing, and equipment, such as light-blocking blinds that reach the floor in door frames to minimize light effects and shadow movements from the external room or hallway.\n2. Recording equipment\nSelect an overhead camera (black and white) based on the contrast needed between the background imagery, virtual fish and subject fish.\nInstall an overhead camera to record the maze from above and to record the behaviors of the fish and the visual projections.",
    "For this demonstration, use b/w Gigabyte Ethernet (GigE) cameras, such that 9 m IP cables were attached to a computer with a 1 Gb Ethernet card in a control room.\nConnect the camera to a computer in an adjoining room where the observer can remotely control the gate, visual stimuli program, and camera recording software.\nEnsure that camera settings are at sampling and frequency rates that prevent any flickering effects, which occur when the camera and software are out of phase with the room lights.\n\t\nCheck the electrical frequency of the location; offset the camera sampling rate (frames per second, fps) to prevent flickering by multiplying or dividing the AC frequency by a whole number.\nSet the camera settings so that image clarity is optimized using the software and computer to visualize the relevant behaviors.\n\t\nFor this demonstration, perform sampling at 30 fps with a spatial resolution of 1280 pixels x 1024 pixels.\n3. Calibrate lighting, projector, and camera settings\nInstall four overhead track lighting systems along the walls of the experimental room.\nInstall adjustable control switches for the lights to provide greater flexibility in achieving the correct room ambient light.\nPosition the lights to avoid reflections on the maze (Figure 1B).\nSecure a short throw (ST) projector to the bottom edge of the maze’s support structure (Figure 1C).\n\t\nSelect the projection resolution (set to 1440 pixels x 900 pixels for this demonstration).\nAdjust ambient light levels, created by the overhead lights and projector, to match the lighting conditions found in the subjects’ housing room (here set to 134 ± 5 lux during the demonstration experiment, which is equivalent to natural lighting on an overcast day).\n\t\nLock or mark the location of the dimmer switch for ease and consistency during experimental trials.",
    "Use a camera viewer program to configure the camera(s) to control exposure mode, gain, and white balance control.\n\t\nIn this demonstration, set the Pylon Viewer to “continuous shot”, 8000 μs exposure time, 0 gain, and 96 white balance, which provides control of the video recording.\n4. Calibrate visual projection program: background\nProject a homogenous background up onto the bottom of the maze and measure any light distortion from the projector. Here the background was created using Processing (v. 3), which is a tractable and well documented platform to create customized visualizations for scientific projects (https://processing.org/examples/).\n\t\nCreate a program that will run a processing window to be projected onto the bottom of the maze. Customizing the background color of the window is done with the background command, which accepts an RGB color code. Several small example programs are found in the Processing tutorials (https://processing.org/tutorials/).\nUse the background color program to calibrate the projector and external lighting conditions.\nMeasure any light distortion created by the projector using an image processing program to identify any deviations from the expected homogeneous background created. The following steps apply to using ImageJ (v. 1.52h; https://imagej.nih.gov/ij/).\n\t\nCapture a still frame image of the illuminated Y-maze with a uniform background color and open in ImageJ.\nUsing the straight, segmented, or freehand line tool draw a straight vertical line from the brightest location in the center of the hotspot to the top of the Y-maze (Figure 2A).\nFrom the analyze menu, select Plot Profile to create a graph of gray scale values versus distance in pixels.\nSave pixel data as a comma separated file (.csv file extension) consisting of an index column and a pixel value column.",
    "Align the projection area with the maze (Figure 2B) and model any unwanted light distortion to reduce any color distortion that may be created by the projector (Figure 2C). The following outline the steps taken in the current demonstration.\n\t\nImport the ImageJ pixel intensity data file using the appropriate tab delimited read function (e.g., read_csv from the tidyverse package to read in comma separated files).\nCalculate the variability in light intensity along the sample transect, such as with a coefficient of variation, to provide a baseline reference for the level of distortion created in the background.\nTransform the raw pixel values to reflect a relative change in intensity from brightest to dimmest, where the smallest pixel intensity will approach the desired background color value selected in the image program.\nPlot the transform pixel intensity values beginning at the brightest part of the anomaly generally yields a decaying trend in intensity values as a function of the distance from the source. Use nonlinear least squares (function nls) to estimate the parameter values that best fit the data (here, a Gaussian decay function).\nCreate the counter gradient using the same program adopted to generate the background counter image (Processing v. 3) to reduce any color distortion that may be created by the projector using R (v. 3.5.1).",
    "NOTE: The gradient function will generate a series of concentric circles centered on the brightest spot in the image that change in pixel intensity as a function of the distance from the center. The color of each ring is defined by subtracting the change in pixel intensity predicted by the model from the background color. Correspondingly, ring radius increases with distance from the source as well. The best fit model should reduce, if not eliminate, any pixel intensity across the gradient to provide a background uniformity.\n\t\nCreate a Gaussian gradient (imgsrc://cloudfront.jove.com/files/ftp_upload/59281/59281eq1.jpg) using the visual stimulus program by adjusting the required parameters.\n\t\t\nParameter a affect the brightness/darkness of the Gaussian distribution gradient. The higher the value, the darker the gradient.\nParameter b affects the variance of the gradient. The larger the value, the broader the gradient will extend before leveling out to the desired background pixel intensity, c.\nParameter c sets the desired background pixel intensity. The larger the value, the darker the background.\nSave the image to a folder using the saveFrame function, so that a fixed background image can be uploaded during the experiments to minimize memory load when rendering the stimuli during an experimental trial.\nRerun the background generating program and visually inspect the results, as shown in Figure 2C. Repeat step 4.3 to quantify any observed improvements in reducing the degree of variability in light intensity across the sample transect.\nEmpirically adjust the lighting levels, model parameters, or the distance covered in the transect (e.g., outer radius of the counter gradient) to make any additional manual adjustments until RGB values of the acclimation zone are similar to the decision area. Model parameters in this test were: a = 215, b = 800, and c = 4.\nAdd the final filter to the experiment visual stimuli program.",
    "5. Calibrate visual projection program: visual stimuli\nNOTE: Rendering and animating the visual stimuli can also be done in Processing using the steps below as guides along with the platform’s tutorials. A schematic of the current program’s logic is provided in (Figure 3) and additional details can be found in Lemasson et al. (2018)7. The following steps provide examples of the calibration steps taken in the current experiment.\nOpen the visual projection program Vfish.pde to center the projection within the maze’s decision area (Figure 1A) and calibrate the visual projections based on the hypotheses being tested (e.g., calibrate the size and speeds of the silhouettes to match those of the test subjects). Calibrations are hand-tuned in the header of the main program (Vfish.pde) using pre-selected debugging flags. In debugging mode (DEBUG = TRUE) sequentially step through each DEBUGGING_LEVEL_# flag (numbers 0-2) to make the necessary adjustments\n\t\nSet the DEBUGGING_LEVEL_0 flag to ‘true’ and run the program by pressing the play icon in the sketch window. Change the x and y position values (Domain parameters dx and dy, respectively) until the projection is centered.\nSet the DEBUGGING_LEVEL_1 to ‘true’ to scale the size of the fish silhouette (rendered as an ellipse). Run the program and iteratively adjust the width (eW) and length (eL) of the ellipse until it matches the average size of the test subjects. Afterwards, set the DEBUGGING_LEVEL_2 to ‘true’ to adjust the baseline speed of the silhouettes (ss).\nSet DEBUG = FALSE to exit debugging mode.\nCheck that distractor silhouettes remain bounded to the Decision Area (DA, Figure 1A), that leader silhouette trajectories are properly aligned with either arm, and that the leader/distractor ratio within the DA remains constant.\nStep through the program’s GUI to ensure functionality of the options.",
    "Check that data are being properly written out to file.\nEnsure that the recording software can track the subject fish with visual projections in place. Steps to track fish have previously been described in Kaidanovich-Berlin et al. (2011)8, Holcomb et al. (2014)9, Way et al. (2016)10 and Zhang et al. (2018)11.\n6. Animal preparation\nChoose the subject species based on the research question and application, including sex, age, genotype. Assign subjects to the experimental holding tanks and record baseline biometric statistics (e.g., body length and mass).\nSet the environmental conditions in the maze to that of the holding system. Water quality conditions for baseline experiments of behavior are often held at optimal for the species and for the experimental domain setup.\n\t\nIn this demonstration, use the following conditions: 12 h light/12 h dark cycle, overhead flicker-free halogen lights set to 134 ± 5 lux, 22 ± 0.3°C, 97.4 ± 1.3% dissolved oxygen, and pH of 7.8 ± 0.1.\nHabituate the animals by transferring them to the domain for up to 30 min per day for 5 days without the computer-generated visual stimuli (e.g., fish silhouettes) before the start of the experimental trials.\nEnsure that the subject fish at that time is selected, assigned, weighed, measured and transferred to experimental tanks.\n\tNOTE: Here, Golden Shiners standard length and wet weight were 63.4 ± 3.5 mm SL and 1.8 ± 0.3 g WW, respectively.\nUse a water-to-water transfer when moving fish between tanks and the maze to reduce stress from handling and air exposure.\nConduct experiments during a regular, fixed light cycle reflecting the subjects’ natural biological rhythm. This allows the subjects to be fed at the end of each day’s experimental trials to limit digestion effects on behavior.\n7. Experimental procedure",
    "Turn on room projector and LED light track systems to predetermined level of brightness (in this demonstration 134 ± 5 lux) allowing the bulbs to warm (approximately 10 minutes).\nOpen the camera viewer program and load the settings for aperture, color, and recording saved from setup to ensure best quality video can be attained.\n\t\nOpen Pylon Viewer and activate the camera to be used for recording.\nSelect Load Features from the camera dropdown menu and navigate to the saved camera settings folder.\nOpen the saved settings (here labeled as camerasettings_20181001) to ensure video quality and click on continuous shot.\nClose Pylon Viewer.\nOpen the visual projection program Vfish.pde and check that the projection remains centered in the maze, that the DataOut folder is empty, and that the program is operating as expected\n\t\nCheck that the calibration ring is centered in the DA using step 5.1.1.\nOpen the DataOut folder to ensure that it is empty for the day.\nRun the visual stimuli program by pressing play in the sketch window of Vfish.pde and use dummy variables to ensure program functionality.\n\t\t\nEnter fish id number (1-16), press Enter, and then confirm the selection by pressing Y or N for yes or no.\nEnter group size (fixed here at 1) and confirm selection.\nEnter desired silhouette speed (0-10 BL/s) and confirm selection.\nPress Enter to move past the acclimatization period and check the projection of the virtual fish in the decision area.\nPress Pause to pause the program and enter the dummy outcome choice, i.e., left (1) or right (2).\nPress Stop to terminate the program and write the data out to file.",
    "Check that data were properly written to file in the DataOut folder and log the file as a test run in the lab notes before fish are placed into the domain for acclimation.\nUse clock time and a stopwatch to log start and stop times of the trial in lab notebook to complement the elapsed times that can later be extracted from video playback due to the short duration of some replicate trials.\nConduct a water change (e.g., 30%) using the holding system sump water before transferring a subject to the maze.\nConfirm that water quality is similar between the maze and holding system, and check gate functioning to ensure that it slides smoothly to just above water height.\nUsing the predetermined experimental schedule, which has randomized subject-treatment exposures over the course of the experiment, enter the values selected for the current trial (stopping at the acclimatization screen, steps 7.3.3.1 - 7.3.3.3).\n\t\nRecord treatment combination data into the lab notebook.\nTransfer the subject into the Y-maze holding area for a 10-minute acclimation period.\nStart the video recording, then hit the Return key in the Vfish.pde window at the end of the acclimation period. This will start the visual projections.\nWhen the virtual fish appear in the domain, log the clock time, and lift the holding gate (Figure 4A).\nEnd the trial when 50% of the subject’s body moves into a choice arm (Figure 4B) or when the designated period of time elapses (e.g., 5 min).\n\t\nLog the clock time, start and stop times from the stopwatch, and the subjects’ choice (i.e., left (1), right (2), or no choice(0)).",
    "Stop the video recording and press Pause in the visual stimuli program, which will prompt the user for trial outcome data (the arm number selected or a 0 to indicate that no choice was made). Upon confirming the selection, the program will return to the first screen and await the values expected for the next experimental trial.\nCollect the subject and return it to the respective holding tank. Repeat Steps 7.7-7.13 for each trial.\nAt the conclusion of a session (AM or PM) press Stop in the program once the last fish of the session has made a decision. Pressing Stop will write the session’s data out to file.\nRepeat the water exchange at the conclusion of the morning session to ensure water quality stability.\nAfter the last trial of the day, review the lab notebook and make any needed notes.\n\t\nPress Stop in the visual stimuli program to output the collected data to the DataOut folder, after the last trial of the day.\nVerify the number, name, and location of the data files saved by the visualization program.\nLog water quality, along with light levels in the maze room to compare with the morning settings. Place the aeration system and heaters into the Y-maze.\nTurn off the projector and experimental room tracking lighting.\nFeed fish the predetermined daily ration.\n8. Data Analysis\nEnsure that the experimental data contain the necessary variables (e.g., date, trial, subject id, arm selected by program, visual factors tested, subject choice, start and stop times, and comments).\nCheck for any recording errors (human or program induced).\nTabulate responses and check for signs of any directional biases on the part of the subjects (e.g., binomial test on arm choice in the control condition)7.",
    "When the experiment is designed using repeated measurements on the same individuals, as in the case here, the use of mixed effects models is suggested.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}