{
  "id": 3020,
  "origin_website": "Cell",
  "title": "Analyzing genomic and epigenetic profiles in single cells by hybrid transposase (scGET-seq)",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nThe GET-seq protocol can be applied to bulk or single cell analysis. It has been validated on several sample types such as cell lines and cancer organoids.1[href=https://www.wicell.org#bib1] We successfully applied this protocol on a input cell number ranging from 50 000 to 200 000, and a target nuclei number of 500 to 10 000. In this protocol, we demonstrate the workflow using Caki1 cell line and describe scGET-seq method steps.\nTransposome assembly and validation\nTiming: 1 day\nThe following steps describe the preparation of the enzymatic complexes which will be exploited for tagmentation and DNA tagging. The validation of transposomes by bulk tagmentation on genomic DNA will also be described. The latter step is necessary to proceed with the GET-seq protocol.\nOptional: If starting from plasmid, follow instructions for Tn5 expression and purification as described in12[href=https://www.wicell.org#bib12] for either Tn5 and TnH protein expression and purification.1[href=https://www.wicell.org#bib1]\nAnneal modified Mosaic End Double-Stranded (MEDS) oligonucleotides.\nTo distinguish tagmentation products derived from Tn5 and TnH transposomes, the two enzymes are loaded with MEDS encoding transposase-specific barcodes (referred to as modified MEDS).\nTn5 and TnH enzymes are used at a 1,62 μM concentration.\nPrepare equimolar mixture of Tn5ME-A and TnHME-A:\nPrepare Tn5ME-A: in a 0.2 mL tube, add 10 μL of each of the four Tn5ME-A oligo (Tn5ME-A.1, Tn5ME-A.2, Tn5ME-A.7 and Tn5ME-A.8, see key resources table[href=https://www.wicell.org#key-resources-table]) to 60 μL H2O, final volume 100 μL.\nPrepare TnHME-A: Add 10 μL of each of the four TnHME-A oligo (TnHME-A.4, TnHME-A.5, TnHME-A.9 and TnHME-A.10, see key resources table[href=https://www.wicell.org#key-resources-table]) to 60 μL H2O, final volume 100 μL.\nPrepare transposons Tn5MEDS and TnHMEDS:\nPrepare Tn5MEDS-A: in a new 0.2 mL tube, mix 10 μL Tn5ME-A (from step 1.a.i.) to 10 μL ME-rev.",
    "Prepare TnHMEDS-A: in a new 0.2 mL tube, mix 10 μL TnHME-A (from step 1.a.ii) to 10 μL TnME-rev.\nPrepare ME-B: mix 50 μL TnME-B with 50 μL TnME-rev.\nAnneal transposons. Incubate the microcentrifuges tubes prepared in previous steps containing TnHMEDS-A, Tn5MEDS-A, ME-B in a thermocycler23[href=https://www.wicell.org#bib23]: denature 3′ at 95°C, ramp down in 30″ steps to 26°C at a rate of −1°C/step (total of 46 cycles). Store transposons at −20°C; transposons are stable for at least 1 year.\nMix equal molar annealed ME-B with Tn5MEDS-A to obtain Tn5MEDS transposon. Mix equal molar annealed ME-B with TnHMEDS-A to obtain TnHMEDS transposon.\nAssemble Tn5 and TnH transposome.\nDilute Tn5MEDS and TnHMEDS transposon to 10 μM in nuclease-free water.\nIn two 1.5 mL tube mix 50 μL of purified Tn5 and purified TnH with 7,15 μL (0.143 vol) Tn5MEDS and TnHMEDS transposon, respectively.\nIncubate 1 h at room temperature, then keep complexes on ice if proceeding with next step, or return tubes to −20°C.\nValidation of transposomes activity.\nBulk tagmentation of genomic DNA.\nSet thermocycler for 55°C incubation.\nThaw gDNA at room temperature. Dilute gDNA to 0.5 ng/μL with TE.\nAssemble tagmentation reaction, using two 0.2 mL tubes. Of those, use one for TnH and the other for Tn5 tagmentation:\nTagmentation reaction mix\ntable:files/protocols_protocol_2563_7.csv\nMix by repeated pipetting, then briefly spin down.\nCRUCIAL: add a positive control reaction. It is possible to use a previously validated in-house produced transposomes or TDE1 Enzyme (formerly Nextera) (Illumina) enzyme. Expect resulting libraries to have the same distribution profile of the positive control.\nIncubate 7′ at 55°C in the thermocycler.\nBring the tube to room temperature and stop tagmentation reaction by adding 5 μL of 0.2% SDS solution. Incubate 5′ at room temperature.",
    "CRUCIAL: This step allows transposase detachment from DNA.12[href=https://www.wicell.org#bib12] If SDS is not added, this will result in failure of the subsequent amplification step. Note that also chaotropic agents, such as guanidinium thiocyanate contained in the column-based purification kit will result in protein detachment from DNA and fragment releasing.\nPause point: Tagmented DNA can be stored at −20°C before purification for at least 1 week.\nPurification of tagmentation product. For this purification we routinely use the DNA Clean & Concentrator- 5 kit (Zymo Research), but it is possible to use other column-based purification kit (e.g., Qiagen MinElute Reaction Cleanup Kit).\nAdd 5× vol of Zymo binding buffer (20 μL) to sample, mix by pipetting and add to the filter column. Centrifuge to ≥10′000 rcf.\nAdd 200 μL Zymo Wash Buffer (prior first use, add absolute ethanol as recommended). Centrifuge for 30 s. Repeat this step once (total of two washes). Discard flowthrough and collection tube. Put the column filter onto a new labeled 1.5 mL microcentrifuge tube.\nElute by adding 15 μL of Zymo Elution Buffer directly to the filter. Incubate 2′ at room temperature, then centrifuge to ≥10′000 rcf.\nPause point: Store eluted purified tagmentation product at −20°C if not proceeding immediately to the next step.\nPCR amplification.\nBefore starting, thaw IDT for Illumina UD Indexes plate at room temperature, spin at 1,000 × g for 1 min and keep it on ice.\nLoad the amplification program on the thermocycler.\nHave the AmpureXP beads equilibrated at room temperature for at least 30′. Prepare fresh 80% ethanol.\nPrepare 8-tube strips (0.2 mL).\nAssembly amplification mastermix for the number of samples prepared plus a negative control (no template, substituting template volume with water) as follows:\ntable:files/protocols_protocol_2563_8.csv\nUse the following PCR program:\ntable:files/protocols_protocol_2563_9.csv",
    "CAUTION: The gap filling step is crucial to create an amplifiable template, as the tagmentation reaction result in a 9 bp gap between the nontransferred strand and the target DNA.24[href=https://www.wicell.org#bib24]\nPost-PCR purification.\nResuspend AmpureXP beads by vortexing.\nAdd 0.8× AmpureXP beads to each PCR-amplified sample, mix by pipetting and incubate 5′ at room temperature.\nPerform a quick spin and put the 8-tube strip on a 96-well plate magnetic stand for 5′ or until solution clears. Discard supernatant while avoid disrupting bead pellet.\nUsing a multichannel pipette, add 200 μL 80% ethanol to each well. Wait 30″ and discard ethanol. Repeat this step once for a total of two washes.\nTransfer the 8-tube strip to a tube rack, wait 3′ to achieve ethanol evaporation but be careful to not overdry beads pellet. This would result in beads cracking and affect recovery yield.\nAdd 20 μL of nuclease-free water or Resuspension Buffer. Pipette mix and put strip back to magnet. Wait 2′. Meanwile, prepare a new 8-tubes strip.\nTransfer supernatant without disrupting bead pellet.\nQuantify product using fluorimetric method such as Qubit (ThermoFisher). Negative control should have a non-detectable concentration (typically <0.5 μg/mL).\nAssessment of tagmentation product fragment size.\nWe routinely utilize a digital capillary electrophoresis platform to evaluate fragment distribution, such as TapeStation (Agilent) or Bioanalyzer (Agilent).\nAlternatives: Other systems can be used to analyze fragments, e.g., LabChip (PerkinElmer). For genomic DNA tagmentation is possible to use D1000 Tape Station assay. Sample concentration should be adjusted according to quantitative chip range (in case of D1000, is 0.1–50 ng/μL; in case of High Sensitivity D1000HS is 10–1,000 pg/μL).\nNuclei preparation\nTiming: 1–2 h",
    "In the following steps we describe cell permeabilization to allow nuclei transposition. We routinely observe a 50% cell loss during nuclei preparation; therefore, we suggest to always start from an excess cell number. We routinely start from 100,000 cells.\nFor this step, precool fixed-angle centrifuge; have freshly prepared (<24 h) Lysis, Wash and Diluted nuclei buffers, keep those refrigerated on ice.\nCritical: For any successful single cell protocol, high quality preparation with viable cells is required. Dead or dying cells can affect cell recovery and release genomic material that will drain the sequencing efficiency for cells selected for the analysis (see Problems and Solutions). For any new sample type, we therefore suggest performing beforehand pilot experiments to assess i) the best protocol for sample dissociation and ii) always thoroughly check vitality using Trypan Blue stain and a manual (Burker chamber) or automated brightfield/fluorescence cell counter (e.g., Luna, Logos Biosystem; TC20, Bio-Rad). In case of a vitality <80% we do recommend performing live cell enrichment by means of FACS-sorting, enrichment kits such as Dead Cell Removal kit (Mylteni), or microfluidic-based separation approaches such as LeviCell (LevitasBio).\nNote: You can start from a fresh sample, cryopreserved nuclei (e.g., obtained after tissue disaggregation) or cryopreserved cells or cryopreserved tissues. Whole cells can be frozen in a 15% DMSO-FBS solution and stored at −80°C for short-term storage, or liquid nitrogen for extended periods, then thawed and processed as fresh cells.\nStarting from cell culture suspension, wash cells in PBS+0.04%BSA two times, then assess cell concentration and vitality.\nNote: If cell suspension vitality is equal to or higher than 80% proceed with the preparation, otherwise see recommendation in the CRITICAL section.\nPrepare 200,000 cells aliquots in a 1.5 mL tube.",
    "Note: It is possible to start from even lower cell numbers. We tested as low as 50,000 cells. In these cases, cell pellets may not be evident during washes, so particular care should be taken during pipetting steps, removing the supernatant gently on the tube side opposite of where the pellet is expected.\nCritical: From now on, always work on ice and use precooled centrifuge.\nCentrifuge tubes at 300 g, 5′ at 4°C. Turn all the tubes hinges to point outward centrifuge axle. Expect the pellet to be on the hinge side.\nWith a p1000 pipette, gently aspirate 80% of the supernatant volume. With a p200 pipette try to aspirate as much supernatant as possible without disturbing the pellet (e.g., if starting with 1,000 μL sample, aspirate 800 μL with a p1000 pipette, and 190 μL with a p200).\nKeeping the tube on ice, add 100 μL Lysis Buffer and pipette mixing 3 times. Start the timer as soon as you mix the reaction components.\nNote: permeabilization time must be assessed for each cell type. Start from 1 min with 30 s increases to find the permeabilization time yielding >90% trypan-blue positive nuclei.\nFor Caki-1 and HeLa cells, incubate cells 3 min in Lysis buffer on ice.",
    "Critical: optimize incubation time in Lysis Buffer for each new sample type. We suggest starting from 1′ incubation and increase in 30″ steps. Before starting the incubation, we suggest having a 96-well plate to dilute cells for vital counting nearby in which you already added 5 μL of Trypan Blue in the first row. Then, for each timing, 10″ before the time is up, take 5 μL of cell suspension in Lysis Buffer and quickly dilute in the plate containing Trypan blue, then load 8 μL on your Burker Chamber or automated counter slide. Check the lysis efficacy (percentage of Trypan Blue positive cells) as function of incubation time.\nNote: If processing multiple samples in parallel, make sure to have all tubes incubated for the same amount of time to avoid different lysis efficacy.\nAdd 1 mL cold Wash Buffer to stop the lysis by dilution. Mix by inversion.\nCentrifuge at 500∗g 5′ at 4°C.\nDiscard the supernatant, being careful of not perturbing the nuclei pellet. With a p1000 pipette, gently aspirate 80% of the supernatant volume. With a p200 pipette try to aspirate as much supernatant as possible without disturbing the pellet (e.g., if starting with 1,000 μL sample, aspirate 800 μL with the p1000 and 190 μL with p200).\nResuspend nuclei pellet in Diluted Nuclei Buffer (DNB) to obtain the final Nuclei Stock. The volume is computed according to target concentration which is function of target nuclei recovery (as described in the ‘Nuclei concentration guidelines’ guide in the Chromium Next GEM Single Cell ATAC Reagent Kits manual[href=https://www.10xgenomics.com/support/single-cell-atac/documentation/steps/library-prep/chromium-single-cell-atac-reagent-kits-user-guide-v-1-1-chemistry], 10× Genomics).",
    "For example, if we aim at 5,000 nuclei target recovery, and we start from 200,000 cells, we suggest a target concentration of 3,000 nuclei/μL. In this case you will resuspend nuclei pellet in 30 μL of DNB. After adding DNB, mix by pipetting 3–4×.\nDouble-check actual concentration by manual counting using a Burker chamber (we suggest diluting the sample 10 times using DNB): this represents the Nuclei Stock Concentration. Calculate the volume of nuclei stock to be used in the following step with this formula (as stated in Chromium Next GEM Single Cell ATAC Reagent Kits v1.1/2 User Guide):\nV\no\nl\no\nf\nN\nu\nc\nl\ne\ni\nS\nt\no\nc\nk\n(\nμ\nL\n)\n=\nT\na\nr\ng\ne\nt\nn\nu\nc\nl\ne\ni\nr\ne\nc\no\nv\ne\nr\ny\nx\n1.53\n(\nr\ne\nc\no\nv\ne\nr\ny\ne\nf\nf\ni\nc\ni\ne\nn\nc\ny\nf\na\nc\nt\no\nr\n)\nN\nu\nc\nl\ne\ni\nS\nt\no\nc\nk\nC\no\nn\nc\ne\nn\nt\nr\na\nt\ni\no\nn\nFollowing the previous case example, if we aim at analyzing 5,000 cells, and our nuclei stock concentration is 3,000 nuclei/μL, the nuclei stock volume will be:\nV\no\nl\no\nf\nN\nu\nc\nl\ne\ni\nS\nt\no\nc\nk\n(\nμ\nL\n)\n=\n5000\nx\n1.53\n3000\n=\n2.55\nμ\nL\nTransposition and GEM formation\nTiming: 2 h\nPrepare the PCR thermocycler at 37°C.\nIn a new tube, prepare the transposition mix:\ntable:files/protocols_protocol_2563_10.csv",
    "If performing multiple reactions, prepare a mastermix accounting for a 10% volume excess. Mix by pipetting; spin down briefly to collect any drops on tube walls. Aliquot 8.5 μL for each experimental condition in a new 8-tube strip.\nAdd Diluted nuclei buffer to the nuclei stock, with a final total volume of 5 μL. In our example, 5 μL total volume – 2.55 μL nuclei stock = 2.45 μL diluted nuclei buffer. Gently pipette mix. Add to the transposition mix tube.\nTransfer the tube-strip to the thermocycler set at 37°C for 30′.\nAfter 30′, pause incubation timer, open tubes cap and add 1.5 μL TnH transposome stock to each reaction tube. Gently pipette mix 3×, very briefly spin down and start last 30′ incubation.\ntable:files/protocols_protocol_2563_11.csv\nDuring this time, equilibrate at room temperature the following reagents from Chromium Next GEM Single Cell ATAC Reagent Kits:\ntable:files/protocols_protocol_2563_12.csv\nLibrary preparation and sequencing\nTiming: 2–3 days\nIn this section we provide instructions and recommendation for library preparation and sequencing on Illumina platforms.\nPrepare sequencing reagents and custom primers for Read1 and Index2. Primers resuspended to 100 μM can be aliquoted and stored at −20°C for >6 months.\nAt the end of the incubation time, proceed with GEM generation and library preparation according to 10X Genomics protocol[href=https://www.10xgenomics.com/support/single-cell-atac/documentation/steps/library-prep/chromium-single-cell-atac-reagent-kits-user-guide-v-1-1-chemistry] (here we refer to V1.1 chemistry).\nAssess library concentration using a fluorimetric method such as Qubit dsDNA assay. Evaluate fragment distribution by digital electrophoresis platform such as TapeStation or Bioanalyzer (Agilent). We use the D5000 HS reagents (Agilent). Final library structure is reported in Figure 1[href=https://www.wicell.org#fig1].\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2563-Fig1.jpg\nFigure 1. Final scGET-seq library structure\nPosition of sequencing primer is reported. Please note use of custom Read 1 and Index 2 primers.",
    "Note: Expected library profile will be slightly different from the standard 10× genomics scATAC library profile. We routinely observe a higher representation of the lower library peak (approx. 250 bp).\nNote: We observed that library fragmentation profile is not always a directly measure of tagmentation performance and specificity. Indeed, in some cases we observed traces with less pronounced library peaks yielding proper relative enrichment over chromatin states. In such cases, we suggest to perform a preliminary library quality check by bulk sequencing aiming at 50M reads, with paired-end sequencing protocol and single index read. In this way you will not read Cell Barcode (i5 read) but obtain a pseudo-bulk tagmentation profile to assess library quality (details in steps 21–26).\nNote: If your library has >50% of fragments higher than 800 bp, we expect this to be due to errors in the last step of library purification and/or to undertagmentation.Under-tagmentation can be related to poor permeabilization, especially when working with complex tissue for which sometimes is difficult to achieve a proper disaggregation resulting in a single cell suspension. This high MW fragment will impact sequencing as those fragments will hybridize to the flow-cell as well but with low sequencing efficiency. It’s possible to eliminate or decrease the amount of >800 bp library by performing a right-side clean up using Ampure XP or SPRI beads (See troubleshooting[href=https://www.wicell.org#troubleshooting] Section, problem 3[href=https://www.wicell.org#sec6.5]).\nCalculate library molar concentration: use ng/μL concentration assessed using fluorimetric assay (e.g., Qubit) and mean library size (bp) assessed by digital electrophoresis (e.g., TapeStation):\nn\nM\n=\nl\ni\nb\nr\na\nr\ny\nc\no\nn\nc\ne\nn\nt\nr\na\nt\ni\no\nn\n(\nn\ng\nu\nL\n)\n660\n(\na\nv\ne\nr\na\ng\ne\nM\nW\no\nf\nd\ns\nD\nN\nA\nb",
    "p\n,\ng\nm\no\nl\n)\n∗\nm\ne\na\nn\nf\nr\na\ng\nm\ne\nn\nt\ns\ni\nz\ne\n(\nb\np\n)\n×\n10\n6\nTo assess mean library size, we routinely use Tapestation Analysis Software and select a Region which includes library up to 750 bp. Please refer to previous notes if your library distribution is significantly enriched in fragments >800 bp.\nCompute target cluster number. We recommend a higher sequencing depth than for standard scATAC-seq, specifically 100,000 reads pairs per nucleus to account for increased genomic coverage. E.g., when targeting 5,000 nuclei, we recommend aiming at 100,000 reads pair /nucleus will result in a total of 500,000,000 read pairs (i.e., 500,000,000 clusters).\nFollow Illumina specification for diluting sample for loading and sequencing on selected platform.\nCRUCIAL: Add 15% PhiX to the library pool to account for the low diversity in the first 27 bases of Read1.\nNote: scGETseq libraries can be sequenced on Novaseq and Nextseq series platforms and require custom primers for Read1 and Index2 reads, as the tag included in the MEDS-A sequence disrupts native Illumina R1 and I2 primer binding site (see key resources table[href=https://www.wicell.org#key-resources-table] for sequences). Custom primers are to be added to the wells containing Illumina primers at a final concentration of 0.3 μM:\nNextSeq loading (reagents v2 and later): add Read1_primer to well #20 and index_2_primer to well #22.\nNovaSeq (reagents V1.5): add Read1_primer to well #24 and index_2_primer to well #23.\nNote: Always refer to Illumina Custom Primer guide for updated instructions about Illumina primer positions and volumes (https://support.illumina.com/bulletins/2016/04/spiking-custom-primers-into-the-illumina-sequencing-primers-.html[href=https://support.illumina.com/bulletins/2016/04/spiking-custom-primers-into-the-illumina-sequencing-primers-.html]).\nAnalysis of minicontrol -bulk data (transposomes validation)\nTiming: 1–2 days",
    "In this section, we detail the analysis of bulk GET-seq data sequenced to evaluate the goodness of enrichment over heterochromatic regions. We exemplify the process assuming a single sample has been processed and it has been given the mock name “sample1”.\nOptional: Merge sequencing lanes into single files. If demultplex was performed allowing multiple lanes to be splitted (i.e., sample1_L001_R1_001.fastq.gz, SEQ1_L002_R1_001.fastq.gz…), these could be merged together to simplify the procedure.\nNote: merging should be performed at read pair level, i.e., R1 and R2 files must be merged separately.\n$ SAMPLE=”sample1”\n$ for r in 1 2\ndo\n  cat ${SAMPLE}_∗_R${r}_∗.fastq.gz > ${SAMPLE}_R${r}.fastq.gz\ndone\nSeparate reads generated by each transposase with tagdust16[href=https://www.wicell.org#bib16] and compress resulting files.\n$ tagdust -1 B:CGTACTAG,TCCTGAGC,TCATGAGC,CCTGAGAT,TAAGGCGA,GCTACGCT,AGGCTCCG,CTGCGCAT ∖\n      -2 S:AGATGTGTATAAGAGACAG ∖\n      -3 R:N ${SAMPLE}_R1.fastq.gz ${SAMPLE}_R2.fastq.gz ∖\n      -o ${SAMPLE} ∖\n      -t 8\n$ gzip ${SAMPLE}_BC_∗.fq\nRepeat this step for each sample. This step generates 8 set of paired reads for each sample. Each file will have a structure like ${SAMPLE}_BC_${BARCODE}_READ[12].fq.gz, where $BARCODE is one of the 8 transposase-specific sequences, also indicated in the box above. More in detail, the expected files are:\nsample1_BC_CGTACTAG_READ1.fq.gz\nsample1_BC_CGTACTAG_READ2.fq.gz\nsample1_BC_TCCTGAGC_READ1.fq.gz\nsample1_BC_TCCTGAGC_READ2.fq.gz\nsample1_BC_TCATGAGC_READ1.fq.gz\nsample1_BC_TCATGAGC_READ2.fq.gz\nsample1_BC_CCTGAGAT_READ1.fq.gz\nsample1_BC_CCTGAGAT_READ2.fq.gz\nsample1_BC_TAAGGCGA_READ1.fq.gz\nsample1_BC_TAAGGCGA_READ2.fq.gz\nsample1_BC_GCTACGCT_READ1.fq.gz\nsample1_BC_GCTACGCT_READ2.fq.gz\nsample1_BC_AGGCTCCG_READ1.fq.gz\nsample1_BC_AGGCTCCG_READ2.fq.gz\nsample1_BC_CTGCGCAT_READ1.fq.gz\nsample1_BC_CTGCGCAT_READ2.fq.gz\nCritical: this step generates uncompressed fastq files, be sure you have enough disk space available (e.g., 10× the size of compressed files at the end of step 1).\nAlign reads to reference genome. In principle any aligner could be used to achieve this, we only tested bwa.13[href=https://www.wicell.org#bib13] We recommend default bwa options for alignment. Options impacting performance, such as number of threads, could be set matching the hardware in use.\n$ bwa mem [BWA OPTIONS] ${SAMPLE}_BC_{BARCODE}_READ[12].fq.gz | ∖\n  samblaster | ∖\n  samtools sort -T ${SAMPLE}_BC_${BARCODE}_tmp -o ${SAMPLE}_BC_${BARCODE}.bam",
    "This step must be repeated for each barcode and for each sample. We suggest samblaster15[href=https://www.wicell.org#bib15] to remove duplicated reads as it can be piped, but alternative strategies could be used as well.\nMerge alignments according to their transposase.\n$ samtools merge -cp ${SAMPLE}_Tn5.bam ∖\n  ${SAMPLE}_BC_CGTACTAG.bam ∖\n  ${SAMPLE}_BC_TCCTGAGC.bam ∖\n  ${SAMPLE}_BC_TCATGAGC.bam ∖\n  ${SAMPLE}_BC_CCTGAGAT.bam\n$ samtools index ${SAMPLE}_Tn5.bam\n$ samtools merge -cp ${SAMPLE}_TnH.bam ∖\n  ${SAMPLE}_BC_TAAGGCGA.bam ∖\n  ${SAMPLE}_BC_GCTACGCT.bam ∖\n  ${SAMPLE}_BC_AGGCTCCG.bam ∖\n  ${SAMPLE}_BC_CTGCGCAT.bam\n$ samtools index ${SAMPLE}_TnH.bam\nThis step is repeated for each sample.\nCompute read counts over chromatin states using bedtools.20[href=https://www.wicell.org#bib20] We provide chromatin segmentation derived from ENCODE project25[href=https://www.wicell.org#bib25] for human (hg38) and mouse (mm10) in the scatACC github repository (see key resources table[href=https://www.wicell.org#key-resources-table]).\n$ ls sample1∗.bam | sort -u > files.txt\n$ bedtools multicov -bed ${CHROMATIN_SEG} -bams `cat files.txt` > state_counts.bed\nCompute the relative enrichment of read counts in heterochromatic regions.\n$ python enrich_qc.py state_counts.bed files.txt\nThis script calculates the relative enrichment of TnH over Tn5 for all chromatin states. It generates three files.\nState_Enrichment.png: a boxplot representation of the relative enrichments over chromatin segmentation groups. The boxplot is ordered according to decreasing mean (see section “expected outcomes[href=https://www.wicell.org#expected-outcomes]”).\nState_Enrichment.txt: a text file containing the average enrichment over chromatin segmentation groups for each sample.\nState_enrichment_state.txt: a text file with descriptive statistics for enrichments.\nAutomated processing of single cell data\nTiming: 2–3 days\nIn this section, we describe the steps for automated data analysis of single cell data. It requires the scGET tools listed in the Resource Table. We exemplify the process assuming two samples have been processed and they have been given the mock names “sample1” and “sample2”.\nDemultiplex sequencing reads. Refer to cellranger-atac manual to perform this step. Only cellranger-atac mkfastq step is required.\nDefine variables into config.yaml file.\ngenome: full path to genome indices for bwa. Must include genome prefix as well.",
    "bed_file: full path to a bed file containing the intervals to be analyzed. We suggest and provide 5kb fixed-size windows over the entire genome.\nthreads: number of computing threads.\ncell_number: the expected number of cells (see step 12).\nscatacc_path: the full path to the scatACC tools directory.\ninput_path: path to the directory containing fastq files. Note that paths defined at step 3 will be relative to this path.\noutput_path: path to the output directory.\ninput_list: the path to input file containing the list of fastq files (see step 3).\n---\nbarcodes: {'tn5':['CGTACTAG','TCCTGAGC','TCATGAGC','CCTGAGAT'],'tnh':['TAAGGCGA','GCTACGCT','AGGCTCCG','CTGCGCAT']}\ngenome: PATH_TO_GENOME_FASTA_FILE\nbed_file: PATH_TO_REGIONS_FILE\nthreads: 8\ncell_number: 5000\nscatacc_path: PATH_TO_scatACC_DIRECTORY\ninput_path: ROOT_PATH_TO_FASTQ_FILES\ninput_list: PATH_TO_INPUT_FILE_LIST\noutput_path: PATH_TO_OUTPUT_FOLDER\nbinary: False\ntnh: True\ntn5: True\natac: False\n...\nOptional values include the possibility to produce binary counts and to analyze only Tn5 or TnH barcodes. The pipeline could also be used to analyze scATAC-seq files, setting “atac” to True and both “tn5” and “tnh” to False.\nCreate a text file named input_file.txt with information about sequence reads separated by space. Each line contains three fields: the path to fastq file, the read number and the name of sample. The path to fastq files could be absolute or relative to step 2.f. The path of input_file.txt should be set in step 2.h.\npath/to/sample1_file1_R1.fastq.gz 1 sample1\npath/to/sample1_file1_R2.fastq.gz 2 sample1\npath/to/sample1_file1_R3.fastq.gz 3 sample1\npath/to/sample1_file2_R1.fastq.gz 1 sample1\npath/to/sample1_file2_R2.fastq.gz 2 sample1\npath/to/sample1_file2_R3.fastq.gz 3 sample1\npath/to/sample2_file1_R1.fastq.gz 1 sample2\npath/to/sample2_file1_R2.fastq.gz 2 sample2\npath/to/sample2_file1_R3.fastq.gz 3 sample2\npath/to/sample2_file2_R1.fastq.gz 1 sample2\npath/to/sample2_file2_R2.fastq.gz 2 sample2\npath/to/sample2_file2_R3.fastq.gz 3 sample2\nMove to scGET tools directory where the github repository has been cloned (hereafter defined as $scGET_tools_DIR) and run the workflow specifying the path to config.yaml file (step 2) and, possibly, the number of threads/processes to be spawned in parallel by the workflow manager ($SLURMTHREADS). Currently only slurm workflow manager is fully supported.",
    "$ cd ${scGET_tools_DIR}\n$ snakemake --profile=slurm ∖\n  --threads=${SLURMTHREADS} ∖\n  --configfile=${PATHTO}/config.yaml\nQuality control\nTiming: 15–45 min\nIn this section, we describe how to control if scGET-seq properly enriched reads on heterochromatic regions of the genome. This step can only be executed if epigenetic annotation is available. We provide annotation files, derived from the ENCODE project, for hg38 and mm10 genomes as part of scatACC tools. This step evaluates enrichment at “bulk level”, i.e., it doesn’t take into account information of single cells.\nCreate a list of files containing all deduplicated bam files and count the number of reads over intervals defining chromatin segmentation using bedtools.20[href=https://www.wicell.org#bib20]\n$ cd $OUTPUT_PATH\n$ find . -name ∗_bcdedup.bam | sort -u > files.txt\n$ bedtools multicov -bed ${CHROMATIN_SEG} -bams `cat files.txt` > state_counts.bed\nRun the QC script, specifying the output files of the previous step.\n$ python enrich_qc_bc.py state_counts.bed files.txt\nData preprocessing\nTiming: 1–5 h\nIn this section, we describe the minimal code snippet used to read data and perform preprocessing. The entire workflow is executed in python. Duration of this step can be influenced by the number of samples and the computing power.\nImport required libraries.\nimport scanpy as sc\nimport cellrank as cr\nimport scipy.sparse as ssp\nimport statsmodels.api as sm\nimport sklearn.preprocessing as skp\nimport tensorly as tl\nimport tensorly.decomposition as tld\nimport copy\nDefine statistical functions to fit Zero Inflated Poisson (ZIP) distributions. This function will be used to fit distributions of Tn5 and TnH read counts.\ndef fit_zip_mme(M):\n  U = skp.StandardScaler(with_mean=False).fit(M.T)\n  m = np.abs(U.mean_)\n  s2 = U.var_\n  mask = m >= s2\n  l_m = np.abs((s2+m∗∗2)/m - 1)\n  p_m = (s2-m)/(s2 + m∗∗2 - m)\n  p_m[mask] = 0\n  l_m[mask] = m[mask]\n  return(l_m, p_m)",
    "Read data and filter background entries. In the current example, the directory will contain files “sample1.h5ad” and “sample2.h5ad”. Different samples need to be imported and concatenated into a single data file. Mitochondrial chromosome information, which usually accumulate a large fraction of counts, should be removed to properly fit the ZIP distribution. Data are stored in a AnnData object.26[href=https://www.wicell.org#bib26] As such it can contain multiple count matrices in slots named “layers”. The current workflows stores counts from both transposases in two layers named ‘Tn5’ and ‘TnH’. For more information about the AnnData object, refer to its official guide (https://anndata.readthedocs.io[href=https://anndata.readthedocs.io]).\nsamples = ['sample1', 'sample2']\n  data = [None for x in samples]\nfor x in range(len(samples)):\ndata[x] = sc.read(f\"{samples[x]}/{samples[x]}.h5ad\")\nadata = data[0].concatenate(data[1:], batch_categories=samples)\nautosomes = [x for x in adata.var_names if not x.startswith('chrM')]\nadata = adata[:, autosomes]\ncells = [x for x in adata.obs_names if not x.startswith('Back') and not x.startswith('GGGGGGGGGGGGGGGG-')]\nadata = adata[cells]\nOptional: regions that are blacklisted, such as genome gaps or centromeric repeats, could be removed at this stage. We provide blacklist overlap with 5kb windows in the same file used in step 27.b.\ndf = pd.read_table(\"hg38_5kbin_dhs_counts_blcounts.txt\", header=None, index_col=0)\nadata.var['DHS_Count'] = df[1]\nadata.var['blacklist_coverage'] = df[2]\nadata = adata[:, adata.var['blacklist_coverage'] == 0]\nFit Zero Inflated Poisson distribuitions over data.\nx5 = adata.layers['Tn5']\nxh = adata.layers['TnH']\nl_h, p_h = fit_zip_mme(xh)\nl_5, p_5 = fit_zip_mme(x5)\nadata.obs['lambda_TnH'] = l_h.ravel()\nadata.obs['lambda_Tn5'] = l_5.ravel()\nadata.obs['p0_TnH'] = p_h.ravel()\nadata.obs['p0_Tn5'] = p_5.ravel()",
    "Filter cells with low coverage or excess of zero counts. The number of cells to retain should be roughly in the same order of magnitude with the number of cells defined at step 12. In our experience, a coverage not lower than 2,000 reads (as sum of Tn5 and TnH reads.) is suitable for most experiments (twice the coverage suggested elsewhere for analysis of scATAC-seq data27[href=https://www.wicell.org#bib27]). In addition, we usually filter out cells with less than 90% of regions with zero counts.\nnnz = (x5 + xh).nonzero()\nu, c = np.unique(nnz[1], return_counts=True)\nadata = adata[:, u[c > np.nanpercentile(c, 90)]]\nmask = adata.obs['coverage'] > 2000\nadata = adata[mask]\nl_h = adata.obs['lambda_TnH']\nl_5 = adata.obs['lambda_Tn5']\np_h = adata.obs['p0_TnH']\np_5 = adata.obs['p0_Tn5']\nDefine the support for ZIP distribution and the number of random samples to evaluate the empirical cumulative function.\ndmin, dmax = np.min(x5-xh), np.max(x5-xh)\ndmax += 1\nXr = np.arange(dmin, dmax)\nZIP = sm.distributions.zipoisson\nECDF = sm.distributions.empirical_distribution.ECDF\nn_rvs = 100000\nCalculate the accessibility according to ZIP distributions.\nNote: Since probabilities are extracted from the empirical cumulative density function, computed on randomly generated numbers, accessibility values can fluctuate in multiple iterations of the same routine.\nDiff = adata.layers['Tn5'] - adata.layers['TnH']\nadata.layers['log_cdf'] = np.zeros(adata.shape)\nfor x in range(Diff.shape[0]):\n  V = Diff[x].A.squeeze()\n  zmask = (adata.layers['Tn5'][x].A.squeeze() == 0) & (adata.layers['TnH'][x].A.squeeze() == 0)\nM = ZIP(l_5[x], p_5[x]).rvs(n_rvs) - ZIP(l_h[x], p_h[x]).rvs(n_rvs)\n  pr = ECDF(M, side='right')(Xr)\n  pl = ECDF(M, side='left')(Xr)\n  tail_thr = Xr[pr >= 0.5][0] # the thr for tails\n  adata.layers['log_cdf'][x][V < tail_thr] = np.log( pl[(V[V < tail_thr] + np.abs(dmin)).astype(int)])\n  adata.layers['log_cdf'][x][V >= tail_thr] = -np.log(1 - pr[(V[V >= tail_thr] + np.abs(dmin)).astype(int)])\n  adata.layers['log_cdf'][x][zmask] = 0\nadata.layers['log_cdf'][adata.layers['log_cdf'] == -np.inf] = -np.ceil(-np.log(1/n_rvs))\nadata.layers['log_cdf'][adata.layers['log_cdf'] == np.inf] = np.ceil(-np.log(1/n_rvs))\nadata.layers['log_cdf'] = ssp.csr_matrix(adata.layers['log_cdf'])",
    "Optional: Normalize and log transform data. This step affects the default count matrix in the object, which stores only Tn5 signals. Since the subsequent analysis of scGET-seq data rely on the difference between Tn5 and TnH data, this step is not necessary and it could be used only to look at scGET-seq data as they were produced by a standard scATAC-seq protocol.\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nCompute tensor decomposition of Tn5 and TnH data. Each region/cell data point in scGET-seq is represented by a tuple of two numbers, one from each enzyme. The two count matrices are then coupled and can be represented as a tensor. Similarly to what is done in scATAC-seq, where Singular Value Decomposition is applied to reduce the dimensionality, we here perform tensor decomposition.\npf = adata.layers['Tn5'].sum(1).A.ravel() + adata.layers['TnH'].sum(1).A.ravel()\nx5 = np.log1p(ssp.diags(pf.mean()/pf)@adata.layers['Tn5'])\nxh = np.log1p(ssp.diags(pf.mean()/pf)@adata.layers['TnH'])\nGET = np.array([x5.A, xh.A])\nGET = tl.tensor(GET)\nrank = 200\nttd = tld.tensor_train(GET, rank=[1, 1, rank, 1])\nadata.obsm['X_ttd'] = ttd.factors[1].reshape((GET.shape[1], rank))\nadata.uns['ttd_weights'] = ttd.factors[0].squeeze()\nadata.layers['NTn5'] = x5\nadata.layers['NTnH'] = xh\nCompute neighbors and UMAP embeddings. We use bbknn28[href=https://www.wicell.org#bib28] for batch integrations, other batch integration strategies could be used. For a detailed overview on integration methods, refer to 29[href=https://www.wicell.org#bib29] and 30[href=https://www.wicell.org#bib30].\nn_samples = len(samples)\nn_neighbors = int(np.sqrt(adata.shape[0])/2)\nn_neighbors=n_neighbors//n_samples\nsc.external.pp.bbknn(adata, use_rep='X_ttd', n_pcs=20,\n            neighbors_within_batch=n_neighbors,\n            metric='angular'\n            )\nsc.tl.umap(adata)\nIn the following box we provide an example of integration using Harmony.31[href=https://www.wicell.org#bib31]\nn_neighbors = int(np.sqrt(adata.shape[0])/2)\nsc.external.pp.harmony_integrate(adata, basis='X_ttd',\n            adjusted_basis='X_ttd_harmony’,\n            max_iter_harmony=100\n            )\nsc.tl.neighbors(adata, metric='cosine’, use_rep='X_ttd_harmony',\n        n_neighbors=n_neighbors)\nsc.tl.umap(adata)\nCompute cell clusters. We here use schist library22[href=https://www.wicell.org#bib22] and select the first level of the hierarchy with more than one group defined.\nimport schist as scs\nscs.inference.nested_model(adata)\nmodularity = adata.uns['schist']['nsbm']['stats']['modularity']\nlevel = np.where(modularity > 0)[0][-1]\nsc.pl.umap(adata, color=f'nsbm_level_{level}',\n      title='Clusters', frameon=False)\nOptional: Compute the global accessibility score.\nn_open = np.sum(adata.layers['log_cdf'] > 0, 1).A.squeeze()\nn_close = np.sum(adata.layers['log_cdf'] < 0, 1).A.squeeze()\nadata.obs['r_open'] = n_open / (n_open + n_close)",
    "Optional: Compute cell-wise accessibility moments, these will be used for cellrank analysis.\nadata.layers['MTn5'] = ssp.csr_matrix.dot(adata.obsp['connectivities'], adata.X)\nM = ssp.csr_matrix.dot(adata.obsp['connectivities'],adata.layers['log_cdf'])\nadata.layers['Macc'] = M\nOptional: Compute cellrank kernels. Use a velocity kernel to model accessibility and a connectivity kernel to regularize. Cellrank21[href=https://www.wicell.org#bib21] is a toolkit to describe cellular dynamics in single-cell data. A cellrank kernel is a computational framework to compute cell-cell transition probabilities.\nvk_cdf = cr.tl.kernels.VelocityKernel(adata, xkey='MTn5', vkey='Macc')\nvk_cdf.compute_transition_matrix(scheme='cosine')\nck = cr.tl.kernels.ConnectivityKernel(adata)\nck.compute_transition_matrix()\ncombk = .8 ∗ vk_cdf + .2∗ck\ncombk.compute_transition_matrix()\nOptional: Compute macrostates. A macrostate is a coarse-grained group of cells having which is unlikely to transition to other macrostates. In this example we only compute two macrostates. Refer to cellrank manual pages on how to inspect cellrank results and calculate the optimal number of states.\ng_fwd = cr.tl.estimators.GPCCA(combk)\ng_fwd.compute_schur()\ng_fwd.compute_macrostates(n_states=2)"
  ],
  "subjectAreas": [
    "Genomics",
    "Sequence Analysis",
    "Cell Separation/Fractionation",
    "Bioinformatics",
    "Cell Biology",
    "Molecular Biology",
    "Sequencing",
    "Single Cell",
    "High Throughput Screening"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics",
    "Bioinformatics & Computational Biology",
    "Bioengineering & Technology"
  ]
}