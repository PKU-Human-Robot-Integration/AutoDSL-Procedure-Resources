{
  "id": 10382,
  "origin_website": "Jove",
  "title": "Evaluating Flight Performance and Eye Movement Patterns Using Virtual Reality Flight Simulator",
  "procedures": [
    "All methods described here have been approved by the Institutional Review Board (IRB) of Tsinghua University, and informed consent was obtained from all participants. After completion, all participants were paid $12 (or a gift of equal value).\n1. Participant selection\nRecruit participants according to a prior study of power analysis using G*Power software35 (see Table of Materials) to ensure the participant number meets the expected sample size given by G*Power, which equals 21.\n\tNOTE: The expected sample size given by G*Power refers to the estimated number of participants needed in a study to achieve a desired level of statistical power based on the specified effect size, significance level, and statistical test used. The expected sample size is an important consideration in research planning. It helps researchers determine the feasibility and cost-effectiveness of their study design and ensures that the study has sufficient statistical power to detect meaningful effects.\nEnsure none participants have a history of epilepsy, heart or brain disease, recent endocrine or psychiatric medication, or severe skin allergies.\nUse the Snellen eye chart (use the metric system 6/6)36 to confirm that participants' vision is normal or corrected-to-normal and that they don't have any visual impairments like color blindness or color weakness.\nEnsure that none of the participants have consumed alcohol or drugs within the previous 24 h that may affect their ability to fly.\nEnsure the participants have had no less than 6 h of sleep and are in good mental condition before the experiment.\n2. Flight simulator hardware\nCheck that all of the flight simulator's hardware is complete. According to its function, this hardware is organized into three modules (Table 1) (see Table of Materials).\n\tNOTE: Researchers need to touch a metal rod before touching the equipment to avoid the risk posed by electrostatic induction.",
    "Check the components of the VR, HMD (head-mounted display), and eye-tracking module with the help of Table 2.\nEnsure that all the flight simulator PC module components meet the following minimum requirements: 3.6G Hz processor, 4G internal memory, 64-bit operating system, and graphics card. The system will support all flight controllers.\nCheck the components of the flight control module and ensure the device's parameter configuration is consistent with Table 3.\nInstall the hardware of the flight simulator according to the layout in Figure 1. Figure 2 shows how the hardware is connected.\n\t\nJoin the throttle and control panel physically and treat them as a unit.\nConnect the throttle, joystick, and pedal to the flight simulator PC module via USB.\nConnect the HMD to the flight simulator PC module via the link box.\nConnect the base stations and VR controllers to the HMD via the VR software on the PC.\ntable:\n﻿0,1\nVR head-mounted display(HMD) and eye tracking module,1. Base Station\nVR head-mounted display(HMD) and eye tracking module,2. VR HMD\nFlight Simulator PC module,3. Flight Simulator PC\nFlight control module,4. Flight Throttle\nFlight control module,5. Flight Joystick\nFlight control module,6. Flight Pedal\nTable 1: Components of the three modules of flight simulator hardware.\ntable:\n﻿0,1\nMain component,Accessories\nVR HMD,Headset cable (attached)\nVR HMD,Face cushion (attached)\nVR HMD,Cleaning cloth\nVR HMD,Earphone hole cap × 2\nLink box,Power adapter\nLink box,DisplayPort cable\nLink box,USB 3.0 cable\nLink box,Mounting pad\nControllers (2018) × 2,Power adapters × 2\nControllers (2018) × 2,Lanyards × 2\nControllers (2018) × 2,Micro-USB cables × 2\nBase Station 2.0 × 2,Power adapters × 2\nBase Station 2.0 × 2,\"Mounting Kit (2 mounts, 4 screws, and 4 wall anchors)\"\nTable 2: List of components of the VR HMD and eye-tracking module.\ntable:\n﻿0,1\nDevice,Parameter configuration\nFlight Joystick,Nineteen action buttons",
    "Flight Joystick,\"One 8-way \"\"point of view\"\" hat\"\nFlight Joystick,Several 3D magnetic sensors\nFlight Joystick,One 5-coil spring system\nFlight Joystick,One 16-bit resolution (65536 x 65536 values).\nFlight Control Panel,Fifteen action buttons\nFlight Control Panel,One TRIM wheel\nFlight Control Panel,Five programmable LEDs\nFlight Throttle,Seventeen action buttons\nFlight Throttle,One mouse hat with a push button\nFlight Throttle,\"One 8-way \"\"point of view\"\" hat\"\nFlight Throttle,Several 3D magnetic sensors\nFlight Throttle,Two 14-bit resolution\nFlight Pedal,Tension between 2.5 kg and 5 kg\nFlight Pedal,Angle between 35° and 75°\nTable 3: The parameter configuration of the devices of the flight control module.\nimgsrc://cloudfront.jove.com/files/ftp_upload/65170/65170fig01.jpg\nFigure 1: The layout of the VR flight simulator hardware. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/65170/65170fig01large.jpg]\nimgsrc://cloudfront.jove.com/files/ftp_upload/65170/65170fig02.jpg\nFigure 2: The connection of flight simulator hardware. (A) Flight control module. The throttle and control panel are physically joined and treated as a unit. If the term \"throttle\" is used in this study, it refers to both the throttle and the control panel. (B) Flight simulator PC module. A computer that meets the requirements outlined in step 2.2. (C) HMD and eye-tracking module. The software development kits (SDKs) for eye tracking and the 3D engine are kept in sync when installed on the same computer. Therefore, the eye-tracking functions and the operating system interact and work together. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/65170/65170fig02large.jpg]\n3. Flight simulator software\nEnsure all the software (see Table of Materials) has been installed before the experiment begins. Information about all software used in the experiment is shown in Table 4.\ntable:\n﻿0,1,2,3,4\nName,Description,Description,Description,Description",
    "VR software,A widely used tool for experiencing VR content on the hardware.,A widely used tool for experiencing VR content on the hardware.,A widely used tool for experiencing VR content on the hardware.,A widely used tool for experiencing VR content on the hardware.\nVR app store,\"The app store for virtual reality where customers can explore, create, connect, and experience the content they love and need.\",\"The app store for virtual reality where customers can explore, create, connect, and experience the content they love and need.\",\"The app store for virtual reality where customers can explore, create, connect, and experience the content they love and need.\",\"The app store for virtual reality where customers can explore, create, connect, and experience the content they love and need.\"\nEye-tracking software,Eye-tracking software developed by the research team via Eye-tracking and 3D engine SDKs.,Eye-tracking software developed by the research team via Eye-tracking and 3D engine SDKs.,Eye-tracking software developed by the research team via Eye-tracking and 3D engine SDKs.,Eye-tracking software developed by the research team via Eye-tracking and 3D engine SDKs.\nFlySimulator,\"The main program of the flight simulator software, developed by the research team.\",\"The main program of the flight simulator software, developed by the research team.\",\"The main program of the flight simulator software, developed by the research team.\",\"The main program of the flight simulator software, developed by the research team.\"\nScreen recording software,A free and open source software for video recording and live streaming.,A free and open source software for video recording and live streaming.,A free and open source software for video recording and live streaming.,A free and open source software for video recording and live streaming.\nTable 4: Information about all software used in the experiment.\n4. Preparation before launching the flight simulator",
    "NOTE: If this is one's first time running the eye-tracking program, perform the additional steps according to Figure 3. The eye-tracking program will activate automatically after the initial run.\nimgsrc://cloudfront.jove.com/files/ftp_upload/65170/65170fig03.jpg\nFigure 3: The additional steps when running the eye-tracking program for the first time. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/65170/65170fig03large.jpg]\nEnsure that the HMD is turned on and connected to the computer.\nPlace the base station diagonally to ensure the HMD can always be inside the base station's monitoring range. Keep the base station fixed to keep a stable VR environment.\nSet up a standing-only play area according to the prompts given by the VR software on the computer.\n\tNOTE: The prompt allows a room-scale area or sets up a standing-only play area. Standing-only mode is generally used to experience VR scenes that do not require walking and can be selected when the user has limited space to move around. Therefore, in this experiment, set up a standing-only play area.\nSet the eye-tracking calibration. The eye-tracking system must be recalibrated every time the participant is switched.\n\t\nConfirm that the participants are not using contact lenses, which causes eye tracking to malfunction.\nOpen the eye-tracking calibration program using the VR controllers (see Table of Materials).\nAdjust the device height, interpupillary distance (IDP), and gaze point as the system directs.\nGet the participant's eyes to light up each spot for 2 s in a clockwise direction to verify the effectiveness of the eye-tracking calibration.\nConnect the tuned flight control module and large screen display (i.e., at least a 27 inch monitor) to the same computer as the VR HMD. The screen allows the experimenter to view what is happening in the VR HMD simultaneously.\n5. Experimental procedure",
    "NOTE: The experiment is divided into four steps: \"collect information,\" \"introduce the task and operation,\" \"practice before the experiment,\" and \"conduct a formal experiment.\" The experimental process is summarized in Figure 4.\nimgsrc://cloudfront.jove.com/files/ftp_upload/65170/65170fig04.jpg\nFigure 4: The flowchart of the experiment. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/65170/65170fig04large.jpg]\nCollect information from participants (15 min).\n\t\nFill out the payment details form with the payment information of the participants.\nInform the participants to read the informed consent document and sign it.\nIntroduce the task and simulator operation to the participants (5 min).\n\t\nExplain to the participants the traffic pattern and map (Figure 5).\nInstruct participants on how to use the VR flight simulator.\nInform the participants that they can leave the experiment if they experience discomfort while simulating a flight.\nAsk the participants to practice using the VR flight simulator (15 min).\n\t\nFit the VR HMD to the participants and calibrate the eye movements. Adjust the device height, interpupillary distance (IDP), and gaze point as instructed by the system.\nOpen the screen recording software.\nLaunch the FlySimulator program to assist participants with flight training.\nInstruct the participants to use the flight pedal, joystick, and throttle in concert to steer the aircraft as closely as possible to the reference line of flight (Figure 5).\nReset the flight throttle and engine switch buttons after exiting the FlySimulator program, and stop recording the screen after the subject has completed the practice.\nConduct formal flight experiments (20 min).\n\t\nPut on the VR HMD for the participants, and run OBS Studio to start recording the screen.\nStart the FlySimulator program, choose a fit perspective, start the engine, let go of the parking brake, and put the flight throttle to full.",
    "Exit the FlySimulator program, then reset the flight throttle and engine switch buttons. Stop recording the screen.\nimgsrc://cloudfront.jove.com/files/ftp_upload/65170/65170fig05.jpg\nFigure 5: The traffic pattern for the VR flight simulator. The pitch angle is the rotation angle around the left and right axes of the aircraft, and the reference line (or the center reference line) is right in the middle of the red and green lines. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/65170/65170fig05large.jpg]\n6. Data analysis\nAnalyze eye movement data.\n\t\nDivide five area of interest (AOI) zones in this study; for more information about the calculation of AOIs, see Figure 6, based on the actual panel of the flight cockpit corresponding to the flight cockpit instrument (Figure 7).\nCalculate the AOI difference test using the percentage of dwell time in the AOI zone37, given the equipment feature of the VR oculomotor used in this study.\n\t\tNOTE: The average percentage of dwell time is the cumulative percentage spent looking within an AOI divided by the total fixation time and averaged across participants.\nAnalyze flight performance data with custom-developed programming scripts using Python 3.10. The core algorithm for performance metrics was adapted from the QAR analysis method, inspired by the 35 BAE-146 aircraft QAR data provided by the National Aeronautics and Space Administration (NASA)38.",
    "NOTE: Flight performance indicators for this study: the total flight time (the total length of time from takeoff to landing for each participant, in seconds), pitch angle 1 s before landing (pitch angle of the aircraft 1 s before landing, obtained from raw data, in degrees), mean distance to reference line (mean error of the spatial distance between the aircraft and the reference line during flight, in meters), and standard deviation of distance to reference line (standard deviation of the spatial distance between the plane and the reference line during flight, in meters).\nConduct the statistical analyses.\n\t\nUse the Shapiro-Wilk test39 to confirm the data's normality.\nUse statistical software (see Table of Materials) for descriptive statistics, Mann-Whitney U test, and Student's t-test.\nDepict the violin plots to indicate better the shape of the data distribution40.\n\t\tNOTE: The explanation for the effect size measured using Cohen's d is as follows: 0.1 is very small, 0.2 is small, 0.5 is medium, 0.8 is large, 1.2 is very large, and 2.0 is huge41,42. The significance level was set at p < 0.05.\nimgsrc://cloudfront.jove.com/files/ftp_upload/65170/65170fig06.jpg\nFigure 6: AOI preprocessing and calculating flow process. Sections 1 to 4 describe how the present study processed the pilots' eye movement data up to the independent-sample t-test. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/65170/65170fig06large.jpg]\nimgsrc://cloudfront.jove.com/files/ftp_upload/65170/65170fig07.jpg",
    "Figure 7: Schematic diagram of AOI division of flight instrument. The function of instruments: (A) The airspeed indicator indicates ﻿the aircraft's speed relative to the air. (B) The altitude indicator shows the aircraft's pitch and roll altitude. (C) The vertical speed indicator indicates the aircraft's ascent or descent speed. (D) The altitude indicator indicates the aircraft's barometric altitude. (E) The engine speed indicator indicates the speed of the aircraft engine. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/65170/65170fig07large.jpg]Subscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}