{
  "id": 13510,
  "origin_website": "Jove",
  "title": "Assessing the Multiple Dimensions of Engagement to Characterize Learning: A Neurophysiological Perspective",
  "procedures": [
    "This protocol received an ethical certificate from the Comité institutionnel de la recherche avec des êtres humains (CIER) de l’Université du Québec à Montréal (UQAM) that was endorsed by HEC-Montreal for the Tech3Lab research facility. The protocol describes each of the specific steps that are performed in our lab environment and equipment. Although precise software paths are provided to clarify the methodology, this technique is transferable and can be replicated with other proprietary eye-tracking, automatic facial emotion recognition, electrodermal activity and electroencephalography equipment and software.\n1. Setup of the Lab Environment\nTurn on the eye-tracker, the EEG amplifier, the four recording computers and the speakers.\nPrepare the setup of the recording equipment:\n\t\nPrepare the EEG setup with required material according to the manufacturer’s recommended procedures. Prepare the EEG software for the upcoming participant. Start the eye-tracking software and create a new participant profile in the software. Start the video recording software and the cameras.\nStart the synchronization software with the specific subroutine created for the project with markers at 60 sec. Start the physiological measurement software (to record electrodermal activity) and open the specific layout created for the project. Adjust the participant’s chair to the highest level.\n2. Participant Preparation\nAsk the participant to read and sign the ethical consent form.\nCarry out skull measurements for EEG:\n\t\nFind the Cz location on the participant’s head (according to 10 - 20 reference systems). Immerse the EEG net in the saline solution (potassium chloride) (see step 1.2.1) and start a timer (10 min) in accordance with the manufacturer’s standards.",
    "Read the objective of the study and the steps in the experiment to the participant, “The objective of this study is to observe your brain activity while you answer physics problems. First we will install the sensors, then you will be asked to solve 10 Newtonian physics problems on the computer. We will ask you to take a 45-sec break after each problem with your eyes closed. After each problem, you will be asked to rate your assessment of the problem.”\nTell the subject that the total duration of the experiment will be 90 min.\nInstall the physiological sensors, according to the manufacturer’s recommendations: two gelified sensors on the top of the left hand.\nInstall the EEG cap, according to the manufacturer’s recommendations and perform an impedance check with a threshold at 40 kΩ (according to the manufacturer’s specifications).\n3. Data Collection\nMake sure that all the recording software is ready to be started in synchrony:\n\t\nPhysiology (EDA data): Click the “start” button.\nVideo recording: Click the “open” button.\nEye-tracking: Click the “on hold” button.\nEEG: Click the “record” button.\nSynchronization software: Click the “green circle” button.\nEye gaze calibration:\n\t\nPerform a five-point on-screen calibration and observe the participant while he/she follows the red dots (click “Tools/Settings/Calibration …”). Repeat this procedure until sufficient accuracy is achieved, according to the manufacturer’s standards.\nProject task instructions onto the participant’s screen: ask if he/she has any questions after reading them, and if he/she is ready to start the experiment.\nAsk the participant to solve 10 Newtonian physics problems.\nIf needed, perform an impedance check during one of the 45 s breaks (not before problem 5).\nMake sure the participant takes the full 45 s break before each problem (to determine the baseline).\n4. End of Data Collection",
    "Stop data acquisition on all computers and remove the sensors from the participant.\n5. After the Participant Has Left\nClean the EEG cap with germicide and tidy up the equipment, according to the manufacturer’s recommendations. Save all the data files collected and create a backup on the FTP server.\nFill in the participant spreadsheet: note any particular event or problem during data collection. Erase all cookies from the web browser.\n6. Data Pre-processing and Export to the Integration Software\nEEG\n\t\nImport EEG data into EEG data analysis software:\n\t\t\nCreate three empty folders on the computer named “Raw data”, “History” and “Export” to paste the raw EEG data into the newly created Raw data file.\nIn the EEG data analysis software, click “File/New Project …” and choose the raw data location by clicking Browse, then selecting the newly created raw data file. Choose the location of the “History” and “Export” folders in the same way.\nClick “OK”. (The window should contain all the participant’s EEG data).\nPre-process the brain signal:\n\t\t\nApply a filter and a notch (click “Transformations/IIR filters…”). In the window, enable the low cutoff at 1.5 Hz with a slope of 12 dB and the high cutoff at 50 Hz with a slope of 12 dB. Also enable a notch at 60 Hz frequency.\nBecause a DC amplifier is used, DC detrend the signal (Click “Transformations/DC Detrend…” and enable “based on time” at 100 msec before marker and 100 msec before DC connection).\nPerform a raw data inspection (Click “Transformation/Raw data inspection…” and select semi-automatic artifact removal). Select the following: maximal voltage 60 µV/ms; Max-min: 200 µV in 200 ms interval; amplitude: -400 to +400 µV).",
    "Perform an automatic ICA with classic sphering for eye blink removal (myographic artifacts do not need to be removed because their range is outside of the frequencies of interest). (Click “Transformations/ICA…”. At the end of the ICA, process the inverse ICA.)\nRe-reference (“Transformations/Re-reference…”) the signal and select “common average”.\nExport (click “Export/Generic Data Export…”) the signal and markers in text format (Select the “.vhdr” box) for an eventual Matlab construction of the engagement index. Also select the “Write header file” and “Write marker file” boxes.\nImport the signal in Matlab.\n\t\t\nStart Matlab and type “eeglab” so the GUI of EEGLab appears and Import the data for one participant at a time. In the GUI, select item menu “File/Import Data/Using EEGLab functions and plugins/From Brain Vis Rec .vhdr file”.\nIn the command window, paste a script16 that generates an engagement index.  \n\t\t\tNOTE: The cognitive engagement script is computed by the average of each Beta/(Alpha + Theta) ratio within a 20 sec sliding window preceding time T. This procedure is repeated every second and a new sliding window is used to update the index.\nIn MS Excel, open the text file of the engagement index that is generated at the end of the script by Matlab and apply a z-score normalization on EEG data to allow intersubject comparison. (For each value, compute this formula in Excel: Z=(value – overall mean)/overall standard deviation.)\nSave the z-score engagement index signal in a CSV file in MS Excel. (Click File/Save as … and select CSV in the format type.)\nRepeat the procedure (from step 6.1.2.2.) for each participant.\nPhysiology:\n\t\nImport EDA data in physiological data analysis software.\nApply these parameters to pre-process the physiological signal:\n\t\t\nApply a logarithmic transformation to normalize the distribution of the conductance as per Venables and Christie’s23 method.",
    "Flat the signal on a 10 sec sliding window24.\nWithin the physiological software, compute a z-score normalization on the EDA data to allow intersubject comparison. (Z=(value – overall mean)/overall standard deviation).\n\t\t\nHighlight all the data with the cursor from the EDA channel.\nIn the top menu, select the EDA channel, and select “mean” to obtain the mean value of the overall channel. Also select the EDA channel and “stddev” to obtain the standard deviation value of the overall channel.\nTo compute the z-score equation, click “Transformation/Waveform Math …” and select the EDA channel in Source 1 . Select “–” (minus) in the mathematical operation window and select K in source 2. Select “New destination” in the destination menu and enter the mean value of the EDA channel (see step 6.2.3.2). Select “Transform entire wave”, click OK and click “Transformation /Waveform Math …”. Select the EDA-K channel in source 1, select “/” (divide) in the mathematical operation window, select K in source 2, select “New destination” in destination and enter the standard deviation value of the EDA channel (step 6.2.3.2). Select “Transform entire wave” and click OK.\nExport the signal (arousal) in a CSV file. (Click File/Save as … and select CSV in the format type.)\nAutomatic facial emotion recognition:\n\t\nImport video data from the media recorder into automatic facial emotion recognition software. (Click “File/New…/Participant…”. After selecting a new participant in the project menu by clicking on it, click “File/New/Analysis/Video…”. Click the magnifying glass next to Analysis 1 and choose the desired video file.\n\t\t\nSelect an offline analysis for “every third frame” and activate “continuous calibration”.",
    "Export valence data in a CSV file. (Click “Options/Settings/Logging…”, check the “Write valence value to the log file” box. Click “File/Export…”, choose the location where the log files will be exported, and check the “Save detailed log” box.)\nOpen the CSV file in MS Excel. Copy the valence data column in a single column of SPSS software. Click “Analyse/Descriptives Statistics/Descriptives” and select the just-pasted variable name. Check the box “Save standardized values in variables”. A column with a z-score will appear. Copy-paste these z-scores over the old data in the Excel file.\nSave the Excel file with the z-scores of the signal (valence) in CSV format.\n7. Data Integration and Synchronization\nIn behavioral analysis software:\n\t\nImport eye-tracking videos (behavioral engagement). (Click “File/Import/Video in a New Observation…”. Name the new observation and choose the desired video file.)\nCode each video with pertinent behaviors and contextual events (time markers, right/wrong answers).\nImport all external data with the appropriate header: z-score of EEG signal (cognitive engagement), z-score of EDA signal (emotional engagement), z-score of valence data (emotional engagement). (Click “File/Import/External Data…”. Select the appropriate file type and select the correct CSV file.)\nSynchronize time between computers according to these formulas:\n\t\nTime in eye gaze from time in EEG = Time in eye gaze + second marker in EEG – first marker in eye gaze.\nTime in eye gaze from time in facial emotion recognition = Time in eye gaze + first marker in facial emotion – first marker in eye gaze.\nTime in eye gaze from time in electrodermal activity = Time in eye gaze + first marker in electrodermal activity – first marker in eye gaze.",
    "Enter the offset data by pressing “Ctrl + Shift + =”, to open the Offset menu. Select “Numerical offset” to enter the time in seconds between each pair of data sources [OK?]), according to the calculations above.\nGenerate a report according to the variables of interest in the study.\n\t\nSelect interesting variables that will be generated in the report (click “Analyze/Select Data/New Profile Data…”). From the left, slide the desired variables between the “Start” box and the “Results” box, on the right.\nGenerate the report. (Click “Analyze/Numerical Analysis/New…”, click “Statistics” and check the mean box in the external data menu. Finish by clicking “Calculate”.)\nExport the data into statistical analysis software and perform analysis according to the study objectives.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}