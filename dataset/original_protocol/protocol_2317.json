{
  "id": 2442,
  "origin_website": "Cell",
  "title": "Imaging and analysis for simultaneous tracking of fluorescent biosensors in barcoded cells",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nEstablishing the pipelines part 1: Training deep learning models\nTiming: 5–7 days\nAlthough the barcodes can be visually identified, we highly recommend using deep learning models for more efficient barcode identification. The main task of these models is to classify the barcode images into different subcellular locations with high accuracy. These models are trained on images from cells expressing known barcodes, and their accuracy can be improved by increasing the number of training images and fine-tuning the hyperparameters. In our experience, an overall accuracy of 95% is required to achieve satisfactory analysis results. Due to differences in cell morphology, models trained on one cell type may not achieve the same accuracy on other cell types (Yang et al., 2021[href=https://www.wicell.org#bib20]). This section describes the steps in training models on HeLa cells expressing 8 different barcodes that are relevant to the experiments in the protocol. All the scripts and associated files are available at https://github.com/BearHuangLab/Biosensor-barcoding[href=https://github.com/BearHuangLab/Biosensor-barcoding]. Throughout the protocol, we will refer to the relative directories of the files on our GitHub. The final models are available in the directory “2. Barcode identification/Barcode reading GUI/”. The same procedure can be applied to other cell types expressing different barcodes.\nSeed 4 × 105 HeLa cells in a 35 mm glass-bottom tissue culture dish with imaging medium. Incubate cells at 37°C, 5% CO2 overnight.\nUse any method of choice to transfect cells with the barcode and biosensor plasmids. Here we use the GenJet™ In Vitro DNA Transfection Reagent Ver. II (SignaGen® Laboratories).\nFor each dish, remove the old medium and replace with 1 mL fresh imaging medium 30 min before transfection.\nPreparation of the DNA-GenJetTM mix.",
    "For each dish, dilute 1 μg of DNA with 50 μL of serum-free DMEM. Two barcode plasmids are used for each transfection as shown in Table 1[href=https://www.wicell.org#tbl1]. Start with a 1:1 ratio for the two plasmids. Adjust the ratio if the fluorescence signal is too bright or too dim.\ntable:files/protocols_protocol_1926_4.csv\naSee Figure 1[href=https://www.wicell.org#fig1]A legend for barcode nomenclature.\nFor each dish, dilute 3 μL GenJet™ Transfection Reagent with 50 μL of serum-free DMEM. Vortex for 5 s and spin down briefly. Immediately add the diluted GenJet™ Reagent to the diluted DNA. Pipette up and down 5 times to mix. Leave the mixture at room temperature for 15 min.\nAdd the DNA-GenjetTM complex dropwise onto cells in the 35 mm dishes. Incubate cells at 37°C, 5% CO2 overnight.\nOn a Zeiss LSM780-FCS laser scanning confocal microscope, capture the images of mCherry and BFP under 633 nm and 405 nm excitation, respectively.\nTurn on the microscope and set the stage incubator to 37°C.\nOpen the Zen software. Switch the objective to the 40× oil lens and locate the cells.\nSwitch to “Acquisition” and click the “Channel Mode” tab under “Light Path”.\nSelect 30 positions with at least 6–10 fluorescent cells in each viewing field. To generate a good training set, a total of 200 or more cells is recommended for each barcode.\nSelect the 633 nm laser as the excitation source and set spectrum collection range from 561 to 695 nm with pinhole set to 30.2.\nClick the “Snap” button to capture the image.\nSelect the 405 nm laser as the excitation source and set spectrum collection range from 371 to 430 nm with pinhole set to 30.2.\nClick the “Snap” button to capture the image.\nRepeat step 3 until images of all barcodes are collected.",
    "Save the two files. Name the files with suffix “633Ex” and “405Ex” accordingly. (e.g., [Experiment ID]_633Ex.lsm and [Experiment ID]_405Ex.lsm).\nImage processing: We use ImageJ and Python to process and save the images. Some examples of processed images can be found at “4. Toy example/Training_image”.\nOpen the image files ([Experiment ID]_633Ex.lsm and [Experiment ID]_405Ex.lsm) and the macro “0. Image Processing/make montage.ijm” with ImageJ by dragging the files onto the ImageJ toolbar or importing the file through File>Open and selecting the file. Example image files can be found at “4. Toy example/Image_processing”.\nSince the image sequences contain multiple positions, we stitch together all 30 positions by clicking “Run” in the macro window (Figure 2[href=https://www.wicell.org#fig2]A, a).\nnPositions =30; // change it to the number of positions\nrun(\"Make Montage...\", \"columns=nPositions rows=1 scale=1\");\nRight-click the images and rename them to “633Ex” and “405Ex”, respectively.\nManually select the cells using the ImageJ selection tool (Figure 2[href=https://www.wicell.org#fig2]A, b) and save the regions of interest (ROIs) in the ImageJ ROI manager by pressing “T” on the keyboard. Selections should only contain one cell and should not overlap with other cells (Figure 2[href=https://www.wicell.org#fig2]A, c). Save the ROIs by clicking More>Save all in the ROI manager (Figure 2[href=https://www.wicell.org#fig2]A, d).\nOpen and run the script (“0. Image Processing/save barcode.ijm”) below to concatenate and save the barcode images with RFP on the left and BFP on the right. Include the barcode labels in the file names in the format of “[Experiment ID]_[Subcellular location]_[Barcode]_[Cell index].tif”, e.g., “20220101_nucleus_B1001_1.tif”. Include “nucleus”, “membrane”, “nuc_mem”, “cytosol”, or “none” in the file name to ensure the correct labels are read and processed by subsequent scripts.\n//Example of an imageJ macro that concatenates and saves barcode images.\ndirectory = \"./raw_images/cytosol/\" // change this to your directory\nfile_name = \"20220101_cytosol_B4001\" // change this to your experiment ID\nroi_no = roiManager(\"count\")",
    "//Rename roi\nfor (i = 0; i < roiManager(\"count\"); i++) {\n        roiManager(\"Select\", i)\n        roiManager(\"rename\", i+1)\n}\n//enables background calculation, 20× faster\nsetBatchMode(\"hide\")\nfor (i = 0; i < roi_no; i++) {\n        //select windows, duplicate each roi\n        selectWindow(\"633Ex\");roiManager(\"Select\", i);\n        roi_name = Roi.getName;\n        run(\"Duplicate...\", \"title=A\");\n        selectWindow(\"405Ex\");roiManager(\"Select\", i);\n        run(\"Duplicate...\", \"title=B\");\n        //combine\n        run(\"Combine...\", \"stack1=A stack2=B\");\n        //save & close\n        saveAs(\"Tiff\", directory + file_name +\"_\"+ roi_name +\".tif\");\n        close();\n}\n//disables background calculation\nsetBatchMode(\"show\")\n//close all windows\nclose(\"633Ex\")\nclose(\"405Ex\")\nRun the python script (“0. Image Processing/preprocess barcode.py”) to preprocess barcodes.\nNote: The script crops the barcode images, resizes the images to 150 × 150 pixels, caps the outlier (1%) signals, and rescales the images to 8-bit.\nBefore running the script, open the script with a text editor, change the barcode_dir and save_dir to the directories to the barcode images and processed images, respectively, and save the script.\nTo run the script, open a command line, and type “python” followed by the path to your script, i.e., > python ./path_to_your_script/preprocess barcode.py\nimport tifffile\nimport cv2\nimport os\nimport numpy as np\nbarcode_dir = '/raw_images/cytosol/' # directory to the barcode images\nsave_dir = '/processed_images' # directory to save the processed images\nimg_path_list = [os.path.join(barcode_dir, i) for i in os.listdir(barcode_dir) if i.endswith('.tif')]\n# resize the images to 150 × 150\nnrows = 150\nncols = 150\ndef crop_1 × 2(img):\n    #crop images\n    y, x = img.shape\n    A = img[0:, 0:int(x/2)]\n    B = img[0:, int(x/2):int(x)]\n    return A, B\n# normalize to [0, 255], set limit for outlier (default 99%)\ndef normalize_saturate_outlier(image, percentile=99):\n    upperlimit = np.percentile(image, percentile)\n    lowerlimit = np.percentile(image, 100 - percentile)\n    image = np.minimum(upperlimit, image)\n    image = np.maximum(lowerlimit, image)\n    image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n    return image\n# save the preprocessed barcodes\nfor img_path in img_path_list:\n    # read grayscale image\n    img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)",
    "# crop images according to barcode ABCD\n    A, B = crop_1 × 2(img)\n    # rescale and clip the extreme (1%) signals\n    A = normalize_saturate_outlier(A, percentile=99)\n    B = normalize_saturate_outlier(B, percentile=99)\n    # resize the images\n    A = cv2.resize(A, (nrows, ncols), interpolation=cv2.INTER_CUBIC)\n    B = cv2.resize(B, (nrows, ncols), interpolation=cv2.INTER_CUBIC)\n    # save image\n    tifffile.imsave(f'{save_dir}/{os.path.basename(img_path)}', np.concatenate(([A], [B])))\nExamine the images to ensure the training images are of good quality (Figure 2[href=https://www.wicell.org#fig2]B). Discard images with cells that are deformed (e.g., apoptotic or blebbing) or with weak or mislocalized signals.\nTrain deep learning neural networks. First, we train Model 1, which classifies BFP images as None (0), Nucleus (1), or Membrane (2) (Figure 3[href=https://www.wicell.org#fig3]A). Second, we train Model 2 and Model 3, which classify mCherry images as None (0), Nucleus (1), Membrane (2), Nuclear membrane (3), or Cytosol (4) in the presence of nuclear and membrane BFP, respectively (Figure 3[href=https://www.wicell.org#fig3]A). Finally, we assemble Model 1, 2 and 3 to increase the overall accuracy (Figure 3[href=https://www.wicell.org#fig3]B).\nNote: We suggest readers who do not have experience in Jupyter notebook to read the beginner guide here (https://docs.jupyter.org/en/latest/start/index.html[href=https://docs.jupyter.org/en/latest/start/index.html]).\nTo start a Jupyter session, open the command line, change the directory to the working directory, and type “jupyter lab”. Open the Jupyter notebook “Model 1 training.ipynb”. Change the train_dir to the directory containing your training images. Change the model_filepath to the directory for trained models. Run the whole script to start training.\nTest the models with data that are not used for training. Determine the models that perform the best and use them for subsequent analysis.\nRedo the model training for another two models. Use “Model 2 training.ipynb” for Models 2 and 3. In our protocol, we assemble three trained models to increase the accuracy.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1926-Fig2.jpg\nFigure 2. Generating training images\n(A) Image processing in ImageJ.",
    "(B) Examples of training images after we run the python script (scale bars are not included due to anisotropic deformation of the images).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1926-Fig3.jpg\nFigure 3. Training deep learning models\n(A) The architecture of the models.\n(B) The workflow of barcode prediction using deep learning models. See text for details.\nEstablishing the pipelines part 2: Acquiring reference spectra\nTiming: 3 days\nIn order to spectrally unmix the emission of mCherry, mCardinal, and iRFP702 in the barcode images, the reference spectra for these FPs need to be collected.\nSeed 4 × 105 HeLa cells in a 35 mm glass-bottom tissue culture dish with imaging medium. Incubate cells at 37°C, 5% CO2 overnight.\nTransfect cells with mCherry-NLS, mCardinal-NLS, or iRFP702-NLS plasmids.\nPreparation of the DNA-GenJetTM mix.\nFor each dish, dilute 1 μg of mCherry-NLS (nuclear localization signal), mCardinal-NLS, or iRFP702-NLS plasmid with 50 μL of serum-free DMEM.\nFor each dish, dilute 3 μL GenJet™ Transfection Reagent with 50 μL of serum-free DMEM. Vortex for 5 s and spin down briefly. Immediately add the diluted GenJet™ Reagent to the diluted DNA. Pipette up and down 5 times to mix. Leave the mixture at room temperature for 15 min.\nAdd the DNA-GenJetTM complex dropwise onto cells in the 35 mm dishes. Incubate cells at 37°C, 5% CO2 overnight.\nOn a Zeiss LSM780-FCS laser scanning confocal microscope, capture the images of cells expressing mCherry-NLS, mCardinal-NLS, or iRFP702-NLS under the Lambda mode in the Zen software.\nTurn on the microscope and set the stage incubator at 37°C.\nOpen the Zen software. Switch the objective to the 40× oil lens and locate the cells.",
    "Switch to “Acquisition” and click the “Lambda Mode” tab under “Light Path” (Figure 4[href=https://www.wicell.org#fig4]A, a). Select the 633 nm laser as the excitation source (Figure 4[href=https://www.wicell.org#fig4]A, b) with pinhole set to 30.2 (Figure 4[href=https://www.wicell.org#fig4]A, c). Select 561–695 nm for the spectrum range to be collected and set resolution to 8.9 nm (Figure 4[href=https://www.wicell.org#fig4]A, d). This setting will generate 15 images from 561 to 695 nm with 8.9 nm intervals.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1926-Fig4.jpg\nFigure 4. Reference spectra acquisition\n(A) Screenshot of reference spectrum acquisition.\n(B) Reference spectra of mCherry, mCardinal, and iRFP702. Note that the dips in the reference spectra are due to blocking of emission by the dichroic mirror used to deflect the excitation beam.\nClick the “Snap” button to capture the image (Figure 4[href=https://www.wicell.org#fig4]A, e).\nIn the captured image, select the “Unmixing” tab (Figure 4[href=https://www.wicell.org#fig4]A, f). Use the crosshair tool to point to a region of the image where the cell has a bright but non-saturating signal (Figure 4[href=https://www.wicell.org#fig4]A, g–I). Check the resulting spectrum, which should look like the examples shown in Figure 4[href=https://www.wicell.org#fig4]. Click “Save to spectra database” (Figure 4[href=https://www.wicell.org#fig4]A, j).\nRepeat step 8 until all spectra of the fluorophores are collected. The reference spectrum of mCherry, mCardinal, and iRFP702 should look like the screenshots in Figure 4[href=https://www.wicell.org#fig4]B.\nBarcoding cells expressing different biosensors\nTiming: 3 days\nThis protocol demonstrates barcoding HeLa cells expressing 10 different biosensors as shown in Table 2[href=https://www.wicell.org#tbl2].\ntable:files/protocols_protocol_1926_5.csv\nSeed 2 × 105 HeLa cells per well with 2 mL culture medium in a 12-well tissue culture plate. Incubate cells at 37°C, 5% CO2 overnight.\nTransfect cells with the barcode and biosensor plasmids.\nFor each well, remove the old medium and replace it with 0.75 mL fresh culture medium 30 min before transfection.\nPreparation of the DNA-GenJetTM mix.",
    "For each well, dilute 0.75 μg DNA with 38 μL of serum-free DMEM. The DNA used consists of two barcodes and one biosensor for each transfection. Start with a 1:1:1 ratio for the two barcodes and the biosensor. Adjust the ratio if the fluorescence signal is too bright or too dim.\nFor each well, dilute 2.25 μL GenJet™ Transfection Reagent with 38 μL of serum-free DMEM. Vortex for 5 s and spin down briefly. Immediately add the diluted GenJet™ Reagent to the diluted DNA. Pipette up and down 5 times to mix. Leave the mixture at room temperature for 15 min.\nAdd the DNA-GenJetTM complex dropwise onto cells in each well of the 12-well plate. Incubate cells at 37°C, 5% CO2 overnight.\nRemove medium from each well. Rinse with DPBS and detach cells with Accutase. Collect cells from all 12 wells and mix them together in a 50 mL centrifuge tube. Resuspend cells with imaging medium, and seed 6 × 105 cells per dish in 35 mm glass-bottom dishes. Incubate cells at 37°C, 5% CO2 overnight.\nImaging mixed populations of barcoded cells\nTiming: 3 h\nOn the day of imaging, remove the old medium and replace it with imaging medium. For EGF stimulation experiments, use serum-free imaging medium instead of a complete medium to starve cells for 1 h prior to imaging.\nNote: Starved cells respond more strongly to EGF stimulation. If cells are kept in a serum-containing medium, responses are still visible albeit reduced for some biosensors.\nCapture barcode images under the Lambda mode in the Zen software as in step 8 but with the following modifications:\nTurn on the microscope and set the stage incubator at 37°C. Place the glass-bottom dish on the stage with the lid removed to allow drug administration during time-lapse imaging.",
    "Open the Zen software. Switch the objective to the 40× oil lens and locate cells.\nSwitch to “Acquisition” and click the “Lambda Mode” tab under “Light Path” (Figure 4[href=https://www.wicell.org#fig4]A, a). Select the 633 nm laser as the excitation source (Figure 4[href=https://www.wicell.org#fig4]A, b) with pinhole set to 30.2 (Figure 4[href=https://www.wicell.org#fig4]A, c). Select 561–695 nm for the spectrum range to be collected and set resolution to 8.9 nm (Figure 4[href=https://www.wicell.org#fig4]A, d). This setting will generate 15 images from 561 to 695 nm with 8.9 nm intervals.\nSelect 30 positions with at least 6–10 fluorescent cells in each viewing field. Click the “Snap” button to capture the image (Figure 4[href=https://www.wicell.org#fig4]A, e). Save the barcode images from these positions as [Experiment ID]_633Ex.lsm.\nNote: The number of positions is chosen to maximize the number of cells while allowing enough time for image acquisition and EGF administration. It should be adjusted based on the speed of the motorized stage and the time-lapse interval during the imaging of biosensors.\nNavigate to the “unmixing” panel (Figure 4[href=https://www.wicell.org#fig4]A, f and g) and load the previously saved reference spectra (Figure 4[href=https://www.wicell.org#fig4]A, k). Click “Linear Unmixing” (Figure 4[href=https://www.wicell.org#fig4]A, l) to generate three separate images (mCherry, mCardinal, and iRFP702) for each position. The unmixed images should look like Figure 5[href=https://www.wicell.org#fig5]. Save the file as [Experiment ID]_633Ex_Linear unmixing.lsm.\nCapture the BFP image for each position under “Channel Mode”. Select the 405 nm laser as the excitation source and set spectrum collection range from 371 to 430 nm with pinhole set to 30.2. Save the file as [Experiment ID]_405Ex.lsm.\nAfter the barcode images are captured for each position, proceed to imaging of biosensors. In this example, time-lapse images are acquired every 3 min for a total of 10 frames, with EGF added after frame 3.",
    "Note: Avoid repeated freezing and thawing by storing small aliquots of the EGF stock solution at −20°C for up to 1 year.\nClick the “Channel Mode” tab under “Light Path”. Select spectrum range of 458–499 nm (for CFP) and 508–543 nm (for YFP and GFP). Use the 458 nm laser as the excitation source, with pinhole set to 300.6.\nSelect “Time Series” and set the frame rate at 3 min per frame for a total of 10 frames.\nSelect “Definite Focus” as the focusing strategy.\nStart time-lapse imaging. To add the stimulant (e.g., EGF) to cells, carefully lift the incubator lid and gently add the reagent to the dish immediately after frame 3 images are acquired for all positions.\nAt completion save the file as [Experiment ID]_FRET.lsm.\nNote: The YFP channel is imaged under the excitation laser for CFP (458 nm). In some publications, it is referred to as the FRET channel. Our use of the YFP/CFP ratio for FRET-based biosensors is equivalent to the FRET/CFP ratio in these publications.\nSave the four files generated from each imaging experiment to a separate folder without other files. This is needed for the macros to correctly identify the files. The four files are shown in Table 3[href=https://www.wicell.org#tbl3].\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1926-Fig5.jpg\nFigure 5. Linear unmixing\nScreenshot of the unmixing panels. Scale bar, 50 μm.\ntable:files/protocols_protocol_1926_6.csv\nImage analysis: Barcode identification\nTiming: 30 min\nConfirm that there are only four files from the experiment in the folder (Figure 6[href=https://www.wicell.org#fig6]A).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1926-Fig6.jpg\nFigure 6. Workflow of barcode identification\nThis macro includes ROI segmentation, saving individual barcode images, measurement of CFP and YFP, and generation of spectral profile.\n(A) Expected files for a single experiment.\n(B) The dialog box after the macro is run.\n(C) The ImageJ interface for selecting the ROIs.\n(D) A prompt to name the experiment.",
    "(E) The expected output files.\nOpen the file ending with “FRET.lsm” in ImageJ.\nOpen the ImageJ macro for image analysis (“2. Barcode identification/Image Analysis.ijm”) using the same method as the last step. Click “Run” on the macro window to run the macro.\nThe dialog box in Figure 6[href=https://www.wicell.org#fig6]B will appear. Enter the number of different positions in the microscope images and the number of time points taken per position. Click “OK” to continue.\nImageJ will process the .lsm file and output two image windows: “combined-YFP” and “combined-CFP”. A dialog box (Figure 6[href=https://www.wicell.org#fig6]C, a) will prompt the user to select ROIs.\nNote: DO NOT click OK until all ROIs are selected.\nFollowing the procedure described in step 4d, select every cell with visible fluorescence in the combine-YFP window using selection tools. When finished with selecting cells, click “OK” on the dialog box to continue (Figure 6[href=https://www.wicell.org#fig6]C, b–d).\nNote: To see dimmer cells, select Image>Adjust> Brightness/Contrast>Auto on the ImageJ toolbar. Also, scroll across all time points to make sure that cells remain in the selected region (Figure 6[href=https://www.wicell.org#fig6]C, c). If it is hard to include the whole cell in the selected area, try to include part of the nucleus and plasma membrane. Avoid including apoptotic cells, debris, or impurities in the selected area.\nExperiment ID prompt (Figure 6[href=https://www.wicell.org#fig6]D) will appear. Enter the experiment name in the box. Click “OK” to continue. ImageJ will proceed to measure the CFP/YFP intensities and generate barcodes and spectral data.\nUpon completion of the macro, the experiment folder should contain the files and folders (Table 4[href=https://www.wicell.org#tbl4], Figure 6[href=https://www.wicell.org#fig6]E).\ntable:files/protocols_protocol_1926_7.csv",
    "Single-fluorophore biosensor reprocessing: For the single-fluorophore biosensors PH-AKT, the ROIs must be shrunk to include only the cell (i.e., no background in the ROIs) for a more accurate determination of biosensor activity. Reprocessing should happen after the deep learning model identifies the biosensor for each cell.\nFrom the experiment folder, open “combined-YFP.tif” and “[Experiment ID]_FRET_RoiSet.zip” in ImageJ.\nFor each ROI that includes a single fluorophore biosensor, “shrink” the size of the selection to only include the cell and not the background (Figure 7[href=https://www.wicell.org#fig7]A).\nSelect all the ROIs in the ROI Manager. Record the intensity in the ROI Manager through More>Multi-Measure>Ok.\nCopy the results and use the values to overwrite the YFP values in the [Experiment ID]_ROIData.csv file before performing Excel analysis (Figure 7[href=https://www.wicell.org#fig7]B).\nNote: This step can be done using a Python script on GitHub (“2. Barcode identification/PH-AKT Reprocessing.ijm”).\nClose the windows.\nOpen the Barcode Prediction Python GUI (“2. Barcode identification/Barcode reading GUI”). The software predicts the barcode of each cell using the above models and spectral data (Figure 3[href=https://www.wicell.org#fig3]B).\nOpen the command line.\nChange to the directory containing this script and execute the Python script to open the GUI:\n> cd “Your_path/Barcode reading GUI”\n> python Barcode.py\nYou should see the interface as in Figure 8[href=https://www.wicell.org#fig8]A.\nClick “Browse” to select the models (Figure 8[href=https://www.wicell.org#fig8]A, a).\nThe default setting for the thresholds of models 2 and 3 are both 0.9. A higher threshold tends to get more accurate results but will identify fewer cells (Figure 8[href=https://www.wicell.org#fig8]A, b).\nClick “Load model” (Figure 8[href=https://www.wicell.org#fig8]A, c).\nOpen a text editor (e.g., Notepad) to create a list of barcodes and save it as a .txt file, which is used to filter the final output. Each line of the text file is a barcode that is used in the experiment.\nB2001\nB3001\nB4001\nB0101\nB0401",
    "B0021\nB2002\nB0302\nB0012\nB0042\nClick “Browse” to select the path for the barcode list. Click “Confirm list”. (Figure 8[href=https://www.wicell.org#fig8]A, d and e).\nSelect the folder with barcode images, which are generated in step 23 (Figure 8[href=https://www.wicell.org#fig8]A, f). The output folder is automatically set to the same folder with the filename modelpred.csv. Change the output folder and file name if you want.\nClick “Browse” to select the path of the spectrum data generated in step 23 (Figure 8[href=https://www.wicell.org#fig8]A, g).\nClick “Predict barcode” to run (Figure 8[href=https://www.wicell.org#fig8]A, h). This generates the prediction of the barcodes (Figure 8[href=https://www.wicell.org#fig8]B) and typically takes less than 10 s.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1926-Fig7.jpg\nFigure 7. Single-fluorophore biosensor reprocessing\n(A) An example of shrinking the ROI to include only the cellular region. Scale bar, 5 μm.\n(B) Copying the YFP values from Results to the spreadsheet.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1926-Fig8.jpg\nFigure 8. The GUI and output of the barcode prediction using deep learning models\n(A) Barcode prediction GUI.\n(B) Output csv file. Index: the cell id corresponding to the number in the ROI manager (Figure 6[href=https://www.wicell.org#fig6]C). Path: path to the image file. Spectrum: output of the spectral analysis for red FPs showing the bin number with the strongest signal based on analyzing the rolling average of every 2 bins in a 15-bin spectral profile. BFP: the prediction of model 1. RFP: the prediction of model 2 or 3. RFP_certainty: the certainty of model 2 or 3. Final: the predicted barcode based on spectral analysis, BFP, and RFP. Output: the barcode in the column “Final” filtered with the list of barcodes used in the experiment. Thresholded: barcodes that pass the threshold of certainty as defined in step 26b.\nImage analysis: Biosensor activities\nTiming: 5 min",
    "Open the Excel template provided on our GitHub page “3. Analysis/10Mix_Template_STAR_Protocols.xlsx”). There are four sheets in the Excel template: Barcodes, Raw, All_Cells, and Analysis. The functions of the sheets are as follows: (Figure 9[href=https://www.wicell.org#fig9])\nBarcodes: information of barcode/biosensor combinations (Figure 9[href=https://www.wicell.org#fig9]A).\nRaw: raw measurements (Figure 9[href=https://www.wicell.org#fig9]B).\nAll_cells: output of the model and transposed measurements. (Figure 9[href=https://www.wicell.org#fig9]C).\nNote: The activity of each biosensor is calculated differently and normalized to the prestimulus levels (typically the average of the first three frames) so that a higher value always means a higher activity.\nAnalysis: The average, standard deviation, and graphs of biosensor activities (Figure 9[href=https://www.wicell.org#fig9]D).\nOpen the output file from step 26 (i.e., “modelpred.csv” by default) (Figure 8[href=https://www.wicell.org#fig8]B). Copy the columns [Index] and [Thresholded], and paste them to the columns [Position] and [Barcode] in the sheet [All_cells] (Figure 9[href=https://www.wicell.org#fig9]C).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1926-Fig9.jpg\nFigure 9. The Excel template used for data analysis\nThe Excel template used for data analysis. The template contains four sheets, including (A) barcodes: information of the barcodes used in the experiment; (B) raw: raw measurements of YFP and CFP signals for each cell; (C) all cells: the barcodes and measurements of each cell; and (D) analysis: automatically computed activities and plots of each biosensor.\nCopy the raw measurements from [Experiment ID]_ROIData.csv (from step 24) and paste them to the sheet [Raw]. Copy the raw data in [Raw] and paste the transposed data into the columns from [YFP1] to [CFP10] in the sheet [All_cells].\nThe activities will be calculated and updated automatically. The final result will be in the sheet [Analysis].\nNote: Steps 27–30 can be done using a Python script on our GitHub (“3. Analysis/Graph_generation.py”)."
  ],
  "subjectAreas": [
    "Molecular/Chemical Probes",
    "Microscopy",
    "Cell Biology",
    "Signal Transduction",
    "Single Cell"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics",
    "Bioengineering & Technology"
  ]
}