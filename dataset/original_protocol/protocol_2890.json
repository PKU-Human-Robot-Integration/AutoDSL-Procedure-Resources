{
  "id": 3059,
  "origin_website": "Cell",
  "title": "Protocol for quantitative characterization of human retinotopic maps using quasiconformal mapping",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\n      Download and set the paths of the required codes and packages\n    \nTiming: 2 min\n      The last step before starting to run the pipeline is to download and set\n      the paths in Matlab for all the required toolboxes.\n    \nNote: We recommend that the user download\n      the Beltrami-Coefficient-Map github repository (https://github.com/NegarJM/Beltrami-Coefficient-Map[href=https://github.com/NegarJM/Beltrami-Coefficient-Map]), which contains all the required codes and packages. We have organized\n      the repository such that it contains all the existing packages in the\n      “utilities” folder, and all the specific functions developed for this\n      project in the “gsl_retinotopic” folder. After downloading it, please\n      unzip the repository file “Beltrami-Coefficient-Map-main.zip” in your\n      desired folder.\n    \n        Add the required toolboxes to the matlab path by running the following\n        command in Matlab.\n      \n> addpath(genpath('utilties'));\nAdd the “gsl_retinotopic” toolbox to the matlab path.\n> addpath('gsl_retinotopic');\nNote: Before running the commands above,\n      make sure that your Matlab path directs to the\n      “Beltrami-Coefficient-Map-main” folder.\n    \nRetinotopic map generation\nTiming: 1 min\n      This section outlines the data requirements and preparation methodology\n      for generating retinotopic maps to be used in the proposed protocol (Figure 1[href=https://www.wicell.org#fig1]). Specifically, we describe the types of data suitable for this pipeline\n      and provide a succinct overview of how to structure and prepare your own\n      data.\n    \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2601-Fig1.jpg\nFigure 1. The retinotopic map\n(A) The visual field.\n(B) The cortical surface.\n(C) The parametric space.\nNote: We recommend that you first download\n      our data and run our pipeline to become familiar with the inputs and\n      outputs at each of the processing steps. Our quantification pipeline\n      should technically work with any retinotopy data as long as they have been\n      converted into the same format as the input files that we have provided.\n      The cortical mesh should be given in G3DOGL format and the retinotopic map",
    "in HCP format. The retinotopic map should be specified at every vertex of\n      the mesh.\n    \nNote: To replicate the work done in Ta\n      et al. (2022),1[href=https://www.wicell.org#bib1] we suggest that you download the\n      “data/data_step0” from our osf website (OSF data:\n      https://osf.io/5hvg6/files/[href=https://osf.io/5hvg6/files/]).\n      The mesh data contain visual cortical surfaces cut from both hemispheres\n      of the brain.1[href=https://www.wicell.org#bib1] Specifically, each cortical surface\n      mesh contains the retinotopic receptive field coordinates and sizes from\n      the pRF solution and initial visual area labels.\n    \nNote: The fundamental data structure in\n      surface processing is the triangular mesh, which consists of a list of\n      vertices, a list of faces, and maybe (very often) some extra features\n      associated with the vertices or faces. In this pipeline, the extra\n      features must contain the pRF decoding results. For our work we used the\n      HCP decoded pRF to generate the retinotopic meshes.\n    \nNote: For data from other sources, based\n      on how the structural and fMRI data are collected and the visual stimuli\n      used to generate the retinotopic map, the user can utilize different\n      toolboxes (e.g., analyzePRF, SamSrf, mrVista, etc) to generate pRF\n      solutions. As mentioned earlier, you need to reconstruct the cortical\n      surface from T1 weighted images by FreeSurfer (recon-all). Then by\n      utilizing SPM fMRI preprocessing tools, you can correct slice timing and\n      align all the fMRI volumes to the first volume. Then the fMRI signal\n      should be projected to one of the cortical surfaces generated by\n      FreeSurfer. To decode the pRF values from the fMRI signals, you need to\n      use one of the mentioned toolboxes (e.g., analyzePRF, SamSrf, mrVista,\n      etc.). Details of the process are described in our earlier work.2[href=https://www.wicell.org#bib2]\n        Use the HCP retinotopy protocol and processing pipeline (https://github.com/Washington-University/HCPpipelines/[href=https://github.com/Washington-University/HCPpipelines/]) as a starting point for collecting new retinotopy data or to convert\n        your retinotopy data to the required format for this retinotopic\n        quantification pipeline.",
    "Note: Retinotopy data generally consists\n      of per voxel fMRI time series data that are fitted using some activation\n      model (e.g., pRF). The model estimates the center and size of the\n      receptive field at each vertex of the cortical surface. In HCP data, the\n      results are provided in MATLAB .mat files, MGH/MGZ .mgz format, and NIFTI\n      .nii files.\n    \n        Before utilizing the downloaded data, you need to add it to the Matlab\n        path.\n      \nNote: The downloaded “data_step0” needs to\n      be unzipped and copied into our pipeline folder, that is, the\n      “Beltrami-Coefficient-Map-main” folder.\n    \n> addpath(genpath('data_step0'));\nConformal flattening\nTiming: 3 min\n      In this step, a cortical surface patch is automatically selected from the\n      subject’s cortical mesh and conformally flattened to a unit disk. The\n      input is a co-registered cortical mesh from the HCP dataset (Mesh file\n      format (.m)), which is a triangle mesh representation of the subject’s\n      cortical surface constructed from their structural MRI scans. Each vertex\n      on the cortical mesh is co-registered with the estimated parameters,\n      including receptive field centers and sizes, from the population receptive\n      field (pRF) decoding of the fMRI data collected in the retinotopy\n      experiment.\n    \n        Subdivide the cortical mesh (Figure 2[href=https://www.wicell.org#fig2]).\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2601-Fig2.jpg\n              Figure 2. Cortical Mesh Subdivision\n            \nNote: This step adds new vertices to\n      up-sample the cortical mesh by “subdivision”. The pRF parameters at the\n      new vertices are obtained by interpolating those at adjacent vertices.\n    \n        Smooth the surface using SPHARM (Figure 3[href=https://www.wicell.org#fig3])\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2601-Fig3.jpg\nFigure 3. SPHARM representations\n        Select a cortical patch (Figure 4[href=https://www.wicell.org#fig4])\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2601-Fig4.jpg\n              Figure 4. The selected visual cortical surface patch\n            \nNote: To select the cortical surface\n      patch, we first select a point located near the fovea and then compute the\n      geodesic distances from this point to all the other points on the cortical\n      surface. We choose the portion of the mesh that is within the",
    "predetermined geodesic threshold (in this work, gth = 90 mm).\n    \nNote: The 90 mm threshold is empirically\n      determined for the HCP data. Other data may have different thresholds. You\n      just need to check that the selected area contains visual areas for all\n      subjects.\n    \n        Flatten the cortical patch to the unit disk (Figure 5[href=https://www.wicell.org#fig5])\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2601-Fig5.jpg\n              Figure 5. The resulting conformal map of the visual cortical\n              surface (ROI); the texture map is applied on the region of\n              interest on the original cortical surface\n            \n            With our processing framework, you can apply all four operations of\n            conformal flattening on the data from a single subject by running\n            the following command:\n            \n> step1_cut_flat (0);\n            A window will pop up and ask you to select a subject (Figure 6[href=https://www.wicell.org#fig6]).\n            \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2601-Fig6.jpg\n                  Figure 6. Select the data to open in MATLAB\n                \n                  (A) Select the folder “data_step0” which contains data from\n                  the HCP.\n                \n(B) Select the subject you want to run step 1 on it.\n            To perform conformal flattening on all subjects, use input 1 instead\n            of 0 in the command above.\n            \n> step1_cut_flat (1);\n            Upon termination of the commands above, folders ‘data_step1’ and\n            ‘data_step0_subdiv’ will be made in the working directory, which\n            contain the output of this step, a mesh file (.m) that contains the\n            triangular mesh information after conformal flattening for the\n            vertices inside the chosen patch, and the updated data with\n            up-sampled meshes, respectively.\n          \nThin plate spline smoothing\nTiming: 1 min\n      To reduce violations of the topological condition in retinotopic data, we\n      smooth retinotopic maps using thin-plate splines. In this step, we select\n      a set of points as the boundary of V1 in the parametric space. The HCP\n      atlas (maximum probability atlas)3[href=https://www.wicell.org#bib3] can be used to find\n      the boundaries of V1. In this atlas, dorsal visual areas are highlighted",
    "while the locations and bounds of 25 other visual areas are also\n      described. This atlas only includes average predicted ROI labels rather\n      than descriptions of retinotopy. Please refer to HCP OSF website for more\n      details (https://osf.io/bw9ec/wiki/home/[href=https://osf.io/bw9ec/wiki/home/]). We choose points within V1 with good pRF model decoding\n      (r-square > 0.25) and refer to them as the high-confidence regions. To\n      smooth the retinotopic map, we apply the spline surface algorithm to the\n      eccentricity and polar angle data in the high-confidence regions. We set\n      the parameter p in the spline smoothness algorithm to 90%, corresponding\n      to 90% data fitting and 10% smoothness. From the output of the thin plate\n      spline function, the pRF parameters in the desired region can be\n      predicted. In this step, the following operations will be performed\n      consecutively.\n    \n        Apply the surface-spline smoothing method on eccentricity and polar\n        angle contours in the high confidence regions of V1\n      \nPredict pRF parameters\nNote: The 0.25 r-squared threshold is\n      empirically determined for the HCP data. Other data may have different\n      thresholds. This value is determined based on the quality of the data\n      collection, that is, the protocol and Quality Assurance (QA).\n    \n        This step requires specification of the r-square threshold. To run this\n        step on the output of the selected dataset in the previous step, use the\n        command:\n      \n> step2_smooth (0, 25);\nNote: Same as the previous step, a window\n      will pop up to ask you to select the dataset for processing (Figure 7[href=https://www.wicell.org#fig7]).\n    \nNote: each step feeds from the output of\n      the previous step. To select an output of the conformal flattening step,\n      we must choose data from the ‘data_step1’ folder in the working directory.\n    \n      Folder ‘data_step2’ will be created in the current directory by running\n      the command above on the selected data. The folder contains three",
    "sub-folders, ‘figures’, ‘smooth’, and ‘unsmooth’. You can find the\n      smoothed and unsmoothed data in the sub-folder ‘smooth’ and ‘unsmooth’,\n      respectively. To visualize the smoothing results, you can go to the\n      sub-folder ‘figures’, which contains the figures in ‘.png’ format.\n    \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2601-Fig7.jpg\n          Figure 7. Select the data to open in MATLAB\n        \n          (A) Select the folder “data_step1” which contains the results of the\n          previous step.\n        \n(B) Select the subject you want to run step 2 on it.\nNote: Since each step uses the result of\n      the previous step, all steps need to be run consecutively.\n    \n        If you want to apply this step to all the data, you can run the command\n        below.\n      \n> step2_smooth (1, 25);\nBeltrami coefficient computing\nTiming: 1 min\n      In this step, we write the smoothed visual field coordinates in complex\n      form. The Beltrami Coefficient (BC), which is a complex-valued local\n      measure of angle distortion is then calculated for each local region. BC\n      (Figure 8[href=https://www.wicell.org#fig8]) represents the “distortion” of f(z) from\n      the circle z = u (1) + iu (2) to an ellipse. In our\n      project, surfaces are represented as triangle meshes and the “compute_bcm”\n      function is used to compute the Beltrami coefficient map on the triangle\n      meshes. It gets the visual field coordinates as the input and computes the\n      Beltrami coefficient for each face (triangle).\n    \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2601-Fig8.jpg\n          Figure 8. Beltrami Coefficient (BC) computation\n        \n          BC evaluates the distortions between each local area z on the\n          retinotopic map and the corresponding mapped region z' on the\n          visual field, computed as \"circle to circles\" (conformal) or\n          \"circle to ellipses\" (quasiconformal).\n        \n        The following command asks the user to select the data. You need to\n        choose the results of the previous step in the “data_step2/smooth”\n        folder. To find the desired high confidence region we need to insert the",
    "threshold percentage from pRF decoding as an input.\n      \n> step3_compute_bcm (0, 25);\nNote: Folder ‘data_step3’ will be created\n      in the current directory. To visualize the BCM, you can check the\n      sub-folder ‘figures’, which contains BCM figures in ‘.png’ format.\n    \n        Same as the two previous steps, to run this step on all the data at\n        once, you can run the command below.\n      \n> step3_compute_bcm (1, 25);\n        If you want to do all three steps together at once on one specific data,\n        you can run the command below.\n      \n> step_all (0, 25)\nNote: After running the command above, a\n      window will pop up and ask you to select a subject. Same as\n      Figure 6[href=https://www.wicell.org#fig6], you need to select a subject from the\n      data_step0 folder. After terminating all the mentioned folders, figures\n      and results from each step will be made.\n    \n        Same as all previous commands, by using “1” instead of “0” in command\n        line above. You can run all steps in batch mode (on all subjects) at\n        once.\n      \n> step_all (1, 25)"
  ],
  "subjectAreas": [
    "Bioinformatics",
    "Health Sciences",
    "Cognitive Neuroscience",
    "Neuroscience",
    "Clinical Protocol"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research",
    "Bioinformatics & Computational Biology"
  ]
}