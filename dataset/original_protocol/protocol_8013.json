{
  "id": 8424,
  "origin_website": "Jove",
  "title": "Assessing Binocular Central Visual Field and Binocular Eye Movements in a Dichoptic Viewing Condition",
  "procedures": [
    "All the procedures and protocol described below were reviewed and approved by the institutional review board of Wichita State University, Wichita, Kansas. Informed consent was obtained from all the participants.\n1. Participant selection\nRecruited participants with normal vision (n=5, 4 females, mean ± SE: 39.8 ± 2.6 years), and with central vision loss (n=15, 11 females, 78.3 ± 2.3 years) due to macular degeneration (age-related/juvenile). Note that grossly different ages of the two groups was secondary to demographics of the subjects with central vision loss (age-related macular degeneration affects older subjects and is more prevalent in females). Further, the goal of this study was not comparing the two cohorts.\n2. Preparation of the experiment\nUse a wireless 3D active shutter glasses (Table of Materials) that can be synced with any 3D-ready monitor. For the shutter glasses to be active, there should be no interference between the infrared transmitter (a small pyramid-shaped black box) and the infrared receiver (sensor) on the nose bridge of the shutter glasses.\nDisplay all the visual stimuli on a 3D monitor (1920 x 1080 pixels, 144 Hz). For the monitor and the 3D glasses to work seamlessly, ensure that appropriate drivers are installed.\nUse a table-mounted infrared video-based eye-tracker (Table of Materials) that is capable of measuring eye movements at the sampling of 1000 Hz for this protocol. Separate the infrared illumination and camera of the eye-tracker use any tripod with adjustable height and angle (Table of Materials) to hold them firmly in place. Place the camera at a distance of 20-30 cm from the participant and place the screen at a distance of 100 cm from the participant.",
    "Use an infrared reflective patch (Table of Materials) to avoid the interference between infrared illumination of the eye-tracker and the infrared system of the shutter glasses (Figure 1, Right).\nUse commercially available software (Table of Materials) to integrate shutter glasses and 3D ready monitor for dichoptic presentation of visual stimuli to control the eyetracker.\nTo stabilize the head movements, use a tall and wide chin and forehead rest (Table of Materials) and clamp it to an adjustable table. The wide dimension of the chin and forehead rest allows comfortable positioning of participants with the shutter glasses on.\n\tNOTE: Figure 1 shows the setup for eye-tracking with dichoptic stimulus presentation using 3D shutter glasses and 3D-ready monitor. The infrared reflective patch was strategically placed below the infrared sensor on the nose bridge of 3D shutter glasses (Figure 1, Right).\nMinimize the leakage of luminance information by deactivating the light-boost option in the 3D ready monitor. The leakage of luminance information from one eye to the other eye is known as luminance leakage or crosstalk13. This is prone to occur with the stereoscopic displays in the high luminance conditions.\nBecause of the shutters, the amount of infrared illumination (from the eye-tracking system) reaching the pupil can be significantly reduced13 – on an average, approximately 65% of luminance was reduced (Supplementary Table 1). To overcome this, increase the strength of the infrared LEDs of the eyetracker to 100% or (the maximum setting) from the default power setting. When using the infrared video-based eye-tracker (Table of Materials) change this setting in the “Illumination power” settings in the left bottom screen as shown in Figure 2.\n3. Running the experiment",
    "NOTE: The main experiment of this study was binocular eye tracking and screening of the central visual field using dichoptic stimulus. The central visual field screening was comparable to the visual field testing of commercially available instruments (Table of Materials). The physical properties of the visual stimulus such as luminance of the target (~22 cd/m2), luminance of the background (~10 cd/m2), size of the target (Goldmann III – 4 mm2), the visual field grid (Polar 3 grid with 28 points, Figure 3), and stimulus duration (200 ms) were identical to the visual field testing of commercially available instruments. Note that these luminance values were measured through shutter glasses when the shutter was ON (Supplementary Table 1). For the purposes of testing discussed here, the luminance of the stimulus was constant unlike visual field testing where the luminance of the stimulus is altered to obtain a detection threshold. In other words, the experiment employed supra-threshold screening and not thresholding. Therefore, the results of the screening were binary responses (stimuli seen or not seen) and not numerical values.\nPre-experiment checks\n\t\nA couple of minutes before the participant arrives for the testing, ensure that both eye tracker and the host computer (that runs the experiment) is turned on and confirm that the host computer is connected to the eyetracker.\nAs a rule, confirm the synchronization accuracy (using platform specific commands) of the display before beginning the experiment.\nInitiating the main experiment\n\tNOTE: The steps below are very platform specific and is contingent on the script that runs the main experiment. See Supplementary Material that contain the samples of the codes used to design and run the experiment.",
    "Initiate the program (See Supplementary Material - ‘ELScreeningBLR.m’) that runs the main experiment from the appropriate interface. When and if prompted by the program, enter the participant information (such as participant ID, test distance) that is needed to save the output data file in the data folder with a unique filename.\nA gray screen with instructions such as “Press Enter to toggle camera; Press C to calibrate, Press V to validate” will appear on the screen. At this stage, adjust the camera of the eye-tracker to align with the participant’s pupil as shown in Figure 2.\nEye-tracker calibration and validation\n\t\nInitiate the calibration of the eye-tracker. Instruct the participants to follow the target by moving the eyes (and not head) and look at the center of the target.\nAfter the successful calibration, initiate the validation. Provide the same instructions as the calibration.\nRead the results of the validation step (usually displayed on the screen). Repeat the calibration and validation until “good/fair” (as recommended by the eyetracker manual) result is obtained.\nDrift correction\n\t\nOnce the calibration and validation of the eye-tracker is done, initiate the drift correction.\nInstruct the participants to “look at the central fixation target and hold their eyes as steady as possible”.\n\t\tNOTE: After the calibration, validation, and drift correction, the eye-tracking will be initiated simultaneously with the main experiment.\nVisual field screening\n\t\nRe-instruct/remind the participant about the task that he/she must do during the experiment. Ask subjects to keep both eyes open during the entire testing.",
    "For this visual field experiment, instruct them to hold the fixation at the central fixation target while responding to “any white light seen” by pressing the “enter” button in the response button (Figure 1, Table of Materials). Instruct them not to move the eyes and search for the new white lights. Also, remind them that the brief white lights can appear at any location on the screen.\n\t\tNOTE: During visual field screening, the functioning of shutter glasses can be probed using monocular targets that can be fused to form a complete percept (See Supplementary Figure 2 – catch trials).\nRe-iterate the instruction to “hold fixation” several times throughout the experiment to ensure the fixation falls within the desired area.\n\t\tNOTE: An audio feedback (like an error tone) can be used to alert loss of fixation (like eyes moved outside a tolerance window). When fixation lapses, reinstruct the participant to fixate only on the cross target. The visual stimuli presentation can be temporarily stopped until the participant brings the fixation back within the tolerance window (like central 2°).\nAt the end of the visual field experiment, the screen will display the result of the testing highlighting the seen and non-seen locations differently (like for example Figure 6).\nSaving the data file\n\t\nAll the visual field data (say saved as “. mat” file) and eye-movement data (say saved as “.edf” file) will be saved automatically for post-hoc analysis. However, ensure that the files have been saved before quitting the program/platform running the experiment.\n4. Analysis",
    "NOTE: The analysis of eye movement and visual field data can be performed in several ways and is contingent on the software used to run the experiment and data format of eye tracker’s output. The steps below are specific to the setup and the program (See Supplementary Materials).\nEye movement analysis (post-hoc)\n\tNOTE: The saved eye movements data file (EDF) is a highly compressed binary format, and it contains many types of data, including eye movement events, messages, button presses, and gaze position samples.\n\t\nConvert EDF to ASC-II files using a translator program (EDF2ASC).\nRun ‘PipelineEyeMovementAnalysisERI.m’ to initialize eye movement analysis and follow the instructions as noted in the code (See Supplementary Materials for the code script).\nRun ‘EM_plots.m’, to extract horizontal and vertical eye positions and to plot as shown in Figure 4 and Figure 5.\n\t\tNOTE: Eye movement data can be further analyzed to compute fixation stability, detect microsaccades, etc. However, this is beyond the scope of the current paper.\nVisual fields\n\t\nTo get the reports of visual field test, run ‘VF_plot.m’.\n\t\tNOTE: All datasets pertaining to the visual field experiment such as points seen/not seen will be plotted as a visual field map as shown in Figure 6. If a point was seen, then it will be plotted as “green” filled square, otherwise a red filled square will be plotted. No post-hoc analysis for visual field data will be required.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}