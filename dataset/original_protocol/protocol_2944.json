{
  "id": 3115,
  "origin_website": "Cell",
  "title": "Protocol for precise signal synchronization of electrophysiology, videography, and audio recordings using a custom-made pulse generator",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nBuilding a pulse generator\nTiming: 2–5 days\nThere are commercially available high quality pulse generators such as Master 8 (AMPI) and Multistim 3800 (A-M systems), whereas low-cost open source pulse generators such as Pulse Pal1[href=https://www.wicell.org#bib1] have become available recently. In our particular case, we had specific requirements in addition to a budget limitation: (a) we needed only monophasic digital input/output; (b) we needed 5 independent channels; (c) output in each channel should be triggered by either pressing a button, external digital input, or MATLAB function. Most commercially available pulse generators do not have trigger input for each channel. Thus, we developed a custom pulse generator using Arduino and Teensy technology (Figure 1[href=https://www.wicell.org#fig1]A). The Teensy board serves the main pulse generator function, whereas the Arduino board works as an interface between the Teensy board and MATLAB. This custom-designed solution offers 5 independent channels. Pulses are triggered by either external TTL input, push button, or MATLAB function via Arduino. Each of the five channels offers four different pulse modes: pulse, toggle, asinput and togglePulse (Table 1[href=https://www.wicell.org#tbl1]). The input is 5 V tolerant TTL, and the output is 3.3 V TTL. To streamline the building process, we designed a printed circuit board (PCB) of the pulse generator (Figures 1[href=https://www.wicell.org#fig1]B and 1C).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2688-Fig1.jpg\nFigure 1. Building a custom-made pulse generator\n(A) An assembled pulse generator in a 19-inch rack housing.\n(B) The back side of the pulse generator housing.\n(C) Printed circuit board (PCB) of the pulse generator. Components to solder are indicated.\n(D) PCB with all components soldered. Connections with a computer and other components in the housing are indicated.\n(E) Interior of the pulse generator before connections are made.\n(F) Interior of the pulse generator with all connections.\ntable:files/protocols_protocol_2688_2.csv",
    "Alternatives: Commercially available pulse generators and other open-source pulse generators can be used for the synchronization technique introduced in this protocol.\nSolder components on the PCB (Figure 1[href=https://www.wicell.org#fig1]C).\nMake the housing (Figures 1[href=https://www.wicell.org#fig1]A and 1B).\nInstall the following components in the front panel:\nTwo power switches with LED indicators.\nA push button with an LED indicator (Stop button).\n5 LEDs as input indicators.\n5 BNC female connectors as external inputs.\n5 LEDs as output indicators.\n5 BNC female connectors as outputs.\n5 push buttons as trigger buttons.\nInstall 2 USB-B/USB-A connectors in the back panel (Figure 1[href=https://www.wicell.org#fig1]B).\nInstall the soldered PCB in the bottom panel using 4x M3 screws and standoff spacers.\nConnect the PCB to components in the housing using jumper wires and USB cables (Figures 1[href=https://www.wicell.org#fig1]D–1F).\nNote: When connecting the LEDs, pay attention to the polarity: connect the pins with the “+” signs on the PCB to the longer wires of the LEDs. There is no polarity for switch and button connections. Since necessary resistors are already installed on the PCB, it is unnecessary to connect further resistors for LEDs and switches.\nNote: Panel mount power switch with LED indicator may have 3 or 4 connectors. See the datasheet of the purchased switch to confirm the role of each connector.\nNote: You may need to solder pin headers to connectors of switches, BNC connectors and push buttons for connections with jumper wires.\nAlternatives: Rack-mount housing is not necessary for the function of the pulse generator, but it substantially facilitates practicality of the operation.\nConnect the two USB cables of the pulse generator housing to a computer (Figure 1[href=https://www.wicell.org#fig1]B).\nPulse generator software settings (standalone)\nTiming: 20 min",
    "You first need to configure a custom sketch on the Teensy board to set pulse settings. This can be achieved by using the Arduino Integrated Development Environment (IDE) and uploading the provided example sketch, “myPulses.ino”, available on the github repository at https://github.com/neurogelotology/synchronization_protocol/tree/main/Pulse_Generator_software[href=https://github.com/neurogelotology/synchronization_protocol/tree/main/Pulse_Generator_software].\nOpen Arduino IDE, Sketch > Include Library > Add .Zip Library, and select “pulseGen.zip”.\nTurn on the main switch of the pulse generator.\nSetup connection of the Teensy board.\nClick on “Tools” in the main menu and select “Port” from the drop-down list.\nA list of available serial ports will appear. The Teensy should be listed as “Teensy” followed by the PORT number (e.g., “Teensy (COM3)”).\nSelect the correct PORT.\nNote: If the Teensy is not listed, try turning off the pulse generator and turning it on.\nNote: If multiple PORT numbers are listed and you are not sure which is the Teensy PORT, turn off the pulse generator main switch. Click on “Tools” and select “Port”. Note which PORTs are listed. Turn on the pulse generator main switch and view the list of the PORTs again. The newly added PORT is the one that Teensy is connected to.\nClick on “Tools” in the main menu, and from Board list, select “Teensy 3.5”.\nFile > Open, select “myPulses.ino” file.\nDefine a pulse mode for each channel in setup() function. Pulse modes must be either “pulse”, “toggle”, “asinput”, or “togglePulse” (Table 1[href=https://www.wicell.org#tbl1]). For example:\nch2.mode = “pulse”;\nFor channels with “pulse” mode, set pulse parameters using the method:\nsetPulseParam(pulseWidth, interval, nPulse)\nwhere pulseWidth and interval are in [ms].\nch2.setPulseParam(50, 100, 10);\nFor channels with “togglePulse” mode, set pulse parameters using,\nsetTogglePulseParam(pulseWidth, interval)\nmethod in [ms].\nClick on the check icon on the top left “Verify”, then click on the right arrow icon next to it “Upload”.",
    "Note: We use 1 Hz pulse trains in Ch1 as the synchronization TTL in this protocol. Therefore, the following settings are needed:\nch1.mode = “togglePulse”;\nch1.setTogglePulseParam(50, 1000);\nCritical: Modify only parameters in the,\nvoid setup(){}\nNote: To ensure a successful verification and upload process, make sure that the Teensyduino is installed on your computer. Additionally, check that the correct PORT and Board for the Teensy board are selected in the Arduino IDE settings (see step 7). If you are still encountering issues, try restarting the software and the pulse generator.\nOptional: If you need to frequently switch between different pulse generator settings, you can create multiple versions of the Arduino sketch file (.ino) by making copies of “myPulses.ino” with different names. You can then easily change the pulse generator settings by uploading the desired .ino sketch file that corresponds to the specific settings you require.\nTest the pulse generator by pressing trigger buttons.\nNote: The output pulses are indicated by the output LED on each channel. Pressing the STOP button will stop all running pulses.\nOptional: You can monitor the pulse output using an oscilloscope. To do so, connect the oscilloscope probe to the BNC output connector on the pulse generator. You can then observe the pulse frequency and the voltage level on the oscilloscope. This will help you verify that the pulse generator is functioning correctly and outputting the desired pulses.\nPulse generator software settings (MATLAB trigger)\nTiming: 3 min\nWith MATLAB integration, users can design more flexible trigger patterns for the pulse generator. Specifically, MATLAB triggers a pulse output in the Arduino in the pulse generator, which in turn trigger a channel of the main Teensy board. The pulse generator can be controlled using four MATLAB functions (Table 2[href=https://www.wicell.org#tbl2]; available at https://github.com/neurogelotology/synchronization_protocol/tree/main/Pulse_Generator_software[href=https://github.com/neurogelotology/synchronization_protocol/tree/main/Pulse_Generator_software]).\ntable:files/protocols_protocol_2688_3.csv",
    "Note: In our pulse generator, [D2, D3, D4, D5, D6] output pins on Arduino are wired to inputs of channels 1-5 of the pulse generator respectively.\nTurn on both the main and Arduino power switches on the pulse generator (Figure 1[href=https://www.wicell.org#fig1]A).\nRestart MATLAB.\nType.\nmyArduino = connectArduino();\nin the command window and press Enter. It should display “Nano 3 is connected” in the command window.\nCritical: If connectArduino does not generate an Arduino instance, please refer to problem 1[href=https://www.wicell.org#sec7.1].\nTry executing,\ntrgPulse(myArduino, ‘D2’);\nwhich sends a pulse to the Ch1 input of the pulse generator. If you configured the togglePulse mode in the previous preparation, the Ch1 output LED should start blinking at 1 Hz.\nCritical: Since output of the Teensy 3.5 board is 3.3 V, the pulse generator may not be able to trigger devices that requires 5 V TTL input. It is possible to convert 3.3 V TTL to 5 V TTL using a level shifter circuit, which, however, might cause delays in the timing of the pulses.\nOptional: In addition to signal synchronization, the pulse generator can be used for a variety of applications including triggering simulations in a stimulus isolator, triggering optogenetic stimulations, switching environmental illumination, and activating audio visual stimuli. Each channel of the pulse generator works independently. For instance, users can design specific behavioral paradigms where optogenetic stimulations are scheduled at certain timings. In such cases, the pulse generator can be used to trigger optogenetic stimulations, and the timing of the stimulations can be controlled in MATLAB. Example MATLAB function to trigger sync pulses and stimulations is available at https://github.com/neurogelotology/synchronization_protocol/blob/main/Pulse_Generator_software/exampleTimer.m[href=https://github.com/neurogelotology/synchronization_protocol/blob/main/Pulse_Generator_software/exampleTimer.m].\nHardware settings\nTiming: 1–3 h",
    "The goal of this section is to establish connections between all devices. To demonstrate this process, we use LabLynx Portable System (Neuralynx) for electrophysiological recordings, UltraSoundGate 116Un (Avisoft) for audio recordings, and two BFS-U3-28S5C-C cameras (FLIR) for behavioral videography. A comprehensive overview of the device wiring is depicted in Figure 2[href=https://www.wicell.org#fig2]A.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2688-Fig2.jpg\nFigure 2. Hardware settings\n(A) Overview of the hardware connections. The pulse generator sends sync TTL pulses to the electrophysiology device, audio device, and the camera connection box. Two cameras and the camera connection box are connected using camera GPIO cables.\n(B) Digital input connectors of the LabLynx (Neuralynx) electrophysiology device and the Avisoft microphone.\n(C) Pinouts of the Mini Din6 male connector (left) and the GPIO female connector (right). The wires of the cables should be soldered to the corresponding wires.\n(D) Diagram of wiring between the Mini Din6 female sockets for the primary and the secondary cameras in the camera connection box. The diagram is a view from the breakout pin side (inside the connection box).\n(E) Wired connectors.\n(F) Assembled camera connector box.\nConnect Ch1 output of the pulse generator to the digital I/O connector on LabLynx (Figure 2[href=https://www.wicell.org#fig2]B, left) using a BNC-AL 0.64 socket cable. The black GND socket should be connected to the lower pin of the LabLynx.\nConstruct a cable with a BNC male connector on one end, and a 2.5 mm TS connector on the other.\nCut a BNC male cable and a 2.5 mm TS cable in the middle.\nStrip the insulation of the two cables. Separate the core wire and the shield wires.\nInsert heat shrink tubes on one of the cables and the core wire.",
    "Solder the core wires of the two cables together, and apply a heat gun to the heat shrink to ensure proper insulation of the core wire.\nSolder the shield wires of the two cables together.\nApply a heat gun to the heat shrink covering the cable.\nTest connectivity using a multimeter.\nSet the multimeter to continuity mode, which is typically with a diode symbol with an audio feedback feature. In continuity mode, the multimeter will beep if there is an electrical connection between the two test probes.\nTest the connection between the BNC pin and the tip of the TS jack. The multimeter should beep if the connection is good.\nNext, test the connection between the BNC shield and the sleeve of the TS jack. The multimeter should beep if the connection is good.\nFinally, test the insulation between the BNC tip and the sleeve of the TS jack. There should be no beep, indicating that there is no electrical connection between these two points.\nCritical: Whenever constructing a custom cable using soldering, it is always recommended to test the connection.\nConnect Ch1 output of the pulse generator to the DIN socket on the UltraSoundGate using the BNC-TS cable (Figure 2[href=https://www.wicell.org#fig2]B, right). BNC distributors (T- or Y-shaped) can be used to split the pulse signals from the pulse generator.\nConstruct two cables that have a GPIO (Hirose HR10) connector on one end and a mini din6 male connector on the other.\nNote: Ensure the wires are soldered properly to the corresponding pins of each connector, as depicted in Figure 2[href=https://www.wicell.org#fig2]C. See steps 20-21 for soldering, insulation and testing the connections.",
    "Assemble a camera connection box housing with two panel mount mini din6 female sockets and a BNC female connector, and solder the wires to the appropriate pins according to the wiring diagram (Figures 2[href=https://www.wicell.org#fig2]D–2F).\nConnect the camera connection box and two cameras using the GPIO-Mini Din6 cables, and connect the camera connection box and the pulse generator Ch1 output with a BNC cable (Figure 2[href=https://www.wicell.org#fig2]A).\nNote: The camera connection box that serves as a hub for managing signals from the two cameras and the pulse generator. In specific, using the connection box, pulses from the pulse generator are sent to both cameras. Moreover, exposures between the two cameras can be synchronized. The diagram in Figure 2[href=https://www.wicell.org#fig2]D provides a visual representation of the wiring in the connection box. Here we use commercially available mini din6 cables to interface between the camera connection box and the GPIO (General Purpose Input/Output) cables that connect to the cameras (Figure 2[href=https://www.wicell.org#fig2]C).\nAlternatives: Soldering all connections directly may work, but having a connection box makes the setup more organized and convenient to use in practical settings. The connection box allows for a clear and easy way to connect and disconnect the cameras and the pulse generator. Additionally, having a connection box can make the setup more portable, which can be easily disconnected and transported to a different location.\nCritical: Having synchronized capture is crucial for accurate multi-camera video analysis, as it ensures that the exposure timing of both cameras is perfectly aligned.\nNote: The cameras used in this setup offer triggered exposure, meaning that an exposure of the primary camera will trigger an exposure of the secondary camera, thereby ensuring that the exposures are synchronized. For technical details about synchronized capture, readers are encouraged to consult the blog post[href=https://www.flir.com/support-center/iis/machine-vision/application-note/configuring-synchronized-capture-with-multiple-cameras/] by FLIR.",
    "Critical: GPIO connections (Figure 2[href=https://www.wicell.org#fig2]D) for synchronized exposure and logging external TTL input may vary between camera models and camera manufacturers. To ensure proper wiring of the connection box, it is crucial to refer to the specific details provided in the user manual of the camera being used.\nAlternatives: Signal synchronization of video using a camera that does not accept external TTL input such as a webcam or a camcorder can be achieved by placing an LED visible to the camera. The anode (long pin) of the LED should be connected to the core pin of the pulse generator’s Ch1 output, while the cathode (short pin) should be connected to a 220 Ohm resistor which in turn should be connected to the shield of the pulse generator’s Ch1 output. The LED method for camera synchronization has limitations in terms of sensitivity to ambient lighting conditions, and complexity in ensuring a clear field of view, making it less suitable for applications involving challenging lighting conditions or multiple cameras.\nCamera software settings (SpinView)\nTiming: 20 min\nIn this section, we demonstrate how to configure the settings of the camera software. Specifically, we use the SpinView software for two BFS-U3-28S5C-C cameras by FLIR as an example.\nCritical: Settings may vary between camera models and camera manufacturers. For the details of camera settings, consult the user manual of the camera.\nConnect cameras to the USB3.1 interface.\nRun SpinView software.\nConfirm the two cameras are listed under “Devices” and can capture images by pressing the “Play” icon.\nCritical: The latest Spinnaker SDK may not be compatible with the bonsai software, which we use in the next section. We confirmed that Bonsai.Spinnaker version 0.7.0 is compatible with Spinnaker SDK version 1.29.0.5. Later version of Spinnaker SDK leads to crash of bonsai upon recording.",
    "Note: For further details of the SpinView software, see the official manual[href=https://www.apostar.com.tw/data/FLIR/SpinView-Getting-Started.pdf] by FLIR.\nConfigure settings for synchronized exposure on the primary camera.\nTo select a camera as the primary, go to the “Devices” section and click on the desired camera.\nIn the properties section below, click on the “Features” tab at the bottom.\nExpand “Digital IO Control”.\nFor “Line Selection”, select “Line 2”.\nEnable “3.3 V Enable”.\nConfigure settings for the secondary camera.\nClick on the secondary camera in the “Devices” section.\nIn the properties section below, click on the “GPIO” tab at the bottom.\nFor “Trigger Source”, select “Line 3”.\nFor “Trigger Overlap”, select “Read Out”.\nFor “Trigger Mode”, select “On”.\nSave these settings as a user setting.\nSelect the primary camera in “Devices”.\nFrom the “Features” tab, Blackfly S, open “User Set Control”.\nFor “User Set Selector”, select “User Set 0”.\nFor “User Set Default”, select “User Set 0”.\nOn “User Set Save”, click on “Execute”.\nSelect the secondary camera in “Devices”.\nRepeat b-e but with “User Set 1”.\nVerify that the secondary camera’s exposure is triggered only when the primary camera is actively capturing images.\nVideo recording software settings (bonsai)\nTiming: 30 min",
    "This section describes the use of the bonsai[href=http://bonsai-rx.org/] software2[href=https://www.wicell.org#bib2] for video recordings. Bonsai provides a visual language for reactive programming and access to FLIR cameras through the Spinnaker library. The example “TwoCam.bonsai” is available at https://github.com/neurogelotology/synchronization_protocol/tree/main/Bonsai[href=https://github.com/neurogelotology/synchronization_protocol/tree/main/Bonsai]. We introduce three custom features on this setting. First, frame ID is embedded on each frame of the videos as an image. This helps users notice if there are drop frames, or frame mismatches between the two cameras during analysis. Second, timestamp of each frame exposure as well as sync TTL state upon exposure are collected from the cameras and saved as CSV files. Since actual frame rate in the camera is not perfectly constant in every frame, exposure timestamps information increases accuracy of video analysis. Third, number of drop frames and sync TTL pulse can be monitored real time so that users can notice when the system is not working properly.\nOpen Bonsai.\nFile > Open, then select TwoCam.bonsai file (Figure 3[href=https://www.wicell.org#fig3]).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2688-Fig3.jpg\nFigure 3. bonsai configuration to manage synchronization\nThe TwoCam.bonsai file manages to record videos from two FLIR cameras, and save frame timestamps and TTL states for each camera.\n(A) Screenshot of the TwoCam.bonsai program. The users need to set file names of the videos and the CSV files before recording.\n(B) Screenshot of a video recording with TwoCam.bonsai. For each camera, a video monitor (frame numbers are embedded at the top left corner), a drop frame counter, and a sync TTL pulse state monitor are shown.\nSet file names (Figure 3[href=https://www.wicell.org#fig3]A).\nClick on the top right “VideoWriter” node with a camera image and purple background.\nIn the Properties panel at right, click “FileName” and click on the “...” button on the right.\nNavigate the destination folder and type the primary video file name that ends with “.avi”.",
    "Next, click on the purple “I/O” node below the primary camera node.\nSimilarly, set the file name for the timestamp file that ends with “.csv”.\nSimilarly, set the video file name and the timestamp file name for the secondary camera below.\nTo ensure that both cameras are capturing images correctly, click “Start” in the top left (Figure 3[href=https://www.wicell.org#fig3]B).\nNote: Verify that the frame ID is indicated on each image. Additionally, if the pulse generator is in operation, the TTL state should be displayed in real time. If the interval between frames is longer than double of the expected inter-frame interval, it will be counted as a dropped frame.\nCritical: If bonsai crashes upon “Start”, the Spinnaker SDK version may not be compatible with the Spinnaker Library of bonsai. Try installing different Spinnaker SDK versions.\nCritical: If the dropped frame counter keeps increasing, refer to problem 2[href=https://www.wicell.org#sec7.3].\nAudio recording software settings (Avisoft RECORDER)\nTiming: 10 min\nHere we focus on the settings regarding the TTL sync pulses in Avisoft RECORDER software. In contrast to video recordings where the timestamp and TTL state of each frame are saved in a separate CSV file, Avisoft RECORDER saves external TTL states in the least significant bit (LSB) of the audio signal within the .wav file. Official manual of the RECORDER can be found here[href=https://www.avisoft.com/RECORDER.pdf].\nNote: Avisoft RECORDER offers various options for handling external TTL inputs, such as triggering recording start with a TTL pulse. In this demonstration, we will manually start and stop the recording without using the triggered record mode.\nConnect an Avisoft device to a computer.\nOpen Avisoft-RECORDER software. If the software is not launched because the driver is not found, see problem 3[href=https://www.wicell.org#sec7.5].\nRight click on the RECORDER window to open Configuration.\nFrom the “Trigger” drop down, select “UltraSoundGate DIN”.",
    "Disable “Toggle”, disable “TC”, and enable “!”.\nFrom the “Trigger” drop down, select “permanent (unlimited)”.\nFrom the “Input Device Settings” section, click on the “Settings” button.\nEnable “Show DIN”.\nNote: With this configuration, the external TTL pulses from the pulse generator will not trigger anything, but will be saved in the LSB of the .wav file. Furthermore, the external TTL states will be indicated as blue bars on the top of the spectrogram.\nRecording experiment\nTiming: Depends on experimental paradigm (a few minutes to hours)\nWe will perform recording of electrophysiology, ultrasound and videos, while sending a synchronization TTL to the recording devices (Figure 4[href=https://www.wicell.org#fig4]A).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2688-Fig4.jpg\nFigure 4. Workflow of the signal synchronization\n(A) A recording session yields electrophysiology data (yellow), audio data (light green), and video data (film). While acquiring signals from these devices, sync pulse train (red) is sent to the devices from the pulse generator. Experiment is performed while the sync pulse train is being sent.\n(B) After the recording session, each signal will be analyzed to acquire time vectors of events. Spike sorting is performed to acquire spike times from the electrophysiology data. Vocalization analysis is performed to acquire vocalization times from the audio data. Start and stop times of behaviors are detected in the video analysis. Moreover, sync pulse times (red ticks) are extracted in each signal. To ensure that all the sync pulses were saved in each signal, compare the number of pulses and inter-pulse intervals between the signals (see Figure 4[href=https://www.wicell.org#fig4]).\n(C) The time of the first pulse is subtracted from the time vectors of events in each signal to align the start time. Then, normalize the duration of each signal (time between the first and the last pulse) to the duration of one of the signals with high temporal precision (e.g., electrophysiology).",
    "(D) Resulting time vectors are aligned and normalized.\nOpen Cheetah (Neuralynx) software. Click on the “ACQ” and the “REC” to start recording electrophysiology.\nOpen Avisoft RECORDER (Avisoft) software. Click the window to start recording audio.\nNote: If the software is not launched because the driver is not found, see problem 3[href=https://www.wicell.org#sec7.5].\nOpen bonsai software. Set four file names as described in the step 35 of the preparation, and click the “Start” button to start recording videos.\nPress the Ch1 trigger button of the pulse generator to start the sync pulse train. Verify that each device is properly receiving the TTL pulses.\nOn Cheetah, new TTL events are listed in the “Events” window.\nOn Avisoft RECORDER, the TTL status is indicated by blue lines at the top of the spectrogram.\nOn bonsai, the TTL status is plotted on a separate window for each camera (Figure 3[href=https://www.wicell.org#fig3]B).\nStart experiment e.g., behavioral paradigm.\nCritical: Throughout the recording session, it is important to ensure that the TTL pulses are being delivered to each device and that the drop frame counters in bonsai are not increasing. Monitoring these parameters can help identify issues and prevent data loss. If you encounter a continuous increase in the drop frame counters, refer to problem 2[href=https://www.wicell.org#sec7.3] for a possible solution.\nAfter completion of the experiment, press the Ch1 trigger button of the pulse generator to stop the sync pulse train.\nStop recording on each device.\nCritical: Sync pulse train must start only after all the devices start recording, and stop before any device stops recording to ensure that the same number of pulses are recorded in all devices (Figure 4[href=https://www.wicell.org#fig4]A).\nSignal alignment\nTiming: 30 min after signal analysis",
    "After a recording session has finished, each signal is analyzed typically to produce time vectors or continuous time series (Figure 4[href=https://www.wicell.org#fig4]B). For example, extracellular electrophysiological signals can be analyzed using spike sorting software to produce spike times for multiple single units. Audio analysis can yield time points of vocalizations. Behavioral analysis of video data can produce start and stop times for different behavioral events. Furthermore, times of the sync pulses in each signal will be extracted as a time vector. In this section, we demonstrate how to align time vectors resulted from different devices.\nComplete analysis of each signal.\nNote: We do not cover each signal analyses in this protocol. The results are expected to be time vectors or continuous time series that may accompany additional data. For example, the electrophysiology signal results in “spike_time” and “unit_id” arrays for multiple neuronal units. Audio analysis may yield “vocalization_time” and “vocalization_type” arrays. Video analysis can result in “event_start”, “event_end” and “event_name” arrays. To be consistent with later analyses, we expect that times are in [s]. Typically, the time values in the resulting time vectors are either timestamps of the recording device, or time relative to the start of the acquisition, dependent on analysis software. In our case, we use JRClust3[href=https://www.wicell.org#bib3] for spike analysis, DeepSqueak4[href=https://www.wicell.org#bib4] for vocalization analysis, and BORIS5[href=https://www.wicell.org#bib5] for video analysis.\nExtract time points of the sync pulses from each signal. Execute,\nnlxTTLtime = getNlxTTL_demo();\nand select the Events.nev file of the recording session.\nNote: We provide example data and a MATLAB Live Script for the sync pulse analysis available at https://github.com/neurogelotology/synchronization_protocol/blob/main/syncTTL/sync_pulse_analysis.mlx[href=https://github.com/neurogelotology/synchronization_protocol/blob/main/syncTTL/sync_pulse_analysis.mlx].",
    "Note: The Neuralynx device stores timestamps of digital inputs in the “Events.nev” file. We provide a MATLAB function “getNlxTTL_demo.m”, which extracts a sync pulse rise time vector, as well as acquisition start time as timestamps of the Neuralynx device in [s].\nNote: Event ID for the digital input in the Events.nev file may vary between Neuralynx devices. To check the event ID for the digital input of your Neuralynx device, download and install NeuraView[href=https://neuralynx.com/software/category/data-analysis]. Open the Events.nev file on NeuraView. Press Ctrl+D to show the data details window. From the drop down menu, select the Events.nev file. Click on the “Record Data” tab. It will show a table of all events including “Starting Recording”, and “TTL Input”. Check the “ID” of “TTL Input” events. In the getNlxTTL_demo.m file, change the value in the line\nTTLeventID = 21;\nto the ID of your device.\nExecute,\naudioTTLtime = getAudioTTL_demo();\nand select the .wav file of the recording session.\nNote: The Avisoft device stores the external TTL status in the least significant bit (LSB) within the .wav file. We provide a MATLAB function “getAudioTTL_demo.m” to extract a sync pulse rise time vector as audio file time in [s].\nExecute,\ncam1TTLtime = getVideoTTL_demo();\nand select the .csv file of camera 1 of the recording session. Repeat the same for camera 2.\nNote: With the configuration described above, bonsai saves timestamp and TTL state of each frame in a CSV file for each camera. We provide a MATLAB function “getVideoTTL_demo.m” to extract a sync pulse rise time vector as timestamp of the camera in [s]. Furthermore, “getVideoTime_demo.m” extracts a time vector of all frames as timestamp of the camera in [s].",
    "Verify the sync pulses in each device. This involves checking whether the numbers of pulses are equal across all devices, and whether the inter-pulse intervals are stable.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2688-Fig5.jpg\nFigure 5. Sync pulse analysis in a representative recording session\n(A) Inter-pulse intervals of 1 Hz sync pulses in the electrophysiology device timestamps across the recording session.\n(B) Same as (A) but in the audio device.\n(C) Same as (A) but in the camera 1.\n(D) Same as (A) but in the camera 2. Inset shows smaller y-axis range.\n(E) Difference in each sync pulse time between electrophysiology and audio device before (‘Raw’) and after (‘Normalized’) normalization of the session duration.\n(F) Simulated inter-pulse interval of a camera where the camera clock runs 0.01% slower than the pulse generator clock, closely matching the actual data in (C) & (D).\ntable:files/protocols_protocol_2688_4.csv\nNote: Figures 5[href=https://www.wicell.org#fig5]A–5D and Table 3[href=https://www.wicell.org#tbl3] show verification of sync pulses in an example recording session. Further details of the sync pulse analysis are described in overview of the sync pulse analysis[href=https://www.wicell.org#sec5.1].\nAlign the time vector data from different signals such as spike times, vocalizations times and event times, using the sync pulses. Alignment of the signals can be achieved by subtracting the time of the first sync pulse from all time vector data for each device, resulting in time vectors relative to the first sync pulse time (Figure 4[href=https://www.wicell.org#fig4]C).\nNote: Time values in the time vector data can be either as timestamps of the recording device, or times relative to the first sample time of the recording, dependent on the analysis algorithm. In the latter case, difference between the first sample timestamp and the first sync pulse rise timestamp must be subtracted from the time vector data.",
    "Normalize the session duration of each time vector to the session duration of the electrophysiology data. Normalization of the duration can be achieved by dividing the time vector data from a given device by the session duration (last sync pulse time - first sync pulse time) of that device, and then multiplying by the session duration of a reference device (Figures 4[href=https://www.wicell.org#fig4]C and 5[href=https://www.wicell.org#fig5]E).     t i m e s   d u r   × r e  f  d u r    . In our demonstration, we use the electrophysiology device as a reference. For technical details of this procedure, refer to normalization of the session durations[href=https://www.wicell.org#sec5.2]."
  ],
  "subjectAreas": [
    "Systems Biology",
    "Biotechnology And Bioengineering",
    "Behavior",
    "Neuroscience",
    "Model Organisms",
    "Biophysics"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research",
    "Molecular Biology & Genetics",
    "Ecology & Environmental Biology"
  ]
}