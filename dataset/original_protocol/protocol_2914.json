{
  "id": 3085,
  "origin_website": "Cell",
  "title": "Protocol to assess fatal embolism risks from human stem cells",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nData preprocessing\nTiming: 2∼5 h\nThis section describes the preprocessing process of the scRNA-seq data, of which outputs is used as the input file to establish a classifier for the pro-embolic cells.\nRaw data quality control and filtering.\nQuality control and filtering of the raw sequencing fastq data file. The analysis process of the S1 sample is as follows, the QC filtering of other samples is the same as that of S1 sample.\n#R1 reads of the S1 sample:\n$fastqc -t 10 -o outdir -d./temp -f fastq S1_R1.fastq.gz\n#R2 reads of the S1 sample\n$fastqc –t 10 –o outdir –d /temp –f fastq S1_R2.fastq.gz\nNote: The outputs of fastqc include a “.zip” file which records detailed information and a QC report file in html format. The report file provides a modular set of analysis which you can use to give a quick impression of whether your data has any problems of which you should be aware before doing further analysis. For the interpretation of the report, please refer to https://www.bioinformatics.babraham.ac.uk/projects/fastqc/[href=https://www.bioinformatics.babraham.ac.uk/projects/fastqc/].\nQuality control pipeline for the BD Rhapsody platform.\nNote: This pipeline is used to process raw sequencing from the BD Rhapsody platform.\nDownload BD repository file (.zip format, see the key resources table[href=https://www.wicell.org#key-resources-table]), decompress the .zip file and obtain “template.yml”.\nDownload the reference genome file and transcriptome annotation file (see the key resources table[href=https://www.wicell.org#key-resources-table]).\nModify the “template.yml“ file to indicate the correct location of sequencing fastq file, reference genome file and transcriptome annotation file (Figure 1[href=https://www.wicell.org#fig1]) before running the following Linux commands.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2660-Fig1.jpg\nFigure 1. Modify the YML file before running preprocessing pipeline of BD Rhapsody platform\nThe file location corresponding to the red character must be filled correctly, especially the sequenced fastq file.",
    "$cwl-runner --parallel --ourdir /home/MSC/S1 --tmpdir-prefix /home/MSC/tmp_Dir --tmp-outdir-prefix /home/MSC/tmp_Dir --rm-tmpdir /home/script/rhapsody_wta_1.9.1.cwl /home/script/template_wta_1.9.1.yml\nNote: Through this step, you can get the quality report.\nfile: /home/MSC/S1/S1_Metrics_Summary.csv and original read count.\nfile: /home/MSC/S1/S1_RSEC_MolsPerCell.csv which is the input of the step 2.\nQuality control pipeline for the 10X genomic platform.\nNote: This pipeline is used to process raw sequence data from the 10X genomic platform.\nDownload compressed reference file: refdata-gex-GRCh38-2020-A.tar.gz (see the key resources table[href=https://www.wicell.org#key-resources-table]) to the appropriate directory (for example, /home/database/cellranger/).\nRun following commands.\n#Make dictionary for fastq files\n$cp S1_R1.fastq.gz /home/fastqs/S1/\n$cp S1_R2.fastq.gz /home/fastqs/S1/\n$tar –zxvf /home/database/cellranger/refdata-gex-GRCh38-2020-A.tar.gz\n#Run cellranger\n$Cellranger count --id S1 --transcriptome /home/database/cellranger/refdata-gex-GRCh38-2020-A --fastqs /home/fastqs/S1 --expect-cells 1000 --localcores 10 --localmem 64\nNote: Through this step, you can get the quality report\nfile: /home/fastqs/S1/outs/ web_summary.html\nOriginal read count folder: /home/fastqs/S1/outs/filtered_feature_bc_matrix, which is the input of the step 2.\nJudge whether the sample is qualified according to quality criterion.\nNote: Criterion is as follows: Estimated Number of Cells >3000, Mean Reads per cell >50k, Median genes per cell >3000, Fraction reads in cells >70%, Valid barcodes >75%, Valid UMIs >75% and Q30 Bases in RNA Read >70%.\nBuilding the cell-gene expression seurat object.\nIn this step, the outputs in step 1 are used as the input (please select the corresponding platform) to run the commands. Of course, variable names in commands can be changed according to your own habits.\nEnter the R interactive environment and load the Seurat package.\n$R\n>library(Seurat)\nFor BD Rhapsody platform.\n>count.data <- t(read.csv(“/home/MSC/S1/S1_RSEC_MolsPerCell.csv”, row.names=1, check.names=FALSE, comment.char=\"#\"))\n>colnames(counts.data) <- paste(“S1”, colnames(counts.data), sep=\"-\")\n>S1 <- CreateSeuratObject(counts=counts.data, project=”S1”, min.cells=10)\nFor 10X genomic platform.\n>S1_dir <- '/home/fastqs/S1/outs/filtered_feature_bc_matrix’\n>S1 <- Read10X(data.dir=S1_dir)\n>S1 <- CreateSeuratObject(counts=S1, min.cells=10, min.features=200)\n>S1$Sample <- rep(“S1”, dim(S1)[2])\nNote: Create the seurat object of other samples using this step.\nNormalization, removal of the batch effect and clustering analysis.\nNormalization.",
    "Note: This sub-block is to remove unwanted cells from the dataset and normalize the data followed by step 2. It employs a global-scaling normalization method “LogNormalize” that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result.\n>ADSC1 <- merge(x=S1, y=list(T1,T2,T3,T4))\n>DefaultAssay(ADSC1) <- \"RNA\"\n>ADSC1[[\"percent.mt\"]] <- PercentageFeatureSet(ADSC1, pattern=paste(c(\"ˆMT-\", \"ˆMt-\", \"ˆmt-\", \"ˆMT.\"), collapse=\"|\"))\n>ADSC1 <- subset(ADSC1, subset=nFeature_RNA > 250 & nCount_RNA > 500 & percent.mt < 10)\n>ADSC1 <- NormalizeData(ADSC1, verbose=FALSE)\nRemoval of the batch effect.\nNote: This sub-block is to correct for technical differences between datasets caused by the batch effect through identify cross-dataset pairs of cells that are in a matched biological state.\n>ADSC1_MG <- FindVariableFeatures(ADSC1_MG, selection.method=\"vst\", nfeatures=2000)\n>adsc.list <- SplitObject(ADSC1_MG, split.by=\"Sample\")\n>adsc.list <- lapply(X=adsc.list, FUN=function(x) {\n      x <- NormalizeData(x)\n      x <- FindVariableFeatures(x, selection.method=\"vst\", nfeatures=2000)\n})\n>features <- SelectIntegrationFeatures(object.list=adsc.list)\n>adsc.anchors <- FindIntegrationAnchors(object.list=adsc.list, anchor.features=features)\n>ADSC1_IT <- IntegrateData(anchorset=adsc.anchors)\nClustering analysis.\nNote: This sub-block is to cluster the cells without technical bias.\nShift the expression distribution of each gene across cells into the standard normal distribution using the “ScaleData”.\nPerform linear dimensional reduction using the “RunPCA”.\nDetermine the ‘dimensionality’ of dataset using the “JackStraw” and the “ScoreJackStraw”.\nCluster the cells using the “FindNeighbors” and the “FindClusters”.\nUse “UMAP” to visualize and explore the datasets.\nNote: The interpretation of the outputs in this sub-block can be referred to https://satijalab.org/seurat/articles/pbmc3k_tutorial.html[href=https://satijalab.org/seurat/articles/pbmc3k_tutorial.html].\n>ADSC1_IT <- ScaleData(ADSC1_IT, verbose=FALSE,vars.to.regress=c(\"S.Score\", \"G2M.Score\",\"nCount_RNA\", \"percent.mt\"))\n>ADSC1_IT <- RunPCA(ADSC1_IT, verbose=FALSE)\n>ElbowPlot(ADSC1_IT, ndims=50)\n>ADSC1_IT <- JackStraw(ADSC1_IT, num.replicate=100)\n>ADSC1_IT <- ScoreJackStraw(ADSC1_IT, dims=1:20)\n>JackStrawPlot(ADSC1_IT, dims=1:20)\n>ADSC1_IT <- FindNeighbors(ADSC1_IT, reduction=\"pca\", dims=1:30)\n>ADSC1_IT <- FindClusters(ADSC1_IT, resolution=0.5)\n>ADSC1_IT <- RunUMAP(ADSC1_IT, reduction=“pca”, dims=1:30)\n>write.csv(GetAssayData(ADSC1_IT,slot=\"data\"),file=\"ADSC1_IT_exp.csv\")\n>write.csv(ADSC1_IT@meta.data, file=\"ADSC1_IT_meta.csv\")\n>write.csv(VariableFeatures(ADSC1_IT),file=\"ADSC1_IT_HVG.csv\")",
    "Note: The “ADSC1_ IT_ Exp.csv” file is the standardized cell gene expression matrix, the “ADSC1_ IT_ The meta.csv” file contains the cluster, cell name, and cell sample information; and the “ADSC1_ IT_ HVG.csv” file is the first 2000 genes with the largest variance of expression in all cells. These files are used for the future analysis.\nCritical: Step 3 consumes a lot of memory, 30 k cells across 5 datasets consumes about 30 GB memory. So please ensure that your computer has enough memory during this step.\nFeature selection\nTiming: ∼4 h\nThis section describes the detailed procedure of the feature (genes expressed in the cell) importance ranking and the optimal feature number analysis for the classifier development using machine learning. This allows us to utilize the most effective feature information while reducing noise (such as genes involved in general biological processes of cells) in the process of classifier establishment.\nSet up training and test sets.\nSet up the training set (S1 mixed data): Randomly selected 70% cells and their HGV gene expression from each subgroup of A2105C3P5 and A2105C2P5 to form the training set (S1) using perl script “RandomSelectCellsAndHVG2000Exp.pl”.\n#Make dictionary for training set\n$mkdir DataSet\n#Extract cell-gene expression matrixes of HVG genes from each subgroup\n$nohup perl script/RandomSelectCellsWithHVG2000Exp.pl ADSC1_IT_meta.csv ADSC1_IT_HVG.csv ADSC1_IT_exp.csv A2105C3P5 0.7 DataSet &\n$nohup perl script/RandomSelectCellsWithHVG2000Exp.pl ADSC1_IT_meta.csv ADSC1_IT_HVG.csv ADSC1_IT_exp.csv A2105C2P5 0.7 DataSet &\n#Use the “jobs” command to check whether the task submitted to the background via nohup is completed\n$jobs\n$cd DataSet\n#Merge cells from each subgroup\n$paste A2105C3P5_C0_HVG2000Exp70.txt A2105C3P5_C1_HVG2000Exp70.txt A2105C3P5_C2_HVG2000Exp70.txt A2105C3P5_C3_HVG2000Exp70.txt A2105C3P5_C4_HVG2000Exp70.txt A2105C3P5_C5_HVG2000Exp70.txt > A2105C3P5_70.txt\n$paste A2105C2P5_C0_HVG2000Exp70.txt A2105C2P5_C1_HVG2000Exp70.txt A2105C2P5_C2_HVG2000Exp70.txt A2105C2P5_C3_HVG2000Exp70.txt A2105C2P5_C4_HVG2000Exp70.txt A2105C2P5_C5_HVG2000Exp70.txt > A2105C2P5_70.txt",
    "Set up the test set 1 (T1 mixed data): The remaining 30% cells and their HGV gene expression in A2105C2P5 and A2105C3P5 are mixed as T1 and used as test set 1.\n#Merge cells from each subgroup\ncd DataSet\n$paste A2105C3P5_C0_HVG2000Exp30.txt A2105C3P5_C1_HVG2000Exp30.txt A2105C3P5_C2_HVG2000Exp30.txt A2105C3P5_C3_HVG2000Exp30.txt A2105C3P5_C4_HVG2000Exp30.txt A2105C3P5_C5_HVG2000Exp30.txt > A2105C3P5_30.txt\n$paste A2105C2P5_C0_HVG2000Exp30.txt A2105C2P5_C1_HVG2000Exp30.txt A2105C2P5_C2_HVG2000Exp30.txt A2105C2P5_C3_HVG2000Exp30.txt A2105C2P5_C4_HVG2000Exp30.txt A2105C2P5_C5_HVG2000Exp30.txt > A2105C2P5_30.txt\nSet up the test set 2 (T2 mixed data): Get cells and their HGV gene expression from each subgroup in A2105C3P3 and A2015C2P3.\n#Extract cell-gene expression matrixes of HVG genes from each subgroup\n$nohup perl script/RandomSelectCellsWithHVG2000Exp.pl ADSC1_IT_meta.csv ADSC1_IT_HVG.csv ADSC1_IT_exp.csv A2105C3P3 1 DataSet &\n$nohup perl script/RandomSelectCellsWithHVG2000Exp.pl ADSC1_IT_meta.csv ADSC1_IT_HVG.csv ADSC1_IT_exp.csv A2105C2P3 1 DataSet &\n#Use the “jobs” command to check whether the task submitted to the background via nohup is completed\n$jobs\n$cd DataSet\n#Merge cells from each subgroup\n$paste A2105C3P3_C0_HVG2000Exp100.txt A2105C3P3_C1_HVG2000Exp100.txt A2105C3P3_C2_HVG2000Exp100.txt A2105C3P3_C3_HVG2000Exp100.txt A2105C3P3_C4_HVG2000Exp100.txt A2105C3P3_C5_HVG2000Exp100.txt > A2105C3P3_100.txt\n$paste A2105C2P3_C0_HVG2000Exp100.txt A2105C2P3_C1_HVG2000Exp100.txt A2105C2P3_C2_HVG2000Exp100.txt A2105C2P3_C3_HVG2000Exp100.txt A2105C2P3_C4_HVG2000Exp100.txt A2105C2P3_C5_HVG2000Exp100.txt > A2105C2P3_100.txt\nSet up test set 3 and set 4 (T3 and T4 mixed data) using the method of setting up the test set 2.\nLabel the class of cells.\nNote: The ADSC cells amplified using different cultivation processes were infused into 6 mice by vein, respectively. Our previous work1[href=https://www.wicell.org#bib1] demonstrated that ADSC samples amplified by MF caused embolism in all mice, while IL amplified samples did not cause embolism. Therefore, we assumed that MF-expanded cells were pro-embolic cells, while IL-expanded cells are non-embolic cells, and labeled pro- and non-embolic cells in training and test sets using the perl script “add_typeToinput.pl” (Table 1[href=https://www.wicell.org#tbl1]).\nLabel the cells of the S1 mixed data.\n$cd DataSet\n#matrix transpose\n$awk '{i=1;while(i <= NF){col[i]=col[i] $i \" \";i=i+1}} END {i=1;while(i<=NF){print col[i];i=i+1}}' A2105C3P5_70.txt | sed 's/[ ]∗$//g' > A2105C3P5_70_T.txt\n$awk '{i=1;while(i <= NF){col[i]=col[i] $i \" \";i=i+1}} END {i=1;while(i<=NF){print col[i];i=i+1}}' A2105C2P5_70.txt | sed 's/[ ]∗$//g' > A2105C2P5_70_T.txt",
    "#add label for each cell\n$perl script/add_typeToinput.pl A2105C3P5_70_T.txt nonembolic > A2105C3P5_70_T_L.txt\n$perl script/add_typeToinput.pl A2105C2P5_70_T.txt embolic > A2105C2P5_70_T_L.txt\n#Combine embolic and non-embolic cell data\n$cat A2105C3P5_70_T_L.txt A2105C2P5_70_T_L.txt > S1_exp.txt\n# Use text editor such as “Vim” to manually remove redundant headers from the “S1_exp.txt” file\nLabel the cells of the T1 mixed data.\n$cd DataSet\n#matrix transpose\n$awk '{i=1;while(i <= NF){col[i]=col[i] $i \" \";i=i+1}} END {i=1;while(i<=NF){print col[i];i=i+1}}' A2105C3P5_30.txt | sed 's/[ ]∗$//g' > A2105C3P5_30_T.txt\n$awk '{i=1;while(i <= NF){col[i]=col[i] $i \" \";i=i+1}} END {i=1;while(i<=NF){print col[i];i=i+1}}' A2105C2P5_30.txt | sed 's/[ ]∗$//g' > A2105C2P5_30_T.txt\n#add label for each cell according to the Table 1[href=https://www.wicell.org#tbl1]\n$perl script/add_typeToinput.pl A2105C3P5_30_T.txt nonembolic > A2105C3P5_30_T_L.txt\n$perl script/add_typeToinput.pl A2105C2P5_70_T.txt embolic > A2105C2P5_30_T_L.txt\n#Combine embolic and non-embolic cell data\n$cat A2105C3P5_30_T_L.txt A2105C2P5_30_T_L.txt > T1_exp.txt\n# Use text editor such as “Vim” to manually remove redundant headers from the “T1_exp.txt” file\nChange the corresponding input file and label the T2, T3 and T4 cells with the same command line as T1, and then get the file T2_exp.txt, T3_exp.txt and T4_exp.txt.\nRank the importance of features and determine the optimal feature number.\nNote: We recommend using the Recursive feature elimination (RFE) to rank the feature importance and calculate cross validation accuracy when using different number of features.\nImport python packages.\n>mkdir RFECV\n>import pandas as pd\n>import numpy as np\n>from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n>from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, log_loss\n>from sklearn import svm\n>from sklearn.feature_selection import RFE,RFECV\n>import matplotlib.pyplot as plt\nBuild Linear SVM Classifiers.4[href=https://www.wicell.org#bib4]\n>input=DataSet/S1_exp.txt\n>rfecv_dir=RFECV\n>c_use=0.2 # Regularization parameter C, need set different value.\n>method=’linear’\n>function=’ovo’\n>raw_data=pd.read_csv(input,index_col=0, header='infer', sep='\\t', low_memory=False)\n>raw_data=raw_data[raw_data.columns[np.sum(raw_data)!=0]]\n>x=raw_data.drop('type', axis=1)\n>y=raw_data['type']\n>raw_embolic=raw_data[raw_data['type']=='embolic']\n>x_embolic=raw_embolic.drop('type', axis=1)\n>y_embolic=pd.DataFrame(raw_embolic['type'])\n>raw_nonembolic=raw_data[raw_data['type']=='nonembolic']\n>x_nonembolic=raw_nonembolic.drop('type',axis=1)\n>x_embolic_train, x_embolic_test, y_embolic_train, y_embolic_test=train_test_split(x_embolic, y_embolic, random_state=1, train_size=0.7, test_size=0.3)\n>x_nonembolic_train, x_nonembolic_test, y_non-embolic_train, y_nonembolic_test = train_test_split(x_nonembolic, y_nonembolic, random_state=1, train_size=0.7, test_size=0.3)\n>x_test=pd.concat([x_embolic_test,x_nonembolic_test], axis=0)\n>y_test=pd.concat([y_embolic_test,y_nonembolic_test], axis=0)['type']\n>x_train=pd.concat([x_embolic_train,x_nonembolic_train], axis=0)\n>y_train=pd.concat([y_embolic_train,y_nonembolic_train], axis=0)['type']",
    ">clf=svm.SVC(C=c_use, kernel=method, gamma='auto', decision_function_shape=function, probability=True, class_weight='balanced', cache_size=2000).\nNote: Use svm SVC function to establish linear SVM as the estimator of RFECV. Set the regularization parameter C to 0.2, 0.6, 0.8, 1.0, 1.2, 1.6, 2.0, 2.2, 2.6 or 3.0 to balance the model complexity and the loss function, and then calculate the corresponding cross validation accuracy when unimportant features are eliminated in turn through the 10-fold cross validation.\nRun the RFE method.\n>rfecv=RFECV (estimator=clf, step=1, cv=10, scoring='accuracy')\n>rfecv.fit(x, y)\nPlot relationship between numbers of selected feature and the cross validation accuracy (Figure 2[href=https://www.wicell.org#fig2]A).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2660-Fig2.jpg\nFigure 2. Selected optimal number of most important features\n(A) the change curve of cross validation accuracy with the continuous addition of important features in a single model, (B) zoom in at the inflection point of the change curve (A) of the feature selection model.\n>plt.figure()\n>plt.xlabel(\"Number of features selected\")\n>plt.ylabel(\"Cross validation Accuracy\")\n>plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n>plt.show()\nOutput the result to a file.\n>ref_txt=’RFECV_’+str(c_use)+’.txt’\n>pd.DataFrame(rfecv.grid_scores_, columns=['socre']).to_csv(ref_txt, index=False, header=False)\nNote: By setting different C values, a total of 10 feature selection models are obtained.\nCount the cross validation accuracy of different C-value models under different feature numbers to determine the optimal number of important features.\nNote: Our previous work1[href=https://www.wicell.org#bib1] demonstrated that in models with different C values, the cross validation accuracy using few important features is more than 95%. When using the first 13 important features, the cross validation accuracy is close to 100%. So we use 13 important features to train classifiers (Figure 2[href=https://www.wicell.org#fig2]B). Therefore, we recommend choosing only the top few important features to train classifiers.\nTraining classifier\nTiming: ∼10 h\nThis section describes how to build and train a classifier for pro-embolic and non-embolic cells.\nDevelop machine learning strategies.\nUse a linear SVM framework to train classifiers based on feature selection.",
    "Set the hyperparameter C to values of 0.0001, 0.0005, 0.001, 0.002, 0.004, 0.008, 0.02, 0.05, 0.2, 0.6, 1.2, 1.8, 2.4 or 3.0 to optimize the performance of classifiers on both the training and test sets.\nNote: C is essentially a regularization parameter that determines how much the SVM classifier should avoid misclassifying each training cell. For large C values, the classifier tends to correctly classify all training set cells, including abnormal cells. However, this can cause the classifier to pay too much attention to the features of training set cells, leading to reduced performance on test sets, which is called over-fitting. The opposite is true for smaller C values. Therefore, selecting an appropriate C value is a vital step in the best practice of using SVMs to develop classifiers that perform well on both the training set and test sets.\nOptimize the training parameters using 10-fold cross-validation.\nImport cell instances of the training set.\n>raw_data=pd.read_csv(S1_exp.txt, index_col=0, header='infer')\n>raw_data=raw_data[raw_data.columns[np.sum(raw_data)!=0]]\n>x_train=raw_data.drop('type', axis=1)\n>y_train=raw_data['type']\nEstablish SVM machine learning framework.4[href=https://www.wicell.org#bib4]\n>clf=svm.SVC(C=c_use, kernel='linear', gamma='auto', decision_function_shape=function, probability=True, class_weight='balanced',cache_size=2000)\n#c_use refers to different C values\nObtain the 13 most important feature genes and their expression levels.\n>rfe = RFE(estimator=clf, n_features_to_select=1, step=1)\n>rfe.fit(x_train, y_train)\n>ranking=sorted(zip(rfe.ranking_, x_train.columns))\n>gene_list=[]\n>for i in ranking:\n    if i[0]<=13:\n        gene_list.append(i[1])\n>print(ranking)\nTrain classifiers and output their performance.\n>svc=clf.fit(x_train_new, y_train.ravel())\n>scores=cross_val_score(clf, x_train_new, y_train, cv=10, error_score='raise', scoring='accuracy')\n>print(\"cross validation Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() ∗ 1.96))\n>print(scores)\n>y_pred=clf.predict(x_train_new)\n>y_proba=clf.predict_proba(x_train_new)\n>print(list(y_train))\n>print(list(y_pred))\n>for i in y_proba:\n      print(i)\nChange the super parameter C value and repeat steps 10, 11 and 12.\nNote: A total of 14 candidate classifiers were obtained.\nTest and determine the optimal classifier\nTiming: ∼1 h\nThis section describes how to evaluate the performance of classifiers on test set and pick the optimal classifier based on test performance.",
    "Import test set 1 cell instances.\n>raw_data_test=pd.read_csv(T1_exp.txt, index_col=0, header='infer', sep='\\t')\n>raw_data_test=raw_data_test[raw_data_test.columns[np.sum(raw_data_test)!=0]]\n>x_test=raw_data_test.drop('type', axis=1)\n>y_test=raw_data_test['type']\nTest the performance of the candidate classifier 1 in test set 1.\n>x_test_new=x_test[gene_list]\n>y_pred=clf.predict(x_test_new)\n>y_proba=clf.predict_proba(x_test_new)\n>print(list(y_test))\n>print(list(y_pred))\n>for i in y_proba:\n    print(i)\n>accuracy=accuracy_score(y_test, y_pred)\n>print(\"Classification Accuracy: %0.4f\" %accuracy)\n>classifi=classification_report(y_test, y_pred)\n>print(classifi)\n>logloss=log_loss(y_test, y_proba)\n>print('log_loss:'+str(logloss))\nOutput classifier 1 parameters.\n>print (\"Weighted coefficients of selected gene features:\")\n>print (svc.coef_)\n>print (\"Bias value of decision function b:\")\n>print (svc.intercept_)\n>print (\"Index of supported_vectors sample:\")\n>print (svc.support_)\n>print (\"All supported_vectors:\")\n>print (svc.support_vectors_)\n>print (\"Number of class-supported_vectors:”)\n>print (svc.n_support_)\nRepeat steps 15 and 16 to test the performance of all 14 candidate classifiers in test set 1.\nRepeat steps 14, 15, 16 and 17 to test the performance of all 14 candidate classifiers in test set 2, 3 and 4.\nDetermine the optimal classifier.\nIf the prediction accuracy of the classifier in all test sets does not increase, then the classifier is optimal. Based on this, the classifier with C = 0.2 is determined as the optimal classifier. Its prediction accuracy in the training set and the four test sets is 100%, 100%, 100%, 100%, 97% and 95% respectively (Table 2[href=https://www.wicell.org#tbl2]).\ntable:files/protocols_protocol_2660_2.csv\nDetails of the performance of the optimal classifier in the four test sets (Table 3[href=https://www.wicell.org#tbl3])\ntable:files/protocols_protocol_2660_3.csv\nDevelopment of mathematical model for embolic risk of ADSC cell\nTiming: ∼1 h\nThis section describes how to develop mathematical model for embolic risk of ADSC cells based on the optimal classifier. We use the 13 key features (genes) obtained from the optimal classifier and their weight coefficients, with the expression level of these genes in cells, to establish the following mathematical model for calculating the embolic risk score of a single cell.",
    "After getting the gene expression profile of a cell, extract the expression amount of its 13 key genes, and then calculate the embolic risk of the cell according to the Equation (1)[href=https://www.wicell.org#fd1]:\n(Equation 1)\nR\nS\n=\n1\n+\ne\n−\n∑\ni\n=\n1\nn\nW\ni\n∗\nG\ni\nNote: Wi is the weighted coefficient of ith gene determined by the optimal classifier and showed by the output of the “print (svc.coef_)” command in the step 16, Gi is the expression of the ith key gene in this cell, and n is the number of key genes. The value of RS ranges from 0 to ∞ with small RS indicating a non-embolic cell and a larger risk score indicating a potential embolic cell.\nSelect an appropriate risk threshold according to the cell production process and determine whether the cell is a pro-embolic cell.\nUse an ROC curve analysis to determine the RS threshold of pro-embolic and non-embolic cells in test samples.\nNote: From the ROC curve, the thresholds of the four test sets were defined to be 2.131, 2.131, 2.048 and 3.368, respectively. The specificity and sensitivity of using the thresholds to distinguish cell embolism is more than 0.96 in each test dataset.\nYou can use following commands to determine RS thresholds of four test sets.\nNote: The input files are “RSandLabel_test1.txt”, “RSandLabel_test2.txt”, “RSandLabel_test3.txt” and “RSandLabel_test4.txt”. Each line of the input file is the cell name, the “RiskScore” column is the RS value of each cell, and the “RealLabel” column is the actual category label of each cell.\nlibrary(pROC)\ndata1 <- read.csv(\"RSandLabel_test1.txt\", header=T, sep='\\t')\ndata2 <- read.csv(\"RSandLabel_test2.txt\", header=T, sep='\\t')\ndata3 <- read.csv(\"RSandLabel_test3.txt\", header=T, sep='\\t')\ndata4 <- read.csv(\"RSandLabel_test4.txt\", header=T, sep='\\t')\nroc1 <- roc(data1$RealLabel, data1$RiskScore, levels=c(\"nonembolic\", \"embolic\"))\nroc2 <- roc(data2$RealLabel, data2$RiskScore, levels=c(\"nonembolic\", \"embolic\"))\nroc3 <- roc(data3$RealLabel, data3$RiskScore, levels=c(\"nonembolic\", \"embolic\"))",
    "roc4 <- roc(data4$RealLabel, data4$RiskScore, levels=c(\"nonembolic\", \"embolic\"))\nplot(roc1, print.auc=TRUE, col=\"purple\", print.auc.x=0.45, print.auc.y=0.4, print.thres=TRUE, cex.axis=1.5, cex.lab=2)\nplot.roc(roc2, add=T, col=\"black\", print.auc=TRUE, print.auc.x=0.45, print.auc.y=0.35)\nplot.roc(roc3, add=T, col=\"blue\", print.auc=TRUE, print.auc.x=0.45, print.auc.y=0.30, print.thres=TRUE)\nplot.roc(roc4, add=T, col=\"red\", print.auc=TRUE, print.auc.x=0.45, print.auc.y=0.25, print.thres=TRUE)\nlegend(\"bottomright\", legend=c(\"Test 1\", \"Test 2\", \"Test 3\", \"Test 4\"), col=c(\"purple\", \"black\", \"blue\", \"red\"), lwd=2, bty=\"n\", cex=1.5)\nCalculate the proportion of embolic cells in the sample, and predict the embolic possibility of reinfused individuals according to the established regression relationship between the embolic cell proportion and the embolic risk after reinfusion.\nUsing seven ADSC samples cultured with different culture techniques, infuse these ADSC samples into the mice (more than 6 mice per ADSC sample).1[href=https://www.wicell.org#bib1]\nCalculate the proportion of mice with pulmonary embolism, which is used as the embolism possibility after in vivo ADSCs infusion.\nFor each ADSC sample, conduct the scRNA-seq experiment and identify the pro-embolic cells through step 20 and 21, and calculate the proportion of pro-embolic cells in each sample.\nEstablish the linear regression relationship between the pro-embolic cell proportion and the embolization possibility after the ADSC reinfusion.\nNote: NCG mice were purchased from GemPharmatech and all animal protocols were approved by the Institutional Animal Care and Use Committee, Experimental Animal Center. All mice were housed in standard SPF facility with a temperature between 18 °C and 23 °C, a humidity of 40%–60%, and a 12 h light-dark cycle. Eight-to-ten-week-old male and female NCG mice were used in this study. The number of mice used in each experiment was indicated, respectively. Mice were randomly assigned into groups. For the injection, 1 × 106 hADSCs were resuspended in saline and infused into each NCG mouse via tail vein slowly (about 10 s) using a 29-gauge needle. For complete details of the experimental models, please refer to our previous research.1[href=https://www.wicell.org#bib1]",
    "Note: The establishment details of this step have been described in the “Mathematical model to predict embolic risk” in the “Results” section, and the established relationship curve of this protocol was shown in Figure 6H of our published article.1[href=https://www.wicell.org#bib1]\nNote: For complete details on the use and execution of this protocol, please refer to our previous research.1[href=https://www.wicell.org#bib1]"
  ],
  "subjectAreas": [
    "Rnaseq",
    "Health Sciences",
    "Stem Cells",
    "Bioinformatics"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research",
    "Bioinformatics & Computational Biology"
  ]
}