{
  "id": 2611,
  "origin_website": "Cell",
  "title": "Protocol for CAROM: A machine learning tool to predict post-translational regulation from metabolic signatures",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nHere we describe the step-by-step methods for running CAROM-ML, from generating the input data in MATLAB to running the source code in Python. This tutorial will use E.coli acetylation data from the Weinert et al. study and phosphorylation data from Soares et al. The major steps of the data workflow are summarized in Figure 1[href=https://www.wicell.org#fig1].\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2109-Fig1.jpg\nFigure 1. Workflow diagram summarizing the steps involved in creating a CAROM-ML model\nGenerating the feature matrix for CAROM-ML\nTiming: ∼6 h\nCAROM-ML uses thirteen features to predict the PTM applied to each gene-reaction pair. As detailed in Table 1[href=https://www.wicell.org#tbl1], these predictors are related to metabolic flux, gene essentiality, network connectivity and enzymes properties. Here we will demonstrate how to generate this matrix of N gene-reaction pairs x 13 features.\nDownload the Orth et al. E.coli GEM from the CAROM-ML Synapse page or the BiGG database (http://bigg.ucsd.edu/models/iJO1366[href=http://bigg.ucsd.edu/models/iJO1366]) and load into MATLAB.\nNote: It is important that the user selects the MATLAB file (with .mat extension) from the BiGG download page.\nLoad the GEM into MATLAB, use the load function. (MATLAB)\n>ecoli_GEM=readCbModel(`Ecoli_GEM_Orth_iJO1366.mat`)\nNote: It is important to constrain the GEM as necessary in order to better simulate the condition of interest. For modeling different metabolic states, experimental time-course metabolomics can be used with the Dynamic Flux Activity (DFA) algorithm (Chandrasekaran et al., 2017[href=https://www.wicell.org#bib2]; Campit and Chandrasekaran, 2020[href=https://www.wicell.org#bib1]). For simulating other experimental conditions from transcriptomics or proteomics, a list of up- and down-regulated genes/proteins can be used as inputs to determine fluxes (Shen et al., 2019[href=https://www.wicell.org#bib16]). Due to the various techniques that can be used for adjusting the GEM, this is not covered in this protocol.\nGenerate the topological variables of the feature matrix.",
    "Use the Centrality Toolbox to calculate closeness, betweenness, page rank and degree. The topo_rxns matrix should therefore be N reactions x 4 topological features.\n(MATLAB)\n>[groups, orphans, R, C] = connectedComponents(ecoli_GEM);\n>GG = graph(R);\n>topo_rxns(:,1) = centrality(GG,'closeness');\n>topo_rxns(:,2) = centrality(GG,'degree');\n>topo_rxns(:,3) = centrality(GG,'betweenness');\n>topo_rxns(:,4) = centrality(GG,'pagerank');\nExtract reaction reversibility information from the GEM.\n(MATLAB)\n>reversible = ecoli_GEM.rev;\nUse FBA (Orth et al., 2010[href=https://www.wicell.org#bib15]) to calculate the geneKO and maxATPafterKO features by knocking out each gene in the model one at a time and solving for the optimization problem for each iteration.\n(MATLAB)\n% initialize the COBRA toolbox and change solver to ‘gurobi’\ninitCobraToolbox(false)\nchangeCobraSolver('gurobi', 'all');\n% initialize variables\ngeneKO = NaN(length(ugenes),1);\nmaxATPafterKO = NaN(length(ugenes),1);\n% find location of ATP in GEM metabolite list\nix_ATP = ismember(ecoli_GEM.metNames, 'ATP');\nfor i = 1:length(ugenes)\n  % knockout gene `i` and solve model\n  GEM_temp = deleteModelGenes(ecoli_GEM, ugenes(i));\n  solution = optimizeCbModel(GEM_temp,[],'one'); % solve FBA problem\n  geneKO(i) = solution.f;\n  % change objective to ATP and resolve\n  GEM_atp = addDemandReaction(GEM_temp, ecoli_GEM.mets(ix_ATP));\n  GEM_atp = changeObjective(GEM_atp, GEM_atp.rxnNames(end));\n  solution = optimizeCbModel(GEM_atp,[],'one');\n  maxATPafterKO(i) = solution.f;\nend\nUse flux variance analysis to derive a range of fluxes, Vmin and Vmax, through every reaction in the network (Mahadevan and Schilling, 2003[href=https://www.wicell.org#bib10]).\n(MATLAB)\n>[Vmin, Vmax] = fluxVariability(ecoli_GEM, 100, 'max', ecoli_GEM.rxns, 1, true);\nCalculate the `growth across conditions` values for each gene in the GEM.\nNote: The 87 different conditions that are tested are controlled using exchange reactions.\n(MATLAB)\n% find exchange rxns in GEM\nload carom_GEMs ecoli_exchanges\n[ix, excpos] = ismember(ecoli_exchanges, ecoli_GEM.rxnNames);\nexc_pos = exc_pos(exc_ix)\n% remove glucose and glutamine\nGEM_temp = ecoli_GEM\nGEM_temp.lb(ismember(ecoli_GEM.rxnNames, {'D-Glucose exchange'}))=0;\nGEM_temp.lb(ismember(ecoli_GEM.rxnNames, {'L-Glutamine exchange'}))=0;\n% initialize growth rate matrices\ncondition_wt1 = zeros(length(exchanges), 1);\ngeneko_biom_allcond = zeros(length(ugenes), length(ecoli_exchanges));",
    "Loop through the exchange reactions, each time setting the LB for the current reaction to -1, and then run gene knockout for all genes.\n(MATLAB)\nfor i = 1:length(exc_pos)\n  % set lower bound of current exchange rxn to -1, then solve\n  modeltemp1 = GEM_temp;\n  modeltemp1.lb(exc_pos(i)) = -1;\n  ffgeneko = optimizeCbModel(modeltemp1);\n  condition_wt1(i,1) = ffgeneko.f;\n  % do gene KO for each j\n  for j = [1:length(ugenes)]\n    modeltemp2 = deleteModelGenes(modeltemp1,ugenes(j));\n    ffgeneko1 = optimizeCbModel(modeltemp2);\n    geneko_biom_allcond(j,i) = ffgeneko1.f; % rows=genes, cols=conditions\n    disp([j i])\n  end\nend\n% Anything that reduces by 1% is condition-specific essential.\ngrowth_norm = geneko_biom_allcond./condition_wt1';\ngrowth_norm1 = (growth_norm < 0.99);\ngrowthAcrossCond = sum(∼growth_norm1,2)/length(exchanges); % fraction of conditions where essential\nPerform parsimonious flux balance analysis (pFBA), which maximizes growth rate while minimizing the sum of fluxes.\n(MATLAB)\n>solution = optimizeCbModel(ecoli_GEM, [], 'one');\n>PFBAflux = solution.x\nRetrieve the enzyme-specific properties, MW and kcat, for each gene in the GEM. These features will need to be gathered from biochemical databases like SABIO or BRENDA.\nNote: In some cases, this data is provided with the GEMs and simply need to be extracted from the GEMs for specific genes of interest.\nIdentify the significantly regulated enzymes using one or more omics datasets of interest. In Smith et al. (2022)[href=https://www.wicell.org#bib17], acetylomics and phosphoproteomics data from various growth conditions were used for training.\nNote: It is up to the user to decide how the significantly regulated enzymes will be identified, whether that involves using fold change, z-scores or some other method. . For the CAROM study, fold change was used to label the significantly regulated proteins and their corresponding genes.\n(MATLAB)\n% load acetyl data w/ log2fc\nec_acet_data = readtable(“Ecoli_Acetyl_Weinert.xlsx”);\n% load bnums-to-enzyme map for ecoli acetyl data\nec_bnums_to_enzymes = readtable(\"Ecoli_bnum_to_enzyme_map.xlsx\");\n% extract high and low acetyl genes\nbnum_acet_high = string(ec_bnums_to_enzymes{ec_acet_data{:,4} > 2, \"bnum\"});\nbnum_acet_low = string(ec_bnums_to_enzymes{ec_acet_data{:,4} < 0.5, \"bnum\"});",
    "% load phos data w/ log2fc and gene names\nphos_data = readtable(“Ecoli_Phos_Soares.xlsx”, 'Sheet','p-sites');\nexpression = '[b].\\d∗'; % extract KEGG IDs (start w/ 'b', followed by #)\nmatch = string(regexp(phos_data.Gene_Names, expression, 'match','once'));\nbnum_phospho_high = string(match(phos_data.T1_Normalized_by_Protein > 2));\nbnum_phospho_low = string(match(phos_data.T1_Normalized_by_Protein < 0.5));\nCreate the final feature matrix.\nMap the gene-specific and reaction-specific features to the appropriate rows of the feature matrix, which are gene-reaction pairs.\nNote: Here we do not show MW and kcat, however the same procedure would follow once the user has collected those values from outside sources.\n(MATLAB)\n%%% map features and PTM labels to gene-reaction pairs %%%\n% geneKO, maxATP and growth across conditions\n[ix pos] = ismember(rxntable_bnums(:,1), ugenes); sum(ix)\nfeatures(:,1) = geneKO(pos,1);\nfeatures(:,2) = maxATPafterKO(pos,1);\nfeatures(:,3) = growthAcrossCond(pos,1);\n% fva, pfba and reversibility\n[ix pos] = ismember(rxntable_bnums(:,2), ecoli_GEM.rxns);\nfeatures(:,4) = PFBAflux(pos,1);\nfeatures(:,5) = Vmin(pos,1);\nfeatures(:,6) = Vmax(pos,1);\nfeatures(:,7) = reversible(pos,1);\n% topology\n[ix pos] = ismember(rxntable_bnums(:,2), ecoli_GEM.rxns); sum(ix) %\nfeatures(:,8:11) = topo_rxns(pos,:);\nfeat_names = {'geneKO', 'maxATPafterKO', 'growthAcrossCond', 'PFBAflux', 'Vmin', 'Vmax', 'reversible', 'closeness', 'degree', 'betweenness', 'pagerank'};\n% create table and add gene+rxn names\ntbl_ecoli = array2table(features,'VariableNames',feat_names);\ntbl_ecoli = addvars(tbl_ecoli,rxntable_bnums(:,1),rxntable_bnums(:,2),...\n  'Before','geneKO','NewVariableNames',{'genes','rxns'});\nMap the significantly regulated enzyme to the gene-reaction pairs. The result should be an array of binary values for each type of PTM.\nNote: Any genes from the GEM that either do not meet the regulation threshold or are not found within the omics dataset should be assigned to the “unknown regulation” class.\n(MATLAB)\n% PTM labels\nec_acetyl = unique([bnum_acet_high; bnum_acet_low]);\nec_phos = unique([bnum_phospho_high; bnum_phospho_low]);\n% 0=unknown, 1=acetylated\nix = ismember(rxntable_bnums(:,1), ec_acetyl); sum(ix)\ntbl_ecoli.Acetyl = ix;\n% repeat for phosphorylation\nix = ismember(rxntable_bnums(:,1), ec_phos); sum(ix)\ntbl_ecoli.Phos = ix;\nIf the user wishes to examine these two PTM types together as multi-class problem, another column can be added which includes all three classes (acetylation, phosphorylation and unknown).",
    "Note: In this case, the user must decide how to handle overlapping labels. In Smith et al. (2022)[href=https://www.wicell.org#bib17], overlapping labels were assigned to the least represented class, phosphorylation.\n(MATLAB)\n% create multi-class target variable (Acetyl=0, Unknown=1, Phos=2)\ntbl_ecoli.PTM = ones(length(tbl_ecoli.Acetyl),1);\ntbl_ecoli.PTM(tbl_ecoli.Acetyl==1)=0;\ntbl_ecoli.PTM(tbl_ecoli.Phos==1)=2;\nAdditional preprocessing steps are up to the user. Below we detail the primary data transformation steps performed for the CAROM paper.\nFill in any missing feature data with the median value from its respective dataset. This should only apply to the MW and kcat data, which must be collected from literature and may not be available for all genes in the GEM. (MATLAB)\n>tbl_ecoli = fillmissing(tbl_ecoli, \"constant\",\nnanmedian(tbl{:, feat_names}), 'DataVariables', feat_names);\nScale geneKO and maxATPafterKO by the wild-type growth rate. (MATLAB)\nno_deletion_solution = optimizeCbModel(ecoli_GEM,[],'one');\nwt_gr = no_deletion_solution.f;\ntbl_ecoli{:,[\"geneKO\",\"maxATPafterKO\"]} = tbl_ecoli{:, [\"geneKO\", \"maxATPafterKO\"]}/wt_gr;\nLimit Vmax and Vmin to values between -100 and 100.\nNote: This threshold is applied to reduce the impact of extremely large fluxes, which can indicate unconstrained reactions.\n(MATLAB)\nVlim = 100;\ntbl_ecoli.Vmax(tbl_ecoli.Vmax > Vlim) = Vlim;\ntbl_ecoli.Vmax(tbl_ecoli.Vmax < -Vlim) = -Vlim;\ntbl_ecoli.Vmin(tbl_ecoli.Vmin > Vlim) = Vlim;\ntbl_ecoli.Vmin(tbl_ecoli.Vmin < -Vlim) = -Vlim;\nScale kcat and pFBAflux by their mean values.\nNote: We found that this method performed best for these features in terms of eliminating organism-specific signatures in the data distribution.\n(MATLAB)\n>tbl_ecoli.kcat = tbl_ecoli.kcat / mean(tbl_ecoli.kcat);\n>tbl_ecoli.PFBAflux = tbl_ecoli.PFBAflux / mean(tbl_ecoli.PFBAflux);\nreversible is a binary value, so does not need scaling. (MATLAB)\n>tbl_ecoli.reversible = categorical(tbl_ecoli.reversible);\nAll features besides kcat, pFBAflux and reversible were normalized to values between 0 and 1.\nNote: This step is not required for XGBoost, which is decision tree-based, however this step can be performed if the user is interested in trying different types of machine-learning algorithms which perform better with feature scaling.\n(MATLAB)\nnum_vars = tbl_ecoli(:,vartype(\"numeric\")).Properties.VariableNames;\nnorm_vars=num_vars;\nnorm_vars(ismember(norm_vars,[\"kcat\",\"PFBAflux\"])) = []",
    "tbl_ecoli(:,norm_vars) = normalize(tbl_ecoli(:,norm_vars), 'range');\nIf multiple datasets or organism types are to be analyzed together, they should be combined at this stage. The datasets can simply be vertically concatenated. (MATLAB)\n>tbl_carom = [tbl_ecoli; tbl_yeast];\nSave data to file.\n(MATLAB)\n>writetable(tbl_carom,\"caromDataset.csv\")\nRunning CAROM-ML in MATLAB\nTiming: ∼15 min\nThe CAROM-ML code was written in Python due to the machine-learning tools available in this language. However, if the user wishes to complete the entire project in MATLAB for simplicity reasons or unfamiliarity with Python, they can reference the below code for training a PTM-classification model.\nCreate a training and test set using the E. coli feature matrix that we created.\n(MATLAB)\nc = cvpartition(tbl_ecoli{:,'PTM'},'Holdout',0.2,'Stratify',true);\nidxTrain = training(c);\ntblTrain = tbl_ecoli(idxTrain,:);\nidxVal = test(c);\ntblVal = tbl_ecoli(idxVal,:);\nUse the fitcensemble function with the “Bag” method to train a random forest model.\nNote: For the CAROM-ML Python code, XGBoost is used for the primary machine-learning model, however this algorithm is not available in MATLAB.\n(MATLAB)\nt = templateTree('MaxNumSplits',5,...\n  'NumVariablesToSample','all',...\n  'PredictorSelection','interaction-curvature',...\n  'Surrogate','on');\nmodel = fitcensemble(tblTrain(:,feat_names),tblTrain{:,'PTM'},...\n  'Method','Bag', 'Learners',t, 'NumLearningCycles',250);\nMake predictions on the validation set using the trained model and evaluate the model performance by displaying the resulting confusion matrix.\n(MATLAB)\n> y_pred = predict(model, tblVal(:,feat_names));\n> confusionmat(tblVal{:,'PTM'}, y_pred)\nPlot the feature importance scores for the train model. For more information on how MATLAB calculates predictor importance, see the documentation page at this link[href=https://www.mathworks.com/help/stats/compactclassificationensemble.predictorimportance.html].\n(MATLAB)\n[impGain, predAssociation] = predictorImportance(model);\nfigure()\nbar(impGain);\ntitle('Predictor Importance Estimates');\nylabel('Estimates');\nxlabel('Predictors');\nh = gca;\nh.XTickLabel = model.PredictorNames;\nh.XTickLabelRotation = 45;\nh.TickLabelInterpreter = 'none';\nRunning CAROM-ML in Python\nTiming: ∼30 min",
    "The following instructions detail how to load the previously formatted data into Python and use it as an input for the various CAROM-ML functions. In addition to training an XGBoost model for classifying gene-reaction pairs by PTM labels, these steps will demonstrate how to explain the model and its predictions.\nOpen your Python editor.\nNote: For the Python editor, we recommend using Spyder, an integrated development environment (IDE) that is included with Anaconda and allows you to run code interactively. By opening Spyder in the conda environment that was setup in the previous steps, all required Python libraries should already be installed and ready for use. For help on opening Spyder in a specific environment, see the “Frequently Asked Questions” page from Spyder’s documentation[href=https://docs.spyder-ide.org/current/faq.html].\nLoad the feature matrix and the CAROM-ML functions (found in carom.py) into your Python editor of choice.\nNote: Ensure that your working directory is set to your project folder (e.g., Desktop/project_folder) and that the conda environment has been activated (see troubleshooting[href=https://www.wicell.org#troubleshooting] Problems 1 and 2).\n(Python)\n# -∗- coding: utf-8 -∗-\n\"\"\"\nCAROM-ML script\n\"\"\"\nimport pandas as pd\nimport carom\n# load the CAROM data\ndf_carom = pd.read_csv(\"caromDataset.csv\")\nYou can inspect the first few rows of your data by running the following command:\n(Python)\n>df_carom.head()\nIf using Spyder, you can instead open the df_carom object in the Variable Workspace. The dataset should look similar to the example data shown in Table 2[href=https://www.wicell.org#tbl2].\ntable:files/protocols_protocol_2109_2.csv\nThe dataset should contain two columns containing the gene and reaction IDs, the 13 CAROM features and an array of PTM labels.\nTrain the CAROM-ML model using the train_model function.",
    "Note: This function trains an XGBoost model using cross-validation. Within each fold, hyperparameter tuning is performed and the model’s performance on the test fold is recorded. By looking at the model’s performance across all five folds, we gain a better idea of its robustness. By default, the train_model function performs 5-fold cross-validation. The number of folds may be altered using the num_folds argument, however the use should be wary of using too many folds on highly imbalanced datasets, thereby leaving too few regulated gene-reaction pairs in each fold. After cross-validation, a final model is fitted to the entire dataset using the hyperparameters from the best performing fold.\nFirst, split the data into a training and validation set, so that there is data we can later test on which the model has not been exposed to. If you already have a validation dataset to test on, you can skip this step. (Python)\nfrom sklearn.model_selection import train_test_split\n% define the feature names\nfeature_names = df_carom.columns[3:16]\n% create X and y variables, then split into training-test\nX = df_carom[feature_names]\ny = df_carom['PTM']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, stratify=y)\nUse the X (independent features) and y (class labels) training data as inputs into the train_model function. (Python)\n[xgb_model, scores] = carom.train_model(X=X_train, y=y_train, class_names=[\"Acetyl\",\"Unknown\",\"Phos\"], num_iter=5, condition=\"TestRun\", fig_path=\"./figures/training\")\nNote: For any of the CAROM Python functions, running the help function will provide details on the required and optional arguments:\n(Python)\n>help(carom.train_model)\nHere we will highlight the possible inputs for the imbalance argument, which dictates how the model training handles class imbalance.",
    "Dictionary OR “auto”: the Adaptive Synthetic (ADASYN) algorithm is implemented. ADASYN is a method used for over-sampling the minority classes, but instead of replicating existing observations (the feature values for gene-reaction pairs), entirely new samples are interpolated (He et al., 2008[href=https://www.wicell.org#bib5]). The user can enter a dictionary with the classes and the corresponding number of samples they want for each class. For example, if the unknown class contains 500 samples, but the phosphorylation and acetylation class have only a fraction of this, the user may wish to generate twice as many samples for the two classes of interest:\n>imbalance = {0:1000, 1:500, 2:1000}\nNote that due to the way the class labels are encoded, the first class in the dictionary should always be set to zero. To generate an even number of samples for all three classes (e.g., 500 each), the user can simply enter “auto”.\n“undersample”: random samples from the larger classes in the dataset are removed until all classes have the same number of samples.\n“balanced”: the inverse proportion of classes are used to assign a balanced set of class weights. Classes with less samples will be given higher weights, meaning that the machine-learning algorithm will more heavily penalize misclassifying those points.\n“none” (default): no adjustments are made.",
    "The two outputs from this function are the trained XGBoost model and a data frame containing the cross-validation classification scores. Additionally, three figures should be saved to the folder specified in the fig_path argument: a confusion matrix with the cross-validation results, a bar graph showing the cross-validation scores (the error bars represent standard deviation) and the XGBoost feature importance plot (Figure 2[href=https://www.wicell.org#fig2]). Note that the feature importance plot here is intended to assist with model explanation, as opposed to feature selection. The feature importance scores demonstrate how all features contribute to the model predictions with different degrees of importance, which is also highlighted in the ensuing Shapley analysis.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2109-Fig2.jpg\nFigure 2. Plots generated from the carom.train_model function\n(A) Confusion matrix showing the cumulative classification results from the cross-validation training of the XGBoost model.\n(B) Various classification scoring metrics are plotted for the cross-validation results. The error bars shown represent the 95% confidence interval for each metric.\n(C) The feature importance scores from the XGBoost model. By default, XGBoost feature importance is measured in gain, which is the improvement in accuracy that a feature adds to the branches it is on (click here[href=https://xgboost.readthedocs.io/en/stable/R-package/discoverYourData.html] for more information).\nMake predictions on the validation dataset using the trained model and the make_predictions function.",
    "Note: This function returns the model’s classification scores on the validation set, as well as the list of predicted class labels. Additionally, a CSV file is saved for each class indicating the model’s performance for each gene-reaction pair (true/false positive, true/false negative). If the user enables the plot argument within the function, a bar graph with the classification scores is generated, as well as box plots for each numeric feature in each class. Example plots are shown in Figure 3[href=https://www.wicell.org#fig3], including the confusion matrix (A), grouped box plots (B) and classification scores bar plot (C).\n(Python)\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2109-Fig3.jpg\nFigure 3. The carom.make_predictions function is used to test the trained CAROM-ML model on a validation dataset where the true PTM labels are already known\nSeveral figures are generated by default which help visualize the model’s performance.\n(A) Confusion matrix showing the true labels on the y-axis and the predicted labels on the x-axis.\n(B) Various classification metrics showing the model’s performance on the test set.\n(C) Boxplots for each numerical feature and for each class, showing the feature distribution grouped by true positives, false positives, true negatives and false negatives.\n# get the gene-reactions pairs in the test set\nix = X_test.index\ntest_genes = df_carom.loc[ix,['genes','rxns']]\n# make predictions on test set\n[df_scores, ypred] = carom.make_predictions(mdl= xgb_model,\n            X_test = X_test, y_test = y_test,\n            class_names = [\"Phos\",\"Unknown\",\"Acetyl\"],\n            gene_reactions = test_genes,\n            plot = True)\nIf you do not know the true labels of the test set, or if you are simply interested in getting a list of predicted labels for the test set, use the following command:\n(Python)\n>ypred = xgb_model.predict(X_test)\nUse the shapley function to explain and interpret the trained model.",
    "Note: This function is a wrapper for several functions from the SHAP library. While Shapley values can potentially be used for feature selection or reduction, the primary purpose of this function is to aid in model interpretation.\nThe inputs include the XGBoost model and the feature matrix for the observations that we want to explain (e.g., X_test).\n(Python)\n[shap_explainer, shap_values] = carom.shapley(\n  xgbModel = xgb_model,\n  X = X_test[feature_names],\n  condition = \"TestInstall\",\n  fig_path = \"./figures/shap\")\nThe function’s outputs include the SHAP explainer object and the Shapley values. The shap_values variable should be a matrix of N observations x M features. The explainer object may be useful if the user wishes to perform their own additional analyses with the SHAP package. Examples of the output plots are shown in Figure 4[href=https://www.wicell.org#fig4]. It is recommended to review SHAP documentation page for interpreting these figures (https://shap.readthedocs.io/en/stable/index.html[href=https://shap.readthedocs.io/en/stable/index.html]).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2109-Fig4.jpg\nFigure 4. The carom.shapley function outputs several figures from the SHAP package, all of which help explain the model’s predictions\n(A) The multi-class summary plot shows the feature importance according to the Shapley values across all three classes.\n(B) A separate Shapley summary plot is generated for each class. The features are sorted from top to bottom by average absolute Shapley value for the specific class. Unlike the multi-class plot, the single class plot shows how each feature is correlated with the model’s output.\n(C) A Shapley value heatmap is created for each class. The model’s output for the respective class is shown on the top x-axis in log odds, the features are ordered on the y-axis by importance, and the observations are clustered according to f(x).",
    "(D) For each class, a Shapley dependence plot is generated for the top three most importance features (according to that class’ summary plot). The feature’s values are on the x-axis and the feature’s Shapley values on the y-axis. The data points are colored by the values of the feature which most interacts with the main feature of the plot.\nAnalyze specific genes of interest using the select_genes function, as shown in Figure 5[href=https://www.wicell.org#fig5].\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2109-Fig5.jpg\nFigure 5. The carom.select_genes function outputs Shapley decision plots for each gene-reaction pair associated with the input genes\nThe features are ordered by descending importance for the specific observation. The gray line intersects the x-axis at the expected value, which is essentially the model’s average prediction for that class in log odds. Moving up the plot from this mark on the x-axis, we can see how the model’s output for each class is changed as features are added. The final outputs are where the colored lines intersect the top x-axis, meaning that the line farthest to the right corresponds to the model’s prediction. The dashed line represents the true class.\nNote: The required inputs include the feature matrix and PTM labels from the background dataset (e.g., X_test, y_test), the gene-reactions pairs associated with that data, a list of genes of interest, the trained XGBoost model and the SHAP explainer from the above step. A multi-output decision plot will be generated for each reaction linked to the genes of interest.",
    "In the below example, we pick two gene-reaction pairs to analyze: the first instance of phosphorylation and acetylation in the test dataset. In order to calculate the Shapley values for these two observations, we have to pass several pieces of data to the function, including the test data, the entire set of gene-reaction pairs, the trained XGBoost model and the Shapley explainer from the previous section.\n(Python)\n# get first Phos gene and first Acetyl gene\nphos_gene = test_genes.genes[y_test==-1].iloc[0]\nacetyl_gene = test_genes.genes[y_test==1].iloc[0]\nselect_genes = [phos_gene, acetyl_gene]\ncarom.select_genes(X = X_test, y = y_test,\n        all_geneRxns = test_genes,\n        select_genes = select_genes,\n        condition = \"my_selecet_genes\",\n        class_names = [\"Phos\", \"Unknown\", \"Acetyl\"],\n        model = xgb_model,\n        explainer = shap_explainer)\nBuild a single decision tree model using the decision_tree function, which provides another method for deconstructing the model’s predictions and measuring feature importance.\nNote: This function is a wrapper for the decision tree classifier and hyperparameter tuning from scikit learn. The outputs of this function include a separate decision tree model trained for each maximum depth that the user inputs, along with a saved PNG file for visualizing the tree (Figure 6[href=https://www.wicell.org#fig6]). For example, if the user inputs depths=[2, 3], two models will be stored in the assigned variable and two images should be saved to the project folder.\n(Python)\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2109-Fig6.jpg\nFigure 6. The carom.decision_tree function is another tool for understanding which features are instrumental in differentiating between PTM classes\nThe function outputs a separate decision tree for each maximum depth value that is specified. The colors indicate the majority class for each leaf, while the strength of the colors represents how dominant the major class is.\nmy_weights = [{0:2,1:1,2:2}, {0:5,1:1,2:5}]\nmy_trees = carom.decisionTree(X = df_carom[feature_names],\n        y = df_carom[\"PTM\"],\n        class_names = [\"Phos\", \"Unknown\", \"Acetyl\"],\n        imbalance=my_weights,\n        condition = \"weighted_dTree\",\n        make_viz=True,\n        depths=[2],\n        pruneLevel=5,\n        random_seed=123)",
    "Class imbalance: similar to the train_model function, several options are available within the imbalance argument for adjusting how the model addresses class imbalance.\nThe user may enter a list of dictionaries, each containing the class weights (see the example above). As described previously, typically the less represented classes are given higher weights, so that the model penalizes misclassifications of that class more severely. In this case, a separate model is trained using cross-validation and hyperparameter tuning for each set of weights within the list. This allows the user to experiment with different sets of weights. The model with the best cross-validation score is then selected as the final model.\n“adasyn”: Uses the ADASYN oversampling method described in the train_model section, with all classes set to the same size.\n\"balanced\": the inverse proportion of classes are used to assign a balanced set of class weights.\n“none”: no adjustments are made to the model training.\nPruning – the pruneLevel argument is used to remove any leaves on the decision tree with less observations than the specified integer."
  ],
  "subjectAreas": [
    "Genomics",
    "Bioinformatics",
    "Systems Biology",
    "Computer Sciences",
    "Metabolism",
    "Proteomics",
    "Microbiology",
    "Metabolomics"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics",
    "Bioinformatics & Computational Biology"
  ]
}