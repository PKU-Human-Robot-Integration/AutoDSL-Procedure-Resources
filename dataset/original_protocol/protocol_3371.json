{
  "id": 3568,
  "origin_website": "Cell",
  "title": "Protocol for the integration of fiber photometry and social behavior in rodent models",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nFiber photometry recordings during a reciprocal social interaction test\nTiming: 25 min per mouse\nThese procedures outline the necessary steps for the acquisition of fiber photometry data during a reciprocal social interaction test. By the end of these procedures, experimenters should have fiber photometry data which has been time-locked to video recordings of the behavioral tests.\nConduct all experiments in a dimly lit room. See Figure 2[href=https://www.wicell.org#fig2]A for a schematic outlining of the behavioral procedures.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3138-Fig2.jpg\nFigure 2. Classification and Analysis of Reciprocal Social Behaviors\n(A) Schematic outlining the behavioral procedures.\n(B) DeepLabCut graphical user interface during the annotation of training frames.\n(C) SimBA graphical user interface during the validation of behaviors classified by the neural network.\n(D) Example of the resident mouse engaging in head-torso sniffing behavior, as predicted by DeepLabCut and SimBA.\n(E) Example of the resident mouse engaging in anogenital sniffing behavior, as predicted by DeepLabCut and SimBA.\nThese experiments were conducted under 50 lux lighting conditions.\nCritical: To minimize the potential impact of external lighting conditions on the photometry recordings, as well as on rodent anxiety during behavioral testing, tests should be conducted in a relatively dark setting.\nRemove the appropriate experimental mouse from its home cage along with its familiar cage mate.\nFor these experiments, mice were pair housed.\nClean the exposed end of the implanted fiber and then securely attach this fiber to the patch cord using a ceramic sleeve.\nReturn the experimental mouse to the home cage and start both the fiber photometry and behavioral recordings.\nAllow the mouse 5 min (00:00–05:00) in the home cage on its own.\nNote: This recording serves as the first baseline recording.",
    "After this first 5-min baseline recording, return the familiar cage mate to the cage and allow it to reciprocally interact with the experimental mouse for 5 min (05:01–10:00).\nNote: This period serves as the familiar interaction period.\nAfter the familiar interaction period, remove the cage mate and leave the experimental mouse alone in the home cage for a second 5-min baseline recording period (10:01–15:00).\nIntroduce an unfamiliar, non-cage mate, stranger (intruder) mouse into the home cage with the experimental mouse for 5 min (15:01–20:00).\nNote: This period serves as the stranger interaction period.\nNote: If the order of presentation of familiar and unfamiliar mice is counterbalanced during these procedures, this information should be incorporated during Process 02. Initialization – Subject Information in the MATLAB workflow during subsequent analysis of the data.",
    "Critical: Patch cord management is critical during interaction periods, as the patch cord can become tangled with increased locomotor activity. A tangled patch cord may compromise the quality of the photometry signal. Furthermore, if the patch cord is too slack in the cage, the stranger (intruder) mouse may be able to damage the cord. However, the use of rotary joints is not advisable during fiber photometry since they can introduce noise or a reduction in light transmission. One strategy that is particularly useful for effective patch cord management is draping the cord over a support located above the cage, which allows the cord to hang straight down towards the testing apparatus. As behavioral recordings across many tests, including these reciprocal social interaction tests, are gathered from an overhead camera, the support holding the camera in place can also serve as a suitable support for the patch cord. Manually feeding patch cord over this support towards the cage during the experiment while the animal is moving allows experimenters to ensure that cables do not become taut to the point of restricting behavior. Manually guiding excessively slack patch cord back over the support away from the cage can help reduce the chances of fibers becoming tangled. Alternatively, the application of heat shrink tubing over the patch cord can help provide rigidity and reduce the likelihood of tangling.\nFollowing the stranger interaction period, remove the stranger mouse and leave the experimental mouse alone in the home cage for one final 5-min baseline recording before the behavioral testing is complete and the photometry recording is turned off (20:01–25:00).\nDetach the patch cord from the implanted fiber, being careful not to dislodge the headcap.\nBehavioral classification – DeepLabCut and SimBA\nTiming: 2–3 h, dependent on video quality",
    "These procedures outline the necessary steps required for behavioral analysis during the reciprocal social interaction test. By the end of these procedures, experimenters should have data outlining the nature of these behavioral interactions presented as a time series.\nThe processes outlined in this section have been described in full in the original articles for DeepLabCut3[href=https://www.wicell.org#bib3],5[href=https://www.wicell.org#bib5],6[href=https://www.wicell.org#bib6],7[href=https://www.wicell.org#bib7] and SimBA.4[href=https://www.wicell.org#bib4] These markerless pose estimation and behavioral classification tools are versatile and can be tailored to a wide variety of experimental designs. The protocol for using these tools for unbiased, high-precision identification of head/torso and anogenital sniffing interactions has been outlined below.\nFurther information on how to use these tools can be found in the detailed guides linked below.\nANY-maze: https://www/any-maze.com/support/guides/[href=https://www/any-maze.com/support/guides/]\nDeepLabCut: http://www.mackenziemathislab.org/deeplabcut[href=http://www.mackenziemathislab.org/deeplabcut].\nSimBA: https://github.com/sgoldenlab/simba[href=https://github.com/sgoldenlab/simba]\nCritical: While these tools are very powerful in behavioral analyses, they each rely on high quality data input and careful training. Inconsistencies in data input quality and pose/behavior classification will introduce considerable variability in the accuracy of these results. It is recommended that users keep these input variables as consistent as possible. Furthermore, it is advised that users randomly sample their outputs at various stages and compare the accuracy of the pose estimation and behavioral classification to manual scoring. Spending extra time during these steps will help yield the most accurate behavioral classification possible.\nPositional tracking and pose estimation with DeepLabCut.\nNote: In this step, video files recorded in ANY-maze are exported and multi-animal tracking is conducted using a supervised-learning deep neural network. By the end of this step, users will have positional tracking data for each animal (experimental, familiar, and stranger) presented during the behavioral task (Figure 2[href=https://www.wicell.org#fig2]B).\nExport video files from ANY-maze as an MP4 format which can be analyzed using DeepLabCut.\nNote: For the current experiment, the framerate of these videos was 20 frames per second.",
    "Import videos into DeepLabCut, where a subset of videos are used to label body parts of the animals that the user intends to track.\nNote: In the current protocol, these body parts are the nose, left and right ears, left and right latissimus dorsi, tail base, and center of the torso of each animal present in a user-selected subset of frames.\nNote: This labelling will be used to train the neural network which will track mice in all videos. Therefore, it is important that the user-selected frames capture a wide range of the possible forms of interactions which can occur during these tests.\nAfter this initial training, evaluate the results of the pose estimation.\nNote: If these results are unsatisfactory, the user may choose to include more training frames and/or refine existing labels. These steps should be repeated until pose estimation is in line with manual scoring. In this case, manual scoring consists of the user manually labelling body parts and comparing with their position with estimations generated by DeepLabCut. Pose estimations are considered to be in line with manual scoring when the neural network consistently labels these body parts correctly.\nOnce satisfied with the quality of these results, process all videos using the trained neural network.\nNote: To further ensure accurate tracking, the data from a subset of novel videos which were not included in the training dataset should be compared to manually scored results prior continuing to SimBA processing.\nPredictive behavioral classification with SimBA.",
    "Note: In this step, pose estimations and positional tracking data from DeepLabCut is classified into complex behaviors of interest using a supervised-learning deep neural network. By the end of this step, users will have data outlining the nature of each social interaction (in this case, head-torso and anogenital sniffing) performed during the behavioral test (Figures 2[href=https://www.wicell.org#fig2]C–2E).\nImport pose estimation data obtained from DeepLabCut.\nNote: With these data, it is important to ensure that the framerate and the pixel size are properly calibrated. This can become an issue if the camera or behavioral apparatus is moved during the testing procedures. This further emphasizes the importance of minimizing variability in the experimental setup during data acquisition.\nManually annotate behaviors of interest in a subset of videos to build the behavioral classifier network.\nNote: After annotating a subset of videos for the behaviors of interest, it is recommended that users evaluate the results of the classification. SimBA offers several tools to assist in this evaluation, including learning curves and means to visualize classification thresholds. If these results are unsatisfactory, the user may choose to include more training data and/or refine existing annotations. These processes should be repeated until behavioral classification is in line with manual scoring.\nOnce the experimenter is satisfied with the quality of the behavioral classification, all pose estimate data are analyzed using the trained neural network.\nNote: To further ensure accurate classification, data from a subset of novel sessions which were not included in the training dataset should be compared to manually scored results.\nIntegrating behavioral classifications into fiber photometry analyses\nTiming: 5 min per mouse",
    "These procedures outline the necessary steps for integrating behavioral classifications obtained from DeepLabCut and SimBA with fiber photometry data. Following these procedures, experimenters should have information on neuronal population activity during specific social interaction types and fiber photometry and behavioral data which have been synchronized on a frame-by-frame basis for further analyses of their choosing.\nDuring this step, the data from the behavioral classification is aligned with processed fiber photometry data to enable the analysis of fiber photometry data during specific behavioral epochs. This step requires MATLAB and the SarginFP_SimBA_v163.m file. This file, along with the steps outlined below, correspond with the data obtained using a Doric Lenses fiber photometry system. The organization of these inputs is different when using data from a Neurophotometrics fiber photometry system; however, the calculations are still similar. For users who would like to conduct these analyses using data collected from a Neurophotometrics fiber photometry system, a separate MATLAB file, SarginFP_SimBA_v163_NP.m, has been included in the supplementary materials of this manuscript.\nWhether using the Doric Lenses or the Neurophotometrics fiber photometry analysis script, it is recommended that end users read through the documentation in the first section of the file. This section outlines required inputs, the conducted analyses, operational definitions, and any assumptions that the code makes during data analysis.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3138-Fig3.jpg\nFigure 3. Fiber Photometry Analyses\n(A) Representative image showing mice socially interacting during the acquisition of fiber photometry recordings.\n(B) Raw fluorescence data from GCaMP (green) and isosbestic (blue) channels during the reciprocal social behavior task.\n(C) Processed GCaMP fluorescence during the reciprocal social behavior task, presented as Z score ΔF/F.",
    "(D) Processed GCaMP fluorescence, presented as Z score ΔF/F, from an experimental mouse during interaction with a familiar mouse. Bouts of head-torso sniffing are depicted in blue, while anogenital sniffing is depicted in green.\n(E) Processed GCaMP fluorescence, presented as Z score ΔF/F, from an experimental mouse during interaction with an unfamiliar intruder mouse. Bouts of head-torso sniffing are depicted in blue, while anogenital sniffing is depicted in green.\nNote: It is recommended that users run through these analyses one process at a time using the “Run Section” command in MATLAB. Data can be saved and reloaded at any time using the save (lines 946–952) and load (lines 953–965) processes.\nComplete process 01. Initialization – Group Information in the MATLAB workflow.\nNote: In this process, the general parameters for the photometry analysis are defined. This section contains several editable variables which can be tailored to meet experimental needs. These variables are outlined below.\nState the number of groups in the current experiment (line 171).\nNote: This value is numeric. In the example below, there are two groups.\nFP.info.groupnum = 2;\nList the titles by which groups will be identified (line 173).\nNote: Variables in this line are listed as character vectors, with each unique identifier written within quotation marks and the full list of variables written within square brackets and without commas separating entries. In the example below, the two groups are control and manipulation.\nFP.info.groups = [“control” “manipulation”];\nList the number of animals per group (line 175).",
    "Note: This value is numeric. The number of animals should be presented in the same order as the identifiers were presented in the previous step, without commas separating entries, and with the full list of variables written within square brackets. Using the groups from step 13b, the example below shows 10 animals in the control condition and 11 animals in the manipulation condition.\nFP.info.pergroup = [10 11];\nAdjust the flag to indicate whether data is to be presented as a Z score or not (line 177).\nNote: In this line, if the numeric variable is set to 0, the analyses will proceed without presenting the data as a Z score. If the numeric variable is set to 1, all analyses will be conducted on Z score ΔF/F data. In the below example, photometry traces will not be analyzed as Z scores.\nFP.info.zscore = 0;\nAdjust the flag to indicate whether data is to be presented as %ΔF/F or not (line 179).\nNote: In this line, if the numeric variable is set to 0, the analyses will proceed without presenting the data as a percentage of the maximum ΔF/F for each given trace. If this variable is set to 1, analyses will proceed with subsequent analyses based on the ΔF/F trace as a percentage of the maximum ΔF/F values. In the below example, photometry traces will not be analyzed as %ΔF/F.\nFP.info.percentdFF = 0;\nNote: These functions for outputting data as Z score and %ΔF/F are not mutually exclusive. If both variables are set to 1, the data will be presented as a percentage of the maximum Z scored ΔF/F values. If both variables are set to 0, the data will be presented as ΔF/F without further processing.\nDefine the desired rolling window size for local peak detection (line 183).",
    "Note: In this line, a rolling window is defined for subsequent local peak detection analyses. This numeric variable will be interpreted as seconds. In the below example, a rolling window of 30 s was used for local peak detection.\nFP.info.windowtime = 30;\nComplete process 02. Initialization – Subject Information in the MATLAB workflow.\nNote: In this process, the user will follow the prompts in the command window and navigate to the appropriate fiber photometry and SimBA output files. This will initialize storage vectors for these data and perform all loading sequences. The user will also manually define whether the first interaction occurred with a familiar or an intruder mouse in response to a prompt in the MATLAB command window, which allows for counterbalancing of intruder/familiar presentation order. Several variables within this process will need to be modified depending on the frame rate of the photometry recording and the duration of each test segment. These variables are described below.\nWithin the internal initialization subsection (lines 201–227), adjust the number of frames according to the times of each portion of the test and the frame rate of the fiber photometry recording.\nNote: In the example below, the number of frames in the array was set to 180,705, to represent a framerate of 120 frames per second over the course of the full 25-min task and a buffer period at the end of the recording.\nFP.inputs.doric.time.(FP.info.groups(ii))=zeros(180705,FP.info.pergroup(ii));\nNote: This value represents the full length of the fiber photometry recording. If the length of this recording varies from mouse to mouse an error will occur. See troubleshooting 4[href=https://www.wicell.org#sec5.10] for potential workarounds when working with fiber photometry recordings with variable number of frames.\nAdjust the number of frames to be allocated with the different segments of the behavioral task.",
    "Note: In the below example, the segment of the test during which familiar interactions could occur was 5 min. Therefore, at a framerate of 120 frames per second, this period is a total of 36,000 frames, as shown in the example below.\nFP.inputs.familiar.headtorso.(FP.info.groups(ii))=zeros(36000,FP.info.pergroup(ii));\nAdjust the following lines to match the number of frames in the photometry array (from the above example, 180,705 frames): 239, 240, 265–267.\nAdjust the following lines to match the number of frames in the behavioral array (from the above example, 36,000 frames): 260, 261, 269–272.\nAdjust the column identifiers for their behaviors of interest, as needed.\nNote: In the current study, the behaviors of interest were head-torso and anogenital sniffing, which were in columns 501 and 499 of the behavioral files respectively. The lines pertaining to these columns are as follows: 269–272.\nComplete process 03. Photometry Processing – Behavior Independent in the MATLAB workflow. During this step the ΔF/F trace is generated from the raw photometry data.\nDefine a baseline period (line 323).\nNote: In this step, the user defines a baseline period which will be used for baseline adjustments to the ΔF/F trace. This variable is presented as a pair of numeric values, with the first representing the time at which the user-defined baseline period is to start and the second being the duration of this period. Both of these values have the unit of seconds. In the example below, the baseline period starts at 60 s and continues for 180 s until the 240th second of the recording.\nFP.info.baseline = [60 180];",
    "Critical: It is important to consider handling stress when defining a baseline period. When animals are initially placed into a testing environment, it is not uncommon for most fiber photometry signals to be elevated drastically above their normal baseline. For this reason, it is recommended that users select a baseline period that begins after this initial elevation in signal has decreased. This timing can be estimated by looking at the raw photometry data.\nPrior to starting the batch processing portion, adjust the number of frames in lines 330 and 331, corresponding with the number of frames entered in line 239. This is the total number of frames in the fiber photometry trace during the full duration of the task itself. These lines create structure array elements to store the outputs of the fiber photometry analyses.\nWith these steps completed, the process can now be executed. The calculations have been outlined in full below.\nDuring the first block of these analyses, data from the isosbestic channel is fit to a biexponential decay. This biexponential decay is then used to linearly scale the data from the channel of interest. Using the raw data and scaled data as references, a ΔF/F trace is calculated (See Figure 3[href=https://www.wicell.org#fig3]B for raw fluorescence data from a GCaMP signal and its appropriate 415 nm isosbestic channel; Figure 3[href=https://www.wicell.org#fig3]C shows these data presented as a Z score ΔF/F trace).\ntable:files/protocols_protocol_3138_1.csv",
    "When examining a ΔF/F trace, it is not uncommon for variation in baseline intensity to be present. These can be indicative of differences in viral expression/cell density, or variability in the focal distance between the tip of the optic fiber and peak virus expression. To account for this, baseline adjustment is performed on all samples. In these steps, the minimum ΔF/F value during the behavioral task is compared to the mean ΔF/F value during a user-defined baseline period.8[href=https://www.wicell.org#bib8] The ΔF/F trace during the behavioral task is then adjusted so that the minimum value recorded during the testing period corresponds with the mean value during the baseline period.\ntable:files/protocols_protocol_3138_2.csv\nIf the user had previously defined further processing criteria, such as analyzing photometry data as a Z score ΔF/F or as a %ΔF/F, these are now applied.\n%z-score\nif FP.info.zscore(1) == 1\n  cordFF=zscore(dFF);\n  dFF=zscore(dFF);\nelse\n  %proceed with non-z-scored data\nend\n%dF/F\nif FP.info.percentdFF(1) == 1\n  cordFF=((dFF-meanbaseline)./meanbaseline)∗100;\nelse\n  %proceed with non-%dF/F data\nend\nWith fiber photometry data now preprocessed, initial behavior independent analyses are conducted to assess area under the curve, peak frequency, mean peak height, max peak height, max ΔF/F, and the time at which the max ΔF/F value occurs. These behavior and test-segment independent values are then stored to the FP.outputs.behaviourindependent element in the structure array.\nNote: For peak analyses, a minimum peak height criterion is applied. In the block of code below, this is defined as 2 standard deviations above the median ΔF/F value within the user-defined rolling window.\n%area under the curve calculation\nauc=trapz(cordFF);\n%peak detection and analysis\n%Note: in this step the minimum peak height is defined as 2 standard deviations above the median dFF value within the rolling window.\nminpk=movmedian(dFF,FP.info.windowframes)+(2∗movstd(dFF,FP.info.windowframes));\ntracedif=ge(dFF,minpk);                                     %identify indices greater\n                                                  %than or equal to the\n                                                  %minimum peak threshold\npks=dFF(tracedif);                                         %identify peaks\n%peak frequency",
    "pkfreq=size(pks,1)/(FP.info.samplingrate(1)∗size(time,1));\n%mean peak height\nmeanpk=mean(cordFF(tracedif));\n%index of maximum dF/F value\nmaxpkidx=find(dFF=max(dFF),1,’first’);\n%maximum dF/F value\nmaxpk=max(cordFF);\n%time at which the maximum dF/F value occurs\nmaxpktime=time(maxpkidx);\nComplete Process 04. Photometry Processing – Behavior Epoch Dependent. In this process, behavioral information will be integrated with the photometry data.\nDefine the starting times and durations of each behavioral epoch in the initialization subsection.\nNote: In the current manuscript, epoch refers to the entire testing period of interest. In the case of the social behavior task, the two epochs of interest are the 5-min block during which a familiar mouse is present and the 5-min block during which an intruder mouse is present. In the current design, regardless of counterbalancing, the first epoch occurs at the 5-min mark (300 s) while the second epoch occurs at the 15-min mark (900 s). Each of these epochs occurs for 300 s. Therefore, the initialization subsection would be as follows.\ntable:files/protocols_protocol_3138_3.csv\nAdjust the number of frames in lines 478–480 to match the number of frames in the photometry trace.\nNote: These lines generate storage vectors for behavioral data at a framerate which coincides with the photometry data. In the below example, line 478 is set up for processing a photometry trace with a length of 180,705 frames. This value should match the user-entered value in line 239.\nFP.outputs.behaviourdependent.behaviour.anogenital.familiar.(FP.info.groups(ii))=zeros(180705,FP.info.pergroup(ii));\nThe script analyzes fiber photometry data by epoch and provides area under the curve, peak frequency, mean peak height, max peak height, max ΔF/F, and the time at which the max ΔF/F value occurs.\nThe script aligns behavioral and fiber photometry data using nearest neighbor approximation at the timestamps of individual data frames.",
    "Note: Following epoch-level analyses, behavioral data is expanded using nearest neighbor approximation to align with the framerate of the fiber photometry recording. This approach allows for the assessment of fiber photometry analyses during specific behaviors within each epoch. For example, this approach allows users to assess area under the curve during head-torso sniffing interactions, which can then be compared between interactions with familiar and intruder mice. In the below example, behavioral data for head-torso and anogenital sniffing interactions is aligned to photometry data during the epoch with the familiar mouse. These vectors are then converted into logical arrays for the purpose of indexing into fiber photometry data. The logical vector is then used to index into the fiber photometry trace to extract only the ΔF/F values occurring during behaviors of interest. In the below example, the ΔF/F data occurring during head-torso sniffing interactions with a familiar mouse is isolated.\nhtf=fdFF(htfstretch);\nCritical: The nearest neighbor approach will not work properly if the framerate of the behavioral recording exceeds that of the fiber photometry recording. See troubleshooting 3[href=https://www.wicell.org#sec5.8] for notes on how to avoid this issue.\n%familiar\nfamtime=(FP.info.epoch.familiar(1):(FP.info.epoch.familiar(2)…\n/size(htf,1)):(FP.info.epoch.familiar(1)+FP.info.epoch.familiar(2)));\n                        %dummy time series for %photometry during %familiar epoch\nfamtime=famtime(2:end)’;           %trim leading zero\nhtfstretch=zeros(size(ftime,1),1);         %sink for head torso data\nagfstretch=zeros(size(ftime,1),1);         %sink for anogenital data\nfor iv=1:size(ftime,1)               %loop through fp frames\n  temp_time=ftime(iv);             %time frame from fp\n  [∼,ix]=min(abs(famtime-temp_time));     %find nearest time value %in behavioral dataset\n  htfstretch(iv)=htf(ix,:);             %assign value from head-\n                          %torso data at the index\n                          %of nearest time value to\n                          %the sink\n  agfstretch(iv)=agf(ix,:);             %same process for\n                          %anogenital data\nend\nhtfstretch=(htfstretch==1);             %convert to a logical\nagfstretch=(agfstretch==1);             %convert to a logical",
    "The script applies fiber photometry analyses to these behavior and epoch specific fiber photometry traces to assess area under the curve, peak frequency, mean peak height, max peak height, max ΔF/F, and the time at which the max ΔF/F value occurs.\nNote: These values are then stored to the FP.outputs.behaviourdependent.analyses element in the structure array (See Figures 3[href=https://www.wicell.org#fig3]D and 3E for an example of social interaction data aligned to a fiber photometry recording).\nComplete Process 05. Photometry Processing – Bout-by-Bout Information.\nNote: In this process, photometry data will be analyzed on a bout-by-bout basis for each of the behavioral measures of interest. For example, this series of calculations will yield the area under the curve for the ΔF/F trace during each bout of head-torso interaction during the familiar epoch. There are no user-defined variables which will need to be edited in this process.\nNote: All data from these analyses are stored under the FP.outputs.boutbybout element in the structure array. When interpreting these outputs under the FP.outputs.boutbybout.analyses element, each column represents a different mouse, with bout-by-bout information presented in chronological order down the column. For example, if the area under the curve during the first bout of head-torso sniffing for mouse 1 is 3, the cell at the intersection of the first column and the third row will be 3. NaN represents a placeholder value in these arrays. It is indicative of either a failure to meet a minimum criterion, such as a bout in which no points in the ΔF/F trace surpassed the minimum peak detection threshold, or that no further bouts have occurred. As a result, the bottom rows of each of these sheets will contain NaN values.",
    "Critical: Following the conclusion of all fiber photometry experiments, it is critical to assess the quality of viral expression and the placement of the fiber optic implant. Variability in each of these can influence the quality of the fiber photometry recording. Animals with poor viral expression, fiber optic implants which are more than the focal distance from the center of the viral injection, or inconsistent regional targeting must be excluded from data analysis."
  ],
  "subjectAreas": [
    "Neuroscience",
    "Model Organisms",
    "Behavior"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research",
    "Molecular Biology & Genetics",
    "Ecology & Environmental Biology"
  ]
}