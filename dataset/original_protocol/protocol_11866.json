{
  "id": 13266,
  "origin_website": "Jove",
  "title": "Using Fiberless, Wearable fNIRS to Monitor Brain Activity in Real-world Cognitive Tasks",
  "procedures": [
    "The protocol was approved by the UCL local research ethics committee, approval number CEHP/2014/901.\n1. Instruments Setup Prior to the Participant’s Arrival\nUse video recordings from 3 cameras to analyse “real-world” type tasks (e.g. Shallice and Burgess, 19913):\n\t\nPlace one camera on the experimenter’s chest in order to follow participant’s movements.\nMount the head camera onto the fNIRS shading cap to track where the participant is looking throughout the experiment.\nPrepare and turn on the camera for the second experimenter, who follows the first experimenter and the participant for the entire session.\nClean the fNIRS headset with a sanitizing wipe.\nPlace a 3D digitizer in an appropriate room (e.g., far away from metal objects, walls and floors) and turn it on.\n2. Participant Preparation and fNIRS Probe Placement\nBefore the experiment starts, have the participant sign the consent form.\nUse the 10-20 system (Figure 2) and digitize the optodes and 10-20 standard positions24, 25 to achieve consistent fNIRS headset placement across all the participants:\n\t\nMark with a washable marker the Nasion (Nz, the intersection point between the frontal bone and the nasal bones), Inion (Iz, the occipital protuberance at the back of the scalp) and Left and Right Pre-auricular points (LPA, RPA, the points anterior to the ears in front of the upper end of the tragus) (Figure 2) in agreement with manufacturer’s instructions.\nMeasure the Nz-Iz distance over and around the head and the LPA-RPA distance over the head.\nMark with a washable marker the Cz (the intersection point between the Nz-Iz line and the LPA-RPA line, located at the 50% of the Nz-Iz distance and the 50% of the LPA-RPA distance), Fpz (10% of the Nz-Iz distance) and Fz (30% of the Nz-Iz distance) points based on the 10-20 system (Figure 2).",
    "Use a headband with holes matching the optodes positions for a more accurate digitizing across participants. Remove hair from the forehead as much as possible using hair clips along the hairline. Place the digitizing headband over the prefrontal cortex accordingly to the Fpz and Fz points: channel 9 in correspondence of the Fpz point and channel 9-channel 8 line aligned to the Fpz-Fz line (Figure 1E).\nDigitize the marked 10-20 reference points and the optodes positions by means of the 3D magnetic digitizer.\nSave the digitized coordinates and use the Spatial Analysis Tool (http://brain-lab.jp/wp/?page_id=52[href=http://brain-lab.jp/wp/?page_id=52]) of the open-source Platform for Optical Topography Analysis Tools (POTATo) software (see the Table of Materials for further information) to register fNIRS data onto a Montreal Neurological Institute (MNI) brain template.\nNOTE: The implemented algorithm for the probabilistic registration converts the digitized locations in the real world coordinate system into the MNI coordinate system and then projects and localizes them onto the MNI brain surface (Figure 1E) 26,27.\n\t\nOpen POTATo through the Matlab command P3.\nSelect “Spatial Analysis” from the menu on the main window of the POTATo Graphical User Interface (GUI) and click the “Spatial Analysis” button.\nLoad the digitized coordinates by clicking the “Empty 10-20” button on the Spatial Analysis Data Viewer window.\nClick the “Empty MNI” button.\nSelect the 10/20 reference points on the MNI estimation window and start the spatial registration.\nCheck for the correct location of the fNIRS channels on the template brain surface (Figure 1E): check if channel 8 and channel 9 overlap the inter-hemispheric fissure28. If correct, save the channel configuration file for further analyses; otherwise replace the digitizing band re-aligning channels 8 and 9 to the Fpz-Fz line and overlapping channel 9 to Fpz. Then repeat the digitizing procedure.",
    "Place the fNIRS headset aligning channels 8 and 9 to the Fpz-Fz line and overlapping channel 9 to Fpz, in agreement with the digitizing headband, and remove the headband (Figure 1B-C). Make sure that the probe is well attached to the participant’s head.\nPlace the shading cap with the head camera mounted on it over the fNIRS headset.\nExplain the experimental rules to the participant. Include device-related precautions (e.g., 'Take as little time as possible without rushing or leaving the experimenter behind (NO running)”) as well as task specific rules (e.g., 'Do not go outside the Queen Square area into neighbouring streets or areas”).\nHave the participant successfully memorize all the rules and go outside to start the experiment.\n3. fNIRS Signals Quality Assessment\nUse the fNIRS system in wireless mode first to visually inspect signals quality on the fNIRS laptop:\n\t\nPress the “Power” button on the portable box and turn on the fNIRS in the wireless mode. Open the fNIRS acquisition software on the fNIRS laptop and establish the connection with the portable box.\nPress the “Probe Adjustment” button to optimize the detectors gain on the base of the detected light.\nCheck the probe adjustment results on the software “Probe Adjustment” window and check if each detector receives enough light from the sources by checking if all the channels are classified as “Normal”. If channels are marked as “Stray” or “Under”, re-place the shading cap and maximize the optodes coupling with the forehead. If channels are marked as “Over”, set the power of the laser source to “low”.\nNOTE: As the lateral channels cover the dorsolateral prefrontal cortex, in some cases it may be necessary to move the hair off the forehead to maximize the received light.",
    "Press the “Ready” button and then “Start” to acquire data for a minute and check if heartbeat (haemoglobin oscillations of ~1 Hz) is visible on concentration signals, which ensures a good signal quality.\nTurn off the portable box in the wireless mode pressing the “Power” button on it. Press the “Power” button in conjunction with the “Mode” button on the portable box to turn on the fNIRS in the stand-alone mode.\nNOTE: The stand-alone mode ensures that the participant can move freely around the experimental area and avoids the necessity to be close to the fNIRS laptop to maintain the wireless connection.\n4. Data Acquisition\nTurn on the head camera and the experimenters’ cameras and start filming. Press the “Probe Adjustment” button on the fNIRS portable box to optimize the detectors gain and then press the “Play/Stop” button to start the fNIRS acquisition (sampling frequency=5 Hz).\nAdd a marker to the fNIRS data manually by using the “Mark” button on the fNIRS portable box in conjunction with an audio trigger (e.g., a beep). The audio trigger must be clearly recorded on all video cameras. Then start the experiment.\nNOTE: This allows a robust time synchronisation between the different video cameras and the fNIRS recording.\n5. Experimental Protocol  \nInclude the following conditions and counterbalance the prospective memory ones across the participants:\n\t\nUse 3 baseline conditions:\nNOTE: This allows to decouple global haemodynamic and oxygenation changes due to walk-related systemic changes versus more localised responses due to brain (neuronal) function.\n\t\t\nFor the Rest 1 condition, have the participant stand stationary on the street where the test is conducted, and count the number of stimuli on a piece of paper (e.g., use a sheet containing Xs and Os printed on it and have the participant count the number of Os on it).",
    "For the Rest 2 condition, have the participant walk a short distance at a normal walking pace, and make no other demands of him.\nFor the Baseline condition, have the participant walk around the entire street area where the experiment is conducted.\nNOTE: In our case, the experiment took place in Queen Square, London WC1N, U.K.\nFor the Uncontaminated Ongoing condition, have the participant walk around the experimental area and count the occurrence of certain items (e.g., the number of signs affixed to buildings that contain the word “Queen”).\nFor the Non-social Prospective Memory condition, have the participant carry out the Ongoing task (e.g., have the participant count the number of dates and opening hours affixed to buildings), but in addition, if they came within a specified distance of a parking meter, have them go over to it and touch it.\nFor the Social Prospective Memory condition, have the participant carry out the Ongoing task (e.g., have the participant count the number doorbells), but in addition, have him respond to one of the experimenters who acts as a confederate who moves around into pre-specified positions within the experimental area. Have the participant go over to them and give them a “fist bump” greeting.\nUse an additional Ongoing condition (Contaminated Ongoing) after the PM conditions (e.g., participants has to count the number of unobstructed stairways within the testing area).\nRepeat the two Rest conditions described above in opposite order (Rest 2 and then Rest 1).\nNOTE: This allows evaluation of walk-related systemic changes at the end of the experiment.\n6. Recover Events from the Videos\nDownload the videos from all cameras and save in mpg4 format.",
    "Load the videos from all cameras into ELAN (https://tla.mpi.nl/tools/tla-tools/elan/[href=https://tla.mpi.nl/tools/tla-tools/elan/]) and synchronise the videos: use Options/Media Synchronisation Mode and align them based on the time point of the audio trigger.\nIn ELAN, use annotations and press the Tier button on the ELAN main window (referring to groups of annotations, i.e., one tier for all social PM targets) to mark events in the video stream.\n\t\nWatch the synchronised video stream and annotate the start and end of each experimental condition, and use tiers for the point at which each PM target is reached. Use separate tiers for social and non-social PM targets.\nComplete the video editing for each participant and use the File/Export As/Interlinear Text to export as a text file all the annotated time points.\n7. Data Analysis\nOpen the fNIRS software and export data from the portable box flash card into the fNIRS laptop.\nNOTE: The fNIRS system processing unit uses the modified Beer-Lambert law and calculates the relative changes in HbO2 and HHb from an arbitrary zero baseline at the beginning of the measurement period. Concentration values are hence expressed in molar concentrations (mmol/l) multiplied by the path length (mm)6 as they are not corrected for the optical path length.\nSave concentrations data and import them into Matlab through an in-house pre-processing software.\nPre-process the signals following these steps (Figure 3B):\n\t\nSignals down sampling to 1 Hz:\n\t\t\nUse a spline interpolation (Matlab function: interp1) to down sample data from 5 Hz to 1 Hz.\nLinear Detrending:\n\t\t\nTo remove slow drifts of the signal, use a linear interpolation (Matlab function: polyfit) between the Rest 1 phases at the beginning and the end of the experiment.\nMotion Artifact Correction:",
    "For each channel, identify and remove motion artifacts through a wavelet-based method31. Improve signals quality by applying the Correlation Based Signal Improvement (CBSI) method32.\nComplex wavelet transform:\n\t\t\nUse a Morlet mother wavelet, scaled and translated over time, to compute the wavelet transform of each channel through the wavelet toolbox (Matlab function: wt) provided by Grinsted et al.33 (http://noc.ac.uk/using-science/crosswavelet-wavelet-coherence[href=http://noc.ac.uk/using-science/crosswavelet-wavelet-coherence]).\nNOTE: From the wavelet spectrum, it is possible to evaluate the spectral content of signals in a time-frequency space.\nBand-pass Filtering:\n\t\t\nOn the base of the wavelet analysis, use a 3rd order Butterworth band-pass filter (Matlab functions: butter and filter) with cut-off frequencies of 0.008-0.2 Hz7,34."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}