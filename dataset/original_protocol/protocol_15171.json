{
  "id": 18997,
  "origin_website": "Jove",
  "title": "Development of an Audio-based Virtual Gaming Environment to Assist with Navigation Skills in the Blind",
  "procedures": [
    "1. Participant Demographics\nThis is an on-going study that recruits blind male and female participants aged between 18-45 years. All participants are legally blind of early onset (documented prior to the age of 3) and of varying ocular etiologies. None of the study participants were previously familiar with the spatial layout of the target physical building.\n2. Preparation and Familiarization with AbES\n Provide the participant with a blindfold and headphones to be worn throughout the training and assessment process. Ensure that the blindfold is comfortably placed over the eyes and the headphones are properly oriented and positioned over the ears (i.e. left speaker over left ear).\nTrain participant how to use assigned keys and the information represented by the audio cues in AbES. Using specific key strokes (Figure 3), a user navigates through and explores the building virtually (moving forward, right or left). Each virtual step approximates one step in the real physical building. \nFamiliarize with rules and premise of the game.",
    "Familiarize with audio cues specific to game play (e.g. sound of locating jewels and sound of monsters nearby). As the user navigates through the building, auditory-based and contextual spatial information is acquired sequentially and is dynamically updated. Spatial and situational information is based on iconic and spatialized sound cues provided after each step taken. Orientation is based on cardinal compass headings (e.g. \"north\" or \"east\") and text through speech (TTS) is used to provide further information regarding a user's current location, orientation and heading (e.g. \"you are in the corridor on the first floor, facing west\") as well as the identity of objects and obstacles in their path (e.g. \"this is a door\"). Distance cues are provided based on modulating sound intensity. The spatial localization of the sounds is updated to match the user's egocentric heading. Essentially, the software is designed to play an appropriate audio file as a function of the location and egocentric heading of the user and keeps track of the user's position as they move through the environment. For example, if a door is located on the person's right side, the knocking sound is heard in the user's right ear (i.e. the software plays an audio file of a knocking sound in the right channel). If the person now turns around 180 degrees so that the same door is now located on their left side, the same knocking sound is now heard in the left channel (i.e. the software plays an audio file of a knocking sound in the left channel). Finally, if the user is facing the door, the same knocking sound is heard in both ears equally.",
    "By keeping track of the user's egocentric heading, the software can play the appropriate spatial localized sounds that identify the presence and location of objects and keep track of these changes as the user moves through the virtual environment. See Figure 4.",
    "3. Training and Game Play with AbES (3 Sessions Each Lasting 30 min for a Total of 1.5 hr)\nAllow for free game play and note any difficulties and challenges (i.e. use of key strokes, audio cues, areas of difficult navigation). Positive reinforcement and clarifications are provided at the end of each training session.\nRecord game performance (e.g. number, time and location where a participant finds a jewel).\n4. Assess Virtual Navigation Task Performance\nExplain to participant the details of the testing and provide instructions on how to complete the virtual navigation tasks. The participant will complete 10 predetermined navigation tasks presented sequentially using the AbES software (i.e. once the participant successfully completes the first task, the computer will automatically re-locate them to the starting point of the following task).\nInform the participant that they will have a maximum of 6 min to complete each navigation task.\n10 virtual navigation paths of comparable difficulty (i.e. distance traveled and number of turns) are chosen based on predetermined pairings of 10 start and stop locations (i.e. rooms). Specifically, the range of steps needed to navigate the target route ranged between 25-35 steps (in the virtual environment) and incorporated between 3-4 turns of 90 degrees.\nLoad the 10 navigation pairs into AbES for automated presentation and data capture of performance.\nOutcome measures are automatically recorded using AbES' internal software. Outcome measures include: successful completion of the navigation task and time taken to reach target. See Figure 5A.",
    "Instructions describing the start location and the target destination are provided automatically by the AbES software at the start of each task. Timing begins immediately once the subject takes their first virtual step from the starting location and ends once arriving at the target location (unless time takes longer than 6 min, for which the run is scored as incomplete and the next path is presented). Captured data is automatically sent to a text file and opened subsequently in database/statistical software for further analysis. \n5. Assess Physical Navigation Task Performance\nExplain to participant the details of the testing and provide instructions on how to complete the physical navigation tasks. The participant will complete 10 predetermined navigation tasks (presented in scrambled order from the previous virtual performance assessment) and under the supervision of an experienced investigator.\nInform the participant they will have a maximum of 6 min to complete each navigation task. For the purposes of the physical navigation task, the participant is allowed to use their white cane for mobility support.\n10 physical navigation paths are chosen based on predetermined pairings of 10 start and stop locations (i.e. rooms) of comparable difficulty (i.e. distance traveled and number of turns).\nInvestigator prepares stopwatch and clipboard with list of navigation tasks for manual scoring of performance. \nOutcome measures are manually recorded by the investigator. Outcome measures include: successful completion of the navigation task and time taken to reach target.",
    "\"Square-off\" the participant (i.e. position the participant with the door of the starting location behind them). Instructions describing the start location and the target destination are provided by the investigator at the start of each task. Timing begins immediately once the subject takes their first physical step from the starting location and ends when the participant verbally reports arriving at the destination (unless time takes longer than 6 min, for which the run is scored as an incomplete and the next path is presented). Captured data is recorded manually and subsequently transferred to database/statistical software for further analysis. See Figure 5B.\n6. Assess Physical Drop off Task Performance\nExplain to participant the details of the testing and provide instructions on how to complete the physical drop off navigation tasks. The participant will complete 5 navigation tasks with the goals of exiting the building using the shortest route possible and under the supervision of an experienced investigator. \nInform the participant that they will have a maximum of 6 min to complete each navigation task. For the purposes of the physical drop off navigation task, the participant is allowed to use their white cane for mobility support.\n5 predetermined physical starting locations are used such that 3 exit paths of different lengths are possible.\nInvestigator prepares stopwatch and clipboard with list of navigation tasks for manual scoring of performance. \nOutcome measures are manually recorded by the investigator. Outcome measures include: successful completion of the navigation task and time taken to reach target. Furthermore, paths are scored such that the shortest path taken is given maximum points (i.e. 3 for shortest path, 2 for the second, 1 for the longest, and 0 for not being able to complete the task). See Figure 5C.",
    "\"Square-off\" the participant at the first starting location. Instructions describing the start location are provided by the investigator at the start of each task. Timing begins immediately once the subject takes their first physical step from the starting location and ends when the participant verbally reports arriving to an exit door of the building (unless time takes longer than 6 min, for which the run is scored as incomplete and the next start location is presented). Captured data is recorded manually and subsequently transferred to database/statistical software for further analysis.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Medicine"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research"
  ]
}