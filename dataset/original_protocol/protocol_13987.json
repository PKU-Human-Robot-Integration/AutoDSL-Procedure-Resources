{
  "id": 17813,
  "origin_website": "Jove",
  "title": "Combining Augmented Reality and 3D Printing to Display Patient Models on a Smartphone",
  "procedures": [
    "This study was performed in accordance with the principles of the 1964 Declaration of Helsinki as revised in 2013. The anonymized patient data and pictures included in this paper are used after written informed consent was obtained from the participant and/or their legal representative, in which he/she approved the use of this data for dissemination activities including scientific publications.\n1. Workstation Set-up for Segmentation, 3D Models Extraction, Positioning, and AR App Deployment\nNOTE: This protocol has been tested with the specific software version indicated for each tool. It is likely to work with newer versions, although it is not guaranteed.\nUse a computer with Microsoft Windows 10 or Mac OS as operating systems.\nInstall the following tools from the corresponding websites per the official instructions:\n\t3D Slicer (v. 4.10.2): https://download.slicer.org/[href=https://download.slicer.org/].\n\tMeshmixer (v. 3.5): http://www.meshmixer.com/download.html[href=http://www.meshmixer.com/download.html].\n\tUnity (v. 2019): https://unity3d.com/get-unity/download[href=https://unity3d.com/get-unity/download].\n\t(For iOS deployment only) Xcode (last version): https://developer.apple.com/xcode/[href=https://developer.apple.com/xcode/].\nNOTE: All software tools required for completing the protocol can be freely downloaded for personal purposes. Software to be used in each step will be specifically indicated.\nDownload data from the following GitHub repository, found at https://github.com/BIIG-UC3M/OpenARHealth[href=https://github.com/BIIG-UC3M/OpenARHealth].\nNOTE: The repository contains the following folders:\n\t\"/3DSlicerModule/\": 3D slicer module for positioning 3D models with respect to the 3D-printed marker. Used in section 3. Add the module into the 3D slicer following the instructions available at https://github.com/BIIG-UC3M/OpenARHealth[href=https://github.com/BIIG-UC3M/OpenARHealth].\n\t\"/Data/PatientData/Patient000_CT.nrrd\": CT of a patient suffering from distal leg sarcoma. The protocol is described using this image as an example.\n\t\"/Data/Biomodels/\": 3D models of the patient (bone and tumor).\n\t\"/Data/Markers/\": Markers that will be 3D-printed, which will be detected by the AR application to position the virtual 3D models. There are two markers available.\n2. Biomodel Creation",
    "NOTE: The goal of this section is to create 3D models of the patient's anatomy. They will be obtained by applying segmentation methods to a medical image (here, using a CT image). The process consists of three different steps: 1) loading the patient data into 3D slicer software, 2), segmentation of target anatomy volumes, and 3) exportation of segmentation as 3D models in OBJ format. The resulting 3D models will be visualized in the final AR application.\nLoad patient data (\"/Data/PatientData/Patient000_CT.nrrd\") by dragging the medical image file into the 3D slicer software window. Click OK. The CT views (axial, sagittal, coronal) will appear on the corresponding windows.\nNOTE: The data used here is found in \"nearly raw raster data\" (NRRD) format, but 3D Slicer allows for loading of medical image format (DICOM) files. Go to the following link for further instructions, found at https://www.slicer.org/wiki/Documentation/4.10/Training[href=https://www.slicer.org/wiki/Documentation/4.10/Training].\nTo segment the anatomy of the patient, go to the Segment Editor module in 3D slicer.\n\t\nA \"segmentation\" item is created automatically when entering the module. Select the desired volume (a medical image of the patient) in the Master Volume section. Then, right-click below on the Add button to create a segment. A new segment will be created with the name \"Segment_1\".\nThere is a panel called Effects that contains a variety of tools to properly segment the target area of the medical image. Select the most convenient tool for the target and segment onto the image windows area.\n\t\t\nTo segment the bone (tibia and fibula in this case), use the Threshold tool to set up minimum and maximum HU values from the CT image, which corresponds to bone tissue. By using this tool, other elements with HU outside these threshold values are removed, such as soft tissue.",
    "Use the Scissors tool to remove undesired areas, such as the bed or other anatomical structures, from the segmented mask. Segment the sarcoma manually using the Draw and Erase tools, since the tumor is difficult to contour with automatic tools.\nNOTE: To learn more details about the segmentation procedure, go to the link found at https://www.slicer.org/wiki/Documentation/4.10/Training#Segmentation[href=https://www.slicer.org/wiki/Documentation/4.10/Training#Segmentation].\nClick on the Show 3D button to view a 3D representation of the segmentation.\nExport the segmentation in a 3D model file format by going to the Segmentations module in 3D Slicer.\n\t\nGo to Export/import models and labelmaps. Select Export in the operation section and Models in the output type section. Click Export to finish and create the 3D model from the segmented area.\nSelect SAVE (upper left) to save the model. Choose the elements to be saved. Then, change the file format of the 3D Model to \"OBJ\" within the File format column. Select the path where files will be stored and click on Save.\nRepeat steps 2.2 and 2.3 to create additional 3D models of different anatomical regions.\nNOTE: Pre-segmented models of the provided example can be found in the data previously downloaded in step 1.3 (\"/Data/Biomodels/\").\n3. Biomodel Positioning\nNOTE: In this section, the 3D models created in Section 2 will be positioned with respect to the marker for augmented reality visualization. The ARHealth: Model Position module from 3D Slicer will be used for this task. Follow the instructions provided in step 1.3 to add the module to 3D Slicer. There are two different alternatives to position the 3D models: \"Visualization\" mode and \"Registration\" mode.\nVisualization mode",
    "NOTE: Visualization mode allows positioning of the 3D patient models at any position with respect to the AR marker. With this option, the user is able to use the AR app to visualize biomodels using the 3D-printed AR marker as a reference. This mode may be used when precision is not required, and visualization of the virtual model can be displayed anywhere within the field-of-view of the smartphone camera and marker.\n\t\nGo to the ARHealth: Model Position module, and (in the initialization section) select Visualization mode. Click on Load Marker Model to load the marker for this option.\nLoad the 3D models created in section 2 by clicking on the â€¦ button to select the path of the saved models from section 2. Then, click on the Load Model button to load it in 3D Slicer. Models must be loaded one at a time. To delete any models previously loaded, click on that model followed by the Remove Model button, or click Remove All to delete all models loaded at once.\nClick the Finish and Center button to center all models within the marker.\nThe position, orientation, and scaling of the 3D models can be modified with respect to the marker with different slider bars (i.e., translation, rotation, scale).\nNOTE: There is an additional \"Reset Position\" button to reset the original position of the models before making any changes in the position.\nSave the models at this position by choosing the path to store the files and clicking the Save Models button. The 3D models will be saved with the extension name \"_registered.obj\".\nRegistration mode",
    "NOTE: Registration mode allows combining of the AR marker with one 3D biomodel at any desired position. Then, any section of the combined 3D models (that includes the AR marker) can be extracted and 3D-printed. All biomodels will be displayed in the AR app using this combined 3D-printed biomodel as a reference. This mode allows the user to easily register the patient (here, a section of the patient's bone) and virtual models using a reference marker.\n\t\nGo to the ARHealth: Model Position module, and (in the initialization section) select Registration mode. Click on Load Marker Model to load the marker for this option.\nLoad the models as done in step 3.1.2.\nMove the 3D models and ensure their intersection with the supporting structure of the cube marker, since these models will be combined and 3D-printed later. The height of the marker base can be modified. The position, orientation, and scaling of the 3D models can be modified with respect to the marker with different slider bars (i.e., translation, rotation, scale).\nSave the models at this position by choosing the path to store the files and clicking the Save Models button. The 3D models will be saved with the extension name \"_registered.obj\".\nThe anatomy model may be too large. If so, cut the 3D model around the marker adaptor and 3D-print only a section of the combination of both models using Meshmixer software.\nOpen Meshmixer and load the biomodel and supporting structure of the cube marker model saved in step 3.2.4. Combine these models by selecting both models in the Object Browser window. Click on the Combine option in the tool window that has just appeared in the upper left corner.",
    "In Meshmixer, use the Plane Cut tool under the Edit menu to remove unwanted sections of the model that will not be 3D-printed.\nTo save the model to be 3D-printed, go to File > Export and select the desired format.\n4. 3D Printing\nNOTE: The aim of this step is to 3D-print the physical models required for the final AR application. The marker to be detected by the application and the different objects needed depend on the mode selected in section 3. Any material can be used for 3D printing for the purpose of this work, when following the color material requirements requested at each step. Polylactic acid (PLA) or acrylonitrile butadiene styrene (ABS) are both sufficient choices.\nUse a 3D printer to print the cubic marker. If a dual extruder 3D printer is not available, skip to step 4.2. Use a dual extruder 3D printer specifically to print the two-color marker provided in \"Data/Markers/Marker1_TwoColorCubeMarker/\". In the 3D printing software, select a white color material for the file \"TwoColorCubeMarker_WHITE.obj\" and black color material for \"TwoColorCubeMarker_BLACK.obj\".\nNOTE: For better marker detection, print on high-quality mode with a small layer height.\nIf a dual extruder 3D printer is not available and step 4.1 was not performed, follow this step to print a 3D-printed marker with stickers as an alternative by doing the following:\n\t\nUse a 3D printer to print the file \"Data/Markers/ Marker2_StickerCubeMarker/ StickerCubeMarker_WHITE.obj\" with white color material.\nUse a conventional printer to print the file \"Data/Markers/ Marker2_StickerCubeMarker/Stickers.pdf\" on sticker paper. Then, use any cutting tool to precisely cut the images though the black frame by removing the black lines.",
    "NOTE: It is recommended to use sticker paper to obtain a higher quality marker. However, the images can be printed on regular paper, and a common glue stick can be used to paste the images on the cube.\nPlace stickers in the 3D-printed cube obtained in step 4.2.1 in the corresponding order following instructions from the document \"Data/Markers/ Marker2_StickerCubeMarker/Stickers.pdf\".\nNOTE: Stickers are smaller than the face of the cube. Leave a 1.5 mm frame between the sticker and edge of the face. \"Data/Markers/Marker2_StickerCubeMarker/StickerPlacer.stl\" can be 3D-printed to guide the sticker positioning and exactly match the center of the cube face.\n3D-print the adaptors, depending on the mode selected in section 3.\n\t\nIf Visualization mode (section 3.1), was selected, 3D-print \"Data/3DPrinting/Option1/ MarkerBaseTable.obj\", which is a base adaptor used to place the marker in vertical position on a horizontal surface.\nIf Registration mode (section 3.2) was selected, 3D-print the model created in step 3.2.8 with the marker adaptor attached.\nNOTE: 3D printed objects from step 4.3 can be printed in any color material.\n5. AR App Deployment\nNOTE: The goal of this section is to design a smartphone app in Unity engine that includes the 3D models created in the previous sections and deploy this app on a smartphone. A Vuforia Development License Key (free for personal use) is required for this step. The app can be deployed on Android or iOS devices.\nCreate a Vuforia Developer account to obtain a license key to use their libraries in Unity. Go to the link found at https://developer.vuforia.com/vui/auth/register[href=https://developer.vuforia.com/vui/auth/register] and create an account.\n\t\nGo to the link found at https://developer.vuforia.com/vui/develop/Licenses[href=https://developer.vuforia.com/vui/develop/Licenses] and select Get Development Key. Then, follow the instructions to add a free development license key into the user's account.",
    "In the License Manager menu, select the key created in the previous step and copy the provided key, which will be used in step 5.3.3.\nSet up the smartphone.\n\t\nTo get started with Unity and Android devices, go to the link found at https://docs.unity3d.com/Manual/android-GettingStarted.html[href=https://docs.unity3d.com/Manual/android-GettingStarted.html].\nTo get started with Unity and iOS devices, go to the link found at https://docs.unity3d.com/Manual/iphone-GettingStarted.html[href=https://docs.unity3d.com/Manual/iphone-GettingStarted.html].\nSet up a Unity Project for the AR app by first opening Unity v.2019 and creating a new 3D project. Then, under Build Settings in the File menu, switch the platform to either an Android or iOS device.\n\t\nEnable Vuforia into the project by selecting Edit > Project Setting > Player Settings > XR Settings and checking the box labeled Vuforia Augmented Reality Support.\nCreate an \"ARCamera\" under Menubar > GameObject > Vuforia Engine > ARCamera and import Vuforia components when prompted.\nAdd the Vuforia License Key into Vuforia Configuration settings by selecting the Resources folder and clicking on Vuforia Configuration. Then, in the App License Key section, paste the key copied in section 5.1.2.\nImport the Vuforia Target file provided in \"/Data/Vuforia/ AR_Cube_3x3x3.unitypackage\" into Unity, which contains the files that Vuforia requires to detect the markers described in section 4.\nCreate a Vuforia MultiTarget under Menubar > GameObject > Vuforia Engine > Multi Image.\nSelect the marker type that will be used for detection by clicking on the MultiTarget created in the previous step. In the Database option under Multi Target Behaviour, select ARHealth_3DPrintedCube_30x30x30. In the Multi Target option under Multi Target Behaviour, select either TwoColorCubeMarker or StickerCubeMarker, depending on the marker created in section 4.",
    "Load the 3D models created in section 3 into Unity Scene under MultiTarget by creating a new folder with the name \"Models\" under the \"Resources\" folder. Drag the 3D models into this folder. Once loaded in Unity, drag them under the \"MultiTarget\" item created in step 5.3.5. This will make them dependent on the marker.\nNOTE: Models should be visible in the Unity 3D view scene.\nChange the colors of the 3D models by creating a new material and assigning the new materials to the models.\n\t\t\nCreate a new folder named \"Materials\" under the \"Resources\" folder by going to Menubar > Assets > Create > Material. Select the material and change the color in the configuration section. Then, drag the file under the 3D model hierarchy.\nOptional: if there is a webcam available, click on the play button located in the upper-middle portion to test its application on the computer. If the marker is visible to the webcam, it should be detected, and the 3D models should appear in the scene.\nIf an Android smartphone is used for app deployment, go to File > Build Settings in Unity, and select the plugged phone from the list. Select Deploy and Run. Save the file with extension .apk on the computer and allow the process to finish. Once deployment is done, the app should be on the phone and ready to run.\nNOTE: This protocol has been tested on Android v.8.0 Oreo or above. Correct functionality is not guaranteed for older versions.\nIf the app will be deployed in an iOS device, go to File > Build Settings in Unity and select Run. Select the path to save the app files. Allow the process to finish. Go to the saved folder and open the file with the extension \".projectxcode\".",
    "In Xcode, follow the instructions from step 5.2.2 to complete deployment.\nNOTE: For more information about Vuforia in Unity, go to the link found at https://library.vuforia.com/articles/Training/getting-started-with-vuforia-in-unity.html[href=https://library.vuforia.com/articles/Training/getting-started-with-vuforia-in-unity.html].\n6. App Visualization\nOpen the installed app, which will use the smartphone's camera. When running the app, look at the marker with the camera from a short distance away (40 cm minimum). Once the app detects the marker, the 3D models created in previous steps should appear exactly at the location defined during the procedure on the smartphone screen.\nNOTE: Illumination can alter the precision of marker detection. It is recommended to use the app in environments with good lighting conditions."
  ],
  "subjectAreas": [
    "Medicine"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research"
  ]
}