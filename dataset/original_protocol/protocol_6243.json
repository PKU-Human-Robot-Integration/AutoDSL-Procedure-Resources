{
  "id": 6599,
  "origin_website": "Bio",
  "title": "Characterization of Biological Motion Using Motion Sensing Superpixels",
  "procedures": [
    "We describe the general protocol to extract superpixel long-time trajectories and motion measurements as described in our original publication (Zhou et al., 2019). The presented code snippets in this section are also provided in the supplementary Python script file (‘general_analysis_protocol.py’)[href=https://os.bio-protocol.org/attached/file/20190616/Supplementary Script Files.zip] to aid re-implementation. Adaptation of the basic procedure for the analysis of different datasets acquired by different microscope modalities is detailed in the Data Analysis section. The code and protocols should work for both Python 2 and 3 installations. They were originally developed using Python 2.7 under a Linux Mint Cinnamon 17 operating system. We assume throughout basic familiarity with working with command line prompts and terminals such as folder navigation using the cd or dir commands and basic Python usage including the importing of Python modules using import, array indexing using NumPy and plotting using Matplotlib libraries.Protocol Nomenclature“Open a terminal”: refers to the launching of an appropriate terminal window on your operating system (OS) to issue command-line commands. On Windows the terminal is the command prompt or Git bash program. On Windows systems a command prompt can be launched by opening the Start Menu, typing in the search bar cmd and clicking on the command prompt logo, usually the first search result. On MacOS one can execute the shortcut key combination (⌘ + Ctrl T). On Linux systems one can execute the shortcut key combination (Ctrl-Alt T).Commands to be executed in a terminal are distinguished from regular text by use of the true typewriter font Courier New for example python script.py.<input folder>: angular brackets denote text placeholders. The user should replace the placeholder with an appropriate text string (enclosed by speech marks or without spaces) according to the prompt text written in true typewriter font within the brackets.",
    "Usually, this is the path to a particular input/output file or folder.Installing Python and MOSESDownload[href=https://www.anaconda.com/distribution/#download-section] the appropriate Python Anaconda installer for your operating system. Install Python Anaconda following the on-screen instruction prompts of the graphical installer to install for macOS and Windows. For Linux distributions open a terminal, execute bash <path to installer file> and proceed to follow the instructions in the terminal.(Optional) Create a new anaconda environment just for MOSES. Open a terminal and execute conda create --name <myenv> pip. This will create a new virtual environment with the name myenv and pip, a package manager for Python. Check the environment was successfully created by executing conda info --envs. We can now install Python software libraries only to this environment without affecting previous Python installations using conda by executing conda install <package_name> --name <myenv>. To load and use this environment execute conda activate <myenv> or source activate <myenv> in MacOS and Linux or activate myenv in Windows. For more information regarding the management of virtual environments see https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html.[href=https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html] Note: This optional step helps to keep all software dependencies for MOSES isolated from the rest of your Python installations.  Download the MOSES scripts from https://github.com/fyz11/MOSES.[href=https://github.com/fyz11/MOSES] Either:Clone the github repository, git clone https://github.com/fyz11/MOSES.git[href=https://github.com/fyz11/MOSES.git].Click the green ‘Clone or download’ button. Then click ‘Download ZIP’ and extract the .zip contents.Install MOSES. Either:Install to your Python installation to make it available system wide. This can be done by executing python setup.py install in the downloaded Github folder. Installation in this manner enables the scripts to be imported and used no matter the location of your analysis scripts. If you have set up a virtual environment previously for MOSES, load the environment before executing the command.",
    "Copy and paste the entire contents of the ‘MOSES’ folder in the Github repository into your top-level or root project folder such that ‘MOSES’ is co-located in the same subfolder used to store the analysis scripts (Figure 1). Note: Option a) minimizes code replication across projects whilst, option b) offers the greatest ease for prototyping and customizing the MOSES scripts.imgsrc:https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201045_8817.jpgFigure 1. Assumed folder structure if copy and pasting MOSES code for installationInstall MOSES dependencies. MOSES depends on the number of externally managed Python code libraries that needs to be installed. Using option a) (Step B5b) above automates these steps. If using option b) (Step B5b) execute pip install –r requirements.txt in the terminal loading the virtual environment before execution if required. Please note MoviePy, one of the external Python dependencies required for reading and writing general video formats depends on the FFMPEG library (https://ffmpeg.org/[href=https://ffmpeg.org/]). This library should be automatically installed when MoviePy is installed. If this is not the case, please install manually.Note: requirements.txt is a file in the downloaded MOSES Github repository which contains the names of all the required Python dependencies.Structure of the MOSES Library The MOSES library is organized according to Figure 2. Scripts are in general organized by function. For example ‘Motion_Analysis’ contains all scripts related to the analysis of motion such as the computation of motion metrics, ‘Optical_Flow_Tracking’ contains scripts related to the computation of the motion field and the tracking of superpixels to generate superpixel tracks and ‘Utility_Functions’ contains useful scripts for file manipulation such as the reading and writing of videos. Importing of MOSES functions follow standard Python practice. Note: Detailed documentation of each implemented function can also be browsed viewed offline by navigating to and opening the index.html file with any web browser.",
    "Within Python the normal help(<function>)can be used to read the corresponding documentation for a given function.For the remaining sections of the protocol, we assume the exemplar folder structure in Figure 1 placing the analysis script and video data in separate folders. imgsrc:https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201142_7776.jpgFigure 2. Folder and file structure of the MOSES Github code repositoryRunning Python Several ways exist to run Python. We recommend for scientific computing the use of Spyder as an integrated development environment for scientific analysis. If not available under the current environment it can be installed using conda install –c conda-forge spyder --name <myenv>.Launch Spyder using the terminal spyder &. The interface is similar to that of RStudio for R users (Figure 3).Copy and paste code snippets into the editor and save the script. Run the entire script using the keyboard shortcut F5 or by clicking the green ‘play’ button. Run selected lines of code using the keyboard shortcut F9.imgsrc:https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201213_9463.jpgFigure 3. Graphical user interface (GUI) of Spyder for scientific programmingCompute MOSES Superpixel TracksDownload the ‘c_EPC2(G)_CP-A(R)_KSFM+RPMI_5_Fast GFP.tif_R-G.tif’ video file to use as an example red-green fluorescent .tif timelapse video from the following Google Drive link[href=https://drive.google.com/drive/folders/0BwFVL6r9ww5BaTUtaUdYM3YyaEk] and save this to a ‘Videos’ subfolder underneath the ‘Data’ folder as in Figure 1. Read in the video as a numpy array object by importing and using the function read_multiimg_PIL. For multi-channel videos, this gives a 4-dimensional matrix, for single-channel videos this gives a 3-dimensional matrix. Note: More generally one can use the function read_multiimg_stack instead to read in a general bio-format image with additional z-slices.from MOSES.Utility_Functions.file_io import read_multiimg_PIL infile = ’../Data/Videos/c_EPC2(G)_CP-A(R)_KSFM+RPMI_5_Fast_GFP.tif_R-G.tif’ vidstack = read_multiimg_PIL(infile) # Check the read size was expected.n_frame, n_rows, n_cols, n_channels = vidstack.shapeprint(‘Size of video: (%d,%d,%d,%d)’ %(n_frame, n_rows, n_cols, n_channels))Define the optical flow parameter settings used for superpixel tracking.",
    "For more details of the used Farnebäck flow computation to compute pixel velocities refer to the OpenCV documentation[href=https://docs.opencv.org/3.0-beta/modules/video/doc/motion_analysis_and_object_tracking.html] and the original paper (Farnebäck, 2003). The parameters determine the accuracy of the motion field computation (see Notes). Note: Use more levels, e.g., 5, increase the winsize, e.g., 21 and increase iterations e.g., 5 to capture discontinuous movement over larger distances (with respect to input image size as measured in pixels), see also notes section of this protocol. optical_flow_params = dict(pyr_scale=0.5, levels=3, winsize=15, iteratons=3, poly_n=5, poly_sigma=1.2, flags=0)Specify the target number of superpixels or square region of interests (ROI) to subdivide the video frame. For an image size of n × m pixels, a specification of N superpixels would yield individual superpixels with an approximate size of imgsrc:https://en-cdn.bio-protocol.org/attached/image/20190920/20190920004434_1358.jpg pixels. For n=512,m=512,N=1000, each superpixel will be of size ≈16×16 pixels.# number of superpixels n_spixels = 1000For each image channel, extract the superpixel tracks and the computed motion field noting the 0-indexing.from MOSES.Optical_Flow_Tracking.superpixel_track import compute_grayscale_vid_superpixel_tracks# extract superpixel tracks for the 1st or ‘red’ channel optflow_r, meantracks_r = compute_grayscale_vid_superpixel_tracks(vidstack[:,:,:,0], optical_flow_params, n_spixels)# extract superpixel tracks for the 2nd or ‘green’ channel optflow_g, meantracks_g = compute_grayscale_vid_superpixel_tracks(vidstack[:,:,:,1], optical_flow_params, n_spixels)Save the computed tracks in .mat MATLAB format. Alternative formats that support Python array saving can be used such as Python pickle or HDF.import scipy.io as spio import os fname = os.path.split(infile)[-1] savetracksmat = (‘meantracks_’ + fname).replace(‘.tif’, ‘.mat’) spio.savemat(savetracksmat, {‘meantracks_r’:meantracks_r, ‘meantracks_g’: meantracks_g}) (Optional) Visualize the motion field for select frames to check the computation (Figure 4) and optionally save the computed motion field. Note: For large images saving the motion field takes up a lot of hard disk space. It is therefore not recommended to do so. The motion field is summarized by the superpixel tracks. import pylab as plt from MOSES.Visualisation_Tools.",
    "motion_field_visualisation import view_ang_flow# visualize first frame of red and green motion fields fig, ax = plt.subplots(nrows=1, ncols=2) ax[0].imshow(view_ang_flow(optflow_g[0])) ax[1].imshow(view_ang_flow(optflow_r[0])) ax[0].grid(‘off’); ax[1].grid(‘off’) plt.show()# save the flow save_optflow_mat = (‘optflow_’+fname).replace(‘.tif’, ‘.mat’) spio.savemat(save_optflow_mat, {‘optflow_r’: optflow_r, ‘optflow_g’: optflow_g})imgsrc:https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201339_4274.jpgFigure 4. Visualization of the computed first frame motion field using optical flow for red and green channel images. The individual pixel velocities are colored by their angular direction using the color wheel with the color intensity encoding the pixel speed. Scale bars: 200 µm.(Optional) Plot the superpixel tracks as a second sanity check. The shape of the tracks should capture the dynamic range of the moving entities in the video. For epithelial sheets, this is the shape of the leading edge of the sheet (Figure 5).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201403_6225.jpgFigure 5. Plot of the red and green channel superpixel tracks. The green EPC2 tracks end on the right where it met the red CP-A tracks and was pushed back to the left. The red CP-A tracks end on the left at the final position where it has pushed the green EPC2 cells to. (Optional for debugging) Produce a video of the superpixel tracks overlaid on the video, plotting each track in temporal segments of 5 frames to avoid clutter. Frames are generated sequentially. Subsequently, import the saved frames using Fiji ImageJ in temporal order, File → Import →   Image Sequence... and save as a multipage .tif video (File → Save As → Tiff...) or .avi video, (File → Save As → AVI...).from MOSES.Utility_Functions.file_io import mkdirfrom MOSES.Visualisation_Tools.track_plotting import plot_tracksimport os  fname = os.path.split(infile)[-1]# specify the save folder and create this automatically. save_frame_folder = ‘track_video’ mkdir(save_frame_folder) len_segment = 5for frame in range(len_segment, n_frame, 1): frame_img = vidstack[frame] fig = plt.figure() fig.set_size_inches(float(n_cols)/n_rows, 1, forward=False) ax=plt.Axes(fig, [0.,0.,1.,1.]); ax.set_axis_off(); fig.add_axes(ax) ax.imshow(frame_img, alpha=0.6)# visualize only a short segment plot_tracks(meantracks_r[:,frame-len_segment:frame+1],ax, color='r', lw=1) plot_tracks(meantracks_g[:,frame-len_segment:frame+1],ax, color='g', lw=1) ax.",
    "set_xlim([0, n_cols]); ax.set_ylim([n_rows, 0]) ax.grid('off'); ax.axis('off')# tip: use multiples of n_rows to increase image resolution fig.savefig(os.path.join(save_frame_folder, 'tracksimg-%s_' %(str(frame+1).zfill(3))+fname.replace('.tif','.png')), dpi=n_rows)  plt.show()Construct Mesh from Superpixel TracksAny individual moving entity inevitably affects the motion of surrounding entities. Considering superpixels as individual moving elements, it becomes natural to capture the interaction between each superpixel and its neighbors. Computationally this interaction can be captured in a mesh or graph with mesh edges representing the presence of an interaction. This mesh construction critically depends on what one considers evidence of interaction or motion similarity. As such different meshes can be constructed to better highlight different aspects of the cellular motion. We direct the interested reader to the supplementary information of Zhou et al., 2019 for an extended discussion. Below we describe the construction steps for three meshes which connect together superpixel tracks based on different notions of spatial proximity. Construct the MOSES mesh for individual image channels by connecting each superpixel track to all superpixel tracks separated by at most a pixel distance less than a multiple (dist_thresh) of the average superpixel width (spixel_size) based on the initial (x,y) position of superpixels. Note: The MOSES mesh captures how superpixels move with respect to their initial neighbors.from MOSES.Motion_Analysis.mesh_statistics_tools import construct_MOSES_mesh# specify the average superpixel size. This is roughly the width for squaresspixel_size = meantracks_r[1,0,1] - meantracks_r[1,0,0]# compute the MOSES mesh, linking together all superpixels located a distance dist_thresh*spixel_size for each colour channelMOSES_mesh_strain_time_r, MOSES_mesh_neighborlist_r = construct_MOSES_mesh(meantracks_r, dist_thresh=1.2, spixel_size=spixel_size)MOSES_mesh_strain_time_g, MOSES_mesh_neighborlist_g = construct_MOSES_mesh(meantracks_g, dist_thresh=1.2, spixel_size=spixel_size)Construct the radial neighbors mesh for individual image channels by connecting each superpixel track to all superpixel tracks at time t separated by at most a pixel distance less than a multiple (dist_thresh) of the average superpixel width (spixel_size) based on the (x,y) position of the superpixels at time t.",
    "Note: Unlike the MOSES mesh, the connections between neighbors in the radial neighbor mesh dynamically changes over time. from MOSES.Motion_Analysis.mesh_statistics_tools import construct_radial_neighbour_mesh radial_mesh_strain_time_r, radial_neighbourlist_time_r = construct_radial_neighbour_mesh(meantracks_r, dist_thresh=1.2, spixel_size=spixel_size, use_counts=False) radial_mesh_strain_time_g, radial_neighbourlist_time_g = construct_radial_neighbour_mesh(meantracks_g, dist_thresh=1.2, spixel_size=spixel_size, use_counts=False)Construct the K nearest neighbor mesh for individual image channels by connecting each superpixel track to the K superpixel tracks at time t that is spatially closest based on the (x,y) position of the superpixels at time t. Note: This mesh is constructed based on topological distance and is suitable when the physical spatial separation is not a significant factor. from MOSES.Motion_Analysis.mesh_statistics_tools import construct_knn_neighbour_mesh knn_mesh_strain_time_r, knn_neighbourlist_time_r = construct_knn_neighbour_mesh(meantracks_r, k=4) knn_mesh_strain_time_g, knn_neighbourlist_time_g = construct_knn_neighbour_mesh(meantracks_g, k=4)(Optional) Visualize the constructed mesh at select frames (here for example frame 20) to check construction (Figure 6). The example code visualizes the MOSES mesh from Step F1. Any mesh specified either as a networkx graph object or as a list specifying the array index of superpixels connected to each superpixel i can similarly be visualized. from MOSES.Visualisation_Tools.mesh_visualisation import visualize_meshfrom MOSES.Motion_Analysis.mesh_statistics_tools import from_neighbor_list_to_graph# use networkx to visualize the mesh at frame 20. To do so need to first convert the neighborlist into a networkx graph object. mesh_frame20_networkx_G_red = from_neighbor_list_to_graph(meantracks_r, MOSES_mesh_neighborlist_r, 20) mesh_frame20_networkx_G_green = from_neighbor_list_to_graph(meantracks_g, MOSES_mesh_neighborlist_g, 20)# set up a 1 x 2 plotting canvas. fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,15))# plot the red mesh in left panel. ax[0].imshow(vidstack[20], alpha=0.7) visualise_mesh(mesh_frame20_networkx_G_red, meantracks_r[:,20,[1,0]], ax[0], node_size=20, linewidths=1, width=1, node_color=’r’) ax[0].set_ylim([n_rows,0]) ax[0].set_xlim([0,n_cols]) ax[0].grid(’off’); ax[0].axis(’off’)# plot the green mesh in right panel. ax[1].imshow(vidstack[20], alpha=0.7) visualise_mesh(mesh_frame20_networkx_G_green, meantracks_g[:,20,[1,0]], ax[1], node_size=20, linewidths=1, width=1, node_color=’g’) ax[1].set_ylim([n_rows,0]) ax[1].set_xlim([0,n_cols]) ax[1].grid(’off’); ax[1].axis(’off’)Extracting MOSES motion measurementsSeveral motion metrics were proposed in the original paper (Zhou et al., 2019). Here we show how to compute the main proposed metrics using the provided functions in MOSES. Construct the motion saliency map for each color.",
    "The motion saliency map reveals spatial regions of significant motion concentration. It is computed by accumulating the mesh deformation strain in local spatial regions across time. from MOSES.Motion_Analysis.mesh_statistics_tools import compute_motion_saliency_map final_saliency_map_r, spatial_time_saliency_map_r = compute_motion_saliency_map(meantracks_r, dist_thresh=5.*spixel_size, shape=(n_rows, n_cols), filt=1, filt_size=spixel_size) final_saliency_map_g, spatial_time_saliency_map_g = compute_motion_saliency_map(meantracks_g, dist_thresh=5.*spixel_size, shape=(n_rows, n_cols), filt=1, filt_size=spixel_size) Compute the boundary formation index from the motion saliency map. The boundary formation index is defined as the normalized ratio of the mean motion saliency map intensity values, I in high intensity image regions over low intensity image regions (‘red’ and ‘blue’ areas in Figure 7A). The intensity cut-off is automatically determined via Otsu thresholding so that a pixel with image coordinate (i,j) is in the ‘high’ region if I(i,j)≥I_thresh or else is ‘low’. The boundary formation index takes values between 0 and 1. The higher the value, the greater the propensity of motion to be concentrated within a particular spatial region. imgsrc:https://en-cdn.bio-protocol.org/attached/image/20190918/20190918210840_2510.jpgNote: Cells moving out of the field of view of the video cause superpixels to concentrate at the boundary of the videos. This causes an artefactual increase in motion density at image edges. To minimize this effect, the boundary formation index is computed in the region at least a pad_multiple times spixel_size away from the image boundary.from MOSES.Motion_Analysis.mesh_statistics_tools import compute_boundary_formation_index boundary_formation_index, av_saliency_map = compute_boundary_formation_index(final_saliency_map_r, final_saliency_map_g, spixel_size, pad_multiple=3) fig = plt.figure() plt.title('Boundary Formation Index %.3f' %(boundary_formation_index)) plt.imshow(av_saliency_map, cmap='coolwarm') plt.axis('off'); plt.grid('off') plt.show()imgsrc:https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201526_6098.jpgFigure 6. Visualization of the constructed MOSES mesh linking individual superpixels with centroids represented by dotsCompute the MOSES mesh strain curve of the video, the mean of curves of the individual red and green channel curves (Figure 7B). The mesh strain curve measures the mean change in the relative spatial arrangement (topology) between neighboring superpixels over time.from MOSES.Motion_Analysis.",
    "mesh_statistics_tools import compute_MOSES_mesh_strain_curveimport numpy as np# set normalise=True to obtain normalised curves between 0-1.  mesh_strain_r=compute_MOSES_mesh_strain_curve(MOSES_mesh_strain_time_r, normalise=False) mesh_strain_g=compute_MOSES_mesh_strain_curve(MOSES_mesh_strain_time_g, normalise=False)# average the channel curves to get one curve for the video. mesh_strain_curve_video = .5*(mesh_strain_r+mesh_strain_g)# normalise the curves, this is equivalent to normalise=True above for a single channel. normalised_mesh_strain_curve_video = mesh_strain_curve_video/ np.max(mesh_strain_curve_video)Compute the mesh stability index defined as 1 minus the normalized gradient of the mesh strain curve, y over a small time window, ΔT at the end of the video motion (in the interval [T,T+ΔT]). Here the time window is ΔT=5 frames (Figure 7B). imgsrc:https://en-cdn.bio-protocol.org/attached/image/20190918/20190918210921_6077.jpgwhere ymax is the maximum value of the mesh strain curve and T0 is the total number of video frames. The mesh stability index is upper bounded by 1. For the example video, you should get a value of 0.892.from MOSES.Motion_Analysis.mesh_statistics_tools import compute_MOSES_mesh_stability_index# the mesh stability index uses an average over the last number of frame specified by the flag, last_frames. One should set this to approximately cover the plateau region of the strain curve.  mesh_stability_index, normalised_mesh_strain_curve = compute_MOSES_mesh_stability_index(MOSES_mesh_strain_time_r, MOSES_mesh_strain_time_g, last_frames=5)print('mesh stability index: %.3f' %(mesh_stability_index))imgsrc:https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201559_4776.jpgFigure 7. Motion saliency map, boundary formation index and mesh stability metrics. A. Computed motion saliency map and associated boundary formation index. B. Non-normalized MOSES mesh strain curve for red and green cell populations together with the average of the two curves (black line). Shaded blue region shows the 5 frame window used to compute the mesh stability index. Compute the mesh strain vector. The mesh strain vector of each superpixel i is the vector sum of the displacements of neighboring superpixels j relative to the superpixel i in the mesh.imgsrc:https://en-cdn.bio-protocol.org/attached/image/20190918/20190918211001_7397.jpgfrom MOSES.Motion_Analysis.",
    "mesh_statistics_tools import construct_mesh_strain_vector# given a mesh as a list of neighbours (also known as a region adjacency list), find the mesh strain vector mesh_strain_vector_r = construct_mesh_strain_vector(meantracks_r, [MOSES_mesh_neighborlist_r]) mesh_strain_vector_g = construct_mesh_strain_vector(meantracks_g, [MOSES_mesh_neighborlist_r])Compute the mesh order. The mesh order is the mean normalized mesh strain vector over all superpixels i, (Figure 8A). If all mesh strain vectors were aligned in the same direction, this value is 1. If there is no alignment it is 0. For the example video you should get 0.00325 (Figure 8B).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20190918/20190918211343_4092.jpgfrom MOSES.Motion_Analysis.mesh_statistics_tools import compute_mesh_order mesh_order_curve_r = compute_mesh_order(mesh_strain_vector_r, remove_mean=False) mesh_order_curve_g = compute_mesh_order(mesh_strain_vector_g, remove_mean=False) av_mesh_order = .5*(mesh_order_curve_r + mesh_order_curve_g)print('average mesh order: %.5f' %(np.nanmean(av_mesh_order)))imgsrc:https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201632_3329.jpgFigure 8. Visualization of the mesh order and mesh order curve. A. Mesh strain vector (colored arrows) of individual superpixels (mesh vertices) for each colored cell population overlaid on top of the MOSES mesh for frame 20. B. Evolution of the mesh order over time for individual colored populations and the average of the two colored curves (black line). Dashed black line is the mean value of all temporal values reported as the mean mesh order for the video."
  ],
  "subjectAreas": [
    "Cell Biology"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics"
  ]
}