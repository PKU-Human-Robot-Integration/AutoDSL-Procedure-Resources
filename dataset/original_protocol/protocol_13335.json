{
  "id": 17161,
  "origin_website": "Jove",
  "title": "A Swin Transformer-Based Model for Thyroid Nodule Detection in Ultrasound Images",
  "procedures": [
    "This retrospective study was approved by the institutional review board of the West China Hospital, Sichuan University, Sichuan, China, and the requirement to obtain informed consent was waived.\n1. Environment setup\nGraphic processing unit (GPU) software\n\t\nTo implement deep learning applications, first configure the GPU-related environment. Download and install GPU-appropriate software and drivers from the GPU's website.\n\t\t​NOTE: See the Table of Materials for those used in this study.\nPython3.8 installation\n\t\nOpen a terminal on the machine. Type the following:\nCommand line: sudo apt-get install python3.8 python-dev python-virtualenv\nPytorch1.7 installation\n\t\nFollow the steps on the official website to download and install Miniconda.\nCreate a conda environment and activate it.\nCommand line: conda create --name SwinFasterRCNN python=3.8 -y\nCommand line: conda activate SwinFasterRCNN\nInstall Pytorch.\nCommand line: conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 \nMMDetection installation\n\t\nClone from the official Github repository.\nCommand line: git clone https://github.com/open-mmlab/mmdetection.git\nInstall MMDetection.\nCommand line: cd mmdetection\nCommand line: pip install -v -e .\n2. Data preparation\nData collection\n\t\nCollected the ultrasound images (here, 3,000 cases from a Grade-A tertiary hospital). Ensure that each case has diagnostic records, treatment plans, US reports, and the corresponding US images.\nPlace all the US images in a folder named \"images.\"\n\t\tNOTE: The data used in this study included 3,853 US images from 3,000 cases.\nData cleaning\n\t\nManually check the dataset for images of non-thyroid areas, such as lymph images.\nManually check the dataset for images containing color Doppler flow.\nDelete the images selected in the previous two steps.\n\t\tNOTE: After data cleaning, 3,000 images were left from 2,680 cases.\nData annotation\n\t\nHave a senior doctor locate the nodule area in the US image and outline the nodule boundary.\n\t\tNOTE: The annotation software and process can be found in Supplemental File 1.",
    "Have another senior doctor review and revise the annotation results.\nPlace the annotated data in a separate folder called \"Annotations.\"\nData split\n\t\nRun the python script, and set the path of the image in step 2.1.2 and the paths of the annotations in step 2.3.3. Randomly divide all the images and the corresponding labeled files into training and validation sets at a ratio of 8:2. Save the training set data in the \"Train\" folder and the validation set data in the \"Val\" folder.\n\t\tNOTE: Python scripts are provided in Supplemental File 2.\nConverting to the CoCo dataset format\n\tNOTE: To use MMDetection, process the data into a CoCo dataset format, which includes a json file that holds the annotation information and an image folder containing the US images.\n\t\nRun the python script, and input the annotations folder paths (step 2.3.3) to extract the nodule areas outlined by the doctor and convert them into masks. Save all the masks in the \"Masks\" folder.\n\t\tNOTE: The Python scripts are provided in Supplemental File 3.\nRun the python script, and set the path of the masks folder in step 2.5.1 to make the data into a dataset in CoCo format and generate a json file with the US images.\n\t\tNOTE: Python scripts are provided in Supplemental File 4.\n3. Swin Faster RCNN configuration\nDownload the Swin Transformer model file (https://github.com/microsoft/Swin-Transformer/blob/main/models/swin_transformer.py), modify it, and place it in the “mmdetection/mmdet/models/backbones/” folder. Open the “swin_transformer.py” file in a vim text editor, and modify it as the Swin Transformer model file provided in Supplemental File 5.\nCommand line: vim swin_transformer.py\nMake a copy of the Faster R-CNN configuration file, change the backbone to Swin Transformer, and set up the FPN parameters.\nCommand line: cd mmdetection/configs/faster_rcnn\nCommand line: cp faster_rcnn_r50_fpn_1x_coco.py swin_faster_rcnn_swin.py",
    "NOTE: The Swin Faster R-CNN configuration file (swin_faster_rcnn_swin.py) is provided in Supplemental File 6. The Swin Faster R-CNN network structure is shown in Figure 1.\nSet the dataset path to the CoCo format dataset path (step 2.5.2) in the configuration file. Open the \"coco_detection.py\" file in the vim text editor, and modify the following line:\n\tdata_root = \"dataset path(step 2.5.2)\"\nCommand line:vim mmdetection/configs/_base_/datasets/coco_detection.py\n4. Training the Swin Faster R-CNN\nEdit mmdetection/configs/_base_/schedules/schedule_1x.py, and set the default training-related parameters, including the learning rate, optimizer, and epoch. Open the \"schedule_1x.py\" file in the vim text editor, and modify the following lines:\n\toptimizer = dict(type=\"AdamW\", lr=0.001, momentum=0.9, weight_decay=0.0001)\n\trunner = dict(type='EpochBasedRunner', max_epochs=48)\nCommand line:vim mmdetection/configs/_base_/schedules/schedule_1x.py\n\tNOTE: In this protocol for this paper, the learning rate was set to 0.001, AdamW optimizer was used, the maximum training epoch was set to 48, and the batch size was set to 16.\nBegin training by typing the following commands. Wait for the network to begin training for 48 epochs and for the resulting trained weights of the Swin Faster R-CNN network to be generated in the output folder. Save the model weights with the highest accuracy on the validation set.\nCommand line: cd mmdetection\nCommand line: python tools/train.py congfigs/faster_rcnn/swin_faster_rcnn_swin.py --work-dir ./work_dirs\n\tNOTE: The model was trained on an \"NVIDIA GeForce RTX3090 24G\" GPU. The central processing unit used was the \"AMD Epyc 7742 64-core processor × 128\", and the operating system was Ubuntu 18.06. The overall training time was ~2 h.\n5. Performing thyroid nodule detection on new images\nAfter training, select the model with the best performance on the validation set for thyroid nodule detection in the new images.\n\t\nFirst, resize the image to 512 pixels x 512 pixels, and normalize it. These operations are performed automatically when the test script is run.",
    "Command line: python tools/test.py congfigs/faster_rcnn/swin_faster_rcnn_swin.py --out ./output\nWait for the script to automatically load the pretrained model parameters to the Swin Faster R-CNN, and feed the preprocessed image into the Swin Faster R-CNN for inference. Wait for the Swin Faster R-CNN to output the prediction box for each image.\nFinally, allow the script to automatically perform NMS postprocessing on each image to remove duplicate detection boxes.\n\t\tNOTE: The detection results are output to the specified folder, which contains the images with the detection boxes and the bounding box coordinates in a packed file.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Medicine"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research"
  ]
}