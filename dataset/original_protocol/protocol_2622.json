{
  "id": 2768,
  "origin_website": "Cell",
  "title": "An open access, machine learning pipeline for high-throughput quantification of cell morphology",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nBinary segmentation in ilastik\nTiming: 1–2 h\n      This section is the machine learning component of the pipeline. Here, the\n      program must be taught what each class of pixel represents in order to\n      segment the images accordingly. This results in binary images with the\n      cell body distinct from the background (Figure 2[href=https://www.wicell.org#fig2]B).\n      Once training is completed for your dataset, it will likely not need to be\n      repeated. All major steps listed here can theoretically be paused at any\n      point, so long as you keep record of where you left off.\n    \n        Open the previously trained ilastik Pixel Classification file and set\n        the desired export location of the resulting Prediction Maps (binary\n        representations of cell body and background). This is done by choosing\n        Prediction Export > Choose Export Image Settings > Select\n        Directory.\n        \nNote: The data should be converted to\n          unsigned 16-bit, renormalized from 0.00, 1.00 to 0, 65535, the axis\n          order should be transposed to axis order cyx, and the output file\n          format should be tif sequence, though settings may vary depending on\n          microscope type. The File Pattern should be\n          “nickname_result_type_slice_index.tif”. If there is no previously\n          trained ilastik model or its training needs to be altered, see the\n          following sub-steps.\n        \n            For preparing a completely new model, open a new Pixel\n            Classification module and choose brightfield images that are\n            representative of the dataset. Input these into the Input Data\n            section.\n            \nNote: We recommend including at\n              least one representative image for each condition, with each\n              condition equally represented.\n            \n                Select the sigma value features under Feature Selection,7[href=https://www.wicell.org#bib7]\n                which enable the computer to account for different image\n                characteristics, such as color, edge, and texture, when making\n                decisions for classifying cell shapes.\n                \nNote: Start with the lower end\n                  of the sigma values and change as necessary later on. Our most",
    "recent iteration of this pipeline has found the sigma values\n                  of 0.70 for color/intensity, 1.00 for edge, and 1.60 for\n                  texture to be effective. See Troubleshooting\n                  problem 3[href=https://www.wicell.org#sec7.5].\n                \n                Add three classes of labels under Training for the Cell Body,\n                Background, and Boundary of the image.8[href=https://www.wicell.org#bib8]\nNote: The boundary label\n                  refers to the region between the cell body and background,\n                  which is often a region of high lighting variation in\n                  brightfield images. We suggest annotating a minimum of 25% of\n                  a single image with all three labels to start, with further\n                  annotations on additional images added as necessary based on\n                  pipeline performance and to account for experimental group\n                  variability.\n                \n                Set location for exporting results under Prediction Export as\n                outlined above.\n              \n            If previous training needs to be changed, further annotations can be\n            added or removed under Training in any of the three label classes.\n            \nNote: If the results are not\n              satisfactory, review the uncertainty filter (chosen from the list\n              under Training) and make annotations in regions with high\n              uncertainty.\n            \n        Import the experimental data (including any images for your dataset used\n        in training) into Batch Processing under Select Raw Data Files and\n        select Process all files, allowing the program to run.\n      \n        Three versions of each input image will be exported to the location\n        chosen in step 1. Probability Map Zero (Figure 2[href=https://www.wicell.org#fig2]B)\n        is what will be used for the following steps (named\n        title of image_Probabilities_0).\n        \n            Review the quality of cell shape recognition of these probability\n            maps by visually comparing the original input image and the\n            probability map. Discard any images with obvious errors. See\n            Troubleshooting problem 2[href=https://www.wicell.org#sec7.3].\n          \n            Ensure that the cells of interest have been accurately represented\n            during segmentation.\n            \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2279-Fig3.jpg\n                  Figure 3. Common problems encountered during analysis\n                  (highlighted with red arrows)\n                \n                  (A) ilastik probability map with a lighting issue, causing a",
    "region to be improperly identified as part of the cell body.\n                \n                  (B) ilastik probability map with large scratch that would be\n                  misread as cellular projections.\n                \n                  (C) Individual cells from ilastik probability map with cell\n                  shape misrepresented, causing cells to appear thicker than\n                  actual size. Each scalebar is equivalent to 400 μm.\n                \nNote: Common errors include light\n      inconsistencies, obvious cell boundary thickening, and plate dots or\n      scratches (examples in Figure 3[href=https://www.wicell.org#fig3]).\n    \nComposite image creation in ImageJ/Fiji\nTiming: 1 h\n      This section creates the images which will actually be quantified during\n      analysis (Figure 2[href=https://www.wicell.org#fig2]C). These composite images show both\n      the cell body and nucleus, allowing for the nucleus to be used as a seed\n      object by CellProfiler and ensure that every cell identified for\n      measurement has an associated nucleus. This prevents the pipeline from\n      arbitrarily drawing lines in between cells and eliminates the need for\n      typical area to be used in cell identification.\n    \n        Import the DAPI image and probability map of the first field into\n        ImageJ/Fiji. Convert both images into 8-bit format\n        (Image > Type > 8-bit).\n        \n            Threshold the DAPI image (Image > Adjust > Threshold) on the\n            B&W default setting so that all nuclei are in black and the\n            background is in white.\n            \nNote: We recommend doing this by\n              hand using the sliders in the pop-up window that ImageJ launches.\n              Ensure that the dark background box is checked, and that the black\n              background setting for binary functions is turned off\n              (Process > Binary > Options > Black Background). If this\n              setting is turned on, then the image will be inverted (with nuclei\n              colored as white and background as black). The following steps\n              will still function appropriately even if this inverted image form\n              is used. See Troubleshooting problem 4[href=https://www.wicell.org#sec7.7].\n            \n            Use the Watershed function to separate overlapping nuclei\n            (Process > Binary > Watershed).",
    "Overlay the binary nuclei image with the probability map\n        (Image > Color > Merge Channels). Set the DAPI image as the gray\n        channel and the probability map as blue.\n      \n        Convert the resulting image from 8-bit to RGB (Image > Type > RGB\n        Color) to 8-bit (Image > Type > 8-bit), making it black and white.\n        Save this image for analysis.\n      \nNote: The image should have the cell\n      bodies highlighted in gray, nuclei in white, and background in black (Figure 2[href=https://www.wicell.org#fig2]C).\n    \nMorphological measurement in CellProfiler\nTiming: 2 h\n      This section performs the quantification of cell morphology (Figures 2[href=https://www.wicell.org#fig2]D and 2E) and exports the results as a spreadsheet. Many of these steps\n      require visual inspection of the image quality and use of the Test Mode\n      function. Much of the description in the following steps details the\n      settings used within the modules in CellProfiler.\n    \n        Open the CellProfiler program and open the project (File > Open\n        Project).\n        \nNote: Ensure that image type is set to\n          Grayscale image and that the intensity range is from image metadata\n          and that images are not processed as 3D under NamesAndTypes. Under\n          Metadata, ensure that metadata is extracted from file/folder names,\n          with the source being the file name from all images and the data type\n          being text.\n        \n            The modules and settings used in this pipeline are outlined below,\n            though more are available in the software.\n            \n                Smooth: This module blurs small objects in the image (such as\n                cellular debris, which can sometimes be incorrectly recognized\n                as part of the cell body) and fills small holes in the cell\n                body. This module is necessary as it allows the skeletonization\n                modules to function more effectively later on.\n                \nNote: In this module, the\n                  input image is selected as DNA, the smoothing technique is set\n                  to Median Filter, artifact diameter is not calculated",
    "automatically, and the typical artifact diameter is set to 5\n                  pixels, which we found to be effective in producing connected\n                  skeleton branches in later steps.\n                \n                IdentifyPrimaryObjects: This module identifies the nuclei\n                highlighted in white in the composite image, so that they can\n                later be used as seed objects. It is important to note that at\n                this stage the program is only able to “see” the white nuclei\n                due to the threshold settings. The input image is set to the\n                previously smoothed image from step 7ai and the reference range\n                of object diameter for detection is 3–40 pixels for IMR-90\n                cells, though this range may need to be adjusted depending on\n                cell type and microscope used.\n                \nNote: While this pipeline is\n                  set to not discard objects even if they fall outside of the\n                  set range, the range is set broadly as a reference for the\n                  software to detect nuclei and can be narrowed as necessary\n                  (see Troubleshooting problem 4[href=https://www.wicell.org#sec7.7]). Nuclei\n                  are also not discarded if touching the border of the image.\n                  The threshold strategy is Global Otsu three-class thresholding\n                  as used previously,8[href=https://www.wicell.org#bib8] middle intensity\n                  pixels are added to the background, threshold smoothing is set\n                  to zero and correction to 1.0. The lower and upper bounds on\n                  the threshold are 0.8 and 1.0. No log transformation is\n                  performed before thresholding, and Intensity8[href=https://www.wicell.org#bib8]\n                  and Propagate are used to distinguish clumped objects. All\n                  other settings except displaying local maxima are set to Yes.\n                  Holes are filled in identified objects after declumping only,\n                  and, if an excessive number of objects is identified, the\n                  pipeline is set to continue.\n                \n                IdentifySecondaryObjects: This module identifies the cell bodies\n                and associates them with the nuclei identified by the previous\n                module (Figure 2[href=https://www.wicell.org#fig2]D). At this stage, the\n                program primarily identifies the gray cell bodies and black\n                background.",
    "Note: The input image is the\n                  original smoothed image from step 7ai, and the input objects\n                  are the nuclei from step 7aii. The secondary objects are\n                  identified by Propagation, and thresholding is done using\n                  Global Otsu two-class thresholding. Smoothing scale and\n                  correction factor are the same as the previous module, and the\n                  lower and upper bounds on the threshold are 0 and 0.1. There\n                  is no log transformation before thresholding, regularization\n                  factor is set to 0. All other settings are set to Yes.\n                \n                ConvertObjectstoImage: This module converts the cell bodies\n                identified in the previous module to an image so that subsequent\n                modules can process it.\n                \nNote: The input objects are\n                  the cell bodies from step 7aiii, and the color format is set\n                  to Binary.\n                \n                MorphologicalSkeleton: This module skeletonizes the cell bodies,\n                converting them into one-pixel branches (Figure 2[href=https://www.wicell.org#fig2]E). This allows for branching measurements to be taken by\n                subsequent modules. The skeletonization procedure (this and\n                following modules) is adapted from prior work.9[href=https://www.wicell.org#bib9]\nNote: The input image is the\n                  result of step 7aiv.\n                \n                MeasureImageSkeleton: This module measures several branching\n                pseudopodia characteristics for the total image.\n                \nNote: The input image is the\n                  result of step 7av.\n                \n                MeasureObjectSkeleton: This module quantifies branching\n                pseudopodia per cell, including the number of endpoints\n                (conceptualized as the number of pseudopodia) and the total\n                length of all pseudopodia per cell.\n                \nNote: The seed objects are the\n                  nuclei resulting from step 7aiii, and the skeletonized image\n                  is the result of step 7av. The branchpoint image is not\n                  retained, and small holes are filled with a maximum size of 10\n                  pixels. Filling is necessary because, according to the\n                  software developers,4[href=https://www.wicell.org#bib4] the skeletonization\n                  process involves steps that can leave hole artifacts in the\n                  image, causing false branchpoints and trunks. We found a",
    "setting of ten pixels to best resolve this issue for our data\n                  set. Skeleton graph relationships are not exported.\n                \n                MeasureObjectSizeShape: This module performs morphological\n                measurements, including area, perimeter, and FormFactor\n                (circularity).\n                \nNote: The object sets chosen\n                  to measure are the cell bodies and filtered nuclei (as some\n                  were excluded due their cell bodies touching the edges of the\n                  image) from step 7aiii. Additional settings should dictate\n                  that Zernike features are not calculated, but advanced\n                  features are. Advanced features include statistics for object\n                  moments and inertia tensors calculated by CellProfiler for\n                  export in the resulting Excel sheets, and can be used for\n                  additional comparisons of cell characteristics between\n                  groups.4[href=https://www.wicell.org#bib4]\n                ExportToSpreadsheet: This module exports the results to an excel\n                spreadsheet in a location chosen by the user.\n              \n            Drag and drop all files for one experimental group into the images\n            section.\n            \nNote: Add in and analyze only one\n              experimental group at a time, as results will be exported together\n              in a single Excel file.\n            \n        Check the quality of the image analysis.\n        \n            Click the green Start Test Mode button at the bottom of the screen.\n          \n            Step through the modules using the Step button for each image. Move\n            to the next image by clicking the Next Image Set button.\n            \n                The most important module to check is the\n                IdentifySecondaryObjects module. Compare the colorful\n                identification of the cells to the original brightfield image\n                and ensure that the shapes of cells seen in the corresponding\n                brightfield image (Figure 2[href=https://www.wicell.org#fig2]A) are accurately\n                depicted in the identification image (Figure 2[href=https://www.wicell.org#fig2]D). Note which images are of acceptable quality. After ensuring\n                that the results of this module are satisfactory, also check the\n                IdentifyPrimaryObjects and MorphologicalSkeleton modules. Common\n                issues can be found in the\n                troubleshooting[href=https://www.wicell.org#troubleshooting] section.\n              \n        Exit test mode and remove any images found to not be satisfactory for\n        analysis.",
    "Edit the ExporttoSpreadsheet module to reflect the desired save\n        location.\n      \n        Quantify images using the Analyze Images button and then repeat steps\n        7b–10 for any remaining experimental groups.\n      \nNote: It is helpful to keep record of\n      which images are accepted and which are rejected at various stages of the\n      pipeline and why. We found useful to document this using an excel files\n      with columns for each stage."
  ],
  "subjectAreas": [
    "Computer Sciences",
    "Cell Culture",
    "Cell Biology",
    "Microscopy"
  ],
  "bigAreas": [
    "Bioengineering & Technology",
    "Molecular Biology & Genetics"
  ]
}