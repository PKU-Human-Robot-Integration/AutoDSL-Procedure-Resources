{
  "id": 3093,
  "origin_website": "Cell",
  "title": "Non-invasive measurement of circadian clock activity in the turquoise killifish",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\n      Video recording of the swimming behavior of turquoise killifish\n    \nTiming: 5–6 days\n      This step provides detailed procedures for recording raw videos of\n      killifish swimming behavior.\n    \n        Automate the video recording process by using a keyboard and mouse macro\n        program. Set the macro program to record for 20 min with a 40 min break\n        every hour for 5 days.\n      \nNote: Many free keyboard and mouse macro\n      programs are available. We used a Korean version (key_macro.exe, Version\n      2.22b,\n      https://techfo.mouda.net/auto-mouse-program-key-macro-download-and-usage.php[href=https://techfo.mouda.net/auto-mouse-program-key-macro-download-and-usage.php]).\n    \nCritical: This key macro program\n      executes and stops video recording every hour. It recognizes pointer\n      movement on the screen and functions like a mouse. The key macro functions\n      independently from other programs. As it recognizes positions on the\n      screen, the position of OBS should not be altered after the key macro is\n      set up.\n    \nNote: For DD, two infrared light\n      illumination schemes can be used: (1) turn on the IR illuminator\n      continuously throughout the recording period (i.e., 4 days) and (2) turn\n      on the illuminator during video recording (i.e., 20 min covering 15 min of\n      video recording). The second scheme can be accomplished by connecting the\n      illuminator power socket to a timer (Figure 1[href=https://www.wicell.org#fig1]B).\n    \nNote: A night vision camera is useful for\n      recording fish movement in DD. However, a typical webcam (e.g., the C920\n      Pro HD Webcam in this protocol) can be used with the maximum aperture and\n      increased exposure time.\n    \n        Feed fish twice a day following the ordinary feeding scheme with blood\n        worms at 1 h and 8 h after lights are turned on under a 12 h light: 12 h\n        dark cycle. After 20 min, clean tanks to avoid noise from leftover\n        bloodworms.\n      \nCritical: It is important that the\n      recording time does not disrupt the feeding scheme. For example, if",
    "feeding is performed at 10 am and 4 pm daily, videos should be recorded at\n      30–50 min every hour.\n    \n        At the end of the experiment, return to a 12 h light: 12 h dark cycle\n        (i.e., normal culture conditions).\n      \n        After 5 days of video recording, 96 video files are obtained. For\n        example, for four controls and four experimental fish, and 96 video\n        files with 8 fish per one screen are generated (Figure 2[href=https://www.wicell.org#fig2],\n        Methods video S1[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2668-Mmc1.zip]).\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/2668-Fig2.jpg\n              Figure 2. Example of video editing using VSDC Free Video Editor\n            \n              Videos are cut to 15 min and the desired number of videos for\n              analysis can be concatenated to obtain a single video file. Key\n              steps are highlighted as yellow boxes and arrows.\n            \n        Your browser does not support HTML5 video.\n      \n          Methods video S1. Videos acquired under continuous light (LL) and dark\n          (DD) conditions, related to step 4 and expected outcomes (raw video\n          files)\n        \nEditing video images for analysis\nTiming: 1–2 days\n      In this step, concatenated videos are produced for analysis (Figure 2[href=https://www.wicell.org#fig2]).\n    \nNote: The video recording software (OBS)\n      generates a single video file every hour by concatenating arenas from\n      every webcam. To analyze the movement of a single fish, it is necessary to\n      obtain a single fish on a screen and concatenate 96 video files into one.\n    \nExecute VSDC Video Editor.\nCreate a “New project.”\n        Open videos to concatenate by clicking Add\n        object > Video > files∗.avi and OK.\n      \n        Crop a single area from each video file by right-clicking and choosing\n        “Cutting and splitting” (Figure 2[href=https://www.wicell.org#fig2]).\n      \n        Mark the editing point by clicking “Add a marker and Apply” to obtain\n        videos of identical lengths. Then, deselect “Split the file using the\n        set of markers” from “Choose file splitting parameters.”\n      \nCheck the order of videos.",
    "Select all videos at the Source panel, adjust the video length to\n        10–15 min at Object drawing duration and adjust brightness and gamma at\n        Basic correction panel for better distinction between background and\n        fish. An example is shown in Figure 2[href=https://www.wicell.org#fig2]. Apply this\n        setup to all videos.\n      \nNote: Fifteen minutes of recording time is\n      important to avoid capturing unexpected movements caused by feeding or\n      cleaning. A longer duration can reduce the impact of sudden movements but\n      also increases the file size. A period of 15 min effectively captures\n      elevated movements after feeding. Obtaining longer movies with a lower\n      frequency (1 h movie obtained every 3 h) is an alternative strategy;\n      however, this is not sufficient to recognize phase changes.\n    \n        Check the final length of videos by clicking the “set order with offset\n        ”(1) icon and “OK(2) (Figure 2[href=https://www.wicell.org#fig2]).\n      \nNote: It took 5 h and 12 min to\n      concatenate 15 min of videos from 00:00–23:00. The duration can be reduced\n      by improving PC specifications (CPU, Graphic card, or RAM).\n    \nExport the project by assigning a file name and location.\nProcessing video images\nTiming: 1–3 days\n      This procedure describes detailed steps for processing the raw videos. If\n      your video format is different or will be used for another type of\n      behavioral analysis, read the EthoVision manual provided by Noldus\n      Information Technology carefully. If the the EthoVision software is not\n      available, try other tracking software, such as AnimalTracker,3[href=https://www.wicell.org#bib3]\n      Toxtrac,4[href=https://www.wicell.org#bib4] idTracker5[href=https://www.wicell.org#bib5] and Ctrax.6[href=https://www.wicell.org#bib6]\nExecute EthoVision XT and create a New experiment.\n        Set experiments.\n        \n            Set the number of video sources and arenas. We set this to 8 since\n            we included 4 control and 4 experimental fish in this trial (Figures 1[href=https://www.wicell.org#fig1]E and 2[href=https://www.wicell.org#fig2]).\n          \n            Set Tracked Features to Center-point, nose-point, and tail-base\n            detection.\n          \nSet Analysis Options to Active analysis.\n        Arena settings.",
    "Load one of the video files and click the Grab button.\n            Calibrate the scale to fit the width and length of the tank. Yellow\n            arrows are shown with calibration lengths near the line.\n          \n            Select Shape and Draw Area for each individual tank. The arena\n            marked with a number is highlighted in orange.\n          \n        Trial control setting.\n        \nUse default settings.\n        Detection settings.\n        \n            The video is automatically imported; if the video is not\n            automatically imported as expected, it can be imported manually by\n            clicking Select Video.\n          \n            In Advanced settings, set the Method to “Differencing” and “Advanced\n            Model/Adult Fish.” Set “Subject color compared to background” to\n            “Darker.”\n          \n            To define the background, click Background in “Detection reference\n            image.”\n          \n            In the reference image pop-up window, click “Start Learning(C)” and\n            close the window.\n          \n            Check the video in the left panel to determine whether the fish is\n            properly detected and highlighted in yellow. Adjust the fish\n            detection sensitivity by moving the Clip on the gray-scale bar or\n            changing the number and Background changes. We set “Background\n            changes” to “Medium Slow.”\n          \n        Trial list.\n        \nCreate trials to match the number of videos.\n            Choose the arena setting, trial control setting, and detection\n            setting for each trial. Each trial denotes a single concatenated\n            video corresponding to Output of step 13.\n          \nRe-name each arena via “Add variable.”\n        Acquisition.\n        \n            After all set-up is done, select “Track all planned trials” and\n            “Auto-start data analysis” in the Acquisition Settings panel.\n          \nClick “Ready for start.” “Slow.”\n            Then, the analysis is automatically performed. In our case, the\n            analysis took 6–7 h per video.\n          \n        Analysis.\n        \n            In the Data Profiles panel, check the Results per time bin and enter\n            the duration of each video before concatenation; for example, if you\n            concatenate 24 videos of 12 min, set “Results per time bin” into\n            14 min in the “Settings” panel.",
    "Apply to all results and click OK.\n            In the Movement tab, select “Moving” in Calculate nesting for box\n            and press OK.\n          \n            In the Analysis profiles panel, choose the Movement tab, confirm\n            that both Moving and Not moving are selected in Calculate statistics\n            for box, and press Add.\n          \n            In the Results Statistic & Chart panel, press the Calculate icon\n            to analyze data.\n          \nWhen the analysis is done, save data by clicking Export Data."
  ],
  "subjectAreas": [
    "Bioinformatics",
    "Neuroscience",
    "Model Organisms",
    "Behavior"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research",
    "Molecular Biology & Genetics",
    "Ecology & Environmental Biology",
    "Bioinformatics & Computational Biology"
  ]
}