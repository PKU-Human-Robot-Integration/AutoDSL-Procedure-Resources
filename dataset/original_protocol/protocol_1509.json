{
  "id": 1614,
  "origin_website": "Cell",
  "title": "Protocol for hybrid flux balance, statistical, and machine learning analysis of multi-omic data from the cyanobacterium Synechococcus sp. PCC 7002",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nIn this section, a comprehensive step-by-step protocol is laid out for running the flux balance analysis of Synechococcus sp. PCC 7002, followed by principal components analysis, k-means clustering, LASSO regression and finally, correlation analysis. Each of these stages comprises a series of inputs and outputs, as well as intermediary processes that transform each type of data (see Figure 2[href=https://www.wicell.org#fig2]). Critical steps for running the code and troubleshooting are interspersed between these steps and further elaborated in the troubleshooting[href=https://www.wicell.org#troubleshooting] section. All steps described in the code are case-specific, but they can easily be adapted to any transcriptomic dataset or GSMM that the user wishes to analyze.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig2.jpg\nFigure 2. Inputs and outputs for all stages of the analysis in step-by-step method details.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig3.jpg\nFigure 3. A workflow summarizing all stages of analysis in step-by-step method details.\nFlux balance analysis\nTiming: <15 min",
    "Note: During flux balance analysis, a single objective is usually specified for optimization within the field fbamodel.c. Using different solvers to perform the same optimization can cause solutions to vary, owing to differences in numerical implementation and the existence of multiple optimal solutions in the solution space. Calculating a unique solution using quadratic optimization is therefore more reliable when the flux distribution is intended for use in further analyses. To this end, minimizing the sum of squared flux values (L2 norm) carried by the metabolic network following maximization of the primary objective guarantees a unique set of flux solutions drawn from a strictly convex space (Angione, 2019[href=https://www.wicell.org#bib3]). This section lists the major processes and steps for running a regularized flux balance analysis that maximizes pairwise objective functions in a bi-level fashion with a penalty term that considers the norm-2 of the flux vector (Heirendt et al., 2019[href=https://www.wicell.org#bib20]). Bi-level regularized FBA is conducted in MATLAB using the quadratic programming solver Gurobi to compute flux distributions by selecting pairs of reactions in the GSMM to act as flux objectives (i.e. by selecting reactions within fbamodel.f and fbamodel.g, as detailed in Figure 4[href=https://www.wicell.org#fig4]). Subsequently, 24 condition-specific growth profiles of Synechococcus sp. PCC 7002 are generated by integrating omics data relating to different environmental conditions, and three pairs of reactions are optimized for each of these profiles, namely: (i) Biomass - ATP maintenance (ii) Biomass - Photosystem I and (iii) Biomass - Photosystem II.",
    "Note: When calculating the flux distribution across conditions, the biomass reaction was chosen as the primary objective, while the secondary objective was set to ATP maintenance, photosystem I or photosystem II reactions in order to reflect the main cellular goals of cyanobacteria. In our case, the carbon-limited biomass reaction has been chosen as a primary objective to represent the maximization of growth rate and cellular yields (Feist and Palsson, 2010[href=https://www.wicell.org#bib16]; Yuan et al., 2016[href=https://www.wicell.org#bib63]; Lakshmanan et al., 2019[href=https://www.wicell.org#bib28]), which is a critical consideration for cyanobacteria as this informs the substrate uptake rates and maintenance requirements that indicate fundamental cellular growth requirements. The chosen secondary objectives are key pathways involved in energy metabolism during photosynthesis. Simulating the cost of ATP maintenance helps to assess the energy required for sustaining metabolic activity even in the absence of growth. The incorporation of the photoexcitation reactions occurring within photosystems I and II serves to characterize how flux under various conditions reflects the light harvesting and energy transfer via photon absorption through these complexes. Thus, solving the quadratic optimization problem for multiple pairs of objectives helped to resolve trade-offs by considering the conditions and constraints affecting each of these objectives.\nIt has been established that the activity of biosynthetic and energy-generating pathways increases with the growth rate (Bernstein et al., 2014[href=https://www.wicell.org#bib5]), which led us to implement multi-level regularized FBA in our pipeline, considering more than one objective function. This allows us to examine the effect of maximizing biomass using regularized flux balance analysis, followed by the maximization of flux through ATP maintenance and photosynthetic reactions. Performing the FBA in this manner has a relatively low computational cost, taking approximately 0.9–1.69 s per growth condition, and 43.53 s to run the entire script.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig4.jpg",
    "Figure 4. Check that the correct reaction indices for flux objectives fbamodel.f and fbamodel.g are selected in fbamodel.mat (indicated by the position of 1 in each vector).\nNote: As an alternative to regularized FBA, we also provide a critical step detailing how users can employ flux variability analysis (FVA) to obtain minimal and maximal flux ranges for each growth condition. The full details for running the analysis are contained in the script RUN_all.m stored in the GitHub repository listed in the key resources table[href=https://www.wicell.org#key-resources-table]: https://github.com/Angione-Lab/Synechococcus7002-metabolic-modelling[href=https://github.com/Angione-Lab/Synechococcus7002-metabolic-modelling].\nFirstly, we load the required variables within a local directory available to MATLAB:\n% Load the pre-existing variables\n% Genome-scale model of Synechococcus sp. PCC 7002\nload('SynechococcusPCC7002.mat');\n% Array indexing the position of genes within reactions\nload('pos_genes_in_react_expr.mat');\n% Array defining the connection between genes and reactions based on GPR rules\nload('reaction_expression.mat');\n% Array indexing genes (required when replacing genes with their expression values)\nload('ixs_genes_sorted_by_length.mat');\n% List of gene IDs extracted from transcriptomic reads file\nload('Syn7002_IDs.mat');\n% Array of fold changes calculated from transcriptomic reads\nload('transcripts.mat');\nWe then specify variables for the genes within the model and those included in the transcriptomic data:\n% Create a variable to store gene accession IDs from the model\ngenes = fbamodel.genes;\n% Create a variable to store gene accession IDs from the transcriptomic datasets\ngenes_in_dataset = Syn7002_IDs;\n% Specify the number of objectives for FBA\nM = 2;\n% Specify the number of variables for FBA (i.e. genes)\nV = numel(genes);\n% Create indices to set the objective functions for FBA\nix_f = find(fbamodel.f==1); %check current primary objective\nix_g = find(fbamodel.g==1); %check current secondary objective\nThis step assigns indices for selecting the objective function(s) to be optimized during flux balance analysis:\nThis step assigns indices for selecting the objective function(s) to be optimized during flux balance analysis.",
    "% Set new primary objective f as the standard biomass reaction\nix_new_f = 735;\n% Set new secondary objective g as ATP maintenance, photosystem I or photosystem II (manually change the\nsecond objective optimized for FBA in each of the three cases by commenting out the other two objectives\nnot in use)\nix_new_g = find(ismember(fbamodel.rxnNames,'ATP maintenance requirment')==1);\n% ix_new_g = find(ismember(fbamodel.rxnNames,'Photosystem I Reaction (cytochrome c6)')==1);\n% ix_new_g = find(ismember(fbamodel.rxnNames,'photosystem II reaction')==1);\n% Select new objective functions for simulation\nfbamodel.f(ix_f) = 0;\nfbamodel.f(ix_new_f) = 1;\nfbamodel.g(ix_g) = 0;\nfbamodel.g(ix_new_g) = 1;\nCritical: Although a large number of studies express the maximization of biomass as the only objective when performing FBA, it is important to recognize that, in reality, most organisms have multiple objectives to satisfy. Depending on the goal of the flux simulation, any reactions within the metabolic network reflecting a property of interest that must be optimized by the cell can be selected as objective functions via vector indexing. Within each pair of objectives, the primary flux objective fbamodel.f is fixed as the standard biomass reaction (fbamodel.rxnNames = 735) since it reflects the universal property of cellular growth maintenance, whereas the secondary flux objective fbamodel.g is manually switched between the reactions for ATP maintenance (fbamodel.rxnNames = 70), Photosystem I (fbamodel.rxnNames = 698) or Photosystem II (fbamodel.rxnNames = 697) to examine processes relating to energy metabolism and photosynthesis. As an alternative approach, users may also wish to force flux by increasing the lower bounds of reactions to ensure a minimum flux through pathways of interest, although in general this would not allow the user to find solutions that maximize their usage.",
    "Critical: Before applying gene-expression derived constraints during FBA, additional boundary constraints based on the varying metabolic capability of cells under different growth conditions (stored in bounds.mat) are used to modify lower and upper bounds in the model (fbamodel.lb and fbamodel.ub), thus shrinking the solution space and refining phenotypic prediction of metabolic activity. For all experimental conditions, a series of uptake and secretion rates are adjusted in the GSMM prior to performing FBA, taking into account: (i) composition of growth media limitation/supplementation of trace elements, e.g. nitrogen, sulfur, iron, phosphorus, etc. (ii) optical density at which cells were harvested (OD730nm = 0.4/0.7/1.0/3.0/5.0), (iii) mode of energy utilization (phototrophy/heterotrophy/mixotrophy), (iv) availability of oxygen/carbon dioxide (low O2, low CO2, oxic/anoxic), (v) light intensity (dark or high light), (vi) temperature (22°C, 30°C, heat shock), (vii) salinity (low/high). This enables a more unique characterization of each growth condition.\nNote: For example, the bounds adjusted in our model are specified in Table 3[href=https://www.wicell.org#tbl3], where a list of uptake and secretion rates (i.e. lower and upper bounds recorded in fbamodel.lb and fbamodel.ub respectively) for various exchange reactions are fixed at different values according to the growth conditions under which the Synechococcus cells were cultured and harvested (Ludwig and Bryant, 2011[href=https://www.wicell.org#bib32], 2012b[href=https://www.wicell.org#bib34],a[href=https://www.wicell.org#bib33]). Apart from glycerol in the mixotrophic condition, lower bounds for other carbon sources (maltohexaose, maltopentaose, maltotriose, maltotetraose, maltose) and carbonate are set to zero for all conditions. γ represents the photon exchange reaction, whose lower bounds are determined using the calculation specified in Equation 1[href=https://www.wicell.org#fd1].",
    "Note: To specify the variation in light uptake across growth conditions, we calculated a photon uptake rate (PU) for each growth condition using a method similar to Vu et al. (2012)[href=https://www.wicell.org#bib58]. In this calculation, light consumption (LC) under each condition (mmol) is multiplied by the surface area (SA) of the culture exposed to the light source (m2); the product is subsequently divided by the total available dry cell weight (DCW) of the culture (grams per volume) as follows:\n   (Equation 1)    P U  =   L C  × S A   D C W       \nIn this instance, the surface area of the culture exposed to the light source was calculated using the diameter of the cylindrical culture tube and the volume of the culture medium (Ludwig and Bryant, 2011[href=https://www.wicell.org#bib32]), but users are advised to consider the shape and capacity of the vessel used to culture the cells in their own experimental setting when calculating this value.\ntable:files/protocols_protocol_1050_3.csv\nNote: If conducting growth experiments to directly measure light availability and DCW in vivo is not possible, users can refer to the literature to find the closest estimates available for their model species. In our case, we use an approximation for the DCW of marine Synechococci (Myers et al., 2013[href=https://www.wicell.org#bib41]), which was confirmed to be in the same range of values as other Synechococci (Aikawa et al., 2014[href=https://www.wicell.org#bib1]; Qiao et al., 2018[href=https://www.wicell.org#bib47]). Upon obtaining these estimates or measured values, a linear calibration for cultures can be used to calculate the DCW from optical density (Kato et al., 2017[href=https://www.wicell.org#bib25]), or a piecewise linear approximation can be adopted to extrapolate the line, calculate its gradient and obtain the growth rate.\nSpecify this series of boundary constraints to simulate growth media for each condition and record experimentally feasible growth rates:",
    "% Load list of variables including reaction names, indices and new values for lower and upper bounds\nin the model for each condition\nload('bounds.mat');\nIn this step, Gurobi is specified as the solver to be used for FBA:\n%% Solver\n% Set Gurobi as the solver for linear and quadratic problems\nchangeCobraSolver('gurobi','LP');\nchangeCobraSolver('gurobi','QP');\n% Avoid solver feasibility error\nchangeCobraSolverParams('QP', 'method', 1);\nThe new boundary constraints are assigned within fbamodel.lb and fbamodel.ub before running FBA in order to characterize condition-specific flux rates:\n%% Set new bounds for standard control condition\nfbamodel.lb(new_lb_ixs) = new_lb_val(1:15,1);\nfbamodel.ub(new_ub_ixs) = new_ub_val(1:2,1);\nFollowing this, a new vector of gene expression values (x) is mapped onto flux bounds for every condition, starting with an all-ones configuration for the standard control:\n%% Flux distribution in standard control condition\n% Set an all−one configuration for gene expression in the control condition\nx = ones(numel(genes),1);\n% Calculate flux rates for the control condition\n[v1_control, f_out_control] =\nevaluate_objective_minNorm(x,M,V,fbamodel,genes,reaction_expression,\npos_genes_in_react_expr,ixs_genes_sorted_by_length);\nCritical: Users could also use alternative methods for constraining the model using gene expression data. For a critical guide of factors to consider when integrating gene expression or other omic data with GSMMs, see troubleshooting problem two[href=https://www.wicell.org#sec6.3].\nAlternatively, the function for flux balance analysis (evaluate_objective_minNorm) can be replaced by a function for flux variability analysis (evaluate_objective_FVA) to obtain minimal and maximal flux vectors:\n% Calculate flux ranges for the control condition\n[minFlux_control,maxFlux_control] =\nevaluate_objective_FVA(x,M,V,fbamodel,genes,reaction_expression,pos_genes_in_react_expr,\nixs_genes_sorted_by_length);\nCritical: If using FVA instead of FBA, change the field fbamodel.f to fbamodel.c prior to calling evaluate_objective_FVA to ensure compatibility with the fluxVariability.m script, i.e. :\n% Rename fbamodel.f as fbamodel.c if conducting FVA instead of FBA\nif isfield(fbamodel, 'f')\n  fbamodel.c = fbamodel.f;\nend\nAll other conditions specify a loop to replace the RNA-seq expression. The dark oxic condition is provided as an example below:",
    "%% Set new bounds for dark oxic condition\nfbamodel.lb(new_lb_ixs) = new_lb_val(1:15,2);\nfbamodel.ub(new_ub_ixs) = new_ub_val(1:2,2);\n%% Flux distribution in dark oxic condition\n% Choose growth condition by changing column vectors 1−23 in the transcripts dataset\nexpr_profile = transcripts(:,1);\npos_genes_in_dataset = zeros(numel(genes),1);\n% Remove the last two characters (e.g. '.1') since transcripts are indicated with '.1' in the model but these are not present in the dataset\nexpression = '[.]\\d';\nreplace = '';\ngenes_truncated = regexprep(genes,expression,replace);\n% Set gene expression to the set of transcript fold changes in the selected growth condition\nfor i = 1:numel(genes)\n    position = find(strcmp(genes_truncated{i},genes_in_dataset));\n    if ∼isempty(position)\n      pos_genes_in_dataset(i) = position;\n      x(i) = expr_profile(pos_genes_in_dataset(i));\n    end\nend\n% Specify the number of variables\nV = numel(genes);\n% Calculate flux rates for the dark oxic condition\n[v1_do, f_out_do] =evaluate_objective_minNorm(x,M,V,fbamodel,genes,reaction_expression,\n  pos_genes_in_react_expr,ixs_genes_sorted_by_length);\nSimilar to Step 8, the flux ranges for each condition can be calculated by replacing the evaluate_objective_minNorm with evaluate_objective_FVA:\n% Calculate flux ranges for the dark oxic condition\n[minFlux_do,maxFlux_do]=\n  evaluate_objective_FVA(x,M,V,fbamodel,genes,reaction_expression,pos_genes_in_react_expr,\n  ixs_genes_sorted_by_length);\nCritical: In Equation 2[href=https://www.wicell.org#fd2], we use the logarithmic vector-valued function φ to map the expression level of each gene set (represented by the vector θ) to a coefficient for the lower- and upper-limits of the corresponding reaction. Here, γ represents the “strength” of gene expression mapped to each reaction - which can be varied to adjust the level of upregulation or downregulation in cases where the values are too low to influence the flux rates (see troubleshooting problem two[href=https://www.wicell.org#sec6.3]). This ensures higher metabolic sensitivity by enabling fine-tuning of flux rates by gene expression values to yield experimentally feasible fluxes for all growth conditions.\n   (Equation 2)   ϕ  ( θ )  =   [ 1 + γ | log  ( θ )  ]   s g n  ( θ − 1 )",
    "For each condition, the function evaluate_objective_minNorm uses the instruction below to perform regularized flux balance analysis:\n% This command is integrated within evaluate_objective_minNorm and does not need to be run separately\n[solution] = optimizeCbModel(fbamodel,'max',1e−6);\nf_out = solution.f;\nv_out = solution.v;\nIf the function evaluate_objective_FVA is used in the place of evaluate_objective_minNorm, the instruction below gives norm-2 minimal and maximal flux vectors as outputs of flux variability analysis:\n% This command is integrated within evaluate_objective_FVA and does not need to be run separately\n[minFlux, maxFlux] = fluxVariability(fbamodel,[],[],[],0,1,'2-norm');\nThe same process is carried out for all growth conditions in the script until all resulting flux vectors can be concatenated within a single matrix:\n% Concatenate flux vectors for all growth conditions\nall_atp_flux = [v1_do,v1_da,v1_hl,v1_od04,v1_od10,v1_od30,v1_od50,v1_lo2,v1_lco2,v1_nlim,v1_slim,\n  v1_plim,v1_felim,v1_no3,v1_nh3,v1_urea,v1_heat,v1_22c,v1_30c,v1_oxs,v1_mix,v1_ls,v1_hs, v1_control];\n% Convert fluxes into absolute values, change all the values < 10ˆ−4 into 0 to account for\nsolver tolerance and save to a .csv file\nall_atp_flux = abs(all_atp_flux)';\nall_atp_flux(all_atp_flux <= 0.0001) = 0;\nsave('all_atp_flux.mat','all_atp_flux');\nwritematrix(all_atp_flux,'all_atp_flux.csv');\nCritical: In this case study, the threshold for setting flux values to zero was selected as 10-4, however we advise users of the protocol to choose their own cut-offs for flux values/fold changes by conducting a robustness analysis to assess different thresholds (see troubleshooting problem three[href=https://www.wicell.org#sec6.5]).\nCritical: An example of the expected output for running the script RUN_all.m is provided in Figure 5[href=https://www.wicell.org#fig5]. After flux rates have been calculated for all growth conditions, the results can be plotted as a simple bar chart where they are re-scaled as values between 0-1 (see Figure 6[href=https://www.wicell.org#fig6] for sample plotting commands and Figure 7[href=https://www.wicell.org#fig7] for the resulting plot).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig5.jpg\nFigure 5. Example output of FBA when running the RUN_all.m script in MATLAB.\nThe code prints flux values for the primary (biomass) and secondary flux objectives in all 24 growth conditions.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig6.jpg",
    "Figure 6. Plotting FBA results in the MATLAB console\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig7.jpg\nFigure 7. Example of horizontal bar chart plotted to display results of FBA for 4 key reactions.\nFlux rates in units of mmol/gDW h-1 have been re-scaled to values between 0-1 (see Figure 6[href=https://www.wicell.org#fig6] for plotting commands). Growth conditions are listed as follows: 1 - Dark oxic, 2 - Dark anoxic, 3 - High light, 4 - OD 0.4, 5 - OD 1.0, 6 - OD 3.0, 7 - OD 5.0, 8 - Low O2, 9 -Low CO2, 10 - N-limited, 11 - S-limited, 12 - PO43- limited, 13 - Fe-limited, 14 - NO3, 15 - NH3, 16 - CO(NH2)2, 17 - Heat Shock, 18°C - 22°C, 19°C - 30°C, 20 - Oxidative stress, 21 - Mixotrophic, 22 - Low salt, 23 - High salt, 24 - Standard Control. Further details of these experimental conditions are given in Table 2[href=https://www.wicell.org#tbl2]. Part of this figure is reprinted with permission from Vijayakumar et al. (2020)[href=https://www.wicell.org#bib56].\nCritical: If calculating flux ranges, the minimum and maximum flux vectors can be used as two sets of fluxomic features, or users could calculate the mean flux between these two values for use in the next steps of the pipeline.\nFor flux variability analysis, the mean of minimal and maximal flux vectors for different conditions can be calculated as follows:\n% Concatenate minimal and maximal flux vectors for all growth conditions\nall_atp_minFlux =\n  [minFlux_do,minFlux_da,minFlux_hl,minFlux_od04,minFlux_od10,minFlux_od30,minFlux_od50,minFlux_lo2,\n  minFlux_lco2,minFlux_nlim,minFlux_slim,minFlux_plim,minFlux_felim,minFlux_no3,minFlux_nh3,minFlux_urea,\n  minFlux_heat,minFlux_22c,minFlux_30c,minFlux_oxs,minFlux_mix,minFlux_ls,minFlux_hs,minFlux_control];\nall_atp_maxFlux =\n  [maxFlux_do,maxFlux_da,maxFlux_hl,maxFlux_od04,maxFlux_od10,maxFlux_od30,maxFlux_od50,maxFlux_lo2,\n  maxFlux_lco2,maxFlux_nlim,maxFlux_slim,maxFlux_plim,maxFlux_felim,maxFlux_no3,maxFlux_nh3,maxFlux_urea,\n  maxFlux_heat,maxFlux_22c,maxFlux_30c,maxFlux_oxs,maxFlux_mix,maxFlux_ls,maxFlux_hs,maxFlux_control];\n% Calculate mean fluxes between minFlux and maxFlux ranges for each condition\nall_atp_meanFlux = zeros(742,24);\nfor m = 1:24\n  all_atp_meanFlux(:,m) = (all_atp_minFlux(:,m) + all_atp_maxFlux(:,m))./2;\nend\nCreation of multi-omic dataset\nTiming:  < 10 min",
    "In our analyses, gene transcripts constitute a vital component of the flux balance analysis since transcriptomic data are integrated into the GSMM to determine condition-specific flux values. Although partially based on transcriptomics, flux rates are additionally subjected to condition-specific GSMM constraints, the steady-state, and their underlying biochemistry. This automatically creates a component of nonredundant information that does not exist in the transcriptomic dataset. Generating flux data supplies more layers of information to further refine phenotypic predictions. It is thus easier to identify important predictors during machine learning analyses; much of the noise in the gene transcript data is no longer present in the flux data, since gene transcripts with low expression have been ‘filtered out’ as they do not have a large influence on linear constraints in the metabolic model, and consequently they have a smaller effect on the flux rates.",
    "Therefore, if a machine learning model can extract the non-redundant information contained in the flux rates, they can contribute new mechanistic information that is not found in the transcriptomic data. Furthermore, the model itself can act as a tool for ranking and noise reduction since the effect of low importance genes can be 'filtered out' even if their expression is highly variable across conditions. Without the metabolic model, the importance of these genes would be overstated, and they would be used erroneously to differentiate conditions. For example, in our case study, reactions involved in succinate dehydrogenation (SUCD1Itlm/SUCD1Icpm), efflux (SUCCt2b) or exchange (EX_succ_E) were found to be positively correlated with growth for all three objective pairs and were also identified among the highest positive correlations when analyzing the concatenated dataset of gene transcripts and Biomass - ATP maintenance flux data (Vijayakumar et al., 2020[href=https://www.wicell.org#bib56]). These reactions are encoded by A1094 and A2569, which had relatively low gene expression and variability across growth conditions (ranging between 0.33 to 3.74 and 0.14 to 3.66, respectively). Being unrelated to genes already identified as significant during LASSO and correlation analyses of the single omic (transcriptomic) data, these reactions were only detected as a result of transcriptomic data being used to adjust the constraints for calculating flux rates, showing the importance of the metabolic model in characterizing the phenotype across conditions.\nIn practice, combining transcript and flux data in a single multi-omic dataset (by converting them into fold change values) provides a direct point of comparison between the two omics and an opportunity to observe in which instances the flux values are more predictive than transcript values. Generally, transcriptomic and fluxomic data produce different outcomes from the modeling and statistical analyses and combining the two omics yields more stable predictions.",
    "In this section, we define how to concatenate transcript and flux data by obtaining fold changes that enable a comparison of their contribution to gene/reaction variables as a result of the conditions under which the cells were grown and harvested.\nIn MATLAB, create datasets for further analysis by concatenating transcripts and fluxes:\n% Find out the highest flux value in the fold change matrix by setting Inf values to 0 and omitting NaN values\nATP_FC_noinf = (all_atp_flux(1:23,:))./(all_atp_flux(24,:));\nATP_FC_noinf(isinf(ATP_FC_noinf)) = 0;\nmax_ATP_FC = max(ATP_FC_noinf,[],'all','omitnan');\n% Divide flux values in all conditions by the standard control to obtain fold changes\nATP_FC = (all_atp_flux(1:23,:))./(all_atp_flux(24,:));\n% Set all fold changes < 10^−4 equal to 0 to account for solver tolerance\nATP_FC(ATP_FC<=0.0001) = 0;\n% Set all NaN values to 1\nATP_FC(isnan(ATP_FC)) = 1;\n% Set Inf values equal to the highest flux value in the matrix\nATP_FC(isinf(ATP_FC)) = max_ATP_FC;\n% Concatenate transcripts and flux fold changes\nATPTF = horzcat(transcripts,ATP_FC);\n% Add a row of all ones to represent the fold change for the standard control\nATPTF(24,:) = ones;\n% Save as .mat variable and .csv file for later analyses\nsave('ATPTF.mat','ATPTF');\nwritemat(ATPTF,'all_ATPTF.csv');\nPrincipal component analysis (PCA)\nTiming:  < 5 min\nPrincipal component analysis (PCA) can reduce multidimensional datasets to a few latent dimensions known as principal components, allowing the identification of variables responsible for the largest variations within datasets. The reduction of dimensionality within voluminous omic datasets is an important process to achieve successful multi-omic integration and is vital to facilitate their interpretation.",
    "In this analysis, PCA is being used to compare the contribution of each growth condition to the construction of dimensions that summarize the greatest proportion of variance in the dataset. Furthermore, specific genes and reactions contributing to variance between conditions can be pinpointed using Pathway-level PCA, wherein they are classified according to their genetic/metabolic function. The role of these genes and reactions in significant pathways or cellular processes can also be ascertained in a more detailed manner.\nHere, principal component analysis is conducted in R using the FactoMineR and factoextra packages. Full details of the code are provided in the script PCA_script.R, which can be found in the GitHub repository listed in the key resources table[href=https://www.wicell.org#key-resources-table]: https://github.com/Angione-Lab/Synechococcus7002-metabolic-modelling[href=https://github.com/Angione-Lab/Synechococcus7002-metabolic-modelling]. For users wishing to carry out the full analysis on gene transcripts and/or flux rates in the form of .mat variables in MATLAB, the function pca can be used to carry out PCA on raw data, pcares returns the residuals obtained by retaining a given number of principal components and pcacov performs PCA on the square covariance matrix. However, we demonstrate our pipeline using the packages in R for improved analysis and visualization of plots that facilitate the biological interpretation. As seen below, the R packages generate detailed plots, lists of variable contributions, principal component scores and the proportions of variance explained by each dimension.\nThe gene transcripts dataset is used as an example below, but the same steps can be repeated for all datasets (transcripts, all_ATP_flux, all_ATPTF, etc.). For an example plot using individual growth conditions, see Figure 8[href=https://www.wicell.org#fig8]. Other useful outputs resulting from the analysis, such as principal component contributions (Figure 9[href=https://www.wicell.org#fig9]) or coordinates (Figure 10[href=https://www.wicell.org#fig10]) relating to all growth conditions or variables within the dataset can also be saved for further inspection.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig8.jpg",
    "Figure 8. Example of principal component analysis plot of growth conditions colored according to cos2 values.\nThe higher the cos2 value, the greater the proportion of contribution to the total distance, signifying greater importance of the principal components for that condition. Part of this figure is reprinted with permission from Vijayakumar et al. (2020)[href=https://www.wicell.org#bib56].\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig9.jpg\nFigure 9. Obtaining principal component contributions for all variables (gene transcripts) in the dataset.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig10.jpg\nFigure 10. Obtaining coordinates for principal components according to individuals (growth conditions).\nWe begin by navigating to the workspace in R and loading the required packages:\nsetwd(C:/Users/)\nlibrary(devtools)\nlibrary(FactoMineR)\nlibrary(factoextra)\nlibrary(corrplot)\nlibrary(PerformanceAnalytics)\nWe then load transcript/multiomic/flux .csv data files for analysis:\ntranscripts <- read.csv(file = transcriptsnew.csv , head = FALSE,sep =,)\nPerform PCA for each dataset:\nres_transcripts.pca <- PCA(transcripts)\nCreate plots to compare principal components scores for the first two dimensions:\ntranscripts_PCA_plot <- fviz_pca_ind(res_transcripts.pca, col.ind = cos2,\ngradient.cols = c(#00AFBB, #E7B800, #FC4E07),\nrepel = TRUE % Avoid text overlapping\n)\nNote: The number of dimensions to be plotted can be adjusted, usually depending on the proportion of variance explained by each component. For each dataset, conditions are colored according to cos2 values that indicate the contribution of the first two components to the squared distance of each condition to the origin.\nObtain contributions of principal component variables (genes) for each dataset:\ncontributions_transcripts <- res_transcripts.pca$var$contrib\nObtain principal component coordinates for individual growth conditions:\nind_coord_transcripts <- res_transcripts.pca$ind$coord\nPathway-level PCA\nTiming:  < 15 min",
    "In order to carry out a more detailed investigation of specific gene transcripts or metabolic reactions in the model, it is possible to perform a pathway-level PCA that categorizes genes and reactions identified during PCA according to their main biological function. Upon obtaining the results of these analyses, we can plot the sum and average principal component contributions across different pathways as well as principal component coordinates for each growth condition against single reaction fluxes. As in the previous principal component analysis[href=https://www.wicell.org#sec3.3] section, there are existing functions for plotting these data in MATLAB. The barh function can be used to generate bar plots displaying sums of subsystem contributions, the polarplot function can be used to display average contributions by subsystem and the scatter function can be used to plot principal coordinates for individual reactions against their corresponding flux values across different growth conditions. In this protocol, we utilize the plotrix and fmsb libraries in R to customize individual pyramid plots and radar charts, facilitating comparisons between different pairs of flux objectives and multiple pathways.\nThis provides an opportunity to study these components in a more detailed manner through expanding the scope of biological insights detected and establishing connections between genes and reactions within the same functional category or pathway. It is important to account for the varying number of reactions within each pathway, therefore both the sum and average contributions to variance can be used as measures of comparison from principal components. Additionally, principal component coordinates for each growth condition can also be compared against single reactions selected from the top flux contributors to variance (identified for all three objective pairs during Principal Component Analysis[href=https://www.wicell.org#sec3.3] (PCA)). This helps to quantify the strength of association between these reactions and the principal components they are best summarized by.",
    "Within MATLAB, import the table of contributions for the dataset (all_atp_flux is provided as an example):\n% Import data table of flux contributions\ncontrib_ATP = readtable('contrib_all_atp_flux.csv');\n% Concatenate with reaction and subsystem names from the GSMM\ncontrib_ATP_new =\nhorzcat(contrib_ATP(:,{'Var1'}),fbamodel.rxns,fbamodel.rxnNames,fbamodel.subSystems,contrib_ATP(:,{'Dim_1'\n'Dim_2' 'Dim_3' 'Dim_4' 'Dim_5'}));\n% Sort contributions in descending order by Dim1 then Dim 2\ncontrib_ATP_sort = sortrows(contrib_ATP_new,{'Dim_1','Dim_2','Dim_3','Dim_4','Dim_5'},{'descend' 'descend'\n'descend' 'descend' 'descend'});\ncontrib_ATP_Dim1 = sortrows(contrib_ATP_new,{'Dim_1'},{'descend'});\ncontrib_ATP_Dim2 = sortrows(contrib_ATP_new,{'Dim_2'},{'descend'});\n% Save vector containing flux contributions for the first and second dimensions, specifying a dataset of contributions\nDim_1_and_2 = table2array(contrib_ATP_new(:,5:6));\n% Save all contributions to .xls file\nwritetable(contrib_ATP_sort,'contrib_atp_sort.xlsx');\nwritetable(contrib_ATP_Dim1,'contrib_atp_dim1.csv');\nwritetable(contrib_ATP_Dim2,'contrib_atp_dim2.csv');\nNote: While gene transcripts can be classified by their Cluster of Orthologous Genes (COG) category, reactions must be classified according to the pathways they are assigned within fbamodel.subSystems. Since each reaction can be classified by multiple subsystems, separate cell arrays can be allocated to store subsystems from each column of fbamodel.subSystems. The number of arrays needed depends on the maximum number of subsystems that a single reaction is categorized by within the model. In this case, each reaction is assigned to a maximum of five subsystems, therefore a total of five cell arrays are required to store the subsystem names, which are later concatenated into a single array and used to replace the original fbamodel.subSystems in the model.\nCreate cell arrays to store subsystems from fbamodel.subSystems:\n% List all subsystems in the model\nlist_subsystems = unique([new_subsystems{:}])';\n% Create cell arrays to store subsystem names\nfirst_subsystems = cell(numel(list_subsystems),1);\n...\nfifth_subsystems = cell(numel(list_subsystems),1);\nWrite a 'for' loop to obtain the names of subsystems according to the number of subsystems that each reaction is categorized by:\nfor k = 1 : length(fbamodel.subSystems)\n    thisCellContents = fbamodel.subSystems{k};\n% Get the first subsystem for all reactions\n    first_subsystems{k} = thisCellContents{1};\n    if length(thisCellContents) > 1",
    "% Get the second subsystem if present\n    second_subsystems{k} = thisCellContents{2};\n    else\n% If there is only one subsystem for the reaction, assign the second a blank []\n    second_subsystems{k} = [];\n    end\n    ...\n    if length(thisCellContents) > 4\n% Get the fifth subsystem if present\n    fifth_subsystems{k} = thisCellContents{5};\n    else\n% If there are no more than four subsystems for the reaction, assign the fifth a blank []\n    fifth_subsystems{k} = [];\n    end\nend\nCreate another series of cell arrays to store reaction indices; then retrieve the indices that match the number of subsystems (between one and five) for each unique subsystem:\n% Specify the number of unique subsystems\nN = length(list_subsystems);\n% Create empty cell arrays (with length of list_subsystems) to store reaction indices of\neach number of subsystems\nix_first = cell(N,1);\n...\nix_fifth = cell(N,1);\n% Retrieve reaction indices for each group of subsystems (1−5):\nfor s = 1:N\n    ix_first{s} = find(strcmpi(list_subsystems{s},first_subsystems));\n    ...\n    ix_fifth{s} = find(strcmpi(list_subsystems{s},fifth_subsystems));\nend\nMerge all five arrays into a single list of indices for all subsystems:\n% Concatenate all five columns\nix_all = horzcat(ix_first,ix_second,ix_third,ix_fourth,ix_fifth);\n% Create cell array to store reaction indices for all subsystems\nixs_subsystems = cell(length(ix_all),1);\n% Merge columns to compile a total list of indices for each subsystem\nfor a = 1:length(ixs_subsystems)\n  ixs_subsystems{a} = vertcat(ix_all{a,:});\nend\nCreate new variables to store the number of reactions as well as the sums and averages of principal component contributions:\n% Create empty vector to store number of reactions within each pathway\ncardinality_subsystems = zeros(numel(list_subsystems),1);\n% Create empty vectors to store sums of contributions within each pathway for the first and second principal\ncomponents\nsum_contrib_subsystems_PC1 = zeros(numel(list_subsystems),1);\nsum_contrib_subsystems_PC2 = zeros(numel(list_subsystems),1);\n% Create empty vectors to store average contributions within each pathway for the first and\nsecond principal components\navg_contrib_subsystems_PC1 = zeros(numel(list_subsystems),1);\navg_contrib_subsystems_PC2 = zeros(numel(list_subsystems),1);",
    "Calculate the sums and averages of flux contributions according to their respective subsystems using another 'for' loop:\n%% Sort flux contributions according to subsystems\nfor i = 1:numel(list_subsystems)\n% Compute the sums of contributions for the first and second principal components\n      sum_contrib_subsystems_PC1(i) = sum(Dim_1_and_2(ixs_subsystems{i},1));\n      sum_contrib_subsystems_PC2(i) = sum(Dim_1_and_2(ixs_subsystems{i},2));\n% Record the number of reactions within each subsystem\n      cardinality_subsystems(i) = numel(ixs_subsystems{i});\n% Compute the mean contributions by dividing sums by the number of reactions\nin each subsystem\n      avg_contrib_subsystems_PC1(i) = sum_contrib_subsystems_PC1(i)./cardinality_subsystems(i);\n      avg_contrib_subsystems_PC2(i) = sum_contrib_subsystems_PC2(i)./cardinality_subsystems(i);\nend\nCreate a table containing all sums and averages of component contributions:\nsubsystem_names = array2table(list_subsystems,'VariableNames',{'Subsystems'});\nsubsys_sum_avg_ATP = horzcat(sum_contrib_subsystems_PC1,avg_contrib_subsystems_PC1,\nsum_contrib_subsystems_PC2,avg_contrib_subsystems_PC2);\nsubsys_sum_avg_ATP_table = array2table(subsys_sum_avg_ATP,'VariableNames',{'PC1 Sum','PC1 Average',\n'PC2 Sum','PC2 Average'});\nsubsys_sum_avg_ATP_table = horzcat(subsystem_names,subsys_sum_avg_ATP_table);\nwritetable(subsys_sum_avg_ATP_table,'pathway_contrib_ATP.csv');\nNote: Within this loop, sum_contrib_subsystems and avg_contrib_subsystems can be manually adjusted to select each dataset of contributions individually, i.e. Dim_1_&_2 originating from contrib_ATP_new, contrib_p1_new or contrib_p2_new.\nThe sums of contributions to variance within each subsystem can be summarized using a pyramid plot in R (Figure 11[href=https://www.wicell.org#fig11]) to compare results between the first and second principal components:\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig11.jpg\nFigure 11. Sums of first and second principal component contributions across metabolic pathways (model subsystems) for the Biomass - ATP maintenance flux objective pair.\nPart of this figure is reprinted with permission from Vijayakumar et al. (2020)[href=https://www.wicell.org#bib56].\n# Load plotrix library\nlibrary(plotrix)\n# Load all pathway contribution data\npathway_contributions <- read.csv(file = pathway_contrib_ATP. csv, head = TRUE, sep = ,)\n# Load pathway labels in reverse order for plotting\npathways <- rev(pathway_contributions[,c(Subsystems)])\n# Load pathway sums of contributions for Component 1 and Component 2 in reverse order\ncomp1atp.pop <- rev(pathway_contributions[,c(PC1.Sum)])\ncomp2atp.pop <- rev(pathway_contributions[,c(PC2.Sum)])\n#Set ATP color gradient using preset-color-palettes from R-colorspace\nlibrary(colorspace)\ncomp1atpcol <- sequential_hcl(9,Greens)\ncomp2atpcol <- sequential_hcl(9,Oranges)\n# Plot ATP pyramid\npar(mar = pyramid.plot(comp1atp.pop, comp2atp.pop, labels = pathways, main = Biomass – ATP",
    "maintenance Component Sum, top.labels = c(Component 1 Sum, Pathway,Component 2 Sum), unit = ,\nlxcol = comp1atpcol, rxcol = comp2atpcol, gap = 0, xlim = c(25,25), show.values = FALSE))\nLikewise, the average contributions to variance within each subsystem can be summarized using a radar chart in R (Figure 12[href=https://www.wicell.org#fig12]) to compare results between the first and second principal components:\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig12.jpg\nFigure 12. Averages of first and second principal component contributions across metabolic pathways (model subsystems) for the Biomass - ATP maintenance flux objective pair.\nPart of this figure is reprinted with permission from Vijayakumar et al. (2020)[href=https://www.wicell.org#bib56].\n# Load fmsb library\nlibrary(fmsb)\n# Load pathway names\npathways <- pathway_contributions [,c(Subsystems)]\n# Load pathway average contributions for Component 1 and Component 2\nPC1_Average <- pathway_contributions [,c(PC1.Average)]\nPC2_Average <- pathway_contributions [,c(PC2.Average)]\n# Specify the maximum and minimum values for plotting\nmax <- rep (c(0.6), each = 39)\nmin <- rep (c(0), each = 39)\n# Create a dataframe of contribution values\nATP_radar_data <- t(data.frame(max,min,PC1_Average,PC2_Average))\n# Specify labels for each data series\nrownames(ATP_radar_data) = c(max,min,Component_1_Average,Component_2_Average)\ncolnames(ATP_radar_data) = pathways\n# Convert the variable back into a data frame\nATP_radar_data <- data.frame (ATP_radar_data)\n# Define line colors\ncolors_line_ATP <- c(scales :: alpha(green3,0.9),scales :: alpha(orangered,0.9))\n# Create the plot (specifying the number of axis segments, title, line colors,axis labels, etc.)\nradarchart (ATP_radar_data,\nseg = 6,\ntitle = Average Component Contributions (Biomass - ATP maintenance),\npcol = colors_line_ATP ,\nplty = 1:1,\nplwd = 2,\naxistype = 4,\ncaxislabels = c(0,0.1,0.2,0.3,0.4,0.5,0.6),\ncglty = 3,\ncglcol = gray70,\naxislabcol = gray0)\n# Add a legend to indicate which series belongs to which component\nlegend (x = 1.35, y = 1.25, legend = rownames(ATP_radar_data [- c(1,2),]),bty = o,\npch = 20, col = colors_line_ATP, text.col = gray0, cex = 1.2, pt.cex = 3)",
    "Note: Finally, we can also analyze principal component coordinates for each growth condition against single reaction fluxes. An example is demonstrated below using Biomass - ATP maintenance flux data in R (with the expected results plotted in Figure 13[href=https://www.wicell.org#fig13]).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig13.jpg\nFigure 13. Example of principal component plots between principal component coordinates (x) and Biomass - ATP maintenance flux (y) across 24 growth conditions.\nPart of this figure is reprinted with permission from Vijayakumar et al. (2020)[href=https://www.wicell.org#bib56].\nWe begin by loading the requisite variables:\n# Load all principal component coordinates\nind_coord_ATP <- read.csv(file = ind_coord_all_atp_flux.csv, head = TRUE, sep = ,)\n# Load all flux data and contributions sorted by PC1 and PC2\nATPflux <- read.csv(file = all_atp_flux.csv, head = FALSE , sep = ,)\ncontrib_ATP_Dim1 <- read.csv(file = contrib_atp_dim1.csv, head = TRUE, sep = ,)\ncontrib_ATP_Dim2 <- read.csv(file = contrib_atp_dim2.csv, head = TRUE, sep = ,)\nSelect only the columns required\n# Select the first principal component\nPC1_ATP <- ind_coord_ATP[, c(Dim.1)]\n# Check the reaction name and index of the highest contributor to the first principal component\nhead(contrib_ATP_Dim1)\n# Select the flux rate corresponding to the reaction yielding the top\ncontribution in the first principal component\nIODP <- ATPflux[, c(708)]\n# Select the second principal component and the reaction corresponding to the\ntop contribution in the second principal component\nPC2_ATP <- ind_coord_ATP[, c(Dim.2)]\n# Check the reaction name and index of the highest contributor to the second principal component\nhead(contrib_ATP_Dim2)\n# Select the flux rate corresponding to the reaction yielding the top\ncontribution in the second principal component\nILEABC <- ATPflux[, c(301)]\nUse the data to fit linear models and create scatter plots for both principal components:\n# Fit linear models\nrequire (stats)\nfit_ATP1 <- lm(IODP ∼ PC1_ATP)\nfit_ATP2 <- lm(ILEABC ∼ PC2_ATP)\n# Create plots",
    "ATP1_plot <- plot (PC1_ATP, IODP, xlab = PC1, ylab = IODP flux, pch = 19, col = chartreuse4, axes = TRUE)\nATP2_plot <- plot (PC2_ATP, ILEABC, xlab = PC2, ylab = ILEABC flux, pch = 19, col = chartreuse4, axes = TRUE)\n# Calculate the Pearson correlation coefficient\ncorr_PC1 = cor(PC1_ATP, IODP)\ncorr_PC2 = cor(PC2_ATP, ILEABC)\nabline(fit_ATP1)\nabline(fit_ATP2)\nK-means clustering\nTiming:  < 10 min",
    "The purpose of clustering techniques is to partition samples into groups based on hidden patterns in data. They are particularly suitable for detecting underlying associations based on shared characteristics where there is little information available. Most clustering methods are categorized within the hierarchical and k-means families. On one hand, hierarchical clustering is an iterative process that progressively combines pairs of observations that are the closest in proximity until all clusters are merged within a hierarchy. On the other hand, k-means finds the number of clusters that minimizes the sum of squared Euclidean distances between each observation and its respective cluster mean (McLachlan et al., 2008[href=https://www.wicell.org#bib37]). K random points in the dataset (known as cluster centroids) define the groups that the remaining data points are assigned to, which are continually relocated to the averages computed within each group until distinctive clusters are formed. When applied to transcriptomic and fluxomic data in our study, k-means clustering is used as a method to assess whether multi-omic datasets identify clusters of growth conditions according to their respective omic responses and which trends can be observed between growth-promoting and growth-limiting conditions. In this instance, they indicate that the single-omic datasets may benefit from being analyzed in isolation, bypassing an increase in data dimensionality that cannot be easily reduced. k-means clustering is run using the script statistics_on_genes.m, which also calls mdscale_robust.m, a script that applies multidimensional scaling to avoid co-location of data points during clustering. Additionally, the generation of silhouette plots (Figures 14[href=https://www.wicell.org#fig14] and 15[href=https://www.wicell.org#fig15]) is used to decide the number of clusters for the final scatter plot (Figure 16[href=https://www.wicell.org#fig16]).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig14.jpg\nFigure 14. Example of silhouette pre-plot to determine the number of clusters to be used for k-means.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig15.jpg\nFigure 15. Example of silhouette plot for transcript data (k=6).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig16.jpg",
    "Figure 16. Example of k-means scatter plot for transcript data (k=6).\nWe begin by loading the required variables into MATLAB:\n% Load the model and transcriptomic IDs\nload('SynechococcusPCC7002.mat'); %fbamodel\nload('Syn7002_IDs.mat'); % list of gene IDs extracted from transcriptomic reads file\n% Create a variable to store gene accession IDs from the model\ngenes = fbamodel.genes;\n% Create a variable to store gene accession IDs from the transcriptomic datasets\ngenes_in_dataset = Syn7002_IDs;\n% Specify the number of objectives\nM = 2;\n% Specify the number of variables\nV = numel(genes);\nSpecify the dataset on which the clustering will be performed. The gene transcripts dataset is shown as an example, but the same steps can be repeated for all datasets (transcripts, all_ATP_flux, ATPTF, etc.):\n% Choose dataset\nall_objpairs = transcripts';\n% Transpose the same dataset here\nall_solutions = transcripts';\nall_biomass_values = all_solutions(:,1);\nIt is important to use the transposed dataset profiles’ and not the original dataset profiles, otherwise the correlation (and all the following measures) would be computed between profiles along all the genes, instead of the correlation between genes along the profiles:\n% Select the index of interest (all reactions in our case)\nprofiles = all_objpairs;\n% Transpose profiles to compute correlation between genes\ngenes_vs_profiles = profiles';\nThe zscore function is used to standardize each of the profiles to have zero mean and unit variance, after which the pdist function is used to compute pairwise distances between pairs of observations in the dataset:\n% Standardize profiles using zscore values and compute the pairwise distances between them\ndist_correlation_vector = pdist(zscore(genes_vs_profiles), 'correlation');\n% Compute the distance correlation matrix\ndist_correlation_matrix = squareform(dist_correlation_vector);",
    "Note: K-means clustering requires the user to decide the number of clusters (K) that the data is partitioned into. Prior to clustering, different values of K can be tested using silhouette analysis in order to select the most suitable number of clusters for partitioning data.\nIn order to establish the optimal number of clusters, a silhouette analysis can be conducted to measure the cohesion of data points within each cluster (given by a silhouette value for each variable). The initial pre-plot in Figure 14[href=https://www.wicell.org#fig14] displays silhouette values (y) against the number of clusters selected (x), which indicates the best value to select for K (i.e., the number of clusters with the highest silhouette value):\nprompt = 'k−means: Press ''y'' if the number of cluster is known, or any other key to execute silhouette analysis ';\nanswer = input(prompt,'s');\n%\nif strcmp(answer,'y')\n    mean_silhouette = zeros(1,30);\n    for NoClust = 2:30\n        [cidx, ctrs] = kmeans(genes_vs_profiles,NoClust,'dist','correlation','rep',5,\n        'disp','final');\nNote: Upon selecting a value for K, the silhouette function in MATLAB produces a plot (Figure 15[href=https://www.wicell.org#fig15]) that displays values for each individual cluster within the range of [−1,1]. This gives a measure of proximity for each point in one cluster to points in the neighboring clusters.\n% Create a silhouette plot to decide the number of clusters\n        figure;\n        [silh5,h] =\n        silhouette(genes_vs_profiles,cidx,'corr');\n        h = gca;\n        h.Children.EdgeColor =\n        [.8 .8 1];\n        xlabel 'Silhouette\n        Value';\n        ylabel 'Cluster';\n    end\nend\nUpon examination of the silhouette plot, the user is prompted to manually select the number of clusters for the k-means plot:\n% Enter the number of clusters\nprompt = 'k−means: what is the number of clusters chosen after inspection of the mean_silhouette plot?';",
    "Note: The closer the silhouette coefficients are to the value of 1, the further that point is from other clusters and the better the separation of clusters. If the point has a coefficient close to 0, this means that it is very close to the decision boundary between two neighboring clusters. After the silhouette coefficients have been calculated for data points in each cluster, a mean silhouette score can be computed to evaluate the feasibility of the entire cluster.\nNonmetric multi-dimensional scaling can be applied to circumvent errors caused by the co-location of data points by multiplying dissimilarities by a scalar:\n% Specify the number of iterations for the scaling algorithm\noptions = statset('MaxIter',500);\n% Perform multi−dimensional scaling\n[Y,stress] = mdscale_robust(dist_correlation_vector,2,'criterion','sstress','start','random','Options',\n    options);\nNote: mdscale_robust is a variation of the mdscale function where scaling is used to minimize the squared stress criterion with 500 iterations of the algorithm.\nThe kmeans function is used to perform clustering using the following command:\n% Perform k-means clustering\n[cidx, ctrs] = kmeans(genes_vs_profiles,num_clusters, 'dist','cityblock','rep',5,'disp','final');\nNote: In this instance, the ‘dist’ metric for clustering is the city block (also called “Manhattan”) distance. The formula for computing this distance can be specified in general as:\n   d  s t   =     ∑  j = 1  n   |  x  s j   −  x  t j    | p    p   \nwhere p = 1 in the case of the Manhattan distance, but the user is encouraged to choose the metric most suitable for their dataset.\nFinally, a scatter plot can be created to display the k-means clusters:\n% Create the final k-means plot\nfigure\nC = cidx; %color according to k-means clustering\ncolormap(jet(256))\nscatter(Y(:,1),Y(:,2),200,C,'.');\ntitle(['K−Means Clustering (k = 'num2str(numel(unique(cidx)))')']);\nlabels = num2str((1:size(Y,1))','%d');    %'\ntext(Y(:,1),Y(:,2),labels,'horizontal','left','vertical','bottom')\nLASSO regression\nTiming:  < 10 min",
    "The main purpose of the analysis is to identify the core subset of predictors (either genes and/or reactions) with positive or negative nonzero coefficients greater than 0.01 that are strongly related to in vivo growth rates by penalizing the recursive predictors (i.e., setting their coefficients to zero). The script lasso.m performs LASSO regression with α= 1, which returns fitted least-squares coefficients for linear models of transcript, flux or multi-omic data (x) and the growth rates (y) in 12 growth conditions. Following this, the mean predictor coefficient (MPC) can be calculated by averaging across nonzero coefficients in all vectors for each gene/reaction. In this example, only 12 out of 23 growth conditions had (i) specified growth rates, (ii) specified doubling times, or (iii) standard growth curves that could be used to calculate growth rates from the original studies (Ludwig and Bryant, 2011[href=https://www.wicell.org#bib32], 2012a[href=https://www.wicell.org#bib33],b[href=https://www.wicell.org#bib34]), so only the subset of the original datasets corresponding to these growth rates has been selected for analysis. We here describe LASSO regression carried out in MATLAB for the subset of gene transcripts corresponding to these 12 growth conditions, but for the sake of clarity, the generation of multi-omic and fluxomic subsets is also demonstrated.\nIn MATLAB, create new variables which are subsets of data corresponding to the 12 conditions with available growth rates:\n% Load transcripts\nload('transcripts.mat')';\ntranscripts = transcripts';\n% Specify the dimensions of the data\nt_size = size(transcripts);\n% Create transcript data corresponding to 12 growth conditions\ntranscripts_subset = ones(1,t_size(2)); % all ones for standard control\ntranscripts_subset(2:12,:) = transcripts([10:12,14:16,18,19,21:23],:);\n% Load flux data\nload('all_atp_flux.mat');\n% Create flux data corresponding to 12 growth\nconditions\nall_atp_flux_subset = all_atp_flux([24,10:12,14:16,18,19,21:23],:);\n% Load multi-omic data (concatenated transcript and flux data)\nload('ATPTF.mat');\n% Create multi-omic data corresponding to 12 growth conditions\nATPTF_subset = ATPTF([24,10:12,14:16,18,19,21:23],:);",
    "% Load available growth rates corresponding to 12 growth conditions\nY2 = [0.075;0.046153846;0.05;0.035294118;0.173286795;0.266595069;0.266595069;0.038659794;\n0.068807339;0.089285714;0.076530612;0.027777778];\n% Create name IDs for growth conditions\nY2_names = {'Standard Control', 'N−limited', 'S−limited', 'P−limited', 'Nitrate',\n'Ammonia', 'Urea', '22C', '30C', 'Mixotrophic', 'Low salt', 'High salt'};\nPerform LASSO regression with each dataset acting as predictor data (x) and the growth rates as response (y):\n% Perform LASSO regression\n[B_transcripts,fitInfo_transcripts] = lasso(transcripts_subset,Y2);\n% Average across all coefficients by finding mean of each row (predictor)\nB_transcripts_mean = mean(B_transcripts,2);\n% Find indices of absolute nonzero mean predictor coefficients\ntranscripts_abs_mean = abs(mean(B_transcripts,2));\nnonzero_transcripts = find(transcripts_abs_mean > 0.01);\n% Convert data into cell arrays\nB_transcripts = array2table(B_transcripts);\nB_transcripts_mean = array2table(B_transcripts_mean,'VariableNames',{'Mean Predictor Coefficient'});\nCreate a table that combines all data relating to nonzero predictors and their coefficients:\n% Create cell array of gene IDs\ntranscripts_IDs = array2table([1:t_size(2)]','VariableNames',{'ID'});\n% Create table of categorical data from original transcriptomic data\nDataset1 = readtable('Dataset1.xlsx');\nnames_transcripts = (Dataset1(:,{'LocusTag','COGCategory','CyanobaseCategory','CyanobaseSubCategory'}));\n% Concatenate categorical data with B coefficients array and mean predictors\nB_transcripts_table = horzcat(transcripts_IDs,names_transcripts,B_transcripts,B_transcripts_mean);\n% Filter for indices with nonzero predictor coefficients > 0.01\nB_transcripts_nonzero = B_transcripts_table(nonzero_transcripts,:);\n% Sort coefficients in descending order\nB_transcripts_zero = sortrows(B_transcripts_nonzero,{'Mean Predictor Coefficient'},{'descend'});\n% Save table of coefficients as .xlsx file\nwritetable(B_transcripts_nonzero,'B_transcripts_nonzero.xlsx');\nCorrelation analysis\nTiming:  < 10 min",
    "This analysis indicates the strength of association between gene transcripts and/or flux values and growth rates where all flux fold changes are converted into absolute (non-negative) values prior to calculating their correlations in order to equally represent the activity of reversible reactions. Using the same data as in LASSO regression, the script corrcoef_tf_gr.m calculates the Pearson correlation coefficients between subsets of transcript/flux data (x) and growth rates (y) across 12 conditions. The example below demonstrates how a table of correlation coefficients calculated between the transcript data and growth rates is generated in MATLAB (corr_transcript_table), but the corresponding tables can also be created for flux data, i.e., corr_ATP_table, corr_P1_table, corr_P2_table. Example plots of the positive/negative correlation between the transcript data and growth rates are provided in Figure 17[href=https://www.wicell.org#fig17].\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig17.jpg\nFigure 17. Example of PCC scatter plots for transcript data.\nPart of this figure is reprinted with permission from Vijayakumar et al. (2020)[href=https://www.wicell.org#bib56].\nIn MATLAB, create output vectors to store correlation coefficients, p-values, and lower and upper bounds of confidence intervals, changing the number of rows for transcripts (3187), fluxes (742), or both (3929):\n% Create empty vectors to store outputs\ncorr = zeros(3187,1); % PCC\npval = zeros(3187,1); % p−value\nlb95 = zeros(3187,1); % lower bound for 95% confidence\nub95 = zeros(3187,1); % lower bound for 95% confidence\nSpecify the size and type of dataset to be used as x (gene transcripts in this example):\n% Specify the number of scalar observations(N)\nN = size(transcripts,2);\nA ‘for’ loop is used to iteratively calculate Pearson correlation coefficients with their respective p−values and 95% confidence intervals over the whole dataset using the corrcoef function:\n% Calculate correlation coefficients (R) with their respective p−values (P) and lower and upper bounds (RL and RU) according to the 95% confidence interval:\nfor i = 1:N",
    "[R,P,RL,RU] = corrcoef(transcripts_subset(:,i),Y2); %Y2 contains growth rates\n    corr(i) = R(1,2);\n    pval(i) = P(1,2);\n    lb95(i) = RL(1,2);\n    ub95(i) = RU(1,2);\nend\nSave the data in an .xlsx table:\n% Create table of correlation coefficients\ncorr_transcripts = array2table(corr,'VariableNames',{'PCC'});\ncorr_transcripts_table = horzcat(transcripts_IDs,names_transcripts,corr_transcripts);\n% Sort table in descending order of PCC values\ncorr_transcripts_table = sortrows(corr_transcripts_table,{'PCC'},{'descend'});\n% Save table of correlation coefficients\nwritetable(corr_transcripts_table,'corr_transcripts_table.xlsx');\nSelect data corresponding to predictors yielding the highest correlations:\n% Retrieve IDs for transcripts that yield the top 10 positive PCC\ntop_10_positive_IDs = table2array(corr_transcripts_table([1:10],1));\n% Retrieve IDs for transcripts that yield the top 10 negative PCC\ncorr_transcripts_table = sortrows(corr_transcripts_table,{'PCC'},{'ascend'});\ntop_10_negative_IDs = table2array(corr_transcripts_table([1:10],1));\n% Select all data points for transcripts indexed by these top 10 PCC\ntranscripts_positive = transcripts_subset(:,top_10_positive_IDs);\ntranscripts_negative = transcripts_subset_new(:,top_10_negative_IDs);\nPlot these predictors against the growth rates as follows:\n% Create a scatter plot for the transcript with the highest positive PCC\nscatter(transcripts_positive(1:12,1),Y2,'filled','black');\nxlabel('Transcript Value');\nylabel('Growth Rate');\n% Add a trendline\nh = lsline;\nh.Color = 'black';\n% Create a scatter plot for the transcript with the highest negative PCC\nscatter(transcripts_negative(1:12,1),Y2,'filled','black');\nxlabel('Transcript Value');\nylabel('Growth Rate');\n% Add a trendline\nh = lsline;\nh.Color = 'black';\nCritical: Examine correlation plots to check for regression artifacts (see troubleshooting problem four[href=https://www.wicell.org#sec6.7]).\nPathway-level correlation analysis\nTiming:  < 15 min",
    "Similar to the pathway-level PCA[href=https://www.wicell.org#sec3.4], a more detailed functional classification of correlation coefficients can be yielded by performing a pathway-level correlation analysis where mean absolute PCC values are classified according to the subsystems assigned to each reaction in the GSMM (see Figure 18[href=https://www.wicell.org#fig18] for a bar plot of pathway correlations). This provides an opportunity to study these components in a more detailed manner through expanding the scope of biological insights detected and establishing connections between reactions within the same pathway. In order to account for the differing number of reactions in each pathway, the number of reactions within a binned range of PCC values can also be recorded for each subsystem listed in the model (see Figure 19[href=https://www.wicell.org#fig19] for a heatmap of pathway correlations). In this way, correlations between flux rates in each pathway and their growth rates can be assessed more fairly. In this section, we demonstrate a pathway-level analysis in MATLAB using a table of correlation coefficients calculated between Biomass - ATP maintenance flux values and growth rates (where corr_ATP_table has been generated using the same steps as in correlation analysis[href=https://www.wicell.org#sec3.7]).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig18.jpg\nFigure 18. Example of bar chart for pathway-level mean absolute Pearson correlation coefficient (PCC) values calculated between Biomass - ATP maintenance fluxes (x) and growth rates (y).\nPart of this figure is reprinted with permission from Vijayakumar et al. (2020)[href=https://www.wicell.org#bib56].\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1050-Fig19.jpg\nFigure 19. Example of PCC heatmap for pathway-level Pearson correlation coefficient (PCC) values calculated between Biomass - ATP maintenance fluxes (x) and growth rates (y)\nRed text in the bin labels indicates a negative correlation coefficient and blue text indicates a positive correlation coefficient. Part of this figure is reprinted with permission from Vijayakumar et al. (2020)[href=https://www.wicell.org#bib56].\nExtract correlation coefficients for the flux data in MATLAB and convert them into absolute values:",
    "% Load PCC values from tables generated during the correlation analysis\nATP_PCC = table2array(corr_ATP_table(:,3));\nATP_PCC(isnan(ATP_PCC)) = 0;\n% Convert coefficients into absolute values\nATP_PCC_abs = abs(ATP_PCC);\nCritical: Correlation coefficients are converted into absolute values prior to calculating the mean PCC for all pathways since only the magnitude of correlation (and not the direction) is considered when plotting the bar chart in Figure 18[href=https://www.wicell.org#fig18]. However, the heatmap in Figure 19[href=https://www.wicell.org#fig19] indicates the signs of individual correlation coefficients as well as the number of reactions within each pathway.\nCalculate mean PCC values for each subsystem using the same number of reactions recorded within each subsystem (cardinality_subsystems) and reaction indices obtained for each subsystem (ixs_subsystems) as in Pathway-level PCA[href=https://www.wicell.org#sec3.4] (optional):\n% Create an empty vector to store averages of PCC values for subsystems:\nATP_PCC_mean = zeros(numel(ixs_subsystems),1);\n% Calculate mean PCC by subsystem\nfor c = 1:numel(ixs_subsystems)\n    ATP_PCC_mean(c) = mean(ATP_PCC_abs(ixs_subsystems{c},1));\nend\nPlot a bar chart using the mean values:\n% Set subsystem names as x−axis labels\nX_labels = categorical(list_subsystems);\n% Plot the subsystems (x) against mean pathway PCC values (y):\nX = categorical(list_subsystems);\nbar(X,ATP_PCC_mean);\nxlabel('Subsystems');\nylabel('Mean PCC');\nhold on\nset(gca, 'XTickLabelRotation',45);\nNote: Since the mean absolute PCC values disregard the signs of individual correlation coefficients, we can also plot a heatmap recording the number of PCCs within a series of binned ranges for each subsystem. This gives a better indication of the number of reactions within each pathway as well as the direction of correlation.\nCreate variables to store PCC values for all reactions within each subsystem:\nall_corr_ATP = cell(numel(ixs_subsystems),1);\n% Create bins to sort PCC values\nbin_1 = zeros(numel(ixs_subsystems),1);\n...\nbin_7 = zeros(numel(ixs_subsystems),1);\nUse a ‘for’ loop to record the number of correlation values within a given range for each bin:\n% Store correlation values for each subsystem in a cell array",
    "for c = 1:numel(ixs_subsystems)\n    all_corr_ATP{c} = ATP_PCC(ixs_subsystems{c},1);\n% Within this loop, temporarily convert each row of cells into numericals\n    all_corr_ATP_val = cell2mat(all_corr_ATP(c,1));\n% Record the number of coefficients within each bin\n    bin_1(c) = numel(find(all_corr_ATP_val >= −0.7 & all_corr_ATP_val < −0.5));\n    bin_2(c) = numel(find(all_corr_ATP_val >= −0.5 & all_corr_ATP_val < −0.3));\n    bin_3(c) = numel(find(all_corr_ATP_val >= −0.3 & all_corr_ATP_val < −0.1));\n    bin_4(c) = numel(find(all_corr_ATP_val >= −0.1 & all_corr_ATP_val < 0.1));\n    bin_5(c) = numel(find(all_corr_ATP_val >= 0.1 & all_corr_ATP_val < 0.3));\n    bin_6(c) = numel(find(all_corr_ATP_val >= 0.3 & all_corr_ATP_val < 0.5));\n    bin_7(c) = numel(find(all_corr_ATP_val >= 0.5 & all_corr_ATP_val < 0.7));\nend\nPlot the number of reactions in each bin and subsystem using a heatmap:\n% Concatenate bins horizontally into an array\ncdata = horzcat(bin_1,bin_2,bin_3,bin_4,bin_5,bin_6,bin_7);\n% Label the bins (x)\nxvalues = {'[−0.7, −0.5[','[−0.5, −0.3[','[−0.3, −0.1[','[−0.1, 0.1[','[0.1, 0.3[','[0.3, 0.5[','[0.5, 0.7['};\n% Label the subsystems (y)\nyvalues = list_subsystems(:)';\n% Plot the heatmap using a custom colormap (ATPmap):\nh = heatmap(xvalues,yvalues,cdata,'Title','Biomass − ATP maintenance','XLabel','PCC','YLabel',\n'Subsystems','Colormap',ATPmap,'ColorbarVisible','off');\nNote: Similar heatmaps can be plotted for the Biomass - Photosystem I and Biomass - Photosystem II correlation coefficients to evaluate the correlation between metabolic flux and growth rates across various pathways."
  ],
  "subjectAreas": [
    "Bioinformatics",
    "Systems Biology",
    "Computer Sciences",
    "Metabolism",
    "Microbiology"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics",
    "Bioinformatics & Computational Biology"
  ]
}