{
  "id": 10991,
  "origin_website": "Jove",
  "title": "From Voxels to Knowledge: A Practical Guide to the Segmentation of Complex Electron Microscopy 3D-Data",
  "procedures": [
    "1. Manual Abstracted Model Generation\nNote: The details of the methodology described below are specific to Chimera, but other software packages may be used instead. Use this approach when the sole objective is to create a geometrical model (e.g., a ball and stick model) in order to make geometric measurements, rather than displaying the volume shape of the objects.\nImport the data volume into a suitable program for manual abstracted model generation.\n\t\nSelect File > Open Map to pull up the Open File dialog. Navigate to the file location of the desired map.\nPull up the Volume Viewer (Tools > Volume Data > Volume Viewer) and select Features > Display Style to display data with different rendering styles.\nAdjust the threshold for the display by dragging the vertical bar on the histogram in the Volume Viewer window.\nNavigate through the 3D volume (e.g., slice by slice) to select an area of interest for segmentation and crop out a smaller sub-volume if necessary.\n\t\nIn the Volume Viewer dialog, click Axis, then select X, Y, or Z.\nIn the Volume Viewer dialog, select Features > Planes. Click One to set Depth to display the plane corresponding to the number in the left box, and click All to display all planes.\nIn the Volume Viewer dialog, select Features > Subregion selection.\n\t\t\nClick and drag to create a rectangular box around the region of interest.\nPlace markers along the feature of interest and connect them with linkers where appropriate (often done automatically by the program) until the model is complete.\n\t\nFrom the Volume Viewer menu bar, select Tools > Volume Tracer dialog to open the Volume Tracer dialog. In the Volume Tracer dialog, select File > New Marker Set.",
    "In the Volume Tracer dialog, check Mouse > Place markers on high quality, Place markers on data planes, Move and resize markers, Link new marker to selected marker, and Link consecutively selected markers.\nClick on the Marker Color swatch, and select a color. Repeat this step for Link color.\nEnter radii for the marker and link model-building elements.\nIn the Volume Tracer Window, select Place markers using [right] mouse button, and insert radii for markers and links.\nRight click on the volume data to begin laying down markers. Markers will be connected automatically.\nIn the Volume Tracer dialog, select File > Save current marker set, then File > Close marker set.\nOpen a new marker set (Step 1.3.1) to begin building a model into a second desired feature of interest. Utilize contrasting colors between marker sets to emphasize differences in features.\n2. Manual Tracing of Features of Interest\nNote: The details of the methodology described below are specific to Amira, but other software packages may be used instead. Use this approach when the population density is relatively small and when accuracy of feature extraction is paramount, as manual tracing is a time-consuming approach.\nImport volume data into a program with manual tracing options. Software with this capability generally offer at least a basic paintbrush tool.\n\t\nFor large volumes or tomograms (e.g., 16-bit 2,048 x 2,048 or larger .rec or .mrc tomograms generated in IMOD): Select Open Data > Right click on filename.rec > Format… >Select Raw as LargeDiskData > Ok > Load. Select appropriate Raw Data Parameters from header information > Ok. Toggle and Save As a new filename.am[href=http://filename.am/] file for use in the following steps.",
    "For smaller 3D image stack files (e.g., 3D .tif or .mrc or .rec): Open Data > Select filename.tif or filename.mrc. Toggle and Right Click > Save As filename.am[href=http://filename.am/]. If an error is generated or the program is unresponsive, the file may be too large and can be opened by following Step 2.1.1.\nNavigate through the slices to select a 3D sub-volume for segmentation, and then crop to this area of interest.\n\t\nIn 3D Viewer window, select Orthoslice to open image file. Use slider at bottom to navigate through slices.\nTo crop larger data opened as LargeDiskData, toggle file name in Pool window > Right click > LatticeAccess. Enter desired box size > Apply. Save new file.\nCreate segmentation file.\n\t\nToggle the file in the Pool window > Right Click > Labeling > LabelField. A new file will be created and automatically loaded in the Segmentation Editor tab.\nTrace the border of the first feature of interest, then fill the trace by hand or by using a command specific to the software used. Follow the feature of interest through all slices and repeat the manual tracing segmentation. Use the following commands when using Amira:\n\t\nTo use the Paintbrush tool, alter brush size as desired, then use the mouse pointer to trace the border of the feature of interest.\nFill the traced area with shortcut “f”. Add the selection by clicking the button with the plus symbol, or the shortcut “a”. If necessary, press “u” to undo, and “s” to subtract or erase.\nGenerate a surface rendering for visualization and basic qualitative or quantitative analysis per software user guide instruction.\n\t\nIn the Object Pool tab, toggle the filename-labels.am in the Pool window > Right click > SurfaceGen.",
    "Select desired Surface properties > Apply. A new file filename.surf will be created in the Pool.\nTo visualize the segmented volume, toggle filename.surf in Pool window > Right click > SurfaceView.\nUse the tools in the 3DViewer window to move, rotate, and zoom in the 3D volume.\nExtract the exact densities and determine measurements such as volume or surface area. Export to other programs for more advanced display, analysis and simulation.\n\t\nOn 3DViewer window, click Measure tool > Select appropriate option (2D length and 2D angle for measurements on a single 2D plane, 3D length and 3D Angle for measurements on a 3D volume).\nClick on mesh surface to measure desired length, distance, and angles. The values will be listed in the Properties window.\n3. Automated Density-based Segmentation\nNote: The details of the methodology described below are specific to Amira, but other software packages may be used instead.\nUse this approach on data sets with any variety of contrast, crispness, or crowdedness to withdraw the densities of interest.\nImport volume data into a program equipped with thresholding, magic wand, or other density-based tools for automatic segmentation. Follow steps outlined in 2.1-2.1.2 in the directions for manual tracing.\nNavigate through slices and select area for segmentation. If necessary, crop out a smaller 3D sub-volume for segmentation. Follow steps outlined in 2.2-2.2.2 in the directions for manual tracing.\nSelect the density of a feature of interest, usually by clicking or placing a mark or anchor point on the feature. If allowed in the software, enter a number range encompassing the feature’s pixel intensity and adjust this tolerance as desired. Densities belonging to the feature will be picked up in accordance to the intensity of the anchor’s pixel or tolerance value. Use the following commands when using Amira.",
    "Use the Magic Wand Tool for features with distinguishable margins.\n\t\t\nClick on the area of interest, then adjust sliders in Display and Masking to capture correct range of values so that the feature is fully highlighted. Add selection with shortcut “a”.\nUse the Threshold Tool for features without clearly distinguishable margins.\nSelect the Threshold icon. Adjust slider to adjust density within desirable range so that only the features of interest are masked. Click Select button, then add selection with shortcut “a”.\nTo segment entire volume, select All slices before adding selection.\nTo remove noise, select Segmentation > Remove Islands and/or Segmentation > Smooth labels.\nGenerate a surface for visualization and qualitative analysis as described in the manual tracing section 2.6-2.6.2. If desired, export to other programs for adequate 3D display, quantitative analysis and simulations.\n4. Custom-tailored Automated Segmentation\nNote: Use this approach to create customized scripts for automatic segmentation, which requires background experience in computer science, but allows the ability to create a precise density model from a large volume.\nTools (Specific Example of Shape-Supervised Segmentation in MATLAB27)\n\t\nImage pre-processing: Perform de-noising, background removal and image enhancement by using the following pipeline:\n\t\t\nLoad the image using the imread command.\n\t\t\t\nIn the command line, enter: >> im = imread($image_path), where $image_path is the location of the image to be analyzed.\nFrom the Image Processing toolbox, call Wiener Filter using an estimated or known Noise-power-to-signal ratio (NSR).\nOn the previously processed image, call the image opening function imopen to estimate the background layer, then allocate the outcome as a different mask.\n\t\t\t\nIn the command line, enter: >> background = imopen(im,strel($shape_string,$size)), in this method, $shape_string is equal to ‘disk’ the variable $size is given by the analyzer. i.e. >> background = imopen(im,strel(‘disk’,15)).\nSubtract the filtered image with the background.",
    "In the command line, enter: >> im2 = im - background\nDepending on the quality of the results, perform image normalization with or without adaptive Otsu’s method28, which can be called using the function imadjust from the Image Processing Toolbox.\n\t\t\t\nIn the command line, enter: >> im3 = imadjust(im2)\nPrepare the features of interest for segmentation, limiting the regions of interest by cropping the normalized image.\n\t\t\t\nUsing the imtool command, explore the region of interest that is to be cropped and provide the coordinates to the command: >> im3_crop = imcrop(im3, [x1 y1 x2 y2]), where the vector [x1 y1 x2 y2] corresponds to the square region to be cropped.\nShape recognition/Supervised shape classification: Train the algorithm by providing specific examples for each different category of objects (linear traces in a 2D image across the features of interest).\n\t\t\nCheck that VLFEAT29 API is successfully installed and visit VLFEAT’s website for more in-depth documentation.\nIn the command line, enter: >> [TREE,ASGN] = VL_HIKMEANS(im3_crop,$K,$NLEAVES) where $K is the number of cluster to be used or the number of classes the observer wants to arrange the data into, and $NLEAVES is the desired number of leaf clusters i.e. >> [TREE,ASGN] = VL_HIKMEANS(im3_crop,4,100)\nUse manually segmented features as the input for VLFeat.\n\t\t\tNOTE: This open source C-based library will perform pixel patching, patch clustering, and cluster center positioning depending on the type of method chosen to work best for the datasets. The available options range from k-mean clustering to texton-based approaches30, and the output is a numerical array that describes the features desired based on the given exemplars.\nSegmentation: Use this fully automated, although computationally expensive, approach to segment multiple classes of objects simultaneously, which will be written out as separate maps for further visualization and analysis.\n\t\nLoad the previously generated numeral array (model).",
    "Call the support vector machine (SVM) function in VLFeat, using the model and the image to be segmented as an input.\n\t\t\nIn the command line, enter: >> [w, b] = vl_svmtrain(x, y, 0.1), where x is the original cropped image im2_crop and y is the objective image, the image that has been manually segmented. Use >> ISEG = VL_IMSEG(I,LABELS) to color the results according to the labels generated by the clustering.\n\t\t\tNOTE: Based on the characteristics of the model, VLFeat will classify the image on the number of classes (features of interest) assigned from the beginning. Depending on the grade of accuracy desired, it is possible to combine this method with other approaches or estimate cluster parameters such as hull and cluster centers. The output of the SVM algorithm is a probabilistic model and multiple binary masks of the desired classes in the new datasets.\nSave results by entering the command: >> imwrite(im, $format, $filename) where $format is 'tiff' and $filename is the path for the output file.\nFor visualizing images, enter the command: >> imshow(im)."
  ],
  "subjectAreas": [
    "Bioengineering"
  ],
  "bigAreas": [
    "Bioengineering & Technology"
  ]
}