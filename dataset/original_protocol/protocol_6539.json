{
  "id": 6898,
  "origin_website": "Bio",
  "title": "HoSeIn: A Workflow for Integrating Various Homology Search Results from Metagenomic and Metatranscriptomic Sequence Datasets",
  "procedures": [
    "Note: This tutorial describes the global procedure for analysing high-throughput metatranscriptomic sequences from an environmental sample, and focuses on how to define its taxonomic and functional profile in a robust and reliable way.  It does not include a detailed description of the pre-processing of high-throughput sequences obtained from an environmental sample (for this, see Kim et al., 2013; Aguiar-Pulido et al., 2016), nor on how to use MEGAN (for this, see Huson et al. [2007 and 2011] and the MEGAN user manual).  Below we provide a detailed tutorial to show how HoSeIn works, exemplifying with one of our samples, a sequence dataset obtained from the gut of a lepidopteran larva. The analysis of the metatranscriptomic part of this dataset was recently accepted for publication (Rozadilla et al., 2020). As this type of analysis is often dictated by the goals of the experiment (Shakya et al., 2019), a few remarks follow to explain certain distinctive features of this particular sample and its subsequent analysis. Spodoptera frugiperda (Lepidoptera: Noctuidae) is an economically important agricultural pest native to the American continent. The purpose for analysing this pest was to describe the taxonomic and functional profile of the larval gut transcriptome and associated metatranscriptome to identify new pest control targets. For this, total RNA was extracted from fifth instar larval guts, submitted to a one-step reverse transcription and PCR sequence-independent amplification procedure, and then pyrosequenced (McCarthy et al., 2015); the high-throughput reads were later assembled into contigs (Rozadilla et al., 2020). As we were interested in identifying, differentiating and characterising both the host (S. frugiperda) gut transcriptome and its associated metatranscriptome, we downloaded the following NCBI databases to perform the homology searches locally (ftp://ftp.ncbi.nlm.nih.gov/blast/db/[href=ftp://ftp.ncbi.nlm.nih.gov/blast/db/]) (download_db.mp4, a video tutorial that shows how to download different types of database files from NCBI, and download_db.",
    "sh, a bash script that automatically downloads these database files one by one, are provided as Supplementary Material 1[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 1.zip]):1)Nucleotide:–“Non-redundant” nucleotide sequence (nt)–16S rRNA gene (16S)–Lepidopteran whole genome shotgun (Lep) projects completed at the time of the analysis.Sequences from nt, 16S and Lep, were then combined in a single database (DB:nt16SLep) using the appropriate BLAST+ applications (ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/[href=ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/]) (blast_tutorial.mp4, a video tutorial that shows how to build and combine different databases and how to run a homology search locally with BLAST, and blast_commands.txt, which contains the commands used in the tutorial, are provided as Supplementary Material 2[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 2.zip]). The Lep sequences in the combined nucleotide database simplified the identification of host sequences (which represented the majority), and the nt and 16S databases enabled the identification of the associated metatranscriptome (and of host sequences).2)Protein:–non-redundant protein sequence (nr)Below follows an outline of the main steps included in our workflow (Figure 2; see the tutorial for details):Analyse sequences with local sequence aligners: Contigs are compared locally to the combined nucleotide database (nt16SLep) using BLASTN (Altschul et al., 1990) with a 1e-50 cutoff E-value, and to the protein database (nr) using BLASTX (Altschul et al., 1990) with a 1e-17 cutoff E-value (Supplementary Material 2[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 2.zip]).Note: Here we use BLASTX because the dataset we are querying is small (the aforementioned assembled reads, namely 737 contigs); but for large datasets and limited computational resources we recommend using Diamond (Buchfink et al., 2015).Process the homology search results:Step A (the stepA.mp4[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step A.zip] video tutorial guides you through step-by-step): The output files from both homology searches are then processed with MEGAN, a software which performs taxonomic binning and assigns sequences to taxa using the Lowest Common Ancestor (LCA)-assignment algorithm (Huson et al., 2007).",
    "Taxonomic and functional assignments performed by MEGAN for each contig are then exported using a MEGAN functionality.Note: MEGAN computes a “species profile” by finding the lowest node in the NCBI taxonomy that encompasses the set of hit taxa and assigns the sequence to the taxon represented by that lowest node. With this approach, every sequence is assigned to some taxon; if the sequence aligns very specifically only to a single taxon, then it is assigned to that taxon; the less specifically a sequence hits taxa, the higher up in the taxonomy it is placed (see the “MEGAN User Manual” for a detailed explanation). We chose MEGAN because this software uses the LCA-assignment algorithm and has a straightforward functionality for exporting the taxonomic and functional information for each sequence from the dataset (i.e., the “species profile” for each sequence can easily be accessed and downloaded). Nevertheless, any other tool or platform that provides this same functionality (i.e., exporting the taxonomic/functional assignment for each sequence from the dataset) can also be used.Step B (the stepB.mp4[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step B.zip] video tutorial guides you through step-by-step): The output files from both homology searches are also processed with a custom bash script. This script parses the homology search output files and generates two files (one for each homology search) containing the name of each contig, its best hit (or no hit) and the corresponding E-value.Create local database: Step C (the stepC.mp4 video tutorial found in Supplementary Material Step C[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step C.zip] guides you through step-by-step): All this information (from the exported MEGAN files and from the bash script output files) is then used to create a local SQLite database which includes all the available information for each contig (from both homology searches).Analyse the local database: Step D (the stepD.",
    "mp4 video tutorial found in Supplementary Material Step D[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step D.zip] guides you through step-by-step): Final taxonomic assignments are then performed by criss-crossing and comparing all this information using different SQLite commands. Step E (the stepE.mp4 video tutorial found in Supplementary Material Step E[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step E.zip] guides you through step-by-step): Transcript assignment is achieved by executing certain SQLite commands to group transcripts that correspond to mRNA, rRNA, those that cannot be assigned (not assigned), and those that have to be revised manually (Revise). Step F (the stepF.mp4 video tutorial found in Supplementary Material Step F[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step F.zip] guides you through step-by-step): Finally, functional assignments of transcripts that were classified by the functional databases are integrated in a single column by executing certain SQLite commands. Only transcripts in the “mRNA” and “Revise” categories can putatively be classified by the functional databases, but because the information in these reference databases is still considerably limited, only around a third of these are assigned a function. Functional assignment of the rest of these transcripts can be done manually on the basis of the homology search results (which are included in the local SQLite database) (see Data analysis).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200712/20200712234708_1870.jpgFigure 2. HoSeIn (Homology Search Integration) workflow. This figure shows an overview of the main steps that make up the workflow (see the tutorial for details): I. Analyse sequences with local sequence aligners: Sequences are submitted to homology searches against nucleotide (nt16SLep) and protein (nr) databases. II. Process results: Results from both homology searches are processed with MEGAN and with a custom bash script. Step A: Files containing the MEGAN taxonomic and functional assignments are exported using a MEGAN functionality. Step B: The custom bash script generates files containing the name of each sequence, its best hit (or no hit) and the corresponding E-value, for both homology searches.",
    "III. Create local database: Step C: The MEGAN and bash script files are then used to create a local SQLite database which includes all available data for each sequence. IV. Analyse local database: Final taxonomic and functional assignments are then performed by criss-crossing and comparing all this information using different SQLite commands. Step D: Taxonomic assignment is defined by using certain criteria and filters: 1) The “host filter” determines which sequences correspond to the S. frugiperda gut transcriptome; 2) the “E-value = 0 filter” for nt16SLep hits, groups those unequivocal hits; 3) the “Lowest Common Ancestor criterion” for sequences with nt16SLep hits showing E-value ≠ 0, defines the identity of the rest of the contigs by criss-crossing the results from both homology searches and retaining the lowest common ancestor assignments. Step E: Transcript assignment is achieved by searching for certain keywords in the hit description. In this way, it is possible to group transcripts that correspond to mRNA, rRNA, those that cannot be assigned (not assigned), and those that have to be revised manually (revise). Step F: Finally, functional annotation of all the sequences that correspond to mRNA (or “Revise”) is then integrated in a single column. N.A., Not assigned.We provide various files as Supplementary Material for the reader to be able to go through the tutorial and reproduce the same results we show below:–A FASTA file containing the assembled sequences (Sf_TV_contigs.fasta) and a text file (coverage.csv) containing the assembly information for each contig (i.e., contig name, number of reads used to assemble each contig, read length and contig coverage), are provided as Supplementary Material 3[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 3.zip];–The output files from both homology searches in BLAST pairwise format (blastn_nt16SLep_total-contigs_Sf-TV.txt and blastx_nr_total-contigs_Sf-TV.txt) are provided as Supplementary Material 4[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 4.",
    "zip];–Two custom scripts written in bash that process the homology search results (search_parser.sh and analyser_blast.sh) are provided as Supplementary Material 5[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 5.zip];–The \"RMA\" files generated by MEGAN6 after processing the homology search output files (blastn_nt16sLep_total-contigs.rma6 and blastx_nr_total-contigs.rma6) are provided as Supplementary Material 6[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 6.zip];–text files containing different commands to intersect, assign and analyse the data in the local SQLite database: step_C_creating_taxonomy.txt found in Supplementary Material Step C[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step C.zip], step_D_crisscrossing_taxonomy.txt found in Supplementary Material Step D[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step D.zip], step_E_assigning transcripts.txt found in Supplementary Material Step E[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step E.zip], step_F_functional_assignment.txt found in Supplementary Material Step F[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step F.zip], and analysing_taxonomy.txt[href=https://os.bio-protocol.org/attached/file/20200525/analysing taxonomy.txt].  HoSeIn Tutorial (also see Figure 2):I. Analyse sequences with local sequence aligners: As mentioned previously, homology searches were performed locally using BLASTN and BLASTX (Altschul et al., 1990) against the combined nucleotide (nt16SLep) and protein (nr) databases with 1e-50 and 1e-17 cutoff E-values, respectively. The homology search results are found in the blastn_nt16SLep_total-contigs_Sf-TV.txt and blastx_nr_total-contigs_Sf-TV.txt files (Supplementary Material 4[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 4.zip]). The video tutorial download_db.mp4 shows how to download different types of database files from NCBI, and the bash script download_db.sh automatically downloads these database files one by one (Supplementary Material 1[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 1.zip]). The video tutorial blast_tutorial.mp4 shows how to build and combine different databases, and how to run a homology search locally with BLAST; the commands used in this video can be found in blast_commands.txt (Supplementary Material 2[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 2.zip]).II. Process the homology search results: The output files from both homology searches were processed with MEGAN and saved as blastn_nt16sLep_total-contigs.rma6 and blastx_nr_total-contigs.rma6 (Supplementary Material 6[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 6.zip]).Export the taxonomic and functional assignments performed by MEGAN for both homology searches (Figures 3-9, StepA.mp4[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step A.zip] video tutorial and Supplementary Figure S1[href=https://os.bio-protocol.org/attached/file/20200616/3679 Supplementary Figures.docx]):Use MEGAN to open the provided RMA files (blastn_nt16sLep_total-contigs.rma6 and blastx_nr_total-contigs.",
    "rma6 found in Supplementary Material 6[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 6.zip]). To open the RMA files, select File > Open and then browse to the desired file (Figure 3). The main window is used to display the taxonomy and to control the program using the main menus. Once a dataset has been processed, the taxonomy induced by that dataset is shown. The size of the nodes indicates the number of sequences that have been assigned to the nodes (see “MEGAN User Manual” for a detailed explanation).To extract the taxonomic information from MEGAN, the taxonomic tree must be progressively expanded from Domain to species, selecting all the leaves, and extracting the text files in csv (comma-separated values) format. Choose the taxonomic level that you wish to extract (from Domain to Species): “Tree” > “Rank” (Figure 4).To select the leaves: “Select” > “All Leaves” (Figure 5).Without deselecting the leaves, export the file to csv format: “File” > “Export” > “CSV Format” (Figure 6).Choose what data you want to export and in what way it will be tabbed in the csv file (choose “summarized” so it exports the sequences contained in the chosen taxonomic level as well as all the lower levels) (Figure 7). We recommend naming the file with a representative name indicating the type of homology search and the taxonomic level, for example “nucl_domain”. In this way a csv text file is obtained (which can be viewed in a basic word processor such as WordPad). Each of these files has two fields, one with the sequence name and another with the corresponding assigned taxonomic level (Domain, Phylum, etc.) (Figure 8).Repeat this procedure for each taxonomic level, and for the other homology search.",
    "In this way, 14 files are obtained (7 files for each homology search), each one corresponding to a particular taxonomic level (Figure 9). The procedure for extracting the functional information is very similar (see Supplementary Figure S1[href=https://os.bio-protocol.org/attached/file/20200616/3679 Supplementary Figures.docx] and StepA.mp4[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step A.zip] video tutorial): 1) Choose the functional tree you want to visualise, e.g., InterPro2GO (Figure S1A.1); 2) Uncollapse all nodes: “Tree” > “Uncollapse All” (Figure S1A.2); 3) “Select” > “All Leaves” (Figure S1A.3); 4) Without deselecting the leaves, export the file to csv format: “File” > “Export” > “CSV Format” (Figure S1A.4); 5) Choose what data will be exported: “readName_to_interpro2goPath” (Figure S1A.5). Repeat the procedure for all the functional trees you want to include in the final analysis; for this tutorial we also exported the EggNOG assignments (Figure S1B).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235518_5021.jpgFigure 3. Opening the provided .rma6 files in MEGAN. A. Select “Open” from the “File” leaf (red rectangle). B. Select one of the provided .rma6 files from the location where you saved it (blastn_nt16sLep_total-contigs.rma6 was selected here; red rectangle). C. Appearance of blastn_nt16sLep_total-contigs.rma6 collapsed to “species” taxonomic rank.imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235546_6152.jpgFigure 4. Selecting a taxonomic rank. A. Select “Rank” from the “Tree” leaf (red rectangle). B. Tick the desired rank from the dropdown menu (the red arrow indicates that “Domain” was selected here).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235622_6264.jpgFigure 5. Selecting all the leaves from the chosen taxonomic rank. Select “All Leaves” from the “Select” leaf (red rectangle).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235653_7241.jpgFigure 6. Exporting in csv format. Select “Export” from the “File” leaf, and choose “Text (CSV) format” from the dropdown menu (red rectangle).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235730_8298.jpgFigure 7. Selecting the way in which data will be exported. Select “readName_to_taxonName” from the “Choose data to export” dropdown menu, “summarized” from the “Choose count to use” dropdown menu, and “tab” from the “Choose separator to use” dropdown menu (red rectangle).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235801_8461.jpgFigure 8. Partial view of the exported “nucl_domain.",
    "csv” file. The first column contains the sequence name (e.g., Contig479), and the second column the taxonomic rank assigned to each sequence (in this figure “Domain”, e.g., “Bacteria”).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235842_3357.jpgFigure 9. Exported MEGAN files. Folder containing all 14 files exported from MEGAN, named according to the corresponding homology search and taxonomic level (red rectangle).Parse the output files from the homology searches (Figure 10 and Supplementary Material stepB.mp4[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step B.zip] video tutorial):This step must be carried out in a Linux Operating System because the scripts that parse the homology search results were written in bash. The scripts process the FASTA file (containing the query sequences) and the homology search output files:The provided scripts (search_parser.sh and analyser_blast.sh from Supplementary Material 5[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 5.zip]), FASTA file (Sf_TV_contigs.fasta from Supplementary Material 3[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 3.zip]) and output files from the homology searches (blastn_nt16SLep_total-contigs_Sf-TV.txt and blastx_nr_total-contigs_Sf-TV.txt from Supplementary Material 4[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 4.zip]), must all be placed in the same folder (Figure 10A).Of the two bash scripts we provide, only execute search_parser.sh. This script works by executing various analyser_blast.sh scripts simultaneously to speed up the process. Open a terminal in the same folder that contains the files and execute the search_parser.sh bash script strictly in the following order (also see example below and Figures 10B-10C):bash search_parser.sh (name and file extension of the query fasta) (name and file extension of the homology search result) (chosen name and file extension for the output file)bash search_parser.sh Sf_TV_contigs.fasta blastn_nt16Slep_total-contigs.txt nucl_hits.csvimgsrc:https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000030_9931.jpgFigure 10. Using the bash script. A. The pale blue rectangle indicates the folder containing all the necessary files for the scripts to work correctly. B. The red rectangle indicates how to execute the script to process the BLASTN output file (homology search against the nucleotide database). C.",
    "The image shows the messages that appear in the terminal after processing the output files from the BLASTN homology search (1 and 2) and from the BLASTX homology search (3 and 4).The script generates a csv file with three fields separated by “%”: the first one shows the name of each sequence, the second shows its best hit (or nothing if there is no hit), and the third its corresponding E-value (or nothing if there is no hit) (Figure 11).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000052_0223.jpgFigure 11. Partial images of the csv files generated by the script. Files showing the listed BLASTN (A) and BLASTX hits (B). In both files, fields showing the sequence name, its best hit and the corresponding E-value, are separated by “%”.Create the database in DB4S (Figures 12-18, and step_C_creating_taxonomy.txt and stepC.mp4 video tutorial found in Supplementary Material Step C[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step C.zip]):The file containing all the information for the assembled reads (coverage.csv found in Supplementary Material 3[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 3.zip]; includes contig name, number of reads used to assemble each contig, read length, and contig coverage), the exported MEGAN files (14 taxonomic files and 2 functional files from Step A) and the bash script output files (2 files from Step B), will now be used to create a local database with DB4S which will include all the available information for each contig (from both homology searches, BLASTN and BLASTX). To do this, first each csv file must be imported individually to DB4S: Create a new database clicking on “New Database” and choosing where to save it (Figure 12).Individually import the csv files that were exported from MEGAN (16 files), those that were created by the bash script (2 files), and the file containing the assembly information for the contigs (1 file): “File” > “Import” > “Table from CSV file” (Figure 13).",
    "Choose a name for the table and indicate field separator (for the files imported from MEGAN, Tab; for the files generated by the bash script, Other > %) (Figure 14). Only for coverage.csv, check the “Column names in first line” box, which will automatically give the columns their correct name (Figure 14C).We recommend renaming table columns with representative names as indicated in Figure 15 to be able to use the commands we provide for Steps C6, D, E and F (and also to simplify interpretation of the commands and avoid mistakes). Figure 16 shows what the list of tables should look like after renaming them.The next step consists in integrating the information from all the imported files in a single new table, as indicated in Figures 17 and 18. The set of commands in step_C_creating_taxonomy.txt from Supplementary Material Step C[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step C.zip], creates a new table named “taxonomy” that unifies the columns from all the imported csv files, and adds empty columns (final_domain, final_phylum, etc.) to be filled with the result of the subsequent taxonomic criss-crossing (Step D). It also adds auxiliary columns “state_taxo” (to indicate if the contig was taxonomically assigned or not and to avoid multiple assignments; Step D), “rna_type” (to indicate if the transcripts correspond to mRNA or rRNA; Step E), “state_function” (to indicate whether the transcripts were assigned or need to be revised; Step E), and “function_type” (to integrate the functional assignment of those transcripts that were classified by the functional databases; Step F).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000228_4545.jpgFigure 12. Creating a new database in DB4S. A. Click on “New Database” (red arrow). B. A window will appear requesting you to choose a filename and location to save the new database (red rectangle).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000251_6866.jpgFigure 13. Importing the csv files. A.",
    "Click on the “File” leaf (red arrow) and select “Import” and “Table from CSV file” from the dropdown menus (red rectangle). B. Select the csv file that you want to import (“nucl_domain.txt” in the figure; red rectangle).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000313_6720.jpgFigure 14. Naming the imported tables. Once you have selected a csv file, a new window will appear in which you have to name the table and indicate the field separator. A. For files imported from MEGAN the field separator is “Tab”; this table was named “nucl_domain” (red rectangle). B. For files generated by the bash script, the field separator is “Other” > “%”; this table was named “nucl_hit” (red rectangle). C. For the “coverage” file, check the “Column names in first line” box (indicated by the red arrow) and choose “Tab” as field separator; the pale blue rectangle indicates the assigned column names.imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000402_4148.jpgFigure 15. Renaming table columns. A. In the main window, select the table that you want to modify with the mouse´s right button, and click on “Modify table” (red rectangle). B. A new window will open where the fields (which correspond to the column names) appear; double click on each to rename. For the tables obtained from the MEGAN files, rename “field1” as “sequence”, name the table and “field2” according to the database which was used for the homology search (nucl or prot) followed by the appropriate taxonomic rank (e.g., domain); in the figure, “nucl_domain” (red rectangles). C. The tables obtained from the files generated by the bash script have three columns: rename “field1” as “sequence”; rename “field2” as “nucl_hit” for the BLASTN hits, and as “prot_hit” for the BLASTX hits; rename “field3” as “nucl_Evalue” for the BLASTN hits, and as “prot_Evalue” for the BLASTX hits (red rectangles).",
    "Note: Columns from the “coverage” file were named in the previous step so they do not need to be modified.imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000429_9983.jpgFigure 16. “Database Structure” window in DB4S listing all the imported and renamed tablesimgsrc:https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000512_7897.jpgFigure 17. Unifying the information from all the imported files to create a single table. 1) In the “Execute SQL” leaf, 2) paste the commands contained in step_C_creating_taxonomy.txt and 3) execute them with “Play”; 4) the lower panel indicates if the commands were executed successfully.imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000537_0090.jpgFigure 18. View of the “taxonomy” table created in the previous step. A. In the “Database Structure” leaf (red arrow) a new “taxonomy” table will appear (red rectangle). B. To browse the new “taxonomy” table, select it from the dropdown menu in the “Browse Data” leaf (indicated by the red arrow and rectangle); the light blue rectangle shows a partial view of the columns that were created in “taxonomy”.Determining the taxonomic profile (Figure 19, and step_D_crisscrossing_taxonomy.txt and stepD.mp4 video tutorial found in Supplementary Material Step D[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step D.zip]):The next step consists in intersecting all the information contained in the “taxonomy” table to elucidate the taxonomic profile of the sample, based on the following criteria:Contigs that were assigned to Arthropoda in at least one of the homology searches are assigned to the host transcriptome.Contigs that have hits with E-value = 0 in the nt16SLep search, are directly assigned to that taxon.The rest of the contigs are assigned by comparing the MEGAN assignments from both homology searches according to the LCA logic; i.e., the level of taxonomic assignment for a contig is the one found in common for both results, or for the only result if it returns no hits in the other homology search.",
    "Contigs that were not assigned to any taxon by MEGAN in any of the homology searches are considered as “not assigned”; contigs that returned no hits in both homology searches are considered as “no hits”.These assignments are carried out by executing the commands in step_D_crisscrossing_taxonomy.txt in DB4S (Figure 19 and stepD.mp4 video tutorial from Supplementary Material Step D[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step D.zip]).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000647_3771.jpgFigure 19. Determining final taxonomic assignments in the “taxonomy” table. A. To perform these assignments: 1) in the “Execute SQL” leaf, 2) paste the commands contained in step_D_crisscrossing_taxonomy.txt and 3) execute them with “Play”; 4) the lower panel indicates if the commands were executed successfully. B. To view the updated “taxonomy” table, select it from the dropdown menu in the “Browse Data” leaf (indicated by the red arrow and rectangle); the light blue rectangle indicates the columns with the final taxonomic assignments after criss-crossing the taxonomic information from both homology searches (final_domain, final_phylum, etc.).Classifying the transcripts (Figure 20, and step_E_assigning transcripts.txt and stepE.mp4 video tutorial found in Supplementary Material Step E[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step E.zip]):As this sample was obtained from total RNA, the sequences can be further classified as either messenger or ribosomal RNA using the information contained in the hit description from the homology searches (“nucl_hit” and “prot_hit” columns), based on the following criteria:Contigs are assigned to mRNA if they show the word “mRNA” in the “nucl_hit” column.Contigs are assigned to rRNA if they show the words “rRNA/ribosomal RNA” in the “nucl_hit” column.Contigs are considered as functionally “Not assigned” if they show the words \"genome/chromosome/scaffold/contig\" or \"uncharacterized/hypothetical/unknown/ncRNA\" in the “nucl_hit” and “prot_hit” columns, respectively.All the rest of the contigs are included in a “Revise” category to be manually revised.These assignments are carried out by executing the commands found in step_E_assigning transcripts.txt in DB4S (Figure 20 and stepE.",
    "mp4 video tutorial from Supplementary Material Step E[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step E.zip]).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000755_3615.jpgFigure 20. Determining transcript assignments in the “taxonomy” table. A. To perform these assignments: 1) in the “Execute SQL” leaf, 2) paste the commands contained in step_E_assigning transcripts.txt and 3) execute them with “Play”; 4) the lower panel indicates if the commands were executed successfully. B. To view the updated “taxonomy” table, select it from the dropdown menu in the “Browse Data” leaf (indicated by the red arrow and rectangle); the light blue rectangle indicates the columns with the final transcript assignments: “rna_type” and “state_function”. The “rna_type” column indicates what category the transcript was assigned to (i.e., “mRNA”, “rRNA”, “Not assigned” or “Revise”). An “Assigned” status in the “state_function” column appears when the transcripts are assigned to either “mRNA”, “rRNA” or “Not assigned”; if the transcript was included in a “Revise” category, it is “NULL”.Functional assignment (Figure 21, and step_F_functional assignment.txt and stepF.mp4 video tutorial found in Supplementary Material Step F[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step F.zip]):This step integrates all the functional assignments of those transcripts that were classified by the functional databases in a single column (“function_type”). This is done by executing the commands found in step_F_functional assignment.txt in DB4S (Figure 21 and stepF.mp4 video tutorial from Supplementary Material Step F[href=https://os.bio-protocol.org/attached/file/20200525/Supplementary Step F.zip]). As can be deduced from the previous step, only transcripts in the “mRNA” and “Revise” categories can putatively be classified by the functional databases. Nevertheless, only about a third are assigned a function because the information in these reference databases is still considerably limited (see “Data analysis”).imgsrc:https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000956_4823.jpgFigure 21. Integrating functional assignments in the “taxonomy” table. A. 1) in the “Execute SQL” leaf, 2) paste the commands contained in step_F_functional assignment.txt and 3) execute them with “Play”; 4) the lower panel indicates if the commands were executed successfully. B.",
    "To view the updated “taxonomy” table, select it from the dropdown menu in the “Browse Data” leaf (indicated by the red arrow and rectangle); the light blue rectangle indicates the “function_type” column showing the integrated functional assignments. Transcripts that were not classified by the functional databases appear as “NULL”."
  ],
  "subjectAreas": [
    "Systems Biology"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics"
  ]
}