{
  "id": 10964,
  "origin_website": "Jove",
  "title": "Flying Insect Detection and Classification with Inexpensive Sensors",
  "procedures": [
    "1. Insect Colony and Rearing\nMosquito Colony and Rearing\n\t\nRear Culex tarsalis, Culex quinquefasciatus, Culex stigmatosoma, and Aedes aegypti adults from lab colonies, which originated from wild caught individuals.\nRear mosquito larvae in enamel pans under standard laboratory conditions (27 °C, 16:8 hr light:dark [LD] cycle with 1 hr dusk/dawn periods), and feed them ad libitum on a mixture of ground rodent chow and Brewer’s yeast (3:1, v:v).\nCollect mosquito pupae into 200 ml cups, and place them into experimental chambers. Alternatively, aspirate the adult mosquitoes into experimental chambers within 1 week of emergence. Make sure each experimental chamber contains 20 to 40 individuals of the same species/sex.\nFeed adult mosquitoes ad libitum on a 10% sucrose and water mixture. Replace food weekly.\nMoisten cotton towels twice a week and place them on top of the experimental chambers to maintain humidity within the cage. In addition, place a 200 ml cup of tap water in the chamber at all times to help maintain the overall humidity level.\nMaintain the experimental chambers on a 16:8 hr light:dark [LD] cycle, 20.5-22 °C and 30-50% RH for the duration of the experiment.\nHouse Fly and Fruit Fly Colony and Rearing\n\t\nRear Musca domestica from a lab colony, derived from wild caught individuals. Catch wild Drosophila simulans individuals and rear them in the experimental chambers.\nRear Musca domestica larvae in plastic tubs under standard laboratory conditions (12:12 hr light:dark [LD] cycle, 26 °C, 40% RH) in a mixture of water, bran meal, alfalfa, yeast, and powdered milk. Rear Drosophila simulans larvae in a rearing chamber and feed them ad libitum on a mixture of rotting fruit.",
    "Aspirate adult Musca domestica into experimental chambers within 1 week of emergence. Adult Drosophila simulans can be directly reared in the experimental chambers. Prior to data collection, make sure each experimental chamber contains no more than 10-15 individual Musca domestica or 20-30 individual Drosophila simulans.\nFeed adult Musca domestica ad libitum on a mixture of sugar and low-fat dried milk, with free access to water. Feed adult Drosophila simulans ad libitum on a mixture of rotting fruit. Replace food weekly.\nMaintain experimental chambers on a 16:8 hr light:dark [LD] cycle, 20.5-22 °C and 30-50% RH for the duration of the experiment.\n2. Record Flying Sounds in Experimental Chambers\nExperimental Chamber Setup\n\tNote: An “experimental chamber” denotes the cage designed in our lab, in which the data was recorded. The sensor is fairly inexpensive. When built in bulk, a set up could be manufactured for less than $10.\n\t\nConstruct an experimental chamber, either of the larger size: 67 cm L x 22 cm W x 24.75 cm H, or the smaller size: 30 cm L x 20 cm W x 20 cm H. The experimental chamber consists of a phototransistor array and a laser line pointing at the phototransistor array.\n\t\tNOTE: Additionally, the chamber consists of Kritter Keepers that are modified to include the sensor apparatus as well as a sleeve attached to a piece of PVC piping to allow access to the insects.\nConnect the phototransistor array to an electronic board. The output of the electronic board feeds into a digital sound recorder and is recorded as audio data in the MP3 format. See the logic design of the sensor in Figure 1.II and a physical version of the chamber in Figure 1.I.",
    "Modify the lids of the experimental chambers with a piece of mesh cloth affixed to the inside in order to prevent escape of the insects.\n\t\tNOTE: When an insect flies across the laser beam, its wings partially occlude the light, causing small light fluctuations. The light fluctuations are captured by the phototransistor array as changes in current, and the signal is filtered and amplified by the custom designed electronic board.\nSet Up the System to Record Sounds Produced by Flying Insects\n\t\nConnect the experimental chamber to a power supply. Turn on the power.\nOn the experimental chamber, find the laser lights and photoarray. Align the laser lights to the photoarray. To achieve the proper alignment, adjust the photoarray using the magnets on the outside of the experimental chamber which correspond to the magnets attached to the photoarray on the interior of the chamber until the laser light is centered on all the individual photodiodes.\nPerform two sanity checks to make sure the system is properly set up.\n\t\tNote: The first step is to make sure that the system is powered, all wires are properly connected and the laser is pointing at the photo array. The second step is to conduct further checks on the laser alignment to ensure it can capture the sound of the insects’ wingbeats.",
    "Plug headphones (rather than the recorder) into the audio jack. Plunge hand in and out of the experimental chamber, near the photoarray, to break the plane of the laser light. Make sure the laser light is on (it will be a red beam of light) and that you break the plane of light a few times with your hand. Listen for changes in noise level as your hand goes in and out of the light beam. If you detect an audible difference, the sensor is able to capture sounds produced by the movement of big objects. If successful, move on to the next sanity check, otherwise, check if the headphone is properly connected and whether the laser is pointing at the photoarray. Adjust the photoarray accordingly until the sound of the hand moving in and out of the experimental chamber can be heard.\nAttach a thin piece of electrical wiring to an automatic toothbrush. Turn on the toothbrush, and plunge the wiring in and out of the experimental chamber close to the phototarray. Make sure the laser light is hitting the piece of wiring as it moves. If you detect an audible change in frequency, when the piece of wiring breaks the plane of laser light, the system is then ready to capture the sounds produced by the movement of tiny objects, i.e., insect sounds. If you do not detect an audible difference, go back to step 2.2.2 to re-align the laser lights and the photoarray.\nAfter the system is properly set up, close the lid and add the insects.\nData Collection: Record Sounds Produced by Flying Insects",
    "Turn on the recorder and make a voice annotation that includes the following information: name of the species in the experimental chamber, age of the insects, date and time, current ambient RT, and relative humidity. Pause the recording.\nConnect the recorder to the system, via the audio cable, and resume the recording. Leave the recorder to record for 3 days, then stop the recording.\nDownload the data from the recorder into a new folder on a PC. Empty the recorder by deleting the data.\nRepeat the above recording process, until the remaining insects have died off and there are no more than 5 insects left alive in the cage.\n3. Sensor Data Processing and Detection of Sounds Produced by Flying Insects\nUse Software to Detect Sounds Produced by Flying Insects.\n\tNote: The software (detection algorithm) is much faster than real-time. It takes less than 3 hr to process a recording session, i.e., three days of data, on a standard machine with Intel(R) Core™ CPU at 2.00 GHz and 8 GB RAM.\n\t\nFor each folder containing data from a recording session, run the detection software to detect insect sounds. To run the software, open MATLAB, and type “circandian_wbf (dataDir)” in the command window, where dataDir is the directory of the recording data. Then press “Enter” to start.\n\t\tNOTE: Download the detection software circadian_wbf from reference #16.",
    "Wait until the algorithm terminates, then check the detection results. The algorithm outputs all the detected insect sounds in a new folder named “dataDir_extf”, where dataDir is the same as in the previous step. Each sound file is a 1 sec long audio clip originally extracted from the raw recording, with a digital filter applied to remove noise. The occurrence time of each detected sound is saved in a file named “dataDir_time.mat”. Observe the example of a detected insect sound in Figure 2.\nDetection Algorithm\n\t\nUse a 0.1 sec long sliding window to slide through the recording. The sliding window starts from the beginning of the recording. For each window, follow the steps below.\n\t\t\nCompute the fundamental frequency of the current window.\nIf the fundamental frequency is within the range of 100 Hz to 1,200 Hz, then do the following:\n\t\t\t\nExtract the 1-sec long audio clip centering at the current window from the recording; apply a digital filter to remove the noise in the clip and save the filtered audio into the folder “dataDir_extf”.\nSave the occurrence time of the current window into the file “dataDir_time”.\nMove the sliding window to the point that immediately follows the extracted audio clip.\nIf the fundamental frequency is NOT within the range of 100 Hz to 1,200 Hz, simply move the sliding window 0.01 sec forward.\nRepeat the process until the sliding window reaches the end of the recording.\n4. Insect Classification\nBayesian Classification Using Just the Flying Sound\n\tNote: Bayesian classifier is a probabilistic classifier that classifies an object to its most probable class.\n\t\nSound Feature Computation",
    "For each insect sound, compute the frequency spectrum of the sound using the Discrete Fourier Transform (DFT). Truncate the frequency spectrum to include only those data points corresponding to the frequency range: 100 Hz to 2,000 Hz. The truncated frequency spectrum is then used in the classification as the “representative” of the insect sound.\n\t\t\tNOTE: The DFT is an algorithm that transforms signals in time domain to the frequency domain. It is a built-in function in most programming libraries, and can be called in the program with just one line of code.\nTrain a Bayesian classifier\n\t\t\nUse the kNN density estimation approach14 to learn the posterior probability distribution using the sound feature. With the kNN approach, the training phase is to build a training dataset.\n\t\t\t\nRandomly sample a number of insect sounds from the data collected for each species of insects.\nFollow the steps in Section 4.1.1 and compute the truncated frequency spectrum for each sampled sound. The truncated spectrums together with the samples’ class labels (insect species name) composed the training dataset.\nUse the Bayesian classifier to classify an unknown insect\n\t\t\nCompute the truncated frequency spectrum of the unknown insect sound.\nCompute the Euclidean distance between the truncated spectrum of the unknown object and all the truncated spectrums in the training dataset.\nFind the top k (k = 8 in this paper) nearest neighbors of the unknown object in the training dataset. Compute the posterior probability of the unknown insect sound belonging to a class as the fraction of the top k nearest neighbors which are labeled as class .\nClassify the unknown object to the class that has the highest posterior probability.\nAdd a Feature to the Classifier: Insect  Circadian Rhythm",
    "Learn the class-conditioned distributions of the occurrence time of insect sound, that is, the  circadian rhythm for each species of insects.\n\t\t\nObtain the occurrence time of each sound from the detection results (c.f. Section 3.2).\nFor each species, build a histogram of the insect sound occurrence time.\nNormalize the histogram so that the area of the histogram is one. The normalized histogram is the  circadian rhythm of the given species. It tells the probability of observing an insect, of that species, in flight within a certain time period.\nClassify an unknown “insect sound” by combining the “insect sound” and the circadian rhythm\n\t\t\nGiven the specific point in time in which the unknown insect sound occurred, obtain the probability of observing an insect of class based on the circadian rhythm of class.\n\t\t\tNOTE: The circadian rhythm is a probability distribution. It is an array specifying the probability of detecting a sound, produced by a specific species of insects, at a specific time of day. So once a time is given, one can simply check the array to get the probability.\nFollow the steps in section 4.1.2 to compute the posterior probability that the unknown sound belongs to class using the sound features. Multiply the posterior probability to the results from the previous step to get the new posterior probability.\nClassify the “unknown sound” to the class that has the highest new posterior probability.\nAdd One More Feature to the Classifier: Insect Geographic Distribution\n\t\nLearn the geographic distribution of the species of interest, either from data published in historical records, relevant literature, or simply gather the first-hand knowledge from field technicians/biologists. For demonstration purposes, use a simulation of the graphic distribution, as shown in Figure 7.\nClassify an “unknown insect sound” using “flying sound” and the two additional features.",
    "Given the geographic location where the insect sound was intercepted, compute the probability of observing an insect from class at that specific location using the graphic distribution of species.\n\t\t\t\nFollow steps in section 4.2.2 and compute the posterior probability that the “unknown sound” belongs to class using the sound features and the circadian rhythms. Multiply the outcome of this step to the results from the previous step, in order to get the new posterior probability.\nClassify the “unknown sound” to the class that has the highest new posterior probability.\nA General Framework for Adding Features\n\t\nConsider the Bayesian classifier that uses just sound features as the primary classifier. Follow the steps below to add new features to the classifier.\n\t\t\nIn the training phase, learn the class-conditioned density functions of the new feature.\nIn the classification phase, given the new feature of the “unknown sound”, compute the probability of observing the feature in class using the density functions learned in the previous step. Multiply the new probability to the previous posterior probability corresponding to the “unknown sound” belonging to class which were computed based on just the odd features, to obtain the new posterior probability. Classify the unknown object to the class that has highest new posterior probability.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Bioengineering"
  ],
  "bigAreas": [
    "Bioengineering & Technology"
  ]
}