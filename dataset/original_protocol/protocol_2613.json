{
  "id": 2759,
  "origin_website": "Cell",
  "title": "Protocol to analyze population structure and migration history based on human genome variation data",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nHere, we describe how to combine variant files from multiple datasets for downstream population structure analysis and historical migration analysis. To illustrate the data process steps, we show the analysis process and results of four different datasets used by Zhang et al. (2022)1[href=https://www.wicell.org#bib1] as an example.\nInstall software\nTiming: 1–2 h\nSeveral analysis toolkits are required to perform computational tasks such as batch-effect estimation, variant calling and filtering, and downstream statistical analyses of population genetics.\nInstall Python and related packages.\nInstall Python (version 3.8 or current version). The package and documentation are available at https://www.python.org/[href=https://www.python.org/].\nInstall NumPy (version 1.19.2 or current version). Download and documentation are available from https://numpy.org/[href=https://numpy.org/]. To install NumPy, you can type:\n>pip install numpy==1.19.2\nInstall scikit-learn (version 0.23.2 or current version). The package and documentation are available from https://scikit-learn.org/stable/[href=https://scikit-learn.org/stable/]. To install scikit-learn, you can type:\n>pip install sklearn==0.23.2\nsk\nInstall PyVCF (version 0.6.8 or current version). The package and documentation are available at https://pyvcf.readthedocs.io/en/latest/[href=https://pyvcf.readthedocs.io/en/latest/]. To install PyVCF, you can type:\n>pip install pyvcf==0.6.8\nsk\nInstall pandas (version 1.4.1 or current version). The download and documentation are available from https://pandas.pydata.org/[href=https://pandas.pydata.org/]. To install pandas, you can type:\n>pip install pandas==1.4.1\nInstall R and related packages.\nInstall R (version 3.6.3 and version 4.2.0). The download and documentation are available from https://www.r-project.org/[href=https://www.r-project.org/].\nInstall Bioconductor (version 3.10 or current version).24[href=https://www.wicell.org#bib24] Installation instructions and documentation are available from https://www.bioconductor.org/[href=https://www.bioconductor.org/]. To install the Bioconductor, start R and type:\n>if (!require(“BiocManager”, quietly = TRUE))\n  install.packages(“BiocManager”)\n>BiocManager::install(version = “3.10”)\nInstall genotypeevel (version 3.15 or current version). The required R version for this package is 4.2.0. Installation instructions and documentation are available at http://bioconductor.org/packages/release/bioc/html/genotypeeval.html[href=http://bioconductor.org/packages/release/bioc/html/genotypeeval.html]. To install genotypeevel, start R and type:\n>BiocManager::install(“genotypeeval”)\nInstall filterfq.\nInstall filterfq (version v1.2.0).6[href=https://www.wicell.org#bib6] The download and documentation are available from https://github.com/bowentan/filterfq[href=https://github.com/bowentan/filterfq].\nInstall BWA.",
    "Install BWA (version v0.7.13).7[href=https://www.wicell.org#bib7] The download and documentation are available from http://bio-bwa.sourceforge.net/[href=http://bio-bwa.sourceforge.net/].\nInstall Samtools.\nInstall Samtools (version v1.9).8[href=https://www.wicell.org#bib8] Download and documentation are available from http://samtools.sourceforge.net/[href=http://samtools.sourceforge.net/].\nInstall Picard.\nInstall Picard (version v2.1.0).25[href=https://www.wicell.org#bib25] The download and documentation are available from http://broadinstitute.github.io/picard/[href=http://broadinstitute.github.io/picard/].\nInstall GATK.\nInstall GATK (version v3.8). The download and documentation are available at https://software.broadinstitute.org/gatk/[href=https://software.broadinstitute.org/gatk/].\nInstall ANNOVAR.\nInstall ANNOVAR (version v2018Apr16). The download and documentation are available from https://annovar.openbioinformatics.org/en/latest/[href=https://annovar.openbioinformatics.org/en/latest/].\nThe dbSNP database is required for downstream analyses. The database can be downloaded and configured using the following command line:\n> perl annotate_variation.pl --downdb --webfrom annovar --buildver hg19 snp138 humandb/\nInstall bcftools.\nInstall bcftools (version v1.9).10[href=https://www.wicell.org#bib10] The download and documentation are available at https://samtools.github.io/bcftools/[href=https://samtools.github.io/bcftools/].\nInstall PLINK.\nInstall PLINK (version v1.90).26[href=https://www.wicell.org#bib26] Download and documentation are available from https://www.cog-genomics.org/plink2[href=https://www.cog-genomics.org/plink2].\nInstall ANGSD.\nInstall ANGSD (version v0.931).13[href=https://www.wicell.org#bib13] Download and documentation are available at http://www.popgen.dk/angsd/index.php/ANGSD/[href=http://www.popgen.dk/angsd/index.php/ANGSD/].\nInstall Beagle and phasing bundle resources.\nInstall Beagle (version v4.0).14[href=https://www.wicell.org#bib14] The download and documentation are available from https://faculty.washington.edu/browning/beagle/b4_0.html[href=https://faculty.washington.edu/browning/beagle/b4_0.html].\nDownload the Beagle phasing bundle from https://bochet.gcc.biostat.washington.edu/beagle/genetic_maps/[href=https://bochet.gcc.biostat.washington.edu/beagle/genetic_maps/].\nDownload the 1KGP phase 3 reference panel from https://bochet.gcc.biostat.washington.edu/beagle/1000_Genomes_phase3_v5a/[href=https://bochet.gcc.biostat.washington.edu/beagle/1000_Genomes_phase3_v5a/].\nInstall SHAPEIT2.\nInstall SHAPEIT2 (version 2.0).15[href=https://www.wicell.org#bib15] Download and documentation are available from https://mathgen.stats.ox.ac.uk/genetics_software/shapeit/shapeit.html[href=https://mathgen.stats.ox.ac.uk/genetics_software/shapeit/shapeit.html].\nInstall KING.\nInstall KING (version v2.0.1).9[href=https://www.wicell.org#bib9] Download and documentation are available from http://people.virginia.edu/∼wc9c/KING/[href=http://people.virginia.edu/%7Ewc9c/KING/].\nInstall EIGENSOFT.\nInstall EIGENSOFT (version v4.2).16[href=https://www.wicell.org#bib16] The download and documentation are available at https://data.broadinstitute.org/alkesgroup/EIGENSOFT/[href=https://data.broadinstitute.org/alkesgroup/EIGENSOFT/].\nInstall fineSTRUCTURE.\nInstall fineSTRUCTURE (version v2.0).16[href=https://www.wicell.org#bib16] Download and documentation are available at http://www.paintmychromosomes.com/[href=http://www.paintmychromosomes.com/].\nInstall ADMIXTURE.\nInstall ADMIXTURE (version v1.3.0).18[href=https://www.wicell.org#bib18] Download and documentation are available at https://dalexander.github.io/admixture/download.html/[href=https://dalexander.github.io/admixture/download.html/].\nInstall CLUMPAK.\nInstall CLUMPAK (version v1.1).19[href=https://www.wicell.org#bib19] The download and documentation are available from http://clumpak.tau.ac.il[href=http://clumpak.tau.ac.il/].\nInstall Ohana.\nInstall Ohana (version v1.0).20[href=https://www.wicell.org#bib20] The download and documentation are available at https://github.com/jade-cheng/ohana[href=https://github.com/jade-cheng/ohana].\nInstall EEMS.\nInstall EEMS (version v1.0).21[href=https://www.wicell.org#bib21] The download and documentation are available from https://github.com/dipetkov/eems[href=https://github.com/dipetkov/eems].\nInstall MSMC.\nInstall MSMC (version v1.0).27[href=https://www.wicell.org#bib27] Download and documentation are available from https://github.com/stschiff/msmc[href=https://github.com/stschiff/msmc].\nInstall AdmixTools.",
    "Install AdmixTools (version v6.0).23[href=https://www.wicell.org#bib23] The download and documentation are available from https://github.com/DReichLab/AdmixTools/[href=https://github.com/DReichLab/AdmixTools/].\nCritical: The indicated software and package versions were used by Zhang et al.1[href=https://www.wicell.org#bib1] Other versions of the software packages than those indicated here were not tested. If you intend to use different versions of software or packages, please check compatibility and be aware that the steps described in this protocol might not work as expected.\nData integration and batch effect evaluation\nTiming: 2–3 h\nThe data-combination step merges the variation data from the four datasets above into a single vcf file. The non-random associated variants described by linkage disequilibrium (LD) add redundancy in subsequential analyses; thus, it is essential to remove linkage variants based on pairwise LD. The remaining variants are then annotated by the dbSNP database and used to evaluate the batch effect. Users can perform batch-effect elimination with a more stringent variant filtering strategy (compared to the aforementioned filtering strategy in the Section “download variation data[href=https://www.wicell.org#sec1.2]”) if the variants fail the batch-effect evaluation. For example, the lowest base quality can be increased to 30 and/or the lowest BWA mapping quality can be increased to 20.\nData integration.\nAdopt the “merge” subcommand of the software “bcftools” to combine the variants vcf files from different resources. Adopt the “view” subcommand to filter the variants in the vcf files.\n> bcftools merge -O z \\\n    -o MergedVariants.vcf.gz \\\n    <source_1>.vcf.gz <source_2>.vcf.gz …\n> bcftools view -v snps -m2 -M2 MergedVariants.vcf.gz\nNote: “bcftools” “merge” subcommand has the option (-0, --missing-to-ref) to use reference allele (0/0) instead of the default missing genotype. In our study, any variant is absent in one of the vcf files to be merged will be treated as missing information in the merging process.\nNote: We keep only biallelic SNPs for subsequent analyses.\nLD pruning.",
    "LD pruning by the software “plink” use the “–indep-pairwise” option with three parameters: window size (kb), step size, and r2 threshold. Blog “https://blog.goldenhelix.com/determining-best-ld-pruning-options[href=https://blog.goldenhelix.com/determining-best-ld-pruning-options]” describes the details of the parameters and how to determine the best parameter values for LD pruning. It is common practice to set the parameters to 500, 50, and 0.2 for window size, step size, and r2 threshold, respectively, in studies of homo species populations. The commands for filtering linkage SNPs with PLINK are:\n> plink --vcf MergedVariants.vcf.gz --indep-pairwise 500 50 0.2 -out prune\n> plink --vcf MergedVariants.vcf.gz --extract prune.in --recode vcf --out MergedVaraints.prune.vcf\nNote: We compressed and moved the pruned vcf file to “MergedVariants.vcf.gz”, which contains independent biallelic SNPs, and we used this filename in the subsequent analyses.\nNote: For the merged variants file used for haplotype phasing, skip this step.\nSite annotation.\nThe command to annotate variants by “ANNOVAR” with the dbSNP database is:\n> perl annotate_variation.pl -downdb -webfrom annovar -buildver hg19 snp138 humandb/\nNote: Reference hg19 is used here as the human reference genome. If you choose hg38 as the reference from the beginning, please use “-buildver hg38”.\nBatch effect evaluation and variant statistics calculation.",
    "We developed an integrated module “SiteEval” for batch effect evaluation and variant statistics calculation on the merged vcf file. SiteEval uses the R package “genotypeeval” to identify batch effects by some key quality metrics, such as percent of variants confirmed in dbSNP, mean genotype quality, median read depth, transition (Ti) transversion (Tv) ratio in noncoding and coding regions, and percent heterozygotes. Genotypeeval requires the coordinate cds regions, dbsnp, and known-gene regions for the corresponding reference genome version in bed format. These information are loaded by including R libraries “TxDb.Hsapiens.UCSC.hg38.knownGene” for hg38, and “TxDb.Hsapiens.UCSC.hg19.knownGene” for hg19, respectively. “SiteEval” also calculates variant statistics, including the number of Ti variants, the number of Tv variants, the Ti / Tv ratio, and the ratio of called variants shared with dbSNP or 1KGP. “SiteEval” is one of the subfolders in the Github repository PopBoost. The command line for running SiteEval is:\n> python get_vcf_stats.py --in MergedVariants.vcf.gz --out MergedVariants.statusV\nPrepare the variant file in bed format for downstream analyses.\nThe command line for transforming variant file in vcf format to bed format is:\n> plink --vcf MergedVariants.vcf.gz --make-bed --out MergedVariants\nNote: This command will generate four output files, namely MergedVariants.bed, MergedVariants.fam, MergedVariants.bim, and MergedVariants.log. The bed file contains variant genotypes in binary format. The fam file indicates the sample information and the bim file indicates the variant information. Detailed documentation of the bed format is available at https://www.cog-genomics.org/plink/1.9/formats[href=https://www.cog-genomics.org/plink/1.9/formats].\nPopulation structure and migration history analyses\nTiming: 1–2 weeks",
    "Population structure and migration history analyses require the merged variants as input. The merged variant file containing linkage SNPs is used for haplotype phasing to perform linked principal component analysis (PCA) and historical effective population size estimation. The merged variants file containing independent biallelic SNPs is used to perform PCA, ADMIXTURE analysis, homozygosity scan runs (ROH), EEMS analysis, and Fst, F3 statistics, and D statistics estimation.\nKinship analysis.\nMost downstream analyzes require unrelated individuals in the cohort as the close inheritance distances of related individuals provide redundant variants. We use the “KING” software to test cryptic relatedness between individuals. In our research, the threshold for the kinship coefficient of unrelated individuals was empirically set to <0.2. Individuals with pairwise coefficients higher than the threshold are excluded. The command line for running “KING” software is:\n> king -b MergedVariants.bed \\\n    --fam MergedVariants.fam \\\n    --bim ex.bim --related\nHaplotype phasing. In our method, we integrate “Beagle” and “SHAPEIT2” to obtain accurate phasing haplotypes due to the low coverage samples in the Tibetan-Yi Corridor Project (5×) and 1KGP (7.4×).\nRun “Beagle” with the default parameters to get an initial set of genotypes. BEAGLE-called genotypes with posterior probability greater than 0.995 can be considered known genotypes.\nNote: Users could also run a smaller number of iterations (e.g., 5) to reduce the runtime of this step. However, the phasing switch error could increase with fewer iterations if the result does not converge.\nRun “SHAPEIT2” to phase the initial genotype set into haplotypes with ten burning-in iterations and ten pruning iterations. The process detail is available at https://mathgen.stats.ox.ac.uk/genetics_software/shapeit/shapeit.html#prephasing[href=https://mathgen.stats.ox.ac.uk/genetics_software/shapeit/shapeit.html#prephasing] in the “Genotype calling from low coverage sequencing” subsection. The phasing process is integrated into the PopBoost repository with a Python program in the “phase” subfolder. Users could run the script using the following command:",
    "> python phase.py --mode low \\\n        --vcf MergedVariants.vcf.gz \\\n        --out MergedVariants.phased.vcf.gz \\\n        --thread 8 --burn 10 --prune 10 \\\n        --shapeit-path <shapeit2 program path> \\\n        --beagle-path <beagle java file path>\nNote: The “MergedVariants.vcf.gz” file here is not processed by LD pruning and contains linkage SNPs.\nNote: Users can ignore the --shapeit-path and --beagle-path parameters if the programs are on their system path.\nNote: The mode parameter provides two options, namely “normal” and “lowcov”. “Normal” is the default mode for the script. In “normal” mode, the script will run SHAPEIT2 directly.\nPCA. PCA could demonstrate population stratification. Users can perform analyses based on genotype and haplotype, respectively. Both methods are integrated into the PopBoost repository PCA sub-folder. Users can perform PCA with the following steps.\nThe command line for running the integrated script “pca.py” for the PCA genotype is:\n> python pca.py --mode lowcov --vcf MergedVariants.vcf.gz --out out.pca\nNote: The script provides a “low coverage” mode and a “normal” mode. “ANGSD” and “smartPCA” will be adopted in low-coverage mode and normal mode, respectively. “ANGSD” will use beagle genotype likelihood (BEAGLE-BL) information when calculating sample PCA, and thus is more suitable for studies with low coverage samples. The vcf file with BEAGLE-BL information can be obtained in the former haplotype phasing step.\nAdopt the software “fineSTRUCTURE” to perform linked PCA and investigate population structure based on haplotype data. “fineSTRUCTURE” requires phased variation data as input. The working flow is available at https://people.maths.bris.ac.uk/∼madjl/finestructure/manualse2.html#x5-40002[href=https://people.maths.bris.ac.uk/%7Emadjl/finestructure/manualse2.html#x5-40002]. The official tutorial recommends running “SHAPEIT2” to obtain phasing variants. Before running “fineSTRUCTURE”, users should transform the “SHAPEIT2” output in “.haps” format to chromopainter format ending with “.phase” by “fineSTRUCTURE” util script “impute2chromopainter.pl” with the following command:\n> perl impute2chromopainter.pl impute.haps output_prefix\nROH.",
    "ROH provides evidence in the demographic history of the population ancestors. The software “bcftools” can calculate the value with fixed sliding window size and the minimum length of an ROH. The ROH analysis requires that each input file have individuals from the same population. Thus, users should separate the merged vcf file by population and run ROH separately. The command line for ROH analysis is as follows:\n> bcftools roh -G30 --AF-dflt 0.4 <population.vcf.gz>\nHistorical population effective size inference.\nThe historical effective population size quantifies the rate of genetic drift and inbreeding in the demographic history of the population.28[href=https://www.wicell.org#bib28] Software Multiple sequentially Markovian coalescent (MSMC) takes both phased and unphased data of multiple samples within a population to infer the population’s historical effective size. The mutation rate and generation time are typically set at 1.25e-8 per base pair and 25 years per generation, respectively.\nThe “MSMC” tutorial and pipeline are available at “https://github.com/stschiff/msmc/blob/master/guide.md[href=https://github.com/stschiff/msmc/blob/master/guide.md]”. We integrate the “MSMC” pipeline into the “msmc” subfolder of the PopBoost repository. The “MSMC” program requires either a bam file or a “masterVarBeta” file as input. The command line for running the integrated “MSMC” pipeline is:\n> python msmc.py --sample-file <sample.list> --bam-folder <bam_folder> --out <outfolder> --ref hg19.fa --thread 8\nNote: Users can manually set the generation time and mutation rate by the “--mu” and “--g” parameters, respectively.\nNote: The script requires “SHAPEIT2” and “samtools” in the system path. Users can also assign the program path by the parameters “--shapeit-path” and “--samtools-path”.\nGenetic diversity between populations (Fixation Index Fst).\nFst measures the genetic differences between populations. The analysis requires a population list file as input to compute pairwise Fst values. The command line for calculating Fst with software “vcftools” is:\n> vcftools --gzvcf MergedVariants.vcf.gz --weir-fst-pop <pop1.indv.lst> --weir-fst-pop <pop2.indv.lst>",
    "Note: <pop1.indv.lst> and <pop2.indv.lst> are lists with sample IDs in population 1 and population 2.\nF3 statistics and D statistics analyzes. Statistics F3 and D provide evidence of historical genetic events between populations. The additive-F3 statistic and the outgroup-F3 statistic f3(X, Y; Z) require three populations X, Y, and Z. For the additive-F3, X and Y are regarded as background populations. Z is tested to check if it has ancestry from populations related to X and Y. A significantly negative value provides strong evidence of a mixture in the test population Z with X and Y. These three populations are selected according to research hypothesis. Outgroup-F3 estimates the shared genetic drift between X and Y. Population Z is considered an outgroup population. The outgroup population is typically set to African populations like Mbuti. D statistics D(X, Y; Z, W) is used to test a tree-like relatedness between four populations. The blocked jackknife value is used to assess the statistical significance of the result. “Admixtools” is an integrated toolkit to calculate F3 statistics and D statistics. For each calculation, a population list representing X, Y, Z in F3 or X, Y, Z, W in D statistics should be provided.\nThe command line to calculate the admixture-F3 statistic f3(X, Y; test) is:\n> qp3Pop -p <param.par>\nNote: <param.par> is the config file for admixture-F3 statistic. The config file is a description of each parameter in a par file. Here is an example from our study:\ngenotypename: MergedVaraints.bed\nsnpname: MergedVariants.bim\nindivname: MergedVariants.ind\npopfilename: <population list>\noutgroupmode: NO",
    "Note: The “MergedVariants.ind” file can be extracted from “MergedVariants.fam”. The first column in the “MergedVariants.ind” file is the sample ID, the second column is the sample gender, and the third column is the sample population. The population list file is a tab-separated file, in which each line represents a three-population group. The input files have the same format in the subsequential outgroup-F3 and D statistics analyses, despite the population list having a four-population group for D statistics analysis.\nThe command line to calculate the outgroup-F3 statistic f3(X, Y; outgroup) is:\n> qp3Pop -p <param.par>\nNote: <param.par> is the config file for outgroup-F3 statistic. The config file is a description of each parameter in a par file. Here is an example from our study:\ngenotypename: MergedVariants.bed\nsnpname: MergedVaraints.bim\nindivname: MergedVariants.ind\npopfilename: <population list>\noutgroupmode: YES\nThe command line for calculating the D statistics D(X, Y; Z, W) is:\n> qpDstat -p <param.par>\nNote: <param.par> is the config file for D statistics. The config file is a description of each parameter in a par file. Here is an example from our study:\ngenotypename: MergedVariants.bed\nsnpname: MergedVariants.bim\nindivname: MergedVaraints.ind\npopfilename: <population list>\nf4mode: NO",
    "Model-based clustering and ancestry component analyses. We apply the “ADMIXTURE” software to perform model-based clustering analysis. The software takes variants in bed format as input. Users can set the number of ancestry components k (represented by the cluster number) according to the scale of their dataset. Our study set the k-value varying from 2 to 13 for the worldwide population dataset and from 2 to 8 for the regional population dataset. “ADMIXTURE” software uses the maximum-likelihood approach. Thus, it requires multiple experiments to obtain the best output clustering result. We set the number of repetitive experiments to 10 in our study. Users can custom set the number of repetitions. A more significant number of experimental repeats (≥ 10) will result in a more robust result. The best output can be identified and visualized by “CLUMPAK”. “Ohana” takes the output components as input to conduct the population tree for the ancestry components.\nRun the “ADMIXTURE” program to perform model-based clustering.\n> admixture -j8 --cv MergedVariants.bed <k>\nNote: The <k> parameter dedicates the number of ancestry components.\n“CLUMPAK” provides an online website available at http://clumpak.tau.ac.il/[href=http://clumpak.tau.ac.il/]. Users can perform the analysis following the instructions on the website http://clumpak.tau.ac.il/help.html[href=http://clumpak.tau.ac.il/help.html]. Note that the Q-matrixes obtained from “ADMIXTURE” should be compressed to a zip file before uploading. The “CLUMPAK” server will send the results to the user’s email after the analysis is accomplished.\n“Ohana” requires a ped format file as input. The command lines for conducting the population tree from ancestry components are as follows:\n> convert ped2dgm MergedVariants.ped MergedVariants.dgm\n> qpas MergedVariants.dgm -k <k> -qo q.matrix -fo f.matrix -mi 5\n> nemeco MergedVariants.dgm f.matrix -co c.matrix -mi 5\n> convert cov2nwk c.matrix tree.nwk\n> convert nwk2svg tree.nwk tree.svg\nNote: The <k> parameter in “qpas” command is the number of ancestry components, similar to “ADMIXTURE” analysis.",
    "Note: In our study, we performed “Ohana” with only high-coverage samples in the Tibetan-Yi Corridor Project. If low coverage samples are included, users can adopt genotype likelihood data as input.\nThe whole process has been integrated in the “admixture” subfolder of the PopBoost repository. Users can perform “ADMIXTURE”, “clumpak”, and “ohana” analyses by one command line:\n> bash run_admixture.sh MergedVariants.bed \\\n<output> \\\n<startk> <endk> \\\n<reptime>\nNote: The parameters start-k and end-k define the minimum number of ancestry components and maximum number of ancestry components in the analysis, respectively. The “reptime” parameter defines the number of experiments in each k-value while running the “ADMIXTURE” program. “Ohana” requires fewer experiments for small k values. The number of experiments in “Ohana” will automatically be determined by the script “run_admixture.py”.\nMigration and isolation by distance. Adopt “EEMS” for performing migration and isolation analysis. Before running “EEMS” for geolocation-based analysis, variants should be formatted in genetic dissimilarities by the “bed2diffs” script in the EEMS repository. “EEMS” takes one million iterations for each run, followed by an additional one thousand iterations for each posterior sample. The migration surfaces vary with the EEMS running threshold. The threshold value ranges from 0 to 1. A more significant threshold generates more stringent migration surfaces. The R script “rEEMSplots.R” is used to visualize the results on the map. The interpolation analysis is to visualize the ancestry coefficients (Q matrix) on a geographic map. The Q matrix is calculated by ADMIXTURE and selected by CLUMPAK in the previous step. The R script “POPSutilities.R” is used to visualize the result.\nThe command line for generating genetic dissimilarity by the “bed2diffs” script is:\n> bed2diffs_v1 --bfile MergedVariants --nthreads 8\nNote: This command will generate an output file named “MergedVariants.diffs”.",
    "The “EEMS” program requires three input files: i) the “diffs” file generated by the previous step; ii) the “coord” file with sample location represented by longitude and latitude (one sample per line); iii) the “outer” file represents habitat coordinates. Users should prepare the second and the third input files according to their project. The command line for running “EEMS” is:\n> runeems_snps --params <eems_param>\nNote: The “eems_param” is the parameter file for running EEMS. Below is an example:\ndatapath = MergedVaraints\nmcmcpath = <output directory>\nnIndiv = <individual number>\nnSites = <SNP site number>\nnDemes = 200\ndiploid = false\nnumMCMCIter = 2000000\nnumBurIter = 1000000\nnumThinIter = 9999\nNote: The three input files should have the same prefix, e.g., MergedVariants.diffs, MergedVariants.coord, and MergedVaraints.outer. EEMS will read the input files by the “datapath” parameter in the config file.\nUser can visualize the results of the previous step by custom R script with “rEEMSplots” package. In the “eems” folder of PopBoost repository, we provide a visualization R script “plotEEMS.R”. The command line for running “plotEEMS.R” is:\n> Rscript plotEEMS.R <output directory> <figure name>\nBefore performing an interpolation analysis, users should prepare an asc-format geographical roster map in the target area. The script also requires a Q matrix file and a coordinate file as input. The coordinate file is the same as the EEMS “coord” file, and the Q matrix is the output of ADMIXTURE analysis. In the “interpolate” folder of the PopBoost repository, we provide an R script “interpolate.R” to perform interpolate analysis and result visualization. The command line for running “interpolate.R” is:\n> Rscript interpolate.R <asc map> <Q-matrix> <coord file> <outfile>"
  ],
  "subjectAreas": [
    "Computer Sciences",
    "Genomics",
    "Evolutionary Biology",
    "Bioinformatics"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics",
    "Bioinformatics & Computational Biology"
  ]
}