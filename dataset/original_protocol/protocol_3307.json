{
  "id": 3501,
  "origin_website": "Cell",
  "title": "A user-driven machine learning approach for RNA-based sample discrimination and hierarchical classification",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nStage 1: Data preprocessing\nTiming: 30 min–1 h\n    \nNote: Timing estimates are based on the\n      example data and hardware specifications used for the creation of this\n      protocol. More complex classification problems, larger datasets, and/or\n      different hardware specifications may require more time.\n    \n      In this stage, we will complete data preprocessing using expression data\n      loaded into MATLAB. Preprocessing is a crucial part of quality control for\n      RNA expression data. Data preprocessing aims to reduce noise and technical\n      variability within our data. Preprocessing includes data normalization,\n      visualization, batch effect and outlier detection, and finally, filtering.\n      Technical outliers and batch effects are detected iteratively, by\n      visualizing data variability and similarity through plots and unsupervised\n      learning techniques. For more information on batch effects, see\n      before you begin[href=https://www.wicell.org#before-you-begin] –\n      minimizing batch effects[href=https://www.wicell.org#sec1.6].\n    \n      Potential technical outliers and/or batch effects are identified through\n      boxplots, mean Spearman correlation, interquartile range (IQR), and\n      hierarchical clustering. On the correlation and IQR scatterplots, samples\n      are marked as potential outliers if they fall below the lower outlier\n      boundary. This boundary is calculated using the IQR method of outlier\n      detection and is dependent on the number of samples and range of the\n      data.38[href=https://www.wicell.org#bib38] All plots are investigated, and\n      laboratory notes (if available) are reviewed to expose and explain any\n      technical issues. Any identified technical outliers and batch effects are\n      removed before subsequent analyses.\n    \n      The working example for this stage is miRNA expression data from 16\n      different NEN types (Table S1[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc2.csv]).\n      Table S1[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc2.csv]\n      contains four header rows: sample IDs, lane IDs, epithelial or\n      non-epithelial status, and NEN pathological type, respectively. The first\n      column contains miRNA names, and the remaining columns have miRNA sequence\n      raw read counts.\n    \n      The following files from the Supplementary Materials serve as example data\n      for this stage:\n    \n      Example of input for this stage:\n      Table S1[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc2.csv].",
    "Example of output for this stage: Stage1_workspace.mat,\n      Table S2[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc3.csv].\n    \nCritical: Before you proceed make sure\n      to follow the MATLAB and MFeaST installation and directory set-up\n      outlined in the before you begin[href=https://www.wicell.org#before-you-begin] -\n      software installation and directory set-up section[href=https://www.wicell.org#sec1.10].\n    \n        Load data into MATLAB: Open the preprocessing_script.m script\n        found in the Neuroendocrine_neoplasms directory. In the MATLAB\n        user interface, select Open from the Files section under the Home\n        tab (Figure 2[href=https://www.wicell.org#fig2]). Follow this step to open any\n        programming code (.m files) in this protocol.\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig2.jpg\n              Figure 2. Open programming (.m) files and evaluate code in MATLAB\n            \n              To open a .m file in MATLAB, select the Open button from\n              the Editor tab toolbar (Stage 1, step 1). To evaluate a\n              line or multiple lines of code from a script in MATLAB, highlight\n              the line(s) of code and right click. Select the “Evaluate\n              Selection in Command Window”. This will run the highlighted code\n              in the command window. If the code generates a variable, the\n              variable name will appear in the MATLAB workspace panel (Stage 1,\n              step 2). Double click on a variable in the MATLAB workspace to see\n              its content.\n            \nNote: In the script file,\n          comments[href=https://www.mathworks.com/help/matlab/matlab_prog/comments.html]\n          are included to describe the code (may appear green, preceded by %).\n          However, these comments are not shown in the code blocks in the\n          protocol text.\n        \n        Read the input data (Table S1[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc2.csv]) into MATLAB by running the following commands from the\n        preprocessing_script.m. In MATLAB, you can highlight lines of\n        code in a script and evaluate them in the command window:\n        \n            Select the following line of code (Figure 2[href=https://www.wicell.org#fig2]):\n            \ndata =\n                  readcell('project_data/Supplementary_Table1.csv');\n            Right-click the selection to open the drop-down menu. Click\n            “Evaluate Selection in Command Window” (Figure 2[href=https://www.wicell.org#fig2]) to execute the highlighted code. The code reads\n            Supplementary_Table1.csv into the data variable. This",
    "newly created variable will appear in the MATLAB workspace (Figure 2[href=https://www.wicell.org#fig2]). Follow this step to execute any code statement in MATLAB.\n            \nNote: In MATLAB, an error message\n              is displayed in the command window when a line of code cannot be\n              executed. See problem 3[href=https://www.wicell.org#sec6.5] if the following\n              error is displayed when executing the above code statement: “Unable to find or open\n                'project_data/Supplementary_Table1.csv'. Check the path\n                and filename or file permissions.”\n            \n        Double-click the data variable under the workspace panel (Figure 2[href=https://www.wicell.org#fig2]) to view the contents in the variables window. Follow this step to\n        view the contents of any variable in your workspace.\n      \n        Retrieve information on sample processing to sort the data into batches\n        (See before you begin[href=https://www.wicell.org#before-you-begin] –\n        minimizing batch effects[href=https://www.wicell.org#sec1.6]).\n        \nNote: In this protocol we use the lane\n          ID of the sequencing machine. Alternatively, the date of processing\n          can be used as the batch information. If lane ID information is not\n          available, see problem 4[href=https://www.wicell.org#sec6.7].\n        \n            Assign the row and column numbers corresponding to the start of the\n            numeric expression data within data to row_start and\n            col_start, respectively. Assign the row number for the row\n            with sample processing information (lane IDs) to the sort_by_row\n            variable.\n            \nrow_start = 5;\ncol_start = 2;\nsort_by_row = 2;\nNote: In-text code snippets do not\n              show comments included in the .m files (scripts).\n            \n            Retrieve lane IDs from data using sort_by_row and\n            col_start. Assign this value to the\n            sort_by_data variable. This is an example of\n            indexing[href=https://www.mathworks.com/company/newsletters/articles/matrix-indexing-in-matlab.html]\n            in MATLAB.\n            \nNote: Indexing in MATLAB starts\n              with 1 and not 0.\n            \nsort_by_data = cell2mat(data(sort_by_row,\n                  col_start:end));\n            Arrange sort_by_data by lane ID, if applicable, using the\n            sort[href=https://www.mathworks.com/help/matlab/ref/sort.html]\n            function.\n            \nNote: The first output of the\n              sort[href=https://www.mathworks.com/help/matlab/ref/sort.html]\n              function is the sorted input (sort_by_data). The second\n              output of the\n              sort[href=https://www.mathworks.com/help/matlab/ref/sort.html]\n              function, sort_idx, stores the indices that can be used to",
    "sort the original sort_by_data or any other data of the\n              same size.\n            \n[sort_by_data,sort_idx] = sort(sort_by_data);\n            Apply the sorting order to data using sort_idx. The\n            column index is adjusted to account for the header columns in\n            data, represented by col_start-1.\ndata = data(:,[1:col_start-1 sort_idx+col_start-1]);\n        Normalize data: Normalize the raw read counts in the\n        data variable using the custom\n        sampleNormalizationRF function.\n        \nNote: This function divides the read\n          count of each miRNA for a given sample, by the total read counts of\n          that sample. Assign the normalized data to the\n          norm_data variable.\n        \nnorm_data = data;\nnorm_data(row_start:end, col_start:end) = ...\n  num2cell(sampleNormalizationRF(cell2mat(data(row_start:end,\n              col_start:end))));\nNote: Data normalization reduces\n          systematic technical and experimental variation while preserving\n          biological variation. Normalization converts raw sequence read counts\n          to normalized measures of gene expression that can be compared between\n          samples. If the data in the data variable from Stage 1, step 2,\n          are already normalized, see problem 5[href=https://www.wicell.org#sec6.9] and skip\n          Stage 1, step 5. If the data in the data variable are not\n          miRNA-Seq data, see problem 6[href=https://www.wicell.org#sec6.11] and skip Stage 1,\n          step 5.\n        \n        Visualize data with boxplots to observe deviations in the distribution\n        of data:\n        \nOptional: Log2\n          transform the positively skewed expression data to resemble a normal\n          distribution and therefore improve its visualization. Steps 6a-b\n          describe how to log2 transform your data. If you do not\n          wish to log2 transform your data, see\n          problem 7[href=https://www.wicell.org#sec6.13].\n        \n            First, replace any zero values in norm_data with a computed\n            low value using the custom replaceZeros function. This low\n            value is of the same magnitude as the smallest value in the data.\n          \n            Assign the log2 transformed data to the\n            transform_data variable.\n            \ntransform_data = ...\nlog2(replaceZeros(cell2mat(norm_data(row_start:end,col_start:end)),\n                  'lowval'));\nNote: The ... (ellipses) indicate line\n      continuation in MATLAB, i.e., the line of code continues onto the next",
    "line. In the protocol text, the ... are shown when a line of code does not\n      fit in one line of the code block. The ... may or may not appear in the\n      corresponding line of the MATLAB script.\n    \n        Plot the log2 transformed miRNA expression data\n        (transform_data) as boxplots using the custom\n        makeBoxplot function. The resultant plot is provided in\n        Figure 3[href=https://www.wicell.org#fig3]A.\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig3.jpg\n              Figure 3. Boxplots of log2 transformed normalized data\n            \n              To visualize the distribution of miRNA expression across samples,\n              generate boxplots of (A) the unfiltered expression data and\n              (B) the 90th quantile filtered expression data. The\n              x-axis corresponds to the samples in the order they were\n              processed, and the y-axis represents the log2\n              transformed, relative frequency normalized expression values. See\n              Stage 1, steps 7–10 for more information.\n            \nNote: If batch information is\n          available (i.e., sort_by_data contains numeric batch\n          information), vertical lines for each sequencing batch appear between\n          the boxplots. Otherwise, replace sort_by_data with an empty\n          vector ([]) in the code below or see problem 4[href=https://www.wicell.org#sec6.7].\n        \nmakeBoxplot(transform_data, norm_data(1, col_start:end),\n              ...\n  'Samples', 'log_2 normalized\n              expression',\n              sort_by_data,'showTickLabels',false);\nOptional: The\n          makeBoxplot function has an optional parameter,\n          ‘showTickLabels’ that can be set to true (1) or false (0) to\n          either show or hide the sample IDs on the x-axis, respectively. We set\n          this property to false to improve the plot appearance. You may set\n          this property to true to show the x-axis tick labels.\n        \nOptional: MATLAB figures can be\n          saved in various formats; see the MATLAB documentation to\n          interactively export figures[href=https://www.mathworks.com/help/matlab/creating_plots/saving-your-work.html]. You may also adjust the\n          size, resolution, or background color of the figure[href=https://www.mathworks.com/help/matlab/creating_plots/save-figure-at-specific-size-and-resolution.html]. See problem 8[href=https://www.wicell.org#sec6.15] to customize a figure before\n          export.\n        \n        To improve boxplot visualizations, filter the data to remove low\n        expressed miRNAs. A low expressed miRNA has expression below a set",
    "threshold value in a given percent of samples per class. Identify low\n        expressed miRNAs using the markLowCountsInGroups function.\n        \n            Set filtering parameters. Set the threshold to 0.9 quantile of\n            overall expression (threshold) in 5% of samples\n            (percent) in each pathological category\n            (category_row).\n            \nthreshold = 0.9;\npercent = .05;\ncategory_row = 4;\nNote: Regarding the filtering\n              parameters: for threshold, select a value between 0–1 for\n              the overall expression quantile at which to establish the\n              threshold. The higher the value, the more miRNAs will be filtered.\n              For percent, select a value between 0–1 for the percent of\n              samples in each category that must pass the threshold for a given\n              miRNA. The higher the percent value, the more miRNAs will be\n              filtered. For category_row, select the row number\n              corresponding to the category to use for filtering. Ideally select\n              the row with the most specific category. For example, NEN\n              pathological type (row 4) is more specific than epithelial type.\n            \n            Create a\n            logical index[href=https://www.mathworks.com/help/matlab/matlab_prog/find-array-elements-that-meet-a-condition.html]\n            for the miRNAs marked as low expressed using the custom\n            markLowCountsInGroups function.\n            \nNote: The function returns a\n              logical vector that is the same size as the number of miRNAs in\n              the input data. False (0) is for miRNAs that are above the\n              threshold in equal or greater percent of samples in\n              at least one class, and true (1) otherwise.\n            \nind_to_rm =\n                  markLowCountsInGroups(cell2mat(norm_data(row_start:end,\n                  ...\ncol_start:end)), threshold, percent, ...\ncategorical(norm_data(category_row,col_start:end)));\n            Extract only those miRNAs that are not marked as low expressed from\n            transform_data. Save the filtered data as filt_data.\nfilt_data = transform_data(∼ind_to_rm,:);\nNote: To keep features that are\n              marked as false in the ind_to_rm variable (i.e., are above\n              the threshold) the ∼ (NOT) operator is required. This will convert\n              all previously false (0) values to true (1) values.\n            \n        Plot filtered miRNA expression data (filt_data) as a boxplot for",
    "each sample using the custom makeBoxplot function as described in\n        Stage 1, step 7. The resultant plot is provided in\n        Figure 3[href=https://www.wicell.org#fig3]B.\n      \nNote: If batch information is not\n      available, replace sort_by_data with an empty vector ([]) in the\n      code below or see problem 4[href=https://www.wicell.org#sec6.7].\n    \nmakeBoxplot(filt_data, norm_data(1, col_start:end), ...\n'Samples', 'log_2 normalized expression',\n          sort_by_data, ...\n'showTickLabels', false);\n        Visually assess the boxplots and note any individual or groups of\n        samples that form a different pattern from all others.\n      \nNote: When using transcriptome-wide data,\n      the median values should be similar across samples. However, samples that\n      have very different medians may have been subject to technical issues\n      during RNA isolation, library construction, and/or sequencing. Samples\n      with medians lower than the rest or 0 should be noted. Continue observing\n      these samples in subsequent visualizations to determine if they are\n      technical outliers and/or batch effects. As an example, observe the first\n      batch in Figures 3[href=https://www.wicell.org#fig3]A and 3B. The medians of samples in\n      the batch are consistently below the rest of the samples.\n    \n        Detect sample outliers and/or batch effects: Create two empty\n        cell arrays[href=https://www.mathworks.com/help/matlab/ref/cell.html?s_tid=doc_ta], samples2remove and samples2investigate, for the sample\n        IDs of samples marked for removal or requiring further investigation,\n        respectively.\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig4.jpg\n              Figure 4. Workflow to detect outliers and batch effects\n            \n              To iteratively detect outliers and/or batch effects for removal,\n              follow the corresponding steps in Stage 1.\n            \nsamples2remove = {};\nsamples2investigate = {};\nNote: The process of detecting technical\n      outliers and batch effects is summarized in Figure 4[href=https://www.wicell.org#fig4].\n    \nNote: Although “batch effect correction”\n      algorithms have been proposed as an alternative to removal, we do not\n      recommend this approach. It is not possible to model the technical issues\n      that initially caused the batch effect. In addition, batch effect\n      correction methods are unable to compensate for data loss or corruption",
    "caused by technical issues. Instead, there is a high risk that the\n      correction will only introduce noise into the data. See Goh et al.,24[href=https://www.wicell.org#bib24]\n      Jaffe et al.,26[href=https://www.wicell.org#bib26] Nygaard et al.39[href=https://www.wicell.org#bib39]\n        Investigate potential outliers and/or batch effects with mean Spearman\n        correlation: Calculate the mean Spearman correlation of each normalized\n        miRNA expression profile to all other profiles, using the custom\n        SampleCorrelation function. Assign the resulting vector of mean\n        correlation values to mean_corr.\nmean_corr =\n          sampleCorrelation(cell2mat(norm_data(row_start:end,...\ncol_start:end)), 'Spearman');\nCritical: The correlation analysis\n      assumes that when compared transcriptome-wide, samples are similar to each\n      other. We expect to see moderately high to high (0.6+) mean Spearman\n      correlation values. Granted, this expectation depends on the biological\n      similarity of samples, source, and quality of the sequencing data. This\n      assumption is not true for a subset of genes or miRNAs (i.e., not\n      transcriptome wide).\n    \n        Use the scatterplotMarkOutliers function to plot the mean\n        Spearman correlation for all samples.\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig5.jpg\n              Figure 5. Correlation analysis to assess the similarity of\n              expression profiles and identify possible outliers and batch\n              effects\n            \n              The x-axis corresponds to the samples in the order they were\n              processed, and the y-axis represents the mean Spearman correlation\n              of each sample to all other samples. The horizontal red line\n              represents the outlier boundary. Vertical dashed lines separate\n              batches. Samples below the outlier boundary are considered\n              potential outliers and are further investigated. Batch effects are\n              identified as batches or consecutively processed samples that, as\n              a group, have lower correlation relative to other samples. The\n              first two batches, Batch 183 and 205 (red arrows) have lower mean\n              Spearman correlation than all other samples and are selected for\n              removal. See Stage 1, step 14 for more information.\n            \nNote: The first output\n      (corr_outliers) of the function is a logical variable with true (1)\n      values for samples below the lower outlier boundary. The second output",
    "(corr_outliers_IDs) contains the sample IDs for the marked samples.\n      If batch information is available (i.e., sort_by_data contains\n      numeric batch information), vertical lines indicating boundaries for each\n      sequencing batch are added to the plot. Otherwise, set\n      sort_by_data to an empty vector ([]) in the code below or see\n      problem 4[href=https://www.wicell.org#sec6.7]. The resultant plot is provided in\n      Figure 5[href=https://www.wicell.org#fig5].\n    \n[corr_outliers,corr_outliers_IDs] =\n          scatterplotMarkOutliers(mean_corr, ...\n  'ColumnLabels', norm_data(1, col_start:end),\n          ...\n  'xlabel','Samples',...\n  'ylabel', 'Mean Spearman\n          correlation',...\n  'PlotTitle','Mean Spearman correlation\n          between miRNA profiles',...\n  'Batch',\n          sort_by_data,'ShowXTickLabel',false);\n        Inspect the mean Spearman correlation plot (Figure 5[href=https://www.wicell.org#fig5]). Note any batch effects or sample outliers that fall below the lower\n        outlier boundary.\n        \n            Identify potential batch effects.\n            \nNote: Samples belonging to the\n              same batch that have low correlation relative to other samples,\n              may have been affected by batch effects. This is the case for the\n              first two batches in Figure 5[href=https://www.wicell.org#fig5]. If no batch\n              effects are identified, proceed to Stage 1, step 14b. In our\n              example, two batch effects are identified. Batches 205 and 183\n              both have mean Spearman correlations noticeably below the rest of\n              the samples (Figure 5[href=https://www.wicell.org#fig5]).\n            \n                Use the data tips button in the figure\n                axes toolbar[href=https://www.mathworks.com/help/matlab/creating_plots/interactively-explore-plotted-data.html]\n                to identify the batch ID for a selected sample. See\n                problem 9[href=https://www.wicell.org#sec6.17] on data tip functionality.\n              \n                Remove identified batch effects. Assign the numeric batch IDs\n                for batches 183 and 205 to batch2remove. All samples\n                included in that batch are then\n                concatenated[href=https://www.mathworks.com/help/matlab/math/creating-and-concatenating-matrices.html]\n                to samples2remove.\nbatch2remove = [183,205];\nsamples2remove = [samples2remove ; norm_data(1,\n                      [false(1,col_start-1), ...\n  ismember(sort_by_data,batch2remove)])'];\nNote: In the code above, the\n                  semicolon operator is used for vertical concatenation.\n                \nCritical: Not all samples\n                  in the batch must be below the lower outlier boundary to be\n                  identified as a batch effect. Nonetheless, all samples within\n                  the batch are impacted and are marked for removal. In our\n                  example, none of the samples from batches 205 and 183 fell",
    "below the outlier boundary (Figure 5[href=https://www.wicell.org#fig5]).\n                  However, these samples had a pattern of lower correlation\n                  relative to all other samples.\n                \n            Identify technical outliers as samples that fall below the red\n            outlier boundary in the mean Spearman correlation plot and have a\n            correlation score less than 0.6. If you do not identify any\n            outliers, proceed to Stage 1, step 15. In our example, INET 17 and\n            PanNET 29 are likely to be technical outliers (Figure 5[href=https://www.wicell.org#fig5]).\n            \nNote: Samples falling below the\n              outlier boundary are not always technical outliers. If the data\n              consist of a subset of genes or are not transcriptome-wide,\n              samples will be less correlated to each other, and a lower\n              correlation cut-off than 0.6.\n            \n                Concatenate the selected technical outliers (INET 17, PanNET 29)\n                to samples2remove.\nsamples2remove = [samples2remove; {'INET\n                      17';'PanNET 29'}];\n        Add the samples IDs for those samples marked as outliers on the\n        correlation plot but have a mean correlation greater than or equal to\n        0.6, to the samples2investigate vector. In our example, these\n        samples are: NB 27, NB 28, AppNET 1, AppNET 8, INET 22, PanNET 13, and\n        LCNEC 16.\n      \nsamples2investigate = [samples2investigate; {'NB 27';'NB\n          28';...\n'AppNET 1';'AppNET 8'; 'INET 22';'PanNET\n          13';'LCNEC 16'}];\n        Investigate potential outliers and/or batch effects with IQR: Calculate\n        the IQR of the normalized, transformed miRNA expression data for each\n        profile, using the\n        iqr[href=https://www.mathworks.com/help/matlab/ref/iqr.html]\n        function. Assign the output to iqr_data.\nNote: IQR is a robust measure of\n      variability in your data. A high IQR is expected for transcriptome-wide\n      expression data. A low IQR indicates low variability in expression and may\n      be due to technical issues affecting sample quality.\n    \nNote: Log2 transformation is\n      optional, see problem 7[href=https://www.wicell.org#sec6.13] if you decide not to\n      log2 transform your data. See Stage 1, step 6 for details on\n      log2 transformation and the custom\n      replaceZeros function.\n    \ntransform_data =\n          log2(replaceZeros(cell2mat(norm_data(row_start:end,...\ncol_start:end)),'lowval'));",
    "iqr_data = iqr(transform_data);\n        Use the custom scatterplotMarkOutliers function to plot the IQR\n        values (iqr_data). See Stage 1, step 13 for details on the\n        scatterplotMarkOutliers function.\n      \nNote: If batch information is not\n      available, do not define this parameter, or see\n      problem 4[href=https://www.wicell.org#sec6.7].\n    \n[iqr_outliers, iqr_outliers_IDs] = scatterplotMarkOutliers(iqr_data,\n          ...\n  'ColumnLabels', norm_data(1,\n          col_start:end),...\n  'xlabel', 'Samples',...\n  'ylabel', 'IQR',...\n  'PlotTitle','RF Normalized IQR',\n          ...\n  'Batch',sort_by_data,'ShowXTickLabel',false);\n        Inspect the IQR plot (Figure 6[href=https://www.wicell.org#fig6]).\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig6.jpg\n              Figure 6. Detect batch effects and outliers using data variability\n            \n              The variability of expression in each sample is visualized using\n              Interquartile Range (IQR). The x-axis corresponds to the samples\n              in the order they were processed, and the y-axis represents the\n              IQR for the expression profiles. The horizontal red line\n              represents the outlier boundary. Vertical dashed lines separate\n              batches. Since molecular expression data are expected to vary\n              between expression values, very low IQR values below the outlier\n              boundary may indicate a technical effect. Samples with IQR = 0\n              should be removed as no variation across all gene expression\n              likely indicates a technical issue. See Stage 1, step 17–18 for\n              more information.\n            \n            Identify individual samples and/or batches that fall below the\n            outlier boundary and/or have lower IQR relative to other samples.\n            Cross reference these samples with the sample IDs in the\n            samples2investigate vector (Stage 1, step 15).\n          \n            Add all samples with an IQR of 0 to samples2remove.\nFigure 6[href=https://www.wicell.org#fig6] shows six samples with an IQR of 0,\n            including PanNET 29, which was already added to\n            samples2remove in Stage 1, step 14b.\n          \nsamples2remove = [samples2remove ; {'NB 27'; 'INET\n          22'; 'PanNET 13'; ...\n'LCNEC 16'; 'PanNET 14'}];\nNote: If your data consist of a subset of\n      genes or are not transcriptome-wide, it is possible that the IQR is low,\n      implying low variability between genes. However, you should carefully",
    "investigate samples with IQR of 0 to make sure there are no technical\n      issues with these samples.\n    \nCritical: When using publicly\n      available data or if stringent data quality is required, add all samples\n      in samples2investigate that fall below the IQR outlier boundary to\n      the samples2remove vector:\n    \nsamples2remove = [samples2remove ; iqr_outliers_IDs];\n        Remove any samples from the samples2investigate list that were\n        added to the samples2remove list.\n      \n[∼,ind] =\n          intersect(samples2investigate,samples2remove,'stable');\nsamples2investigate(ind) = [];\n        Investigate potential outliers and/or batch effects with unsupervised\n        hierarchical clustering: Prepare data and select parameters for\n        unsupervised hierarchical clustering.\n        \nNote: In MATLAB, a clustergram is a\n          heatmap and dendrogram. The dendrogram is generated through\n          unsupervised hierarchical clustering. The heatmap shows the values in\n          the data (e.g., expression level) that inform clustering.\n        \n            Log2 transform the normalized data as described in Stage\n            1, step 6.\n            \ntransform_data =\n                  log2(replaceZeros(cell2mat(norm_data(row_start:end,...\ncol_start:end)),'lowval'));\nNote: Log2\n              transformation is optional. If you decide not to log2\n              transform your data, skip Stage 1, step 20a and see\n              problem 7[href=https://www.wicell.org#sec6.13].\n            \n            For better visualization of the heatmap, median center the log2\n            transformed data. Subtract the overall median value from the\n            transformed expression values (transform_data).\n            \ntransform_data_median_centered =transform_data -\n                  median(transform_data, 'all');\n            Determine the display range parameter for the heatmap of the\n            clustergram by generating boxplots of the median-centered data.\n            \nNote: Display range indicates the\n              range of standardized values for which there will be color\n              variation in the heatmap. If lane ID information is not available,\n              replace sort_by_data with an empty vector ([]) in the code\n              below or see problem 4[href=https://www.wicell.org#sec6.7]. See Stage 1, step 7\n              for more on the makeBoxplot function.\n            \nmakeBoxplot(transform_data_median_centered, ...\n  norm_data(1, col_start:end), 'Samples',\n                  ...\n'log_2 normalized median centered expression',\n                  ...\n  sort_by_data,'showTickLabels',false);\n            Observe the boxplot and choose the display_range value based\n            on the upper quartile of majority of the plotted boxes. A boxplot\n            for the median-centered expression is shown in",
    "Figure 7[href=https://www.wicell.org#fig7]. In our example, the\n            display_range is set to 7 (red arrow in\n            Figure 7[href=https://www.wicell.org#fig7]). A display range of 7 means there is\n            color variation for values between −7 to 7.\n            \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig7.jpg\n                  Figure 7. Select the display range for the clustergram using\n                  boxplots\n                \n                  To identify the display range input for the clustergram (Stage\n                  1, step 21), generate boxplots of the median centered\n                  expression data. The x-axis corresponds to the samples in the\n                  order they were processed, and the y-axis represents the\n                  median centered, log2 transformed, relative\n                  frequency normalized, expression data. Select the display\n                  range as an estimate of the upper quartile for majority of the\n                  boxplots. The red arrow indicates a display range of 7. See\n                  Stage 1, step 20 for more information.\n                \ndisplay_range = 7;\n        Generate a clustergram of expression profiles using the\n        clustergram function (Figure 8[href=https://www.wicell.org#fig8]).\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig8.jpg\n              Figure 8. Detect batch effects and outliers using a clustergram\n            \n              To detect potential outliers and/or batch effects that do not\n              cluster with other samples, generate a clustergram. Clustergrams\n              evaluate the hierarchical clustering pattern of samples and\n              visualize the patterns with a dendrogram and accompanying heatmap.\n              The colorbar on the left displays the heatmap colors scaled to the\n              plotted expression values. The dendrogram at the top displays\n              sample clustering with Spearman correlation as the distance\n              metric. The dendrogram on the left shows clustering of features or\n              miRNAs, with Euclidean distance as the distance metric. This\n              clustergram identifies LCNEC 16 and PanNET 29 as outliers because\n              they cluster away from all other LCNEC and PanNET samples,\n              respectively. See Stage 1, step 21–22 for more information.\n            \nNote: Set the ‘RowLabels’ property\n      to the miRNA names, and the ‘ColumnLabels’ property to the sample\n      IDs. Set the column distance metric, ‘ColumnPDist’ to “Spearman”.\n      Set the row distance metric, ‘RowPDist’, to “Euclidean.” Set the",
    "‘DisplayRange’ parameter as determined in Stage 1, step 20d. Set\n      the ‘Colormap’ to a colormap of your choice. Here, we use the red-blue\n      custom\n      colormap[href=https://www.mathworks.com/help/matlab/ref/colormap.html]\n      (custom_colorMap_RedBlue). The hierarchical clustering and heatmap\n      parameters are further explained in the\n      MATLAB documentation[href=https://www.mathworks.com/help/bioinfo/ref/clustergram.html]\n      and in Stage 2 of this protocol.\n    \ncg = clustergram(transform_data_median_centered,...\n  'RowLabels', norm_data(row_start:end, 1),\n          ...\n  'ColumnLabels',norm_data(1, col_start:end),\n          ...\n  'ColumnPDist','spearman',...\n  'RowPDist','euclidean',...\n  'Colormap', custom_colorMap_RedBlue,...\n  'DisplayRange',display_range);\nNote: Samples are located on the x-axis of\n      the clustergram. To view the individual values or sample IDs for a given\n      column in the heatmap, click the data tips button on the figure toolbar.\n      Then click on any point in the heatmap to view its value and sample ID.\n      See problem 9[href=https://www.wicell.org#sec6.17] for more information.\n    \n        Inspect the clustergram and mark individual or batches of samples that\n        unexpectedly cluster separately from all other samples.\n      \nNote: These potential outlier samples will\n      likely be on either edge of the clustergram. Cross reference these samples\n      with those identified as potential outliers in the mean Spearman\n      correlation scatterplot (Stage 1, steps 13–14) and IQR scatterplots (Stage\n      1, steps 17–18). Samples that were marked as outliers in the mean Spearman\n      correlation scatterplot and do not cluster with other samples, should be\n      removed. In our example, samples PanNET 29 and LCNEC 16 cluster separately\n      from others (Figure 8[href=https://www.wicell.org#fig8]), supporting the decision to\n      remove them.\n    \nNote: If your data includes samples from\n      different biological classes, you may see samples clustering separately,\n      but with others of the same biological class. If this is the case, these\n      samples would not be considered outliers. Instead, samples that (a) do not\n      form clusters and/or are away from all others or (b) form clusters based\n      on their batch information, should be inspected.\n    \n        Remove individual sample outliers and batch effects: Review the samples\n        in the samples2investigate variable and determine whether their",
    "outlier status is due to technical issues or biological differences.\n      \nNote: To identify technical issues, review\n      laboratory notes to see if discrepancies in sample processing or nucleic\n      acid isolation, library preparation, sequencing, analysis, or other issues\n      may have occurred. Add samples where technical issues were identified to\n      the samples2remove vector, as shown in Stage 1, step 14b,i.\n      Otherwise, no action is required because the variation is possibly due to\n      biological differences. In our example, samples AppNET 1, AppNET 8, and NB\n      28 (Stage 1, step 15) are kept since no technical explanation was\n      identified.\n    \n        Find the\n        indices[href=https://www.mathworks.com/company/newsletters/articles/matrix-indexing-in-matlab.html]\n        for outlier samples (samples2remove), in the normalized\n        expression data (norm_data), using the\n        intersect[href=https://www.mathworks.com/help/matlab/ref/double.intersect.html]\n        function.\n      \n[∼,idx2rm] = intersect(norm_data(1,\n          col_start:end),samples2remove,'stable');\n        Remove identified outliers and batch effects. Set the columns for\n        outlier samples (samples2remove) to empty (indicated by ‘[]’\n        syntax) in norm_data and sort_by_data. See MATLAB\n        documentation on\n        indexing[href=https://www.mathworks.com/company/newsletters/articles/matrix-indexing-in-matlab.html].\n      \nnorm_data (:,idx2rm+col_start-1) = [];\nsort_by_data(:,idx2rm) = [];\n        Repeat Stage 1, steps 6–25 to identify and remove additional outliers\n        and/or batch effects, until no new issues are identified. Removal of\n        samples changes the correlation and IQR boundaries; therefore, the\n        repeated round of preprocessing may reveal additional outliers and batch\n        effects that were previously obscured.\n      \nCritical: The data in this example\n      were relative frequency normalized, which is a sample-independent method.\n      Otherwise, when using normalization methods that depend on all samples in\n      a dataset (e.g., TMM, DeSeq), normalization is repeated each time a sample\n      is removed. For more information, see problem 10[href=https://www.wicell.org#sec6.19].\n    \n        Filter preprocessed data: Filter miRNA expression data using the custom\n        markLowCountsInGroups function as described in Stage 1, step 8.\n        Assign the filtered data to the final_filt_data variable.\n      \nNote: For the filtering parameters, set\n      the threshold to 0.9 quantile of overall expression (threshold) in\n      5% of samples (percent) in each pathological category\n      (category_row).\n    \nthreshold = 0.9;\npercent = .05;",
    "category_row = 4;\nmark2remove =\n          markLowCountsInGroups(cell2mat(norm_data(row_start:end,...\ncol_start:end)), threshold, percent, ...\ncategorical(norm_data(category_row, col_start:end)));\nfinal_filt_data = norm_data;\nheaders = false(row_start-1,1);\nfinal_filt_data([headers; mark2remove], :) = [];\nNote: If the variability is very large,\n      i.e., boxes in the boxplot are very long, with a median greater than 0,\n      then you may need to increase your filtering threshold in Stage 1, step\n      27. See problem 11[href=https://www.wicell.org#sec6.21].\n    \n        If you are working with miRNA expression data, remove “STAR”(∗) miRNAs\n        from the dataset.40[href=https://www.wicell.org#bib40] See\n        problem 12[href=https://www.wicell.org#sec6.23] for an explanation on why it is\n        suggested to remove STAR(∗) miRNAs. This step only applies to miRNA\n        expression data. For other data types, skip this step and proceed to\n        Stage 1, step 29.\n        \n            Extract the miRNA names into the feature_names variable.\n            \nfeature_names =\n                  final_filt_data(row_start:end,col_start-1);\n            Mark indices of miRNAs with “STAR” or “∗” in their name using the\n            contains command. True (1) connotes “STAR” miRNAs and false\n            (0) otherwise.\n            \nind_to_rm =\n                  contains(feature_names,{'STAR','∗','star'});\n            Remove all “STAR” miRNA rows by replacing them with the empty (‘[]’)\n            operator. To avoid removing the header rows, concatenate false\n            values corresponding to the number of header rows to\n            ind_to_rm.\nheaders = false(row_start-1,1);\nfinal_filt_data ([headers; ind_to_rm], :) = [];\n        Visualize the final filtered data using the makeBoxplot function\n        as shown in Stage 1, steps 6–7.\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig9.jpg\n              Figure 9. Boxplots of preprocessed miRNA expression data filtered\n              at 90th quantile\n            \n              To remove low expressed features, the expression profiles are\n              filtered at the 90th quantile of expression (Stage 1,\n              step 27). Generate boxplots to visualize the distribution of the\n              preprocessed, filtered miRNA expression profiles. The x-axis\n              corresponds to the samples in the order they were processed, and\n              the y-axis represents the log2 transformed, normalized\n              expression values. See Stage 1, steps 27–29 for more information.\n            \nNote: If lane ID information is not\n      available, set sort_by_data to an empty vector ([]) in the code",
    "below or see problem 4[href=https://www.wicell.org#sec6.7]. The boxplots for the\n      filtered data, with outliers removed, are provided in\n      Figure 9[href=https://www.wicell.org#fig9].\n    \ntransform_data = ...\nlog2(replaceZeros(cell2mat(final_filt_data(row_start:end,\n          col_start:end))));\nmakeBoxplot(transform_data, norm_data(1, col_start:end), ...\n  'samples', 'log_2 normalized\n          expression',sort_by_data);\n        Save the preprocessed and filtered data.\n        \n            Assign the final versions (i.e., with outliers removed) of\n            norm_data and transform_data to\n            final_norm_data and\n            final_transform_data, respectively.\n            \nfinal_transform_data = transform_data;\nfinal_norm_data = norm_data;\n            Use the clearvars function to clear variables from your\n            workspace that are not required for the upcoming steps. The\n            -except option indicates which variables to keep while\n            clearing the rest.\n            \nclearvars -except final_norm_data final_transform_data\n                  final_filt_data col_start row_start\n            Save key variables from this stage of the protocol as a .mat file,\n            Stage1_workspace using the save function. These\n            intermediate workspace files (.mat) may be loaded into the workspace\n            at any point in the protocol. Navigate to the\n            Neuroendocrine_neoplasms directory before executing the\n            following lines of code:\n            \nsave\n                  (fullfile('project_data','Stage1_workspace.mat'),...\n'final_norm_data', 'final_transform_data',\n                  ...\n'final_filt_data', 'col_start',\n                  'row_start')\nNote: The fullfile function\n              is used to generate a full file name from the text inputs. The\n              function is useful for a protocol that may run across operating\n              systems with different file separators (e.g., / and ∖ are used on\n              Mac and Windows, respectively).\n            \nOptional: Export the finalized\n              data variables final_filt_data and\n              final_norm_data into a CSV file using the\n              writecell function. The example output is provided in\n              Table S2[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc3.csv].\n            \nwritecell(final_filt_data,fullfile('results_data',...\n  'final_filt_dataset.csv'));\nwritecell(final_norm_data,fullfile('results_data',...\n  'final_norm_dataset.csv'));\n      Stage 2: Visualize and explore data using unsupervised learning techniques\n    \nTiming: 20 min–1 h\n      In this stage, we apply unsupervised machine learning techniques to\n      visualize and identify patterns among samples and features (miRNAs, in\n      this case). Here, we analyze preprocessed miRNA expression data using\n      unsupervised hierarchical clustering with heatmaps and t-Distributed\n      Stochastic Neighbor Embedding (t-SNE).\n    \n      Hierarchical clustering is a widely used method for visualizing gene",
    "expression data by building clusters of genes with similar patterns of\n      expression.41[href=https://www.wicell.org#bib41] t-SNE is a dimension\n      reduction and visualization technique that maps high-dimensional data into\n      two or three dimensions while preserving the local structure of the data.\n      To learn more about t-SNE, see Van der Maaten & Hinton.42[href=https://www.wicell.org#bib52]\n      A more experienced user may also explore other dimension reduction\n      techniques such as Uniform Manifold Approximation and Projection\n      (UMAP),43[href=https://www.wicell.org#bib42] Autoencoders (AE)44[href=https://www.wicell.org#bib43]\n      and Variational Autoencoders (VAE)45[href=https://www.wicell.org#bib44] for\n      additional data insights.\n    \nCritical: Clustering is an\n      unsupervised learning technique used for visualization and pattern\n      recognition. It should not be interpreted as a classifier, which is a\n      supervised learning technique.\n    \n      In this stage, we continue to use the preprocessed and filtered miRNA\n      expression data generated in Stage 1 as an example.\n    \n      The following files from the Supplementary Materials serve as example data\n      for this stage:\n    \n      Example of input for this stage:\n      Table S2[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc3.csv].\n    \n        Read the data into the MATLAB workspace: Open the\n        unsupervised_learning_script.m file found in the\n        Neuroendocrine_neoplasms directory.\n      \n        The final_filt_data variable will be used for subsequent\n        visualizations and analyses. final_filt_data was generated in\n        Stage 1, step 27.\n      \nNote: If you are starting from Stage 2\n      and/or do not have this variable in your workspace, load the\n      Stage1_workspace.mat file using the load function. The\n      workspace file is found under the\n      Neuroendocrine_neoplasms/project_data directory.\n    \nload Stage1_workspace.mat\n        Extract the numeric data from final_filt_data into\n        numeric_data using the cell2mat function.\n      \nnumeric_data = cell2mat(final_filt_data(row_start:end,\n          col_start:end));\n        Unsupervised hierarchical clustering with heatmap: Prepare the data and\n        select parameters for unsupervised hierarchical clustering.\n        \n            Log2 transform the normalized data as shown in Stage 1,\n            step 6.\n            \ntransform_data = log2(replaceZeros(numeric_data,\n                  'lowval'));\nNote: Log2\n              transformation is optional, see\n              problem 7[href=https://www.wicell.org#sec6.13] if you decide not to log2\n              transform your data and skip Stage 2, step 34a.\n            \n            For better visualization of the heatmap, median center the log2",
    "transformed data. Subtract the overall median value from all\n            expression values.\n            \ndata_median_centered = transform_data -\n                  median(transform_data, 'all');\n            Generate boxplots of median-centered data to determine the display\n            range parameter for the clustergram. See Stage 1, step 20c for more\n            information.\n            \nmakeBoxplot(data_median_centered, ...\n    final_filt_data(1, col_start:end),\n                  'Samples',...\n  'log_2 normalized median centered\n                  expression');\n            Inspect the boxplot to choose the display_range variable\n            value based on the upper quartile of majority of the plotted boxes.\n            Here, the display_range is set to 5.\n            \ndisplay_range = 5;\n        Use the clustergram function to create the hierarchical\n        dendrogram and heatmap (clustergram) with data_median_centered.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig10.jpg\n              Figure 10. Visualize sample clustering with unsupervised learning\n            \n              To visualize how samples cluster based on their miRNA expression\n              profiles, create a hierarchical dendrogram and heatmap\n              (clustergram). The colorbar on the left displays the heatmap\n              colors scaled to the plotted log2, median-centered,\n              normalized expression values. The dendrogram at the top displays\n              sample clustering with Spearman correlation as the distance\n              metric. The dendrogram on the left displays features (miRNA)\n              clustering with Euclidean distance as the distance metric. See\n              Stage 2, steps 35–36 for more information.\n            \nNote: Set the ‘RowLabels’ property\n      to the feature names, and the ‘ColumnLabels’ property to the sample\n      IDs. Set the column distance metric, ‘ColumnPDist’ to ‘Spearman’.\n      Set the row distance metric, ‘RowPDist’, to ‘Euclidean’. Set the\n      'DisplayRange' parameter to display_range. Set the\n      ‘DisplayRatio’ parameter to 0.1, this will adjust the height of the\n      dendrogram. Here, we use the red-blue custom\n      colormap[href=https://www.mathworks.com/help/matlab/ref/colormap.html]\n      (custom_colorMap_RedBlue) for the heatmap. You can choose a\n      built-in colormap[href=https://www.mathworks.com/help/matlab/ref/colormap.html]\n      or build a custom colormap, see problem 13[href=https://www.wicell.org#sec6.25] for more\n      details. The generated clustergram is shown in\n      Figure 10[href=https://www.wicell.org#fig10].\n    \ncg = clustergram(data_median_centered, ...\n  'ColumnLabels',\n          final_filt_data(1,col_start:end),...\n  'RowLabels', final_filt_data(row_start:end, 1),\n          ...\n  'RowPDist', 'euclidean',...\n  'ColumnPDist', 'spearman', ...\n  'Colormap', custom_colorMap_RedBlue\n  'DisplayRange', display_range, ...\n  'DisplayRatio', 0.1);\n        Click on the “Insert Colorbar” icon on the clustergram figure toolbar",
    "(problem 14[href=https://www.wicell.org#sec6.27]). This will generate a colorbar that\n        displays the heatmap colors scaled to the plotted expression data.\n      \n        To visualize how samples from different biological classes cluster, add\n        corresponding color labels along the horizontal axis. To create the\n        clustergram with color labels, use either option (a) or (b) below\n        depending on the number of biological categories to visualize.\n        \n            Only one category of classes (Figure 11[href=https://www.wicell.org#fig11]); e.g.,\n            only epithelial status.\n            \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig11.jpg\n                  Figure 11. Visualize sample clustering by epithelial status\n                \n                  To visualize if miRNA expression profiles cluster samples by\n                  their epithelial status, add color labels to the samples along\n                  the horizontal axis of the clustergram. The top dendrogram\n                  depicts sample clustering, with Spearman correlation as the\n                  distance measure. Generally, non-epithelial samples (blue) are\n                  clustering away from epithelial samples (pink). However, one\n                  non-epithelial sample in clustering with epithelial samples.\n                  The dendrogram on the left displays feature (miRNA)\n                  clustering, with Euclidean distance as the distance measure.\n                  The colorbar on the left displays the heatmap colors scaled to\n                  the plotted log2 median-centered, normalized\n                  expression values. See Stage 2, step 37a for more information.\n                \n                Generate a clustergram as described in Stage 2, step 35, but set\n                the ‘LabelsWithMarkers’ option to true (1).\n                \ncg_a = clustergram(data_median_centered, ...\n  'ColumnLabels',\n                      final_filt_data(1,col_start:end),...\n  'RowLabels',\n                      final_filt_data(row_start:end, 1), ...\n  'RowPDist',\n                      'euclidean',...\n  'ColumnPDist', 'spearman',\n                      ...\n  'Colormap',\n                      custom_colorMap_RedBlue,...\n  'DisplayRange',\n                      display_range,...\n  'DisplayRatio', 0.1,...\n  'LabelsWithMarkers', true);\n                Assign the row number for the chosen category in\n                final_filt_data to category_row. In our example,\n                category_row is set to 3, which is the epithelial\n                category for the NENs data.\n                \ncategory_row = 3;\n                Create a matrix of\n                RGB triplets[href=https://www.mathworks.com/help/matlab/ref/colorspec.html].\n                \nNote: Each triplet is a 1-by-3\n                  vector of values between 0–1 and represents a color for each\n                  unique class in the chosen category. “Epithelial” samples are\n                  pink ([1 0 0.5]) and “Non-epithelial” samples are light blue",
    "([0.43 0.71 1]). For an example with more than two unique\n                  classes in a category, see problem 15[href=https://www.wicell.org#sec6.29].\n                  To scale from 1–255 RGB scale to a 0–1 scale, see\n                  problem 16[href=https://www.wicell.org#sec6.31].\n                \ncolors = [1 0 0.5;0.43 0.71 1];\nNote: The epithelial status of\n                  samples is considered “prior knowledge,” as it provides\n                  information about the data aside from the features and most\n                  specific class labels. The prior knowledge (epithelial status)\n                  is used to create class labels for the complete hierarchical\n                  classifier, as described in Nanayakkara et al.12[href=https://www.wicell.org#bib12]\n                  Similarly, prior knowledge of the embryonic origin of NETs\n                  informs class labels in Stage 3, step 48.\n                \n                Use the custom clustergramLabel function with three\n                inputs: sample IDs, the class labels in the chosen category, and\n                the color matrix (colors). The output variable combines\n                both the class labels and associated colors into a\n                structure array[href=https://www.mathworks.com/help/matlab/ref/struct.html], color_labels.\ncolor_labels =\n                      clustergramLabel(final_filt_data(1,col_start:end),...\nfinal_filt_data(category_row,col_start:end),colors);\nNote: A warning may appear in\n                  the command window:\n                  “Warning: COLUMNLABELSCOLOR is not supported and will be\n                    removed in a future release. Use LabelsWithMarkers\n                    for similar functionality.”\n                  This warning will not result in an error and can be ignored or\n                  turned off.\n                \n                Set color_labels as the input for the\n                ‘ColumnLabelsColor’ property for the clustergram,\n                cg_a.\nset(cg_a, 'ColumnLabelsColor',\n                      color_labels);\n            More than one category of classes (Figure 12[href=https://www.wicell.org#fig12]);\n            e.g., epithelial status and pathological type.\n            \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig12.jpg\n                  Figure 12. Visualize sample clustering by both epithelial\n                  status and pathological type\n                \n                  To visualize clustering of samples by epithelial status and\n                  pathological type, add two rows of color labels along the\n                  horizontal axis of the clustergram. The first row of color\n                  labels represents the epithelial status of the samples. The\n                  second row of color labels represents the pathological type of\n                  the samples, listed in the legend to the right. The dendrogram\n                  on the top displays sample clustering, with Spearman",
    "correlation as the distance metric. The dendrogram on the left\n                  displays feature clustering, with Euclidean distance as the\n                  distance metric. The colorbar on the left displays the heatmap\n                  colors scaled to the plotted log2 median-centered,\n                  normalized expression values. See Stage 2, step 37b for more\n                  information.\n                \n                Generate a clustergram as described in Stage 2, step 35.\n                \ncg_b = clustergram(data_median_centered, ...\n'ColumnLabels',\n                      final_filt_data(1,col_start:end),...\n'RowLabels', final_filt_data(row_start:end, 1),\n                      ...\n'RowPDist', 'euclidean',...\n'ColumnPDist', 'spearman', ...\n'Colormap', custom_colorMap_RedBlue,...\n'DisplayRange', display_range, ...\n'DisplayRatio', 0.1);\n                Create an empty color_labels structure array to store\n                multiple sub-structures corresponding to each category to be\n                labeled.\n                \ncolor_labels = struct();\n                In this example, there are two categories: epithelial status and\n                NEN pathological type. Indicate the row numbers for the\n                categories in the final_filt_data variable. Set\n                category_row1 to 3, corresponding to the epithelial\n                status. Then, set category_row2 to 4, corresponding to\n                the NEN pathological type.\n                \ncategory_row1 = 3;\ncategory_row2 = 4;\n                The color_labels structure contains a field for each\n                category. The field for each category then contains 4\n                sub-fields: labels, colors, ordered_lbls, and\n                description.\nNote: 1)\n                  labels contains the class labels for each sample; 2)\n                  ordered_lbls stores the unique class labels with the\n                  same order they will have in the legend; 3)\n                  colors contains the matrix of standardized RGB values,\n                  one for each unique class label in ordered_lbls; 4) the\n                  description contains a text description of the\n                  category. Use\n                  dot notation[href=https://www.mathworks.com/help/matlab/ref/struct.html]\n                  to assign values to each subfield in label1 and\n                  label2. If you have more than two categories, repeat\n                  Stage 2, step 37b,iii-iv for each category.\n                \n%{\nCreate a color_labels structure that stores the\n                      information to generate color labels corresponding to each\n                      category of classes in the clustergram. See detailed\n                      inline comments in the script.\n%}\ncolor_labels.label1.labels =\n                      final_filt_data(category_row1,col_start:end);\ncolor_labels.label1.colors = [0.7 0 0.5; 0 0.2\n                      0.7];\ncolor_labels.label1.ordered_lbls =\n                      unique(final_filt_data(category_row1,col_start:end));\ncolor_labels.label1.description = {'Epithelial",
    "Type'};\ncolor_labels.label2.labels =\n                      final_filt_data(category_row2,col_start:end);\ncolor_labels.label2.ordered_lbls =\n                      unique(final_filt_data(category_row2,col_start:end));\nrand_color =\n                      [rand(1,length(color_labels.label2.ordered_lbls));...\nrand(1,length(color_labels.label2.ordered_lbls));...\nrand(1,length(color_labels.label2.ordered_lbls))]';\ncolor_labels.label2.colors = rand_color;\ncolor_labels.label2.description = {'Pathological\n                      Type'};\nNote: rand_color is a\n                  matrix of randomly generated RGB triplets.\n                  rand_color is assigned to the colors field for\n                  the second category, label2 (NEN pathological type).\n                  The\n                  length[href=https://www.mathworks.com/help/matlab/ref/length.html]\n                  function is used to find the number of ordered_lbls. If\n                  you prefer to use randomly generated colors, you may use this\n                  notation. Otherwise, assign the colors as shown for\n                  label1 above.\n                \n                Add the color labels to the clustergram, c_b, using the\n                custom modifyClustergram function.\n                \nNote: The first input is the\n                  clustergram object (cg_b). The second input is the\n                  color_labels structure. Set the third ‘ischangepossize’\n                  parameter to true, to allow re-sizing of the clustergram\n                  figure for accommodating the different labels. Next, the\n                  ‘columnLabels’ input must match the column labels that\n                  were used to generate the clustergram in Stage 2, step 37b,i.\n                  The last set of optional parameters (e.g., ‘textfont’, ‘maxrowsOfLbls’) adjust the font size and/or additional aesthetic\n                  properties. See problem 17[href=https://www.wicell.org#sec6.33] and the\n                  modifyClustergram function description for more\n                  information.\n                \nmodifyClustergram(cg_b, color_labels,\n                      'ischangepossize', true,...\n'columnLabels', final_filt_data(1,col_start:end),\n                      'textfont', 14, 'maxrowsOfLbls', 8);\n        Save the clustergram as an image by clicking\n        File → Export Setup from the figure window toolbar.\n        \n            In the pop-up window, click Apply to figure to change the\n            figure background to white.\n          \n            Click Export and select the destination and output format\n            (default is a MATLAB figure (.fig)). See\n            problem 8[href=https://www.wicell.org#sec6.15] for more information on export\n            settings.\n          \nNote: The clustergram can also be exported\n      in a vector graphics (.eps) format that can be further adjusted in a\n      graphics editor program.\n    \n        Repeat Stage 2, step 37 with different linkage (‘Linkage’) and\n        distance (‘RowPDist’ and ‘ColumnPDist’) methods.\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig13.jpg\n              Figure 13. Visualize hierarchical clustering with different\n              linkage and distance measures\n            \n              To visualize how different linkage and distance metrics alter the",
    "clustering of the samples along the horizontal axis of the\n              clustergram, generate hierarchical clustering with (A) average\n              linkage and Euclidean distance for the column distance measure,\n              and (B) weighted linkage and Cityblock for the column distance\n              measure. The color labels along the horizontal axis represent the\n              epithelial status of samples: epithelial (pink) and non-epithelial\n              (blue). The colorbar on the left indicates the log2\n              transformed median centered expression values corresponding to the\n              colors in the heatmap. See Stage 2, step 39 for more information.\n            \nNote: Linkage methods include average,\n      centroid, complete, median, single, ward, and weighted methods (see\n      linkage[href=https://www.mathworks.com/help/stats/linkage.html]).\n      Distance methods include Euclidean, Mahalanobis, city block, Minkowski,\n      Chebychev, cosine, correlation, Hamming, Jaccard and Spearman correlation\n      (see pdist[href=https://www.mathworks.com/help/stats/pdist.html]).\n      Alternatively, you may create a custom distance function. By changing the\n      linkage and/or distance parameters, the clustering results also change. As\n      an example, Figure 13[href=https://www.wicell.org#fig13] shows two clustergrams with two\n      different linkage and distance parameters. To learn more or modify these\n      linkage and distance metrics, see the\n      clustergram[href=https://www.mathworks.com/help/bioinfo/ref/clustergram.html]\n      function documentation and problem 18[href=https://www.wicell.org#sec6.35].\n    \n        t-Distributed Stochastic Neighbor Embedding (t-SNE): Use the\n        tsne function to create a two-dimensional embedding of the\n        numeric_data variable and assign it to the\n        tSNE_data variable.\n      \nNote: The tsne function returns an\n      n-by-2 matrix where n is the number of samples. The matrix is a\n      2-dimensional representation of the high-dimensional data. The t-SNE\n      algorithm has a random (i.e., stochastic) component, therefore, running\n      the algorithm multiple times may produce different values.\n    \ntSNE_data = tsne(numeric_data');\nNote: The tsne function expects\n      features to be stored as columns, not rows. Therefore, the\n      numeric_data variable is transposed using the’ (apostrophe)\n      operator.\n    \n        Visualize the two-dimensional t-SNE embeddings labeled by epithelial\n        status (Figure 14[href=https://www.wicell.org#fig14]A).\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig14.jpg\n              Figure 14. Visualize sample grouping with t-stochastic neighbor\n              embedding (t-SNE) plots\n            \n              To visualize how samples group in 2-dimensions, generate",
    "scatterplots of the t-SNE embeddings labeled by (A) the epithelial\n              status and (B) the pathological type. See Stage 2, steps 40–42 for\n              more information.\n            \n            Set scatterplot parameters.\n            \n                Assign the row number for the chosen category in\n                final_filt_data to category_row. In our example,\n                category_row is set to 3, which is the epithelial\n                category for the NENs data.\n              \n                Create a matrix of RGB triplets, colors. “Epithelial”\n                samples are pink ([1 0 0.5]) and “Non-epithelial” samples are\n                light blue ([0.43 0.71 1]).\n                \ncategory_row = 3;\ncolors = [1 0 0.5;0.43 0.71 1];\n            Create a scatterplot using the\n            gscatter[href=https://www.mathworks.com/help/stats/gscatter.html?s_tid=doc_ta]\n            function.\n            \nNote: The first two inputs are the\n              x and y coordinates for the scatterplot, respectively. The third\n              input is the grouping variable by which colors will be added to\n              the scatterplot. Index into the final_filt_data variable to\n              extract the values for epithelial status from category_row.\n              Adjust the\n              gscatter[href=https://www.mathworks.com/help/stats/gscatter.html]\n              function parameters to change marker size, marker symbol, axis\n              labels, and other plotting parameters.\n            \nfigure; gscatter(tSNE_data(:,1),tSNE_data(:,2),\n                  final_filt_data(category_row,...\ncol_start:end)',colors,[],25);\nNote: The colors in\n              colors should be in the same order they appear in the\n              category row. To see the order, type the following command into\n              the command window:\n            \nunique(final_filt_data(category_row, col_start:end),\n                  ‘stable’)\n        Visualize the two-dimensional t-SNE embeddings by NEN pathological type\n        (Figure 14[href=https://www.wicell.org#fig14]B).\n        \n            Select scatterplot parameters.\n            \n                Assign the row number for the chosen category in\n                final_filt_data to category_row. In our example,\n                category_row is set to 4, which is the epithelial\n                category for the NENs data.\n              \n            Use the gscatter function as shown in Stage 2, step 41b.\n          \ncategory_row = 4;\nfigure; gscatter(tSNE_data(:,1),tSNE_data(:,2), ...\nfinal_filt_data(category_row, col_start:end)',[],[],25);\nNote: If colors are not assigned in the\n      gscatter function, MATLAB will automatically assign colors for each\n      unique value in the grouping variable.\n    \n      Stage 3: Hierarchical decision structure design and feature selection\n    \nTiming: 3–6 h (Preparation time: 1–2 h,\n      Run time: 2–4 h)",
    "In this stage, we determine a hierarchical decision structure for the\n      classification. We then assign labels to correspond with the decision\n      structure. This process may involve some trial and error as we determine a\n      hierarchy suitable for the data. After the hierarchy is developed, we\n      split the data for validation, and conduct feature selection for each\n      decision in the hierarchy. In case of poor discrimination between classes,\n      we may need to revise the hierarchy. Data with no intrinsic hierarchy, or\n      hierarchies with more than two levels, may require more time and trials.\n    \n      Hierarchical classification applies a “divide and conquer” approach for\n      multiclass classification problems, enabling discrimination between\n      classes that would otherwise be too similar. Additionally, feature\n      selection at each decision node increases the customizability of the\n      classifier design. Features specific for each decision node may also\n      increase the accuracy of the classifier, compared to an “all-in-one”\n      multiclass classifier. Additionally, the feature subsets can be\n      interpreted biologically or pathologically, for the classes they\n      discriminate at the decision node.\n    \n      There are several approaches for selecting the top-ranked features. The\n      discriminatory features can be selected using all, a top percentage (Stage\n      3, step 67), and/or a custom list of ranked features (Stage 3, step 68).\n      The selected features can be visualized as a group, individually or\n      pairwise. To learn more about unsupervised machine learning techniques,\n      see before you begin[href=https://www.wicell.org#before-you-begin] –\n      unsupervised and supervised machine learning[href=https://www.wicell.org#sec1.1].\n    \nNote: To simplify the example hierarchy,\n      only the GEP-NET samples are used in subsequent analyses. The NEN\n      pathological types (e.g., INET, PanNET, RNET, AppNET) are the most\n      specific classes for the decision structure. The complete analysis for\n      GEP-NET samples is available in Panarelli et al.1[href=https://www.wicell.org#bib1]\n      The following files from the Supplementary Materials serve as example data\n      for this stage:\n    \nExample of input for this stage: Stage1_workspace.mat,",
    "Example of output for this stage: Stage3_featureSelection.mat,\n      Tables S3[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc4.csv],\n      S4[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc5.csv],\n      S5[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc6.csv],\n      S6[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc7.csv],\n      S7[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc8.csv], and\n      S8[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc9.csv].\n    \n        Prepare data for analysis: Open the\n        validation_scheme_script.m file found in the\n        Neuroendocrine_neoplasms directory.\n      \n        The final_filt_data variable is used for the upcoming\n        visualizations and analyses. final_filt_data was created in Stage\n        1, step 30.\n      \nNote: If you are starting from Stage 3\n      and/or do not have this variable in your workspace, load the\n      Stage1_workspace.mat file using the load function. This file\n      is found under the Neuroendocrine_neoplasms/project_data directory.\n    \nload Stage1_workspace.mat\n        Extract the GEP-NET (INET, AppNET, PanNET, RNET) samples from\n        final_filt_data. For simplicity, only these samples will be used\n        in our hierarchy.\n        \n            Assign row number 4 (NEN pathological type) as the\n            category_row for indexing.\n          \n            Mark samples that have ‘INET’,’AppNET’,’PanNET’, or ‘RNET’ as their\n            NEN pathological type using the contains function. The\n            resulting logical variable ind is true (1) for all GEP-NET\n            samples and false (0) otherwise.\n          \n            To retain all header columns, set columns 1 through\n            col_start-1 to true (1) in the ind variable. The\n            col_start variable is the row number for where numeric data\n            starts in final_filt_data.\n            Use the ind variable to index into final_filt_data and\n            extract expression data for the GEP-NET samples.\n          \ncategory_row = 4;\nind = contains(final_filt_data(category_row,:),\n          {'INET','AppNET','PanNET',\n          'RNET'});\nind(1:col_start-1) = true;\nfinal_filt_data = final_filt_data(:,ind);\n        Determine a hierarchical decision structure: To visualize any inherent\n        hierarchy within the data, generate a clustergram as shown in Stage 2,\n        step 37.\n        \n            Use ‘Complete’ as the linkage metric, and ‘Euclidean’ distance as\n            the similarity metric for the features (rows), and ‘Spearman’ as the\n            similarity metric for the samples (columns).\n          \n            Label the samples with colors for each of the four NET pathological\n            types.\n            \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig15.jpg\n                  Figure 15. Workflow to create a hierarchical decision\n                  structure and format the data for feature selection and\n                  classifier design\n                \n                  To identify a hierarchical decision structure suitable for",
    "your data, follow the recursive process outlined in Stage 3,\n                  steps 46–51.\n                \nCritical: Determining a hierarchical\n      structure is a recursive process that involves repeating Stage 3, steps\n      46–51 for each decision node in the hierarchy. See\n      Figure 15[href=https://www.wicell.org#fig15] for a summary of this process.\n    \nNote: For multiclass classification\n      problems where discrimination involves three or more\n      conditions-of-interest, we recommend applying a hierarchical decision\n      structure for classification. If no natural hierarchy is known, follow the\n      upcoming steps to determine a suitable hierarchy for the data. For a\n      multiclass classifier without a hierarchical decision structure, see\n      problem 19[href=https://www.wicell.org#sec6.37].\n    \n%{\nGenerate a clustergram for the preprocessed, filtered data with color\n          labels for the NET pathological type. See detailed inline comments in\n          the script.\n%}\nnumeric_data = cell2mat(final_filt_data(row_start:end,\n          col_start:end));\ntransform_data =\n          log2(replaceZeros(numeric_data,'lowval'));\ndata_median_centered = transform_data - median(transform_data,\n          'all');\nmakeBoxplot(data_median_centered, ...\n  final_filt_data(1, col_start:end), ...\n  'Samples', 'log_2 normalized median centered\n          expression');\ndisplay_range = 5;\ncg = clustergram(data_median_centered, ...\n  'ColumnLabels',\n          final_filt_data(1,col_start:end),...\n  'RowLabels',final_filt_data(row_start:end,1),...\n  'RowPDist', 'euclidean',...\n  'ColumnPDist', 'spearman', ...\n  'Linkage','complete',...\n  'Colormap', custom_colorMap_RedBlue,...\n  'DisplayRange', display_range, ...\n  'DisplayRatio', 0.1,...\n  'LabelsWithMarkers', true);\ncategory_row = 4;\ncolors = [0.83 0.14 0.14 % red, PanNET\n    1.00 0.54 0.00 % orange, INET\n    0.47 0.25 0.80 % purple, AppNET\n    0.25 0.80 0.54]; % green, RNET\ncolor_labels =\n          clustergramLabel(final_filt_data(1,col_start:end),...\nfinal_filt_data(category_row,col_start:end),colors);\nset(cg, 'ColumnLabelsColor', color_labels);\n        Generate a t-SNE plot to further visualize sample grouping. See Stage 2,\n        steps 40–41 for instructions on creating a t-SNE scatterplot.\n      \ntSNE_data = tsne(transform_data.');\nfigure; gscatter(tSNE_data(:,1),tSNE_data(:,2),...\nfinal_filt_data(category_row,\n          col_start:end)',colors,[],25);\n        Inspect the generated clustergram (Figure 16[href=https://www.wicell.org#fig16]A) and\n        t-SNE plot (Figure 16[href=https://www.wicell.org#fig16]B).\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig16.jpg\n              Figure 16. Visualize GEP-NET data with unsupervised learning\n            \n              To visualize any inherent hierarchy within the GEP-NET data,\n              generate (A) a clustergram and (B) a t-SNE scatterplot labeled by\n              pathological type. PanNET samples (red) and RNET samples (green)\n              cluster together, while AppNET samples (purple) and INET samples\n              (orange) cluster together. However, both clusters are separate,",
    "indicating two broad classes within the data composed of: 1)\n              PanNET and RNET (non-midgut), and 2) AppNET and INET (midgut). See\n              Stage 3, step 46–48 for more information.\n            \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig17.jpg\n              Figure 17. Schematic of hierarchical decision structure for\n              GEP-NET classification\n            \n              To discriminate between the four GEP-NET pathological types, a\n              hierarchical decision structure is generated as described in Stage\n              3, steps 46–51. Rectangles represent decision nodes where a binary\n              decision is made between classes. The decision at level 1 node 1\n              assigns samples to midgut (level 2 node 1) or non-midgut (level 2\n              node 2). The decision at level 2 node 1 (midgut) assigns samples\n              to INET or AppNET. The decision at level 2 node 2 (non-midgut)\n              assigns samples to PanNET and RNET. Ovals represent terminal nodes\n              where samples have been assigned to their most specific class,\n              e.g., pathological type. All samples are assigned to their\n              terminal nodes at level 3.\n            \nNote: Notice that most of the RNET and\n      PanNET samples cluster together, while INET and AppNET samples form a\n      separate cluster. Furthermore, we have prior knowledge that the behavior\n      of GEP-NETs depends on their embryonic origin in the fore-, mid- and\n      hindgut.46[href=https://www.wicell.org#bib45] By applying this prior\n      knowledge, the data can be split into two broader classes: midgut (INET\n      and AppNET) and non-midgut (PanNET and RNET). Both the observed grouping\n      and prior knowledge inform the hierarchy design. The hierarchical decision\n      structure begins at level 1 node 1 with all GEP-NET samples. Here, the\n      first decision is between midgut and non-midgut samples. The decision\n      divides the samples into two nodes at the next level: level 2 node 1,\n      midgut samples (INET and AppNET) and level 2 node 2, non-midgut samples\n      (PanNET and RNET) (Figure 17[href=https://www.wicell.org#fig17]).\n    \n        Create class labels for the binary separation at level 1 node 1 of the",
    "observed hierarchy (Stage 3, step 48). Each of these classes will be a\n        node in the next level of the hierarchy. For each sample, assign a value\n        of ‘Midgut’ or ‘Non-midgut’ based on the NEN pathological type.\n        \n            Assign row number 4 (NEN pathological type) as the\n            category_row for indexing.\n            \ncategory_row = 4;\n            Create an empty 1-by-n cell array, label1, where n is the\n            number of columns in final_filt_data. This includes both the\n            number of samples and any header columns, e.g., the first column\n            (feature names).\n            \nlabel1 = cell(1,size(final_filt_data,2));\n            Assign a title for this level, ‘Embryological_Origin’, to the first\n            cell of label1.\nlabel1(1)= {'Embryological_Origin'};\n            Assign a default value, ‘ND’ to the rest of the cells in\n            label1.\nlabel1(col_start:end) = {'ND'};\n            Mark samples with INET or AppNET as their NEN pathological type as\n            true (1), using the ismember function. The resulting logical\n            variable ind is true (1) for all midgut samples and false (0)\n            otherwise.\n            \nind = ismember(final_filt_data(category_row,:),\n                  {'INET','AppNET'});\n            Assign all samples marked as true (1) in ind, as ‘Midgut’ in\n            label1.\nlabel1(ind) = {'Midgut'};\n            Repeat Stage 3, steps 49e-f with RNET and PanNET in the\n            ismember function. Assign marked samples as ‘Non-midgut’ in\n            label1.\nind =\n                  ismember(final_filt_data(category_row,:),{'RNET','PanNET'});\nlabel1(ind) = {'Non-midgut'};\n        Check that all samples in label1 have been assigned a ‘Midgut’ or\n        ‘Non-midgut’ value and that none of the values are the default\n        'ND' value (assigned in Stage 3, step 49d).\n        \n            Use the custom checkLabel function to check if any samples\n            have not been assigned a class label in label1.\n            The first input is the class labels variable (label1), the\n            second input is the category_row row from the\n            final_filt_data variable. The third input is the default\n            value to look for (‘ND’).\n          \n            If there are samples with the value ‘ND’ assigned to them, the",
    "function will print their name and index in the command window,\n            formatted as: sample ID (location in label1). This may\n            indicate an error during the assignment of class labels, in which\n            case, return to Stage 3, step 49 and review the sample labeling.\n          \ncheckLabel(label1,final_filt_data(category_row,:),'ND')\nNote: As per the flowchart in\n      Figure 15[href=https://www.wicell.org#fig15]; the decision at level 1 node 1 assigns all\n      samples to nodes in the next level. However, these are not yet terminal\n      nodes, therefore we continue building the hierarchy until terminal nodes\n      are reached.\n    \n        Split the data for each node in the next level. In our example, the\n        decision at level 1 node 1 splits the data into two nodes for level 2:\n        'Midgut' (node 1) and 'Non-midgut' (node 2).\n        \n            Extract the data for samples in level 2 node 1: midgut samples.\n            \n                Find the indices for ‘Midgut’ samples in label1, using\n                the strcmp function to. The resulting logical\n                variable, ind_node, is true (1) for midgut samples and\n                false (0) otherwise.\n                \nind_node =\n                      strcmp(label1(:,col_start:end),'Midgut');\n                Extract the data for midgut samples from\n                final_filt_data and assign them to\n                subset_level2node1. To retain the header columns in\n                final_filt_data, concatenate true values for the number\n                of header columns (col_start - 1) to ind_node.\nsubset_level2node1 = final_filt_data(:,[true([1\n                      col_start-1]) ind_node]);\nNote: Repeat Stage 3, step\n                  51a,i-ii for each node in the level using the respective\n                  string in the strcmp function. Stage 3, step 51b\n                  repeats this process for level 2 node 2.\n                \n            Extract the data for samples in level 2 node 2: non-midgut samples.\n            \n                Find the indices for ‘Non-midgut’ samples in\n                label1, using the strcmp function. The\n                resulting logical variable, ind_node, is true (1) for\n                midgut samples and false (0) for non-midgut samples.\n                \nind_node =\n                      strcmp(label1(:,col_start:end),'Non-midgut');\n                Extract the data for non-midgut samples from\n                final_filt_data and assign it to\n                subset_level2node2. To retain the header columns in",
    "final_filt_data, concatenate true values for the number\n                of header columns (col_start - 1) to ind_node.\nsubset_level2node2 = final_filt_data(:,[true([1\n                      col_start-1]) ind_node]);\n        Repeat Stage 3, steps 46–51 until all samples have been assigned to a\n        terminal node (Figure 17[href=https://www.wicell.org#fig17]; circles). In our example,\n        level 2 node 1 contains two classes INET and AppNET, and level 2 node 2\n        contains two classes: PanNET and RNET. Therefore, we are repeating Stage\n        3, steps 46–51 two more times.\n        \n            Generate a clustergram and t-SNE plot for level 2 node 1 as shown in\n            Stage 3, steps 46–47. The colors variable has the two colors\n            for INET and AppNET classes.\n            \n%{\nGenerate a clustergram and t-SNE plot for the data at level 2\n                  node 1. Use color labels to indicate the sample pathological\n                  type in the clustergram and t-SNE plots. See detailed inline\n                  comments in the script.\n%}\nnumeric_data = cell2mat(subset_level2node1(row_start:end,\n                  col_start:end));\ntransform_data =\n                  log2(replaceZeros(numeric_data,'lowval'));\ndata_median_centered = transform_data -\n                  median(transform_data, 'all');\nmakeBoxplot(data_median_centered, ...\n  subset_level2node1(1, col_start:end), ...\n  'Samples', 'log_2 normalized median\n                  centered expression');\ndisplay_range = 4;\ncg = clustergram(data_median_centered, ...\n  'ColumnLabels',subset_level2node1(1,col_start:end),...\n  'RowLabels',subset_level2node1(row_start:end,1),...\n  'RowPDist', 'euclidean',...\n  'ColumnPDist', 'spearman',\n                  ...\n  'Linkage','complete',...\n  'Colormap',\n                  custom_colorMap_RedBlue,...\n  'DisplayRange', display_range, ...\n  'DisplayRatio', 0.1,...\n  'LabelsWithMarkers', true);\ncategory_row = 4;\ncolors = [1.00 0.54 0.00 % orange, INET\n    0.47 0.25 0.80]; % purple,\n                  AppNET\ncolor_labels =\n                  clustergramLabel(subset_level2node1(1,col_start:end),...\nsubset_level2node1(category_row, col_start:end)\n                  ,colors);\nset(cg, 'ColumnLabelsColor', color_labels);\ntSNE_data=tsne(transform_data.');\nfigure; gscatter(tSNE_data(:,1),tSNE_data(:,2),...\nsubset_level2node1(category_row,\n                  col_start:end)',colors,[],25);\n            Since level 2 node 1 contains only two classes, the binary\n            hierarchical separation is implied. If a node contains more than 2\n            classes, then observe the hierarchy as in Stage 3, step 48.\n          \n            Generate a clustergram and t-SNE plot for level 2 node 2 as shown in\n            Stage 3, step 46–47. The colors variable has the two colors\n            for PanNET and RNET.\n            \n%{\nGenerate a clustergram and t-SNE plot for the data at level 2",
    "node 2. Use color labels to indicate the sample pathological\n                  type in the clustergram and t-SNE plots. See detailed inline\n                  comments in the script.\n%}\nnumeric_data = cell2mat(subset_level2node2(row_start:end,\n                  col_start:end));\ntransform_data =\n                  log2(replaceZeros(numeric_data,'lowval'));\ndata_median_centered = transform_data -\n                  median(transform_data, 'all');\nmakeBoxplot(data_median_centered, ...\n  subset_level2node2(1, col_start:end), ...\n  'Samples', 'log_2 normalized median\n                  centered expression');\ndisplay_range = 4;\ncg = clustergram(data_median_centered, ...\n  'ColumnLabels',\n                  subset_level2node2(1,col_start:end),...\n  'RowLabels',subset_level2node2(row_start:end,1),...\n  'RowPDist', 'euclidean',...\n  'ColumnPDist', 'spearman',\n                  ...\n  'Linkage','complete',...\n  'Colormap',\n                  custom_colorMap_RedBlue,...\n  'DisplayRange', display_range, ...\n  'DisplayRatio', 0.1,...\n  'LabelsWithMarkers', true);\ncategory_row = 4;\ncolors = [0.83 0.14 0.14 % red, PanNET\n    0.25 0.80 0.54]; % green, RNET\ncolor_labels =\n                  clustergramLabel(subset_level2node2(1,col_start:end),\n                  ...\nsubset_level2node2(category_row,\n                  col_start:end),colors);\nset(cg, 'ColumnLabelsColor', color_labels);\ntSNE_data=tsne(transform_data.');\nfigure; gscatter(tSNE_data(:,1),tSNE_data(:,2), ...\nsubset_level2node2(category_row,\n                  col_start:end)',colors,[],25);\n            Since level 2 node 2 contains only two classes, the binary\n            hierarchical separation is implied. If a node contains more than 2\n            classes, then observe the hierarchy as done in Stage 3, step 48.\n          \n            Create class labels for level 3 of the hierarchy. In our example,\n            the level 3 class labels are the same as the ‘Pathological_type’ row\n            in final_filt_data. However, if your hierarchy contains more\n            than two levels, assign labels as shown in Stage 3, step 49.\n            \nlabel2 = final_filt_data(category_row,:);\nNote: The hierarchy discovery\n              process is summarized in Figure 15[href=https://www.wicell.org#fig15]. After all\n              samples have been assigned to a terminal node, i.e., the most\n              specific class, proceed to Stage 3, step 53.\n            \n        Create a new variable, data_labelled with the class labels\n        created in Stage 3, steps 49 and 52.\n        \n            Concatenate label1 and label2 into one cell array\n            variable, labels, where each row represents one of the above\n            created labels.\n            \nlabels = [label1;label2];\n            Extract header rows to keep from the original\n            final_filt_data. In this example, we only keep the row for\n            Sample IDs (row 1).\n            \nrows_to_keep = final_filt_data([1],:);\n            Concatenate any header columns to keep from\n            final_filt_data (rows_to_keep), with the class labels",
    "for all levels of the hierarchy (labels), and the expression\n            data (final_filt_data(row_start:end,:)).\n            \ndata_labelled =\n                  [rows_to_keep;labels;final_filt_data(row_start:end,:)];\nNote: The data_labelled may\n              have a different number of headers or label rows based on the\n              hierarchical structure suitable for your data. To see examples of\n              alternative hierarchical structures, see\n              problem 20[href=https://www.wicell.org#sec6.39].\n            \n        Prepare data for hold-out cross-validation and feature selection: Choose\n        an appropriate validation method depending on the number of samples\n        available.\n      \nNote: For hold-out validation, split the\n      data into training and validation sets. Each set should have approximately\n      the same proportion of the most specific class (e.g., NEN pathological\n      type). In this example, we perform a hybrid validation with both hold-out\n      and k-fold validation. For more information on validation of machine\n      learning models, see Before you begin – Validation scheme for machine\n      learning. If your dataset does not have enough samples in each class for a\n      hybrid validation, see problem 21[href=https://www.wicell.org#sec6.41] for performing\n      k-fold validation only.\n    \n        From data_labelled, extract the row containing grouping\n        information as groupingVar_row.\nNote: The second row of\n      data_labelled has the NEN pathological type, which is used to\n      determine the proportion of samples in the validation and training sets.\n      Generally, the selected grouping variable contains the most specific\n      classes in the hierarchy.\n    \ngroupingVar_row = data_labelled(2,col_start:end);\n        Generate indices for splitting the data by the NEN pathological type\n        (groupingVar_row) using the\n        cvpartition[href=https://www.mathworks.com/help/stats/cvpartition.html]\n        function. The first input is the grouping variable,\n        groupingVar_row. The second input is the type of validation, with\n        ‘Holdout’ for hold-out validation. The third input parameter is the\n        ratio of samples to reserve for validation; set this to 0.3 to reserve\n        30% of the data for validation. This also sets 70% of the data for\n        training.\n      \nsplit_data =\n          cvpartition(groupingVar_row,'HoldOut',0.3);\nNote: For machine learning, a greater\n      proportion of data should be dedicated for training and a smaller\n      proportion for testing or validation.8[href=https://www.wicell.org#bib7]",
    "Divide data into training and testing sets.\n        \n            Retrieve the indices for the training and validation data from\n            split_data (cvpartition object) generated in Stage 4,\n            step 56. Extract the indices for samples assigned to the training\n            and validation data, using the training and\n            test functions, respectively.\n          \n            Extract the training and validation data into\n            training_data and validation_data, respectively. To\n            retain the header columns in data_labelled, concatenate true\n            values for the number of header columns to the column index.\n          \ntraining_data = data_labelled(:,[true(1:col_start-1);\n          training(split_data)]);\nvalidation_data = data_labelled(:,[true(1:col_start-1);\n          test(split_data)]);\n        Use the clearvars function to clear all the variables in your\n        workspace except the training_data and\n        validation_data. Save these variables in a workspace variable,\n        trainingValidation_data.mat under the results_data folder.\n        \n            In addition, export the training data with the\n            writecell function into a CSV file to be used for feature\n            selection in MFeaST. Subsequent model construction steps are\n            only performed on the training dataset. The validation set is used\n            for the final validation of the hierarchical classifier in Stage 4.\n          \nclearvars -except training_data validation_data\nsave\n          (fullfile('results_data','trainingValidation_data.mat'),\n          ...\n'training_data', 'validation_data');\nwritecell(training_data,fullfile('results_data',\n          'training_data4MFeaST.csv'));\n        Rank molecules with the strongest discriminatory power using\n        MFeaST: Open the MFeaST application. If this is your first\n        time opening the application and/or you receive an error, see\n        problem 2[href=https://www.wicell.org#sec6.3].\n      \nNote: Feature selection is performed based\n      on the decision hierarchy determined in Stage 3, step 48 (Figure 17[href=https://www.wicell.org#fig17]). The purpose is to identify a non-redundant list of molecular features\n      with the greatest discriminatory ability for each decision in the\n      hierarchy. To perform feature selection, we recommend using an ensemble\n      feature selection tool, MFeaST.10[href=https://www.wicell.org#bib10]\n      We have successfully applied this tool in many omics studies.1[href=https://www.wicell.org#bib1],11[href=https://www.wicell.org#bib11],12[href=https://www.wicell.org#bib12],14[href=https://www.wicell.org#bib14],15[href=https://www.wicell.org#bib15],16[href=https://www.wicell.org#bib16],17[href=https://www.wicell.org#bib17],47[href=https://www.wicell.org#bib46],48[href=https://www.wicell.org#bib47],49[href=https://www.wicell.org#bib48] For download instructions,\n      see before you begin[href=https://www.wicell.org#before-you-begin] –\n      software installation and directory set-up[href=https://www.wicell.org#sec1.10]. If you\n      decide not to use MFeaST, see the\n      MATLAB documentation[href=https://www.mathworks.com/help/stats/feature-selection.html]\n      on feature selection or see the custom alternative_FS_script.m for",
    "an example on how to implement a built-in feature selection algorithm and\n      generate visualizations.\n    \n        Click Import Data and navigate to\n        training_data4MFeaST.csv located within the\n        Neuroendocrine_neoplasms/results_data directory (Figure 18[href=https://www.wicell.org#fig18]A).\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig18.jpg\n              Figure 18. Import data and select comparison for feature selection\n              in Molecular Feature Selection Tool (MFeaST)\n              (A) To import data into MFeaST, click the\n              Import Data button and navigate to the .xlsx or .csv file\n              to import. Verify expected values through the\n              Value Check parameter.\n            \n              (B) To select a comparison for feature selection, select the\n              category from the left menu. Go through potential binary\n              comparisons from the drop-down menu on the right and select the\n              specific binary comparison to perform. Click Next to\n              proceed. See Stage 3, steps 60–62 for more information.\n            \nCritical: MFeaST requires the\n      data to be formatted with sample IDs as the first row, class labels as the\n      subsequent rows, followed by the remaining feature expression rows and the\n      feature names in the first column. Our formatted data is saved in the\n      training_data4MFeaST.csv file. For data set-up instructions, see\n      before you begin[href=https://www.wicell.org#before-you-begin] –\n      formatting dataset for analysis[href=https://www.wicell.org#sec1.9].\n    \n        When prompted, indicate that the data are not log2\n        transformed. Click Next to proceed.\n      \nNote: The data must be positive unless\n      they are log2 transformed. If your data are log2\n      transformed, select “Yes”. If the data are log2 transformed\n      and/or contain negative values, “Negative values detected” will appear\n      next to the Value Check (under the Data Input section,\n      Figure 18[href=https://www.wicell.org#fig18]A). It is assumed that expression data must\n      be positive, therefore if your data has negative values, it may be\n      log-transformed or contain an error.\n    \n        Select the binary comparison for the decision node for which to run the\n        feature selection.\n        \n            The categories in the input file are listed on the lefthand menu.\n            All possible binary comparisons of classes within a category are",
    "listed on the righthand menu.\n          \n            Under the Comparisons Selection tab, select\n            ‘Embryological_Origin’ from the lefthand menu (Figure 18[href=https://www.wicell.org#fig18]B).\n          \n            Then, select the comparison ‘Midgut vs. Non-midgut’ from the\n            righthand menu. Click Next to continue.\n          \n        Under the Feature Selection tab (Figure 19[href=https://www.wicell.org#fig19]),\n        set the relevant feature selection parameters. There are three menus on\n        this page: Select algorithms, Cross-validation, and # Iterations for\n        Sequential algorithms (alg.). Recommendations for each menu are listed\n        below. After adjusting the menu options, click Run to proceed.\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig19.jpg\n              Figure 19. Select parameters for feature selection in\n              Molecular Feature Selection Tool (MFeaST)\n              Select feature selection algorithms from the\n              Select Algorithms menu on the left. Select the\n              cross-validation method from the Cross-Validation menu, the\n              default is set to 5-fold cross-validation. Set the number of\n              iterations for the sequential algorithms in the\n              # Iterations for Sequential alg. menu. Select Run to\n              begin feature selection. See Stage 3, step 63 for more\n              information.\n            \n            Select Algorithms: We recommend using all algorithms. However, the\n            sequential algorithms will take a long time to run and may need to\n            be excluded for datasets with thousands of features remaining after\n            filtering.\n          \n            Cross-validation: Select 5-fold cross-validation (default). For\n            datasets with less than five samples in one class, use leave-one-out\n            validation.\n          \n            # Iterations for Sequential alg.: Use the default 5 iterations. This\n            value is the maximum number of iterations the sequential algorithms\n            perform to compute a stable solution.\n          \nNote: You may increase the number of\n      iterations to improve the stability of features selected by the sequential\n      algorithms. Or you may decrease this value to speed up execution. Using\n      the example data, this step may take 2–4 h to run depending on the\n      computer specifications and if sequential algorithms were selected. See\n      problem 22[href=https://www.wicell.org#sec6.43] for speeding up execution.\n    \n        Once the feature selection ranking algorithms are complete, the results",
    "are presented under the Results tab (Figure 20[href=https://www.wicell.org#fig20]).\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig20.jpg\n              Figure 20. View results of feature selection in\n              Molecular Feature Selection Tool (MFeaST)\n            \n              To view the ranked list of features after running feature\n              selection, scroll through the list on the left (1). To visualize\n              how samples discriminate based on the selected features, plot the\n              expression data through scatterplots, t-SNE plots or hierarchical\n              clustering (Clustering tab;\n              Figure 21[href=https://www.wicell.org#fig21]). Select a subset of features based\n              on their ability to discriminate classes. See Stage 3, steps 64–69\n              for more information on the Results tab.\n            \n            To review the ranking information from each feature selection\n            algorithm, select Ranked Features from the drop-down list (Figure 20[href=https://www.wicell.org#fig20], number 1).\n          \n            Select Ranked cell data from the drop-down menu to view the\n            ranked expression data.\n          \n        Export the results into a .mat file (Figure 20[href=https://www.wicell.org#fig20],\n        number 2).\n        \n            Click Export Results and then click on the\n            .mat button.\n          \nName the file as midgut_v_nonmidgut_rankedResults.mat.\n            Following our hierarchical decision structure, save the results for\n            the decision at level 1 node 1 as\n            midgut_v_nonmidgut_rankedResults.mat, level 2 node 1 as\n            INET_v_AppNET_rankedResults.mat, and level 2 node 2 as\n            PanNET_v_RNET_rankedResults.mat.\n            The ranking results can also be exported into an Excel file by\n            clicking Export Results → .xlsx. See\n            Tables S3[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc4.csv],\n            S4[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc5.csv],\n            S5[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc6.csv],\n            S6[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc7.csv],\n            S7[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc8.csv], and\n            S8[href=https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Mmc9.csv]\n            for examples of the exported expression and ranked results tables\n            from MFeaST.\n        Save the session by clicking Save as from the drop-down list at\n        the top right of the window (Figure 20[href=https://www.wicell.org#fig20], number 13).\n      \nNote: This saves the entire\n      MFeaST session. The session can be opened later, without re-running\n      the feature selection, by selecting Open in the Session drop down\n      list. You can override an existing session or save as a new session.\n    \n        Select top ranking features: If the goal is to select all possible",
    "features that are important for discrimination, select the top % of\n        features (Figure 20[href=https://www.wicell.org#fig20], number 14) for which the best\n        clustering is observed.\n        \n            Select the top 1% and visualize with a clustergram and/or t-SNE\n            plot.\n            \nNote: There is a minimum number of\n              features required to generate a t-SNE scatterplot and/or\n              clustergram. For t-SNE, you require at least two features. For\n              hierarchical clustering, this value may vary based on the distance\n              metric chosen.\n            \n                To generate a clustergram using the features in the\n                Selected Features list, proceed to the\n                Clustering tab (Figure 21[href=https://www.wicell.org#fig21]).\n                \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig21.jpg\n                      Figure 21. Visualize clustering of samples by selected\n                      features in\n                      Molecular Feature Selection Tool (MFeaST)\n                      To visualize how the selected features (Results\n                      tab; Figure 20[href=https://www.wicell.org#fig20]) cluster the samples,\n                      generate a clustergram through the Clustering tab.\n                      Select the distance measure for the samples and features,\n                      the linkage method, the colormap for the heatmap, the\n                      display range and whether the colorbar should be symmetric\n                      around 0. Click Generate to create the clustergram.\n                      See Stage 3, step 67 for more information.\n                    \nNote: We recommend using the\n                  default parameters (Samples similarity: Spearman, Features\n                  similarity: Euclidean, Linkage: Average, Color map: RedBlue,\n                  Symmetric: yes) and adjusting as necessary. Click on the\n                  Boxplot button to create a boxplot and select a value\n                  for the display range (Stage 1, step 20d). Choose the display\n                  range based on the upper quartile of majority of the plotted\n                  boxes. After adjusting the parameters, click the\n                  Generate button. After reviewing the clustergram,\n                  return to the Results tab.\n                \n                To generate a t-SNE plot using the selected features, click on\n                the TSNE button in the Results tab (Figure 20[href=https://www.wicell.org#fig20], number 18).\n              \n            Repeat the visualization with the top 5%, 10%, etc. of selected\n            features. Note the range of top percentages for which the best",
    "clustering is observed, i.e., where the two classes form distinct\n            clusters. The range identifies features to use in subsequent\n            analysis. For midgut vs. non-midgut samples this range is between 1%\n            and 10%.\n            \nNote: Depending on your\n              application and objective, you may go with the smallest or largest\n              percentage of features within the range.\n            \n        If the goal is to select the smallest set of features, then further\n        custom selection is required.\n        \n            Click on the Predictive Importance Plot button (Figure 20[href=https://www.wicell.org#fig20], number 12) to visualize the ranked discriminatory ability of all\n            features. For a given feature, a value closer to 1 indicates higher\n            importance in discriminating between the two classes.\n          \n            Make a note of where there is a drop in discriminatory ability on\n            the predictive importance plot (e.g., an L shaped curve or an\n            inflection point). This point is an estimate of how far to go down\n            the ranked list when selecting features. In our midgut vs.\n            non-midgut comparison, the drop occurs between the top 1% and 5% of\n            features (Figure 22[href=https://www.wicell.org#fig22]).\n            \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig22.jpg\n                  Figure 22. Predictive importance of ranked features in\n                  Molecular Feature Selection Tool (MFeaST)\n                  To estimate the range of features for selection, visualize the\n                  predictive importance of the ranked features under the\n                  Results tab. The “Average Discriminatory Ability” of a\n                  feature is the average of the scores from all feature\n                  selection algorithms that were run\n                  (Feature Selection tab;\n                  Figure 19[href=https://www.wicell.org#fig19]). The ranked list of features\n                  is presented along the horizontal axis, with the dashed lines\n                  representing the divisions between the top % of features.\n                \n            Review the discriminatory power of (i) individual features (ii)\n            consecutive pairs of features, or (iii) one feature paired with any\n            other feature, by generating scatterplots under the\n            Plot panel. You may edit the plot markers by clicking on the\n            eyedropper button (Figure 20[href=https://www.wicell.org#fig20], number 9).",
    "To plot features individually: Click on the first feature in the\n                ranked list. The feature row will become highlighted on the\n                ranking list panel. This will plot the expression values on the\n                y-axis against the sample numbers on the x-axis.\n              \n                To view paired features: Select the button underneath the ranked\n                list with two circles and a downward arrow (Figure 20[href=https://www.wicell.org#fig20], number 3) to plot the first two features. Click on this\n                button again to move down the ranked list pairwise. To move up\n                the list, click on the button beside it, with an upward arrow.\n              \n                To view any feature paired with any other feature: Click on any\n                two features consecutively. The two selected features will be\n                highlighted on the ranking list panel and displayed on the\n                scatterplot, one versus the other.\n                \nNote: To better visualize\n                  positively skewed expression values, select the “LOG 2” button\n                  (Figure 20[href=https://www.wicell.org#fig20], number 8) to apply log2\n                  transformation.\n                \n            Add a feature shown on the scatterplot to the\n            Selected Features list by clicking the plus button beside the\n            axis corresponding to the feature (Figure 20[href=https://www.wicell.org#fig20],\n            number 5 and 10).\n          \n            Remove a feature from the Selected Features list by clicking\n            the minus button beside the axis corresponding to the feature (Figure 20[href=https://www.wicell.org#fig20], number 6 and 11). Alternatively, select the feature on the\n            Selected Features list and click the minus button (Figure 20[href=https://www.wicell.org#fig20], number 16).\n          \n            Based on the results of the scatterplot (Stage 3, step 68c) and\n            predictive importance plot (Stage 3, step 68a), add, or remove\n            features from the custom list. Visualize the combined discriminatory\n            ability of the features through generating t-SNE scatterplot (Figure 20[href=https://www.wicell.org#fig20], number 18) and clustergram, as shown in Stage 3, step 67a,i-ii.\n          \n            Copy the list of selected features by clicking the\n            Copy button (Figure 20[href=https://www.wicell.org#fig20], number 19).\n            \nNote: This process requires some",
    "trial and error as features are added or removed.\n            \n        For the midgut vs. non-midgut comparison, select miRs-92b and -615.\n        These miRNAs are excellent candidates for selection as they separate\n        midgut vs. non-midgut samples into two distinct, tightly grouped\n        clusters on the scatterplot (Figure 23[href=https://www.wicell.org#fig23]A).\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig23.jpg\n              Figure 23. Visualize separation of classes by the selected\n              features with scatterplots in\n              Molecular Feature Selection Tool (MFeaST)\n              To visualize how individual or paired features separate classes,\n              generate scatterplots in the Results tab. View the log2\n              transformed (optional) expression scatterplots for each decision\n              node with the selected miRNAs: (A) midgut vs. non-midgut with\n              hsa-miR-615(1) and hsa-miR-92b(1), (B) AppNET vs. INET with\n              hsa-miR-149(1) and hsa-miR-125b(2), (C) PanNET vs. RNET with\n              hsa-miR-429(1) and hsa-miR-487b(1). See Stage 3, steps 69–70 for\n              more information.\n            \n            Clear the Selected Features list by clicking the ‘X’ on the\n            right of the list (Figure 20[href=https://www.wicell.org#fig20], number 17).\n          \n            Select hsa-miR-615(1) and hsa-miR-92b(1) on the left panel so that\n            they appear on the scatterplot (Figure 23[href=https://www.wicell.org#fig23]A).\n          \n            While the miRNAs are plotted, click the plus button next to each\n            axis to move the miRNAs into the Selected Features list (Figure 20[href=https://www.wicell.org#fig20], number 5 and 10).\n          \n            Visualize the discriminatory ability of the selected features\n            (hsa-miR-92b(1) and hsa-miR-615(1)) with a clustergram and t-SNE\n            scatterplot, as shown in Stage 3, step 67a,i-ii.\n          \n        Repeat feature selection (Stage 3, steps 60–69) for all remaining\n        decisions in the hierarchy (level 2 node 1: AppNET vs. INET, select\n        miR-192, -125b (Figure 23[href=https://www.wicell.org#fig23]B) and -149; and level 2\n        node 2: PanNET vs. RNET), select miR-429 and -487b (Figure 23[href=https://www.wicell.org#fig23]C).\n      \nCritical: Remember to save the\n      MFeaST session for each comparison (Figure 20[href=https://www.wicell.org#fig20],\n      number 13). After completing feature selection, close MFeaST and\n      return to MATLAB.\n    \nNote: The selected features can be further\n      inspected by domain experts and pathway analysis.",
    "Create subset of data for selected features: Indicate the starting row\n        and column for the numeric expression data in training_data.\nrow_start = 4;\ncol_start = 2;\nNote: In this step, we continue working\n      from the validation_scheme_script.m in MATLAB. This script arranges\n      the selected features from MFeaST into the format needed for the\n      Classification Learner App in Stage 4.\n    \n        Load the MFeaST ranked results for the decision at level 1 node\n        1: midgut vs. non-midgut. The resultRankedCellData variable will\n        appear in the workspace.\n      \nload('midgut_v_nonmidgut_rankedResults.mat',\n          'resultRankedCellData');\n        Rename the resultRankedCellData variable as\n        resultRankedCellData_level1node1.\nresultRankedCellData_level1node1 = resultRankedCellData;\n        Create a cell array with the names of the selected features for level 1\n        node 1 (Stage 3, step 69).\n      \nselectedFeatures_level1node1 = {'hsa-miR-615(1)',\n          'hsa-miR-92b(1)'};\n        Repeat Stage 3, steps 72–74 for each decision in the hierarchy. The next\n        decisions are at level 2 node 1: INET vs. AppNET and level 2 node 2:\n        PanNET vs. RNET.\n      \nload('INET_v_AppNET_rankedResults.mat','resultRankedCellData');\nselectedFeatures_level2node1 = ...\n{'hsa-miR-192(1)','hsa-miR-125b(2)','hsa-miR-149(1)'};\nresultRankedCellData_level2node1 = resultRankedCellData;\nload\n          ('PanNET_v_RNET_rankedResults.mat','resultRankedCellData');\nselectedFeatures_level2node2 =\n          {'hsa-miR-487b(1)','hsa-miR-429(1)'};\nresultRankedCellData_level2node2 = resultRankedCellData;\n        Save the selected features for each decision node, row_start,\n        col_start, and the formatted data from Stage 3, steps 73–75, as a\n        workspace variable, Stage3_featureSelection.mat. Save the ranked\n        results for each node as a workspace variable,\n        rankedResults.mat under the\n        Neuroendocrine_neoplasms/project_data directory.\n      \nsave (fullfile('project_data',\n          'Stage3_featureSelection.mat'), ...\n'selectedFeatures_level1node1',\n          'selectedFeatures_level2node1', ...\n'selectedFeatures_level2node2', 'col_start',\n          'row_start', ...\n'validation_data', 'training_data')\nsave (fullfile('project_data', 'rankedResults.mat'),\n          ...\n'resultRankedCellData_level1node1',\n          'resultRankedCellData_level2node1',...\n'resultRankedCellData_level2node2')\nStage 4: Training and testing of classifier models\nTiming: 1–2 h\n      Machine learning models apply mathematical algorithms to identify patterns\n      between features and samples. Different algorithms may perform better on\n      different data; however, no algorithm is superior overall (i.e., No Free\n      Lunch Theorem8[href=https://www.wicell.org#bib7]). For the hierarchical classification task, the best performing\n      algorithm is selected at each decision node. Then, the individual models\n      are assembled according to the predefined hierarchy (See Stage 3,",
    "“Determining hierarchical structure”). Lastly, the hierarchical classifier\n      is evaluated using independent validation data.\n    \n      This stage consists of two sections: training and validating the\n      classifier. Training involves building a classifier for each decision in\n      the hierarchy using the training data with k-fold validation. This is\n      followed by validating the hierarchical classifier model on the held-out\n      validation data. This stage uses the training and validation sets created\n      in Stage 3, step 57–58.\n    \nNote: Features are selected using the\n      training data, both during feature selection (Stage 3) and if necessary,\n      during classifier training (Stage 4).\n    \n      The following files from the Supplementary Materials serve as example data\n      for this stage:\n    \nExample of input for this stage: Stage3_featureSelection.mat,\nExample of output for this stage: trainedModels.mat.\n        Prepare data for the Classification Learner App: Open the\n        feature_selection_and_machine_learning_script.m file from the\n        Neuroendocrine_neoplasms directory.\n      \n        If you do not have the variables from Stage 3 in your workspace, load\n        the Stage3_featureSelection.mat file using the\n        load function. This includes the training, validation, and\n        selected features data:\n        selectedFeatures_level1node1, selectedFeatures_level2node1,\n          selectedFeatures_level2node2, col_start, row_start, validation_data,\n          training_data.\n        This workspace file is found under the\n        Neuroendocrine_neoplasms/project_data directory.\n      \nload Stage3_featureSelection.mat\n        Extract the data for the selected features at each decision node of the\n        hierarchy using the custom createSubset function.\n        \nNote: The createSubset function\n          reformats the data into a table (subset_level1node1) suitable\n          for the Classification Learner App. The first input into the\n          function is training_data, followed by the number of header\n          rows (row_start -1), and a vector of selected features\n          (selectedFeatures_level1node1; see Stage 3, steps 74–75). The\n          rows of the table are the samples, and the columns are the headers in\n          training_data and the selected features. Though not mandatory,\n          this tabular format makes the process of loading data into the\n          Classification Learner App more efficient.\n        \n            Extract the expression data for the selected features for level 1",
    "node 1: midgut vs. non-midgut.\n            \nsubset_level1node1 = ...\ncreateSubset(training_data,row_start-1,\n                  selectedFeatures_level1node1);\nNote:\nselectedFeatures_level1node1 was created in Stage 3, step\n              74. It stores the names of the selected features for the midgut vs\n              non-midgut decision at level 1 node 1.\n            \n            Extract the selected expression data for the decision at level 2\n            node 1 (midgut) of the hierarchy: INET vs. AppNET.\n            \n                Index into training_data to extract only the samples for\n                level 2 node 1. Assign row number 2 as the\n                category_row for indexing.\n                \ncategory_row = 2;\n                Use the strcmp function to find the indices for samples\n                with “Midgut” as their “Embryological_Origin”\n                (category_row).\n                \nind_col =\n                      strcmp(training_data(category_row,col_start:end),\n                      'Midgut');\nNote: The function returns a\n                  Boolean vector where midgut samples are marked as true (1) and\n                  non-midgut samples are marked as false (0).\n                \n                To retain the header columns in training_data,\n                concatenate true values for the number of header columns (col_start -1) to ind_col.\nsubset_level2node1 = training_data(:,[true([1\n                      col_start-1]) ind_col]);\n                Reformat the data using the createSubset function as\n                shown in Stage 4, step 79a.\n                \nsubset_level2node1 = ...\ncreateSubset(subset_level2node1,row_start-1,\n                      selectedFeatures_level2node1);\n            Repeat Stage 4, step 79b for all decisions within the hierarchy. In\n            our example, the next decision is at level 2 node 2 (non-midgut):\n            PanNET vs. RNET. Repeat Stage 4, step 79b with ‘Non-midgut’ instead\n            of ‘Midgut’ in the strcmp function.\n            \ncategory_row = 2;\nind_col =\n                  strcmp(training_data(category_row,col_start:end),'Non-midgut');\nsubset_level2node2 = training_data(:,[true([1 col_start-1])\n                  ind_col]);\nsubset_level2node2 = ...\ncreateSubset(subset_level2node2,row_start-1,\n                  selectedFeatures_level2node2);\nNote: If you have more decisions\n              in your hierarchy, repeat Stage 4, step 79b for each decision\n              node.\n            \n        Training in the Classification Learner App: Under the\n        Apps tab in MATLAB, launch the\n        Classification Learner App (Figure 24[href=https://www.wicell.org#fig24]).\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig24.jpg\n              Figure 24. Open the Classification Learner App\n              To launch the Classification Learner App, open the app from\n              the Apps menu. See Stage 4, step 80 for more information.\n            \nNote: Maximize the",
    "Classification Learner App window for the layout to match the\n      provided figures in this protocol.\n    \n        Click New Session in the Classification Learner App (Figure 25[href=https://www.wicell.org#fig25]A) to open a new session window.\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig25.jpg\n              Figure 25. Set-up a new session in the\n              Classification Learner App\n              (A) Click New Session from the\n              Classification Learner App toolbar.\n            \n              (B) To import the expression data, select the corresponding data\n              variable from the Data Set Variable drop-down menu. The\n              variable must be a numeric matrix or table. To indicate the class\n              labels, select the corresponding variable from the\n              Response drop-down menu. To indicate the predictors or\n              features to use, check, or uncheck values from the\n              Predictors section. Adjust the validation scheme settings\n              and then click Start Session. See Stage 4, step 81–83 for\n              more information.\n            \n        Import your data as follows (Figure 25[href=https://www.wicell.org#fig25]B):\n        \n            Under Data Set Variable, select the\n            subset_level1node1 variable from the drop-down menu. For the\n            example data, this should register as a 57-by-4 table.\n          \n            Under Response, select From data set variable. Then,\n            select “Embryological_Origin” as the response variable from the\n            drop-down menu. This row contains the class labels for\n            classification.\n          \n            Under the Predictors section, select only the features as the\n            predictors, not the categories (e.g., “Pathological_type”).\n          \n            Under the Validation section, select cross-validation from\n            the Validation Scheme drop-down menu and set the\n            cross-validation folds to 5. In general, sample size permitting, we\n            recommend using 5- to 10- fold cross-validation for training.\n          \nNote: We do not select\n      Set aside a test data set underneath the Test section,\n      because validation data was set aside in Stage 3.\n    \nNote: If your data are not formatted in a\n      table using the custom createSubset function (Stage 4, step 79),\n      see problem 23[href=https://www.wicell.org#sec6.45].\n    \nClick Start Session (Figure 25[href=https://www.wicell.org#fig25]B).\n        View all available training algorithms by clicking on the drop-down menu",
    "under the Models section (Figure 26[href=https://www.wicell.org#fig26]A).\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig26.jpg\n              Figure 26. Train classifier models in the\n              Classification Learner App\n              (A) To train all available classifier models, select\n              All from the Models section in the\n              Classification Learner App toolbar. To speed up training,\n              and if multiple CPU cores are available, select\n              Use Parallel. Select Train All to begin model\n              training.\n            \n              (B) To sort the trained models as they appear in the\n              Models pane, click the Sort by drop-down menu and\n              select a measure for sorting (e.g., accuracy, misclassification\n              cost, number).\n            \n              (C) To visualize model performance, click the\n              Plots drop-down menu and select scatterplots, confusion\n              matrix, and/or an ROC curve from the\n              Validation Results section.\n            \n              (D) To export the trained model, click the\n              Export Model drop-down menu and select\n              Compact Model. See Stage 4, steps 84–91 for more\n              information.\n            \nSelect All to train all available models.\nNote: Based on a principle called the No\n      Free Lunch Theorem, no single machine-learning algorithm is superior\n      overall.8[href=https://www.wicell.org#bib7] Therefore, we try all possible\n      algorithms available and choose the one with the best performance. If\n      there are multiple classifier models with equally high performance, see\n      problem 24[href=https://www.wicell.org#sec6.47] on selecting a model.\n    \n        Click Use Parallel to turn on parallel pool if you have more than\n        one CPU core available (Figure 26[href=https://www.wicell.org#fig26]A). This will\n        significantly speed up execution.\n      \n        Click the Train All button (Figure 26[href=https://www.wicell.org#fig26]A).\n      \nNote: As models are trained, they will\n      appear on the left side of the window, under the Models pane (Figure 26[href=https://www.wicell.org#fig26]B). To sort the trained models, use the Sort by menu at the top of\n      the Models pane, to sort by accuracy, misclassification cost (i.e.,\n      how many samples marked as the wrong class), or model number (default).\n    \n        Assess performance of the trained models. The overall accuracy of each",
    "classification model is shown in the Models pane. Click the\n        Naïve Bayes Classifier model from the list to view the\n        performance summary of this classifier.\n        \nNote: The summary includes accuracy,\n          total misclassification cost, prediction speed, training time, as well\n          as information on model hyperparameters and optimization (see\n          problem 25[href=https://www.wicell.org#sec6.49]). See the\n          MATLAB documentation[href=https://www.mathworks.com/help/stats/assess-classifier-performance.html]\n          for more details on visualizing classifier model performance.\n        \n            Visualize the performance of the classifier model with a confusion\n            matrix. Under the Plots section of the toolbar, select\n            Confusion Matrix (Validation) (Figure 26[href=https://www.wicell.org#fig26]C).\n            \n                On the Plot menu, beside the confusion matrix, you may\n                choose the values to view in the confusion matrix: number of\n                observations, the true positive rates (TPR) and false negative\n                rates (FNR), and positive predictive values (PPV) and false\n                discovery rates (FDR).\n              \n                The Classification Learner App will automatically assign\n                one class as “positive” and the other as “negative”. This is not\n                necessarily appropriate for all class labels (e.g., Pathological\n                type). Instead of only relying on the overall accuracy value, go\n                through each view of the confusion matrix to obtain a better\n                understanding of how samples from both classes were classified\n                (also see Stage 4, step 88b below).\n              \n            Open the evaluation_metrics_live_script.mlx file under the\n            Neuroendocrine_neoplasms directory. From the information\n            provided in the confusion matrix, compute additional evaluation\n            metrics including precision, sensitivity, specificity, F1 score,\n            recall, and MCC (Matthews Correlation Coefficient). For a more\n            in-depth discussion of these classification performance metrics, see\n            Hossin and Sulaiman.50[href=https://www.wicell.org#bib49]\nNote: This script is suited for\n              binary classification problems. To calculate performance measures\n              for multiclass classification problems, see the custom\n              evaluationMetrics function in Stage 4, step 101.\n            \n            Visualize the performance of the classifier model with a 2-D\n            scatterplot.\n            \n                Under the Plots section of the toolbar, select\n                Scatter (Figure 26[href=https://www.wicell.org#fig26]C).\n              \n                Select two features to compare from the Plot menu beside",
    "the scatterplot. Misclassified samples are labeled as ‘x’.\n              \n            Visualize performance with an ROC (receiver operating\n            characteristic) curve and AUC (area under the curve) value. Under\n            the Plots section of the toolbar, select\n            ROC Curve (Validation) (Figure 26[href=https://www.wicell.org#fig26]C).\n            \nNote: For additional\n              functionalities of the Classification Learner App, see the\n              MATLAB documentation[href=https://www.mathworks.com/help/stats/classification-learner-app.html?s_tid=CRUX_lftnav].\n            \n        Select and export the most accurate model from the Models pane.\n        In this example, select the Naïve Bayes Classifier from the\n        Models pane. This classifier was chosen as one of the most\n        accurate models.\n      \n        Export the Naïve Bayes Classifier trained model into the\n        workspace by clicking Export Model on the toolbar (Figure 26[href=https://www.wicell.org#fig26]D). Then, select Export Model from the drop-down menu\n        with the name, trainedModel_level1node1.\nOptional: Save this session of the\n      Classification Learner App by selecting Save from the app\n      toolbar. The session can be opened in the future using the\n      Open button. For level 1 node 1, save the session as\n      ClassificationLearnerSession_level1node1.mat under the\n      results_data directory. To open the session at a later point,\n      first, open the Classification Learner App and then click\n      Open on the app toolbar.\n    \n        Repeat Stage 4, steps 81–90 for each decision in the hierarchy, but\n        following our example use the subset_level2node1 and\n        subset_level2node2 variables for Stage 4, step 79.\n        \n            Export the trained models as variables (Figure 26[href=https://www.wicell.org#fig26]D), trainedModel_level2node1 and\n            trainedModel_level2node2, respectively.\n          \n            Save the Classification Learner App sessions as:\n            ClassificationLearnerSession_level2node1.mat and\n            ClassificationLearnerSession_level2node2.mat, respectively.\n          \n        Return to the\n        feature_selection_and_machine_learning_script.m. Save all the\n        classification models into one workspace variable using the\n        save function.\n      \nsave (fullfile('project_data', 'trainedModels.mat'),\n          ...\n'trainedModel_level1node1',\n          'trainedModel_level2node1',\n          'trainedModel_level2node2')\n        Summary of classifier performance on training data: If you do not have\n        the trained models (Stage 4, step 92) and the training or validation\n        data in your workspace, use load to load in\n        trainingValidation_data.mat and trainedModels.mat. If you\n        are not using hold-out validation, see\n        problem 21[href=https://www.wicell.org#sec6.41].\n      \nload trainingValidation_data.mat",
    "load trainedModels.mat\nCritical: To view how the complete\n      hierarchical decision structure performs on the training data, we make\n      predictions on the training data. However, the following steps performed\n      on the training data do not assess the generalizability of the classifier\n      model. To assess classifier generalizability, we predictions on the unseen\n      validation data (Stage 4, step 102). This section is only for internal use\n      to summarize the training performance of the complete hierarchical\n      classifier.\n    \n        Extract and reformat the training data for level 1 node 1 of the\n        hierarchical classifier: midgut vs. non-midgut, using the custom\n        createSubset function. Extract only the selected features, in the\n        same order as ranked in the classifier model.\n      \ndata2classify_level1node1 = ...\ncreateSubset(training_data,row_start-1,\n          trainedModel_level1node1.RequiredVariables)\nCritical: The order of the features in\n      the data must match the order of the features in the trained classifier.\n      This is ensured by using the createSubset function and using\n      trainedModel_level1node1.RequiredVariables as the input for feature\n      names.\n    \n        Apply the level 1 node 1 classifier to the corresponding training data,\n        data2classify_level1node1. The prediction results are stored in\n        predictions_level1node1.\npredictions_level1node1=trainedModel_level1node1.predictFcn(data2classify_level1node1);\n        Create a confusion matrix for the level 1 node 1 results using the\n        confusionmat and the confusionchart functions.\n        \n            The confusionmat function calculated the values shown in the\n            confusion matrix. The first input is the expected class labels,\n            followed by the predicted class labels (Stage 4, step 95). Store the\n            confusion matrix values in cm_level1node1 (first output).\n            Store the corresponding class labels as they will appear in the\n            plotted confusion matrix in order_level1node1 (second\n            output).\n            \n[cm_level1node1,order_level1node1] = ...\nconfusionmat(data2classify_level1node1.Embryological_Origin,\n                  predictions_level1node1);\nNote: To compute additional\n              performance metrics (e.g., F-score, MCC, etc.), see Stage 4, step\n              101.\n            \n            Plot the confusion matrix using the confusionchart function.\n            The inputs are the outputs from the confusionmat function\n            above. The first input is the confusion matrix values, followed by\n            the ordered class labels.",
    "figure;confusionchart(cm_level1node1,order_level1node1)\n        Apply the level 2 node 1 classifier model to the predicted data.\n        \n            Mark samples predicted as midgut by the preceding decision\n            (predictions_level1node1), using strcmp. Mark midgut\n            samples as true (1) and non-midgut samples as false (0).\n            \nind_col =\n                  strcmp(predictions_level1node1,'Midgut')';\n            Extract the predicted midgut samples from training_data. To\n            retain the header columns in training_data, concatenate true\n            values for the number of header columns (col_start -1) to\n            ind_col.\ndata2classify_level2node1 = training_data(:,[true([1\n                  col_start-1]) ind_col]);\n            Reformat data2classify_level2node1 as shown in Stage 4, step\n            79a. Extract only the selected features, in the same order as\n            ranked in the classifier model (trainedModel_level2node1).\ndata2classify_level2node1 =\n                  createSubset(data2classify_level2node1,row_start-1,...\ntrainedModel_level2node1.RequiredVariables);\n            Apply the trainedModel_level2node1 classifier to generate\n            predictions for level 2 node 1, as shown in Stage 4, step 95.\n            \npredictions_level2node1 = ...\ntrainedModel_level2node1.predictFcn(data2classify_level2node1);\n            Create a confusion matrix as shown in Stage 4, step 96.\n            \n[cm_level2node1,order_level2node1] = ...\nconfusionmat(data2classify_level2node1.Pathological_type,\n                  predictions_level2node1);\nfigure;confusionchart(cm_level2node1,order_level2node1)\n        Apply the level 2 node 2 classifier to the predicted data as shown in\n        Stage 4, step 97.\n        \n            Mark samples predicted as non-midgut by the preceding decision\n            (predictions_level1node1), using strcmp. Mark\n            non-midgut samples as true (1) and midgut samples as false (0).\n            \nind_col =\n                  strcmp(predictions_level1node1,'Non-midgut')';\n            Extract the predicted non-midgut samples from\n            training_data. To retain the header columns in\n            training_data, concatenate true values for the number of\n            header columns (col_start -1) to ind_col.\ndata2classify_level2node2 = training_data(:,[true([1\n                  col_start-1]) ind_col]);\n            Use the custom createSubset function to reformat\n            data2classify_level2node2 as shown in Stage 4, step 79a.\n            Extract only the selected features, in the same order as ranked in\n            the classifier model (trainedModel_level2node2).\ndata2classify_level2node2 =\n                  createSubset(data2classify_level2node2,row_start-1, ...\ntrainedModel_level2node2.RequiredVariables);\n            Apply the trainedModel_level2node2 classifier to generate\n            predictions for level 2 node 2, as shown in Stage 4, step 95.\n            \npredictions_level2node2 = ...\ntrainedModel_level2node2.predictFcn(data2classify_level2node2);\n            Create a confusion matrix as shown in Stage 4, step 96.\n            \n[cm_level2node2,order_level2node2] = ...\nconfusionmat(data2classify_level2node2.Pathological_type,\n                  predictions_level2node2);\nfigure;confusionchart(cm_level2node2,order_level2node2)",
    "Inspect any misclassified samples. In some cases, this could uncover an\n        error in the class labels or a misdiagnosis.\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig27.jpg\n              Figure 27. Visualize training performance of the hierarchical\n              classifier with confusion matrix\n            \n              To visualize the performance of the hierarchical classifier on the\n              training data, generate a confusion matrix. In this example, one\n              PanNET sample and one AppNET sample are misclassified as INET\n              samples. The PanNET sample is misclassified as a midgut sample.\n              However, upon chart review, this tumor was an illeal tumor that\n              had invaded the head of the pancreas with full thickness invasion\n              of the duodenal wall with liver and lymph node metastases.1[href=https://www.wicell.org#bib1]\n              See Stage 4, steps 93–99 for more information. Note: This figure\n              is for visualizing training performance and does not predict the\n              accuracy or generalizability of the classifier model.\n            \nNote: In our training data, one of the\n      non-midgut samples is classified as midgut. This sample appears in the\n      confusion matrix (Figure 27[href=https://www.wicell.org#fig27]) as a PanNET sample that\n      was classified as INET. Upon chart review, this tumor was an illeal tumour\n      that had invaded the head of the pancreas with full thickness invasion of\n      the duodenal wall with liver and lymph node metastases.1[href=https://www.wicell.org#bib1]\n      Hence, the classifier correctly identified the tumour type.\n    \n        Create a confusion matrix for the overall classification performance on\n        the training data.\n        \n            Concatenate the expected and predicted results for the most specific\n            classes (i.e., terminal nodes) in the hierarchy. For the terminal\n            nodes, assign the predicted results to predicted_overall and\n            expected results to expected_overall.\npredicted_overall =\n                  [predictions_level2node1;predictions_level2node2];\nexpected_overall =\n                  [data2classify_level2node1.Pathological_type;...\ndata2classify_level2node2.Pathological_type];\n            Create a confusion matrix as shown in Stage 4, step 96 with\n            expected_overall and predicted_overall as inputs.\n            \n[cm_overall, order_overall] = confusionmat\n                  (expected_overall,predicted_overall);\n        Save the overall performance of the hierarchical classifier on the\n        training data as a table, training_results using the custom\n        evaluationMetrics function.",
    "Note: The function computes different\n      evaluation metrics for the overall performance of the classifier. The\n      first input is the confusion matrix values (cm_overall) from the\n      confusionmat function above. The second input is the ordered class\n      labels (order_overall). The third input sets how the performance\n      metrics for each class should be combined into one score, ‘macro’\n      takes an average of the performance metrics for each class. See the custom\n      evaluationMetrics function for more information.\n    \nfigure;training_results =\n          evaluationMetrics(cm_overall,order_overall,'macro');\nCritical: Applying the hierarchical\n      classification model on the training data does not test the\n      generalizability of the model. Instead, the goal is to generate a\n      performance summary for training of the hierarchical classifier. Recall,\n      the Classification Learner App reports the performance at each\n      decision node, not necessarily overall. The performance values generated\n      in Stage 4, step 101 should not be reported as classifier accuracy.\n    \n        Validation of hierarchical classifier: Extract and reformat the\n        validation data for level 1 node 1 of the hierarchical classifier:\n        midgut vs. non-midgut, using the custom createSubset function.\n        Extract only the selected features, in the same order as ranked in the\n        classifier model.\n      \ndata2classify_level1node1 = createSubset(validation_data,row_start-1,\n          ...\ntrainedModel_level1node1.RequiredVariables)\nCritical: The order of the features in\n      the validation data must match the order of the features in the trained\n      classifier. This is ensured by using the createSubset function and\n      using trainedModel_level1node1.RequiredVariables as the input for\n      feature names.\n    \nNote: After training, the hierarchical\n      classifier is validated on the unseen validation data to assess\n      generalizability to new data. Repeat Stage 4, steps 94–101 for the\n      validation_data; the steps are outlined below.\n    \n        Apply the level 1 node 1 classifier to the corresponding validation\n        data, data2classify_level1node1. The prediction results are\n        stored in predictions_level1node1.\n      \npredictions_level1node1 = ...\ntrainedModel_level1node1.predictFcn(data2classify_level1node1);\n        Create a confusion matrix with the confusionmat function and plot\n        it with the confusionchart function.",
    "The first input into the confusionmat function is the\n            expected class labels followed by the predicted class labels made in\n            Stage 4, step 103. Store the confusion matrix values and the\n            corresponding ordered class labels in cm_level1node1 and\n            order_level1node1 respectively.\n            \n[cm_level1node1,order_level1node1] = ...\nconfusionmat(data2classify_level1node1.Embryological_Origin,\n                  predictions_level1node1);\n            Use the confusionchart function to plot the outputs from\n            confusionmat (Stage 4, step 104a) as a confusion matrix\n            figure.\n            \nfigure;confusionchart(cm_level1node1,order_level1node1)\n        Apply the level 2 node 1 classifier model to the predicted data.\n        \n            Use strcmp to mark the samples predicted as midgut by the\n            preceding decision (predictions_level1node1). Mark midgut\n            samples as true (1) and non-midgut samples as false (0).\n            \nind_col =\n                  strcmp(predictions_level1node1,'Midgut')';\n            Extract the predicted midgut samples from validation_data. To\n            retain the header columns in training_data, append true\n            values for the number of header columns (col_start -1) to\n            ind_col.\ndata2classify_level2node1 = validation_data(:,[true([1\n                  col_start-1]) ind_col]);\n            Use the custom createSubset function to reformat\n            data2classify_level2node1 as shown in Stage 4, step 79a.\n            Extract only the selected features, in the same order as ranked in\n            the classifier model (trainedModel_level2node1).\ndata2classify_level2node1 =\n                  createSubset(data2classify_level2node1,row_start-1, ...\ntrainedModel_level2node1.RequiredVariables);\n            Apply the trainedModel_level2node1 classifier as shown in\n            Stage 4, step 103.\n            \npredictions_level2node1 = ...\ntrainedModel_level2node1.predictFcn(data2classify_level2node1);\n            Create a confusion matrix as shown in Stage 4, step 104.\n[cm_level2node1,order_level2node1] = ...\nconfusionmat(data2classify_level2node1.Pathological_type,...\npredictions_level2node1);\nfigure;confusionchart(cm_level2node1,order_level2node1)\n        Apply the level 2 node 2 classifier to the predicted data as shown in\n        Stage 4, step 105.\n        \n            Use strcmp to mark the samples predicted as non-midgut by the\n            preceding decision (predictions_level1node1). Mark non-midgut\n            samples as true (1) and midgut samples as false (0).\n            \nind_col =\n                  strcmp(predictions_level1node1,'Non-midgut')';\n            Extract the predicted non-midgut samples from\n            validation_data. To retain the header columns in\n            training_data, append true values for the number of header\n            columns (col_start -1) to ind_col.\ndata2classify_level2node2 = validation_data(:,[true([1\n                  col_start-1]) ind_col]);\n            Use the custom createSubset function to reformat\n            data2classify_level2node2 as shown in Stage 4, step 79a.",
    "Extract only the selected features, in the same order as ranked in\n            the classifier model (trainedModel_level2node2).\ndata2classify_level2node2 =\n                  createSubset(data2classify_level2node2,...\nrow_start-1,\n                  trainedModel_level2node2.RequiredVariables);\n            Apply the trainedModel_level2node2 classifier as shown in\n            Stage 4, step 103.\n            \npredictions_level2node2 = ...\ntrainedModel_level2node2.predictFcn(data2classify_level2node2);\n            Create a confusion matrix as shown in Stage 4, step 104.\n            \n[cm_level2node2,order_level2node2] = ...\nconfusionmat(data2classify_level2node2.Pathological_type,\n                  predictions_level2node2);\nfigure;confusionchart(cm_level2node2,order_level2node2)\n        Inspect any misclassified samples. In some cases, this could uncover an\n        error in the class labels or a misdiagnosis.\n      \n        Create a confusion matrix for the overall classification performance (Figure 28[href=https://www.wicell.org#fig28]).\n        \nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/3074-Fig28.jpg\n              Figure 28. Visualize validation performance of the hierarchical\n              classifier with confusion matrix\n            \n              To visualize the performance of the hierarchical classifier on the\n              held-out validation samples (30%), generate a confusion matrix.\n              One PanNET sample was misclassified as an RNET sample in level 2\n              node 2. See Stage 4, steps 102–108 for more information.\n            \n            Concatenate the expected and predicted results for the most specific\n            classes in the hierarchy. Assign the predicted results to\n            predicted_overall and expected results to\n            expected_overall.\npredicted_overall =\n                  [predictions_level2node1;predictions_level2node2];\nexpected_overall =\n                  [data2classify_level2node1.Pathological_type;...\ndata2classify_level2node2.Pathological_type];\n            Create a confusion matrix (Figure 28[href=https://www.wicell.org#fig28]) as shown\n            in Stage 4, step 103 with expected_overall and\n            predicted_overall as inputs.\n            \n[cm_overall, order_overall] = confusionmat\n                  (expected_overall,predicted_overall);\n        Save the overall results of the classifier as a table,\n        validation_results using the custom\n        evaluationMetrics function.\n      \nNote: This function computes various\n      evaluation parameters for the overall performance of the classifier model.\n      For more details, see confusionmat function documentation.\n    \nfigure;validation_results =\n          evaluationMetrics(cm_overall,order_overall,'macro');\n        Use the writetable function to save the\n        validation_results as\n        Table_1_Validation_Results.xlsx under the\n        project_data directory. Open the file to view in Excel.\n      \nwritetable(validation_results, ...\nfullfile('project_data','Table_1_Validation_Results.xlsx'),...\n'WriteRowNames',true,'WriteVariableNames',true);"
  ],
  "subjectAreas": [
    "Rnaseq",
    "Sequence Analysis",
    "Bioinformatics",
    "Gene Expression",
    "Sequencing"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics",
    "Bioinformatics & Computational Biology"
  ]
}