{
  "id": 10560,
  "origin_website": "Jove",
  "title": "Lexical Decision Task for Studying Written Word Recognition in Adults with and without Dementia or Mild Cognitive Impairment",
  "procedures": [
    "The protocol follows the guidelines of the Ethics Committee of the Hospital District of Northern Savo (IRB00006251).\n1. Participant screening\nRecruit younger and older adults who have normal or corrected-to-normal vision and are native speakers of the language tested unless the study addresses specific research questions regarding second language acquisition.\nFor healthy control groups, exclude participants who have a history of neurological or psychiatric disorders.\nFor the clinical groups, recruit individuals who have been diagnosed with Alzheimer’s disease15 or mild cognitive impairment16,17. Recruit only individuals who are able to give informed consent, according to the clinician's judgment. For accurate comparisons, match the age range and mean of the clinical groups with that of the healthy older adult participants.\nMeasure the severity of dementia, for example, using the Clinical Dementia Rating Scale18 (CDR, 0=no dementia, 0.5=very mild, 1=mild, 2=moderate, 3=severe). Exclude patients with severe dementia because the task may be too difficult for them. Do not include participants who seem unable to follow instructions, despite their severity rating.\n2. Stimulus construction\nSelect word stimuli to address specific research questions, for example, whether semantic or orthographic/phonological variables have a stronger influence on word recognition19 in different populations.\nCalculate from a corpus20 or retrieve from a database21 variables reflecting semantic, phonological, and orthographic characteristics of the stimuli so they can be used either as theoretically motivated predictors explaining word recognition reaction times or as control variables. Also, use participants’ gender, age, and years of education as explanatory or control variables.",
    "In addition to the real words, build a set of matched pseudo-words. Pseudo-words resemble real words in that they conform to the language’s norms for placement of certain letters in certain word positions (phonotactics). In order to control for phonotactics, create pseudo-words, for example, by randomly recombining the first syllables from some words with the second syllables from other words. Remove any items that happened to produce a real word through this recombination and all the items that violate the phonotactics of the language.\nMatch the pseudo-words with the target words in terms of the word length in letters and bigram frequency, which is the average number of times that all combinations of two subsequent letters occur in a text corpus. These variables have been shown to influence recognition speed.\n\tNOTE: Manipulating the pseudo-word ratio (e.g., the number of real words relative to the number of pseudo-words) may lead to different results, with responses to the less probable stimuli being slower and less accurate22.\nAdd a set of real-word fillers in order to decrease participant’s expectancy of the next stimulus belonging to a certain type (e.g., a certain inflectional class). Choose them, for instance, from different word categories (e.g., inflectional classes) than the ones used to construct stimuli according to the characteristics of interest.\n3. Experimental design\nPresent letter strings horizontally, one at a time, subtending a visual angle of about 5°.",
    "Begin the experiment with a practice session that includes a small number of trials, with one word presented per trial (e.g., 15 words and 15 pseudo-words not included in the actual experiment). This is to familiarize the participant with the task and the response buttons. If the participant is not responding accurately (‘yes’ button for real words and ‘no’ button for pseudo-words) during the practice trials, provide feedback and redo the practice session.\nDivide the experiment into blocks and give short breaks after the practice session and between the blocks. These breaks allow participants to rest their eyes and will reduce fatigue.\nStart each new block with a few filler items that will not be included in the analysis (e.g., common nouns such as dog, sister, year) because the first few trials of the block are sometimes ignored by participants with MCI or AD.\nPresent the experimental items in a random order for each participant.\nBegin each trial with a fixation mark (e.g., a + sign) appearing in the center of the screen for 500 ms, followed by a blank screen for a fixed (e.g., 500 ms) or variable amount of time (e.g., 500-800 ms).\nImmediately after the blank screen, present a letter string (word or pseudo-word) for 1,500 ms or until the participant responds.\nAfter a response is made or after 1,500 ms from the onset of the word (whichever comes first), follow again with a blank screen until 3000 ms has passed from the beginning of the trial.\nRepeat this sequence until all of the items in the experiment have been presented.\n\tNOTE: Times for the delay between the stimuli serve as an example. Changing them may affect the pattern of results.\n4. Experimental procedure",
    "Place the participant in front of a computer monitor at a viewing distance of about 80 cm in a normally lit room.\nInstruct the participant to decide as quickly and accurately as possible whether the letter string on the screen is a real word or not by pressing one of two corresponding buttons with their dominant hand (e.g., the index finger for real words and the middle finger for pseudo-words) or using the index finger of each hand.\n\tNOTE: Participants try to optimize their performance in line with the instructions. Thus, their responses will be affected by stressing speed over accuracy or vice versa23.\n5. Analyzing data with a mixed-effects model in R\nNOTE: Many different statistical programs can be used to perform the analysis. This section describes steps for analyzing data in R24.\nObtain the reaction time (RT) measured in milliseconds for each trial from the output file of the presentation program (e.g., E-Studio software).\nInstall the packages lme428 and lmerTest29. Attach packages with the function library or require.\nImport data into R by using, e.g., the read.table function.\nCheck the need for transformation, e.g., with the boxcox function from the MASS package25, as the distribution of RT data is typically highly skewed.\n\t> library (MASS)\n> boxcox(RT ~ Expnanatory_variable, data = yourdata)\n\tNOTE: The graph produced by the boxcox function shows a 95% confidence interval for the boxcox transformation parameter. Depending on the lambda values located within this interval, the needed transformation can be chosen, e.g., λ=−1 (inverse transformation), λ=0 (logarithmic transformation), λ=1/2 (square root transformation), and λ=1/3 (cube root transformation).\n\t\nTransform the RT values using inverted transformed RTs (e.g., -1000/RT) or binary logarithms of RTs (e.g., log2(RT)) since these transformations tend to provide more normal-like distributions for reaction times in lexical decision experiments than raw RTs26.",
    "Alternatively, use statistical methods that do not rely on normal distributions and fit robust linear mixed-effects models and provide estimates on which outliers or other sources of contamination have little influence27.\nSince reaction time analyses are typically conducted on accurate responses, exclude trials in which the participants’ response was incorrect (a response of “no” to real words) as well as omissions.\n\t\nAlso, exclude responses to pseudo-words and fillers unless there are specific hypotheses about them.\nExclude trials with response times faster than 300 ms because they typically indicate that the participant was too late responding to a previous stimulus or that he or she accidentally pressed the response button before reading the stimulus.\nBuild a basic linear mixed-effects model that identifies RT as the outcome measure and Subject, Item, and Trial as random effects. Note that variables whose values are randomly sampled from a larger set (population) of values are included as random effects and variables with a small number of levels or for which all levels are included in the data are fixed effects. Add the random effects in the form (1 | Subject) in order to estimate random intercepts for each of the random effects.\n> g1 = lmer (RT ~ (1 | Subject) + (1 | Item) + (1 | Trial), data = yourdata)\n> summary (g1)\nAdd explanatory variables in a theoretically motivated order. For instance, add words’ base frequency as a fixed effect. Some variables, such as base or surface frequency, have Zipfian distributions, so insert them in the model with a transformation that results in a more Gaussian distribution shape, e.g., logarithmic transformation.\n\t> g2 = lmer (RT ~ log(BaseFrequency + 1) + (1 | Subject) + (1 | Item) + (1 | Trial), data = yourdata)\n\t> summary (g2)",
    "Check with the Anova function if adding each predictor (e.g., BaseFrequency) significantly improved the predictive power of the model compared to a model without the predictor.\n\t> anova (g1, g2)\nIf there is no significant difference in the fit of the new model over the simpler model, prefer the simplest model with fewer predictors. Also, check the Akaike Information Criterion (AIC)30 of each model. AIC is a measure of how well statistical models fit a set of data according to maximum likelihood. Lower values indicate a better fit for the data31.\n> AIC (g1); AIC (g2)\nRepeat steps 5.7. and 5.8. by adding other explanatory variables, e.g., some of those that are presented in Table 1, one by one in a theoretically motivated order and keeping only those that significantly improve the predictive power of the model. If variable stimulus onset asynchrony was used, include it as a fixed-effect variable in the model.\nCheck for theoretically motivated interactions between predictors. For instance, add a term of interaction the log of Base Frequency by Age.\n\t> g3 = lmer (RT ~ log(BaseFrequency + 1) + Age + log(BaseFrequency + 1) : Age + (1 | Subject) + (1 | Item) + (1 | Trial), data = yourdata)\n\tNOTE: It is possible that a predictor is significant as a term of interaction with another variable, but not significant as the main predictor. In this case, do not remove this predictor from the model (include it also as the main effect).\nAdd by-participant random slopes32 for predictors by including “1 +” before the variable name, then “| Subject”, e.g., (1 + log(BaseFrequency  + 1) | Subject), because participants’ response times might be affected by words' lexical characteristics in different ways.",
    "NOTE: If there are many continuous predictors, allowing them all to have random slopes is unrealistic because random slope models require large amounts of data to accurately estimate variances and covariances33,34. In case the maximal model does not converge (in other words, successfully compute), simplify the model33. Alternatively, implement Bayesian versions of multilevel modeling35.\nRun the analysis for each participant group separately. Alternatively, run an analysis on all data, with group as a fixed-effect predictor, and then test for an interaction of group by significant predictors.\n> g4 = lmer (RT ~ log(BaseFrequency + 1) + Age + log(BaseFrequency + 1) : Age  + Group + log(BaseFrequency + 1) : Group +  (1 + log(BaseFrequency + 1) | Subject) +  (1 | Item) + (1 | Trial), data = yourdata)\nIn order to remove the influence of possible outliers, exclude data points with absolute standardized residuals exceeding, e.g., 2.5 standard deviations26, and re-fit the model with the new data (yourdata2).\n> yourdata2 = yourdata [abs(scale(resid(g4))) < 2.5, ]\n> g5 = lmer (RT ~ log(BaseFrequency + 1) + Age + log(BaseFrequency + 1) : Age  + Group + log(BaseFrequency + 1) : Group + (1 + log(BaseFrequency +1) | Subject) +  (1 | Item) + (1 | Trial), data = yourdata2)\n\tNOTE: Not all extreme data points are harmful for the model – only those that have excessive leverage over the model.\nIn the case of exploratory (data-driven) analysis, use backward stepwise regression: include all variables in the initial analysis and then remove non-significant variables from the model in a step-by-step fashion. Alternatively, use the automatic procedure of eliminating non-significant predictors with the step function provided by the package lmerTest29.\n\t> step (g4)\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}