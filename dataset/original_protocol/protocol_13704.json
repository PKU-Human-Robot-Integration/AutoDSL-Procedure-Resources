{
  "id": 17530,
  "origin_website": "Jove",
  "title": "Robotized Testing of Camera Positions to Determine Ideal Configuration for Stereo 3D Visualization of Open-Heart Surgery",
  "procedures": [
    "The experiments were approved by the local Ethics Committee in Lund, Sweden. The participation was voluntary, and the patients' legal guardians provided informed written consent.\n1. Robot setup and configuration\nNOTE: This experiment used a dual-arm collaborative industrial robot and the standard control panel with a touch display. The robot is controlled with RobotWare 6.10.01 controller software and robot integrated development environment (IDE) RobotStudio 2019.525. Software developed by the authors, including the robot application, recording application, and postprocessing scripts, are available at the GitHub repository26.\nCAUTION: Use protective eyeglasses and reduced speed during setup and testing of the robot program.\nMount the robot to the ceiling or a table using bolts dimensioned for 100 kg as described on page 25 in the product specification24, following the manufacturer's specifications. Ensure that the arms can move freely and the line of sight to the field of view is unobscured.\n\tCAUTION: Use lift or safety ropes when mounting the robot in a high position.\nStart the robot by turning the start switch located at the base of the robot. Calibrate the robot by following the procedure described in the operating manual on pages 47-5625.\nStart the robot IDE on a Windows computer.\nConnect to the physical robot system (operating manual page 14027).\nLoad the code for the robot program and application libraries for the user interface to the robot:\n\t\nThe robot code for a ceiling-mounted robot is in the folder Robot/InvertedCode and for a table mounted robot in Robot/TableMountedCode. For each of the files left/Data.mod, left/MainModule.mod, right/Data.mod and right/MainModule.mod:\nCreate a new program module (see operating manual page 31827) with the same name as the file (Data or MainModule) and copy the file content to the new module.\nPress on Apply in the robot IDE to save the files to the robot.",
    "Use File Transfer (operating manual page 34627) to transfer the robot application files TpSViewStereo2.dll, TpsViewStereo2.gtpu.dll, and TpsViewStereo2.pdb located in the FPApp folder to the robot. After this step, the robot IDE will not be further used.\nPress the Reset button on the back of the robot touch display (FlexPendant) to reload the graphical interface. The robot application Stereo2 will now be visible under the touch display menu.\nInstall the recording application (Liveview) and postprocessing application on an Ubuntu 20.04 computer by running the script install_all_linux.sh, located in the root folder in the Github repository.\nMount each camera to the robot. The components needed for mounting are displayed in Figure 3A.\n\t\nMount the lens to the camera.\nMount the camera to the camera adaptor plate with three M2 screws.\nMount the circular mounting plate to the camera adaptor plate with four M6 screws on the opposite side of the camera.\nRepeat steps 1.9.1-1.9.3 for the other camera. The resulting assemblies are mirrored, as shown in Figure 3B and Figure 3C.\nMount the adaptor plate to the robot wrist with four M2.5 screws, as shown in Figure 3D.\n\t\nFor a ceiling-mounted robot: attach the left camera in Figure 3C to the left robot arm as shown in Figure 2A.\nFor a table-mounted robot: attach the left camera in Figure 3C to the right robot arm.\nConnect the USB cables to the cameras, as shown in Figure 3E, and to the Ubuntu computer.\n2. Verify the camera calibration\nOn the robot touch display, press the Menu button and select Stereo2 to start the robot application. This will open the main screen, as shown in Figure 6A.\n\t\nOn the main screen, press on Go to start for 1100 mm in the robot application and wait for the robot to move to the start position.",
    "Remove the protective lens caps from the cameras and connect the USB cables to the Ubuntu computer.\nPlace a printed calibration grid (CalibrationGrid.png in the repository) 1100 mm from the camera sensors. To facilitate correct identification of the corresponding squares, place a small screw-nut or mark somewhere in the center of the grid.\nStart the recording application on the Ubuntu computer (run the script start.sh located in the liveview folder inside the Github repository). This starts the interface, as shown in Figure 4.\n\t\nAdjust the aperture and focus on the lens with the aperture and focus rings.\nIn the recording application, check Crosshair to visualize the crosshairs.\nIn the recording application, ensure that the crosshairs align with the calibration grid in the same position in both camera images, as shown in Figure 4. Most likely, some adjustment will be required as follows:\n\t\nIf the crosses do not overlap, press the Gear icon (bottom left Figure 6A) in the robot application on the robot touch display to open the setting screen, as shown in Figure 6B.\nPress on 1. Go to Start Pos, as shown in Figure 6B.\nJog the robot with the joystick to adjust the camera position (operating manual page 3123).\nUpdate the tool position for each robot arm. Press 3. Update Left Tool and 4. Update Right Tool to save the calibration for the left and the right arm, respectively.\nPress on the Back Arrow icon (top right, Figure 6B) to return to the main screen.\nPress on Run Experiment (Figure 6A) in the robot application and verify that the crosshairs align. Otherwise, repeat steps 2.3-2.3.5.",
    "Add and test any changes to the distances and/or time at this point. This requires changes in the robot program code and advanced robot programming skills. Change the following variables in the Data module in the left task (arm): the desired separation distances in the integer array variable Distances, the convergence distances in the integer array ConvergencePos and edit the time at each step by editing the variable Nwaittime (value in seconds).\n\tCAUTION: Never run an untested robot program during live surgery.\nWhen the calibration is complete, press on Raise to raise the robot arms to the standby position.\nOptionally turn off the robot.\n\t窶起OTE: The procedure can be paused between any of the steps above.\n3. Preparation at the start of the surgery\nDust the robot.\n\t\nIf the robot was turned off, start it by turning on the Start switch located at the base of the robot.\nStart the robot application on the touch display and recording application described in steps 2.1 and 2.2.\nIn the recording application, create and then select the folder where to save the video (press Change Folder).\nIn the robot application: press the gear icon, position the cameras in relation to the patient. Change X and Z direction by pressing +/- for Hand Distance from Robot and Height, respectively, so that the image captures the surgical field. Perform the positioning in the Y-direction by manually moving the robot or patient.\n\t窶起OTE: The preparations can be paused between the preparation steps 3.1-3.4.\n4. Experiment\nCAUTION: All personnel should be informed about the experiment beforehand.\nPause the surgery.\n\t\nInform the OR personnel that the experiment is started.\nPress Record in the recording application.\nPress Run experiment in the robot application.",
    "Wait while the program is running; the robot displays \"Done\" in the robot application on the touch display when finished.\nStop recording in the recording application by pressing Quit.\n\t\nInform the OR personnel that the experiment has finished.\nResume surgery.\n\t窶起OTE: The experiment cannot be paused during steps 4.1-4.6.\n5. Repeat\nRepeat steps 4.1-4.6 to capture another sequence and steps 3.1-3.4 and steps 4.1-4.6 to capture sequences from different surgeries. Capture around ten full sequences.\n6. Postprocessing\nNOTE: The following steps can be carried out using most video editing software or the provided scripts in the postprocessing folder.\nIn this case, debayer the video as it is saved in the RAW format:\n\t\nRun the script postprocessing/debayer/run.sh to open the debayer application shown in Figure 8A.\nPress Browse Input Directory and select the folder with the RAW video.\nPress Browse Output Directory and select a folder for the resulting debayered and color-adjusted video files.\nPress Debayer! and wait until the process is finished - both progress bars are full, as shown in Figure 8B.\nMerge the right and left synchronized videos to 3D stereo format28:\n\t\nRun the script postprocessing/merge_tb/run.sh to start the merge application; it opens the graphical user interface shown in Figure 8C.\nPress Browse Input Directory and select the folder with the debayered video files.\nPress Browse Output Directory and select a folder for the resulting merged 3D stereo file.\nPress Merge! and wait until the finish screen in Figure 8D is shown.\nUse off-the-shelf video editing software such as Premiere Pro to add text labels to each camera distance in the video.\n\t窶起OTE: In the video, there is a visible shake every time the robot moved, and the camera distance increased. In this experiment, labels A-T were used for the camera distances.\n7. Evaluation",
    "Display the video in top-bottom 3D format with an active 3D projector.\nViewing experience depends on the viewing angle and the distance to screen; evaluate the video using intended audience and setup.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Medicine"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research"
  ]
}