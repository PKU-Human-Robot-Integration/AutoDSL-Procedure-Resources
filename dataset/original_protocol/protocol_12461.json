{
  "id": 14277,
  "origin_website": "Jove",
  "title": "Studying Food Reward and Motivation in Humans",
  "procedures": [
    "All the procedures described in this protocol were developed and tested following ethical approval from the Cambridge Local Research Ethics Committees.\n1. Grip Force as a Measure of Food Related Motivation\nApparatus and set up:\n\t\nInstall MATLAB with Cogent toolboxes on the stimulus delivery laptop.\nConnect the force transducer and associated data acquisition system to the stimulus delivery laptop via the ethernet port. See Table 1 for details of the required hardware and software.\n\t\tNote: To run the task in the magnetic resonance imaging (MRI) scanner a simple clench force rubber bulb is used, linked to pressure transducer outside the scanner. Changes in air pressure inside the bulb when it is squeezed, can be measured by the transducer and be directly related to the exerted effort.\nSet up the program to continuously poll the data acquisition system and read in 10 samples on each polling. Take the mean of the samples as the force exerted. Note: Galvanic skin response (GSR) can also be measured alongside. For this the stimulus delivery laptop requires a parallel port to connect to the GSR data acquisition system to synchronize the GSR with the other measures. Use a separate computer to record the measured GSR signal to minimize the load on the stimulus delivery laptop. GSR measurement is not discussed further.\nimgsrc://cloudfront.jove.com/files/ftp_upload/51281/51281fig1.jpg\nFigure 1. Hardware set up for the grip force task.\nProcedure:\n\t\nSet up the equipment on a table or other stable surface as shown in Figure 1. Wait for the data acquisition system to connect to the laptop.\nCollect a baseline measure for the grip force transducer and the participant's maximal effort, hereafter referred to as the maximal voluntary contraction (MVC) prior to starting the task.\n\t\t\nPlace the grip force transducer on the table and collect the baseline measure.",
    "To measure the MVC, ask the participant to hold the grip force transducer and choose a comfortable arm position to maintain for the duration of the task. Instruct the participant to squeeze the transducer five times as hard as possible and take the mean of the five exertions as the maximal calibration for the task.Note: The force exerted by the participant during the response period is measured as a percentage of the difference between the baseline and the MVC as follows:imgsrc://cloudfront.jove.com/files/ftp_upload/51281/51281eq1.jpgIf the effort is negative it is set to the minimum force of zero and if it is greater than the MVC measured during calibration it is set to the maximum effort of 100 units. This is done to account for any remaining noise after the 10 sample point smoothing is applied as described above. The resulting series of effort samples are accumulated during the response period and stored as the effort response for the trial.\nStart the task.\n\t\tNote: If the task session is long, then fatigue effects can be taken in to account by measuring the MVC at the end of the task as well, and relating the fatigue effect to the difference between the MVCs at the beginning and the end of the task session.\nKey dependent variables:\n\tThis method captures the force-time curve on each trial. From the force-time curve extract the following variables: area under the curve (AUC), maximum or peak force exerted and the rate or the slope of the force time curve.\nApplications:\n\tThree applications of the grip force measure are described below.\n\t\nExamining relative reward value: the Effortful Picture Selection task.",
    "Note: This task measures the relative effort participants are willing to exert to view different kinds of rewarding images such as foods and consumer goods. The effort ratings are related to their subjective liking ratings for the same images. The experimental design is as follows:\n\t\t\nPresent two images side by side on each trial of the task; one is a large (300 x 300 pixels) and clearly visible default image, and the other a small (5 x 5 pixels) indistinct nondefault image. Exerting force on the transducer enlarges the nondefault image and shrinks the default image.\nSelect 6 images from three reward categories: high calorie food, low calorie food and (gender specific) rewarding nonfoods. Have the images independently rated for subjective liking by a healthy volunteer group. Create image pairs such that every image is paired with all the images from the other two categories. Counterbalance the pairs such that each image appears as default and nondefault image in an equal number of trials.\nRunning the task: Perform all steps described in section 1.2.\nExplain the trial structure to the participant and tell her that she can increase the size of the size of the nondefault image and correspondingly decrease that of the default image by squeezing the transducer.\n\t\t\tNote: The counterbalancing ensures that all images will have equal numbers of trials in which effort will enlarge or shrink them.\nSet the force required to make the nondefault image as large as possible at 10% of each individual's MVC (This percentage may have to be set individually for each Biopac module).",
    "Note: The relationship between exerted force and picture size is determined as follows. Assuming both the background and foreground images are square, let lB and lF be the length of background and foreground images respectively. Let g, GMVC and, GBASE be the grip force response measured during the response period of a trial, maximum force measured during calibration and baseline measured during calibration respectively. Further, assuming a linear relationship between grip force and image size, lB and lF can be written asimgsrc://cloudfront.jove.com/files/ftp_upload/51281/51281eq2.jpgunder the constraintsimgsrc://cloudfront.jove.com/files/ftp_upload/51281/51281eq3.jpg\n\t\t\twhereimgsrc://cloudfront.jove.com/files/ftp_upload/51281/51281eq4.jpg\n\t\t\tThe constraints ensure that an image does not expand more than Lmax even if a force exceeding GMVC is exerted.\nPresent a short demonstration of the task.\nTell the participant that she can view images as she choses depending on how much effort she exerts. Leave the participant on her own to complete the task.\nAfter the task is complete, collect liking ratings for each image on visual analogue scales subsequently.\nTo analyze the data, for each image take the average of the areas under the force-time curves across all the trials in which it was the nondefault image and effort was required to enlarge it. This mean AUC is taken as the measure of the motivation for that particular image.\nExamining subliminal motivation for food.\n\t\tNote: Using both subliminal and conscious stimulus presentations, this task examines both subliminal and conscious motivation for food. The description below is based on a previous study using sensory specific satiation (see Ziauddeen et al.16). The experimental design is as follows:",
    "Select three stimuli: a savory food, a sweet food and a neutral nonfood item. Collect two images of each item, one for the conscious trial and the other for the subliminal trials so as to minimize direct motor specification effects12. Using Adobe Photoshop, format all images to have the same luminance and the same patterned background (a checkered array of 1 mm squares of yellow, red, green, and brown). Blur the picture edges using a single pass.\nCreate a mask image by randomly scrambling all pictures, and then blend them to create a composite image.\nThe subliminal presentation is achieved by sandwich masking. To do this present the mask image for 200 msec, then the stimulus image for 33 msec, followed by the mask again for 267 msec. For the conscious trials present the mask for 200 msec, then the stimulus image for 200 msec and the backward mask for 100 msec. The total presentation is 500 msec in both trial types.\nAfter the masked stimulus presentation, start the response window during which the participant can exert force on the grip force transducer. Provide real time feedback by way of a fluid level on the screen.",
    "Note: In all tasks using the fluid level for feedback to the participants, the height of the column and the maximal height that can be achieved are both varied randomly across trials. e.g. the height of the column is set to vary between 100, 110, and 120 units and the maximal height that can be achieved between 80, 90, and 100 units as a percentage of each participant's maximal force as measured at the start of the task. While the feedback serves an important role in engaging subjects with the task, this set up ensures that there is no consistent relationship between the exerted force and the height of the fluid level from trial to trial. The purpose is to prevent participants from modulating their effort to achieve a particular feedback, such as the getting the fluid level to the very top. Participants are explicitly informed that the feedback is unreliable and are instructed to judge their effort themselves and not to rely on the fluid level.\nFor each trial, present a fixation cross for 500 msec, followed by the masked stimulus for 500 msec and then the response window with fluid level feedback for 3,000 msec.\nRunning the task: Perform all steps as described in section 1.2.\nOn each trial ask the participant to focus her attention on the central fixation cross. Explain to her that when the fluid level appears she can squeeze the force transducer to win points towards the item just presented. Explain that on some trials the image may be difficult to see and suggest she follow her instincts. Emphasize that the feedback in unreliable.\nRun the task in as many blocks as required.",
    "Following the completion of the task, check how well the masking procedure worked. This can be done in two ways: by collecting the participant's subjective report and by performing a forced choice discrimination. In the latter, present the masked stimulus as in the main task, followed by two options and ask the participant to indicate which one was just presented. Present each image as many times as it was presented in each block of the main task.\nCalculate the discriminability index (d') as per signal detection theory, if the masking has worked well, the d' should be close to zero.\nExamining food related motivation in the scanner.\n\t\t\nUsing the grip force bulb and the accompanying pressure transducer, these grip force based tasks can be run in the MRI scanner. If feedback is used, then do so as in section 1.4.2.\n2. Willingness to Pay as a Measure of Reward Value\nNote: This task can be programmed in any appropriate stimulus delivery software and requires only a standard desktop or laptop computer. The version described here has been programmed in Presentation (version 14.5, Neurobehavioral Systems).\nProcedures:\n\tNote: This procedure is a modification of the computerized auction procedure from Plassmann 13. The auction procedure is as follows:\n\t\nThe auction involves a series of rounds, each featuring one food item. Photograph all food items on identical plates and backgrounds. Prior to the start of the task show participants the actual plates used in the images to provide an accurate sense of scale.\nGive the participants a fixed monetary budget, e.g. £3.\nTell the participant that she will be taken through several rounds of the auction and she can place a bid on each round. She can place her bid on a sliding scale that goes from £0-£3 in increments of 10p.",
    "Inform the participant that one round will be selected at the end of the auction as the round that counts. Therefore she does not have to spread her £3 budget across different rounds, and can treat every round as if were the only one.\nTell the participant the computer will be bidding against them in each round. If they outbid the computer on the selected round, they win the food item and only have to pay the amount the computer bid and will be able to keep any remaining change. If however, the computer outbids or matches their bid, they do not get the food item, but still get to keep their monetary budget.\nExplain to the participant that that given these set of rules, the best strategy for bidding in this auction is to bid the amount closest to how much they would be really willing to pay for the food item on offer.\n\t\tNote: The bid collected in this way corresponds to their WTP.\nApplications:\n\t\nExamining sensitivity of the measure to changes in internal state.\n\t\tNote: As a proof of concept, the sensitivity of the measure to changes in value with changes in hunger and satiety was examined. Healthy normal-weight volunteers took part in the auction procedure before and after eating a fixed-calorie meal (550 kCal). A sensory specific satiety manipulation was used.\n\t\t\nCollect hunger and fullness ratings on a visual analogue scale.\nPerform the first block of the task as described in section 2.1. Design the task such that the planned food item is selected as the round that counts provided a nonzero bid is placed.\nPresent the participant with the food they have won and give them 15 min to consume the meal. Subtract the payment from the £3 budget.\nCollect hunger and fullness rating again.",
    "Perform the second block of the task with a new £3 budget. No food is won in the second block.\nContrast the WTP for different items across the two blocks.\nFuture applications: Examining neural systems involved in value computation.\n\t\tNote: This task can be set up and run in the fMRI scanner to examine the neural correlates of value computation. It has recently been used in a pharmacological fMRI study looking at the effect of dopaminergic influences on value computation for food reward. Participants performed a single block of the task after receiving a single dose of either a dopamine agonist (bromocriptine), a dopamine antagonist (sulpiride) or placebo. The procedure was almost identical to section 2.1 apart from the fact that the scale was set to increase in 20p increments. Compared to similar tasks13, this measure permits the capture of the WTP as a more continuous variable as opposed to a discrete variable that takes a maximum of 4 values (corresponding to each button of the standard MRI button box)."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}