{
  "id": 19709,
  "origin_website": "Wiley",
  "title": "Using Mothur to Determine Bacterial Community Composition and Structure in 16S Ribosomal RNA Datasets",
  "procedures": [
    "The purpose of this protocol is to (1) remove poor quality sequences, (2) chimeric sequences, and (3) reduce the number of similar sequences to optimize computation. Typically, a sequenced library is generated from PCR products of about 400 base pairs from two or three variable regions of the 16S rRNA gene. For this basic protocol, we assume that sequences are generated from paired-end 250 or 300 bp sequences generated from an Illumina MiSeq. This pipeline will include the following steps (1) contig generation; (2) quality filtering; (3) alignment to a reference; and (4) the removal of chimeric sequences.\nNecessary Resources\nHardware\n64-bit computer running Linux, Mac OS X, or Windows operating system\nSoftware\nMothur (mothur, RRID:SCR_011947; the program can be downloaded from the software git repo, https://github.com/mothur/mothur/releases[href=https://github.com/mothur/mothur/releases], where software executables are available for Windows, Linux, and Macintosh computers)\nFiles\nPaired-end read data in FASTQ or FASTA format\nSequence list file, containing the sample name and the fastq files names (Table 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-tbl-0001]; an example dataset is available here: https://github.com/bcantarel/microbiomeprotocol[href=https://github.com/bcantarel/microbiomeprotocol])\nTest data, downloaded from the site; use the Download button and select “Download ZIP” or download from the command line terminal using git or curl:\n               \n$ git clone [email protected][href=https://currentprotocols.onlinelibrary.wiley.com/cdn-cgi/l/email-protection]:bcantarel/microbiomeprotocol.git\n$ curl -LJO https://github.com/bcantarel/microbiomeprotocol/archive/0.01.tar.gz\n$tar xvfz microbiomeprotocol-0.01.tar.gz\nAlignment Database, downloaded at the mothur website: https://www.mothur.org/wiki/Alignment_database[href=https://www.mothur.org/wiki/Alignment_database] [We recommend the latest SILVA reference data, version 132 (at the time of publication); for Alignments (in Basic Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-prot-0001]) and Taxonimic Classification in (Basic Protocol 2[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-prot-0002]): https://mothur.org/w/images/3/32/Silva.nr_v132.tgz[href=https://mothur.org/w/images/3/32/Silva.nr_v132.tgz] ]\nTable 1.\n                Example Input File for the Make_Contigs Command\ntable:\n﻿0,1,2\nSample1,Sample1.R1.fastq.gz,Sample1.R2.fastq.gz\nSample2,Sample2.R1.fastq.gz,Sample2.R2.fastq.gz\n1. Generate contigs from FASTQ/FASTA data.",
    "Paired FASTQ or FASTA files containing paired end sequencing reads, typically have the same name where the forward read file is labeled with an R1 and the reverse read file with an R2. The make.contigs command combines these overlapping reads from the sample sequence cluster into contigs. This step requires an input file containing the names of the FASTQ or FASTA files that will be used in the analysis. The input sequence list file can be generated manually or through a mothur script called make.file.\nThe output for this command is fasta files of the contigs and report files. Samples are called “groups” in mothur.\nFrom the command-line prompt (using Terminal in Mac OS X and in Linux or Putty in Windows), run mothur using its full path from the directory where you have saved the data files, for example, if you download the data into microbiomeprotocol/test_data and you installed mothur in the directory:\n/home/user/mothur\nThen execute mothur using:\n         \n$ cd microbiomeprotocol/test_data\n$ /home/user/mothur/mothur\n> make.contigs(file=microbiome.files)\n2. Filter sequences with user defined criteria.",
    "Checking the quality of your contig fasta file could help you decide how to proceed with removal of low-quality data. In order to determine the quality of your data, you can run the summary.seqs command to produce a summary of the contig sequences created in step 1. This step is optional but recommended if you are new to 16S rRNA analysis. Because this protocol is based on PCR, sequences that are larger than the target region are likely errors and should be removed, as should any sequence with an excessive number of homopolymer strings and ambiguous bases. The screen.seq command is used to remove low-quality reads or those likely to contain errors. The input for the screen.seq command is the contig FASTA and group files from step 1 and the summary file that you will create with the command summary.seq, if this step was performed. Each option defines the criteria for quality including the maximum number of ambiguous (N) bases (maxambig = 0) and the maximum length. Sometimes, it is desirable to filter on a metric, such as read length, without defining the specific criteria, minlength >200. The optimize and criteria options are removed based on that metric using the percentile, so to make this criterion based on maxlength using the 90th percentile, the options add is: optimize=minlength, criteria=90. The user could choose to optimize based on other factors such as maxlength or maximum homopolymers. The screen.seqs command produces a new file called microbiome.trim.contigs.good.fasta.\n         \n> summary.seqs(fasta=microbiome.trim.contigs.fasta)\n> screen.seqs(fasta=microbiome.trim.contigs.fasta, summary=microbiome.trim.contigs.summary, group=microbiome.contigs.groups, maxambig=0, optimize=maxlength, criteria=90)\n3. Create FASTA of unique sequences and a table of the counts for each of those representative sequences.",
    "In order to reduce downstream computational resources and speed up compute time, duplicate sequences can be removed with their duplicate count taken into account for abundance measurements. The unique.seqs command removes duplicate sequences and creates a file that tracks the number of sequences represented by the reference sequence. Use the command to get unique sequences from the filtered FASTA file created in step 2. Output will be a FASTA file with unique sequences and a names files with the name of the sequences that are identical to the retained reference sequence. With the count.seq command, generate a table of the count of identical sequences for each group. This table is necessary for determining the abundances of taxonomic classification and OTUs in downstream steps. This command simplifies the names file created in unique.seqs and the groups file from step 2 by setting the rows as the names of the unique sequences and the columns as the names of the groups. Finally, create a summary stats file using the summary.seqs command.\n         \n> unique.seqs(fasta=microbiome.trim.contigs.good.fasta)\n> count.seqs(name=microbiome.trim.contigs.good.names, group=microbiome.contigs.good.groups)\n>summary.seqs(fasta=microbiome.trim.contigs.good.unique.fasta,count=microbiome.trim.contigs.good.count_table)\n4. Generate a sequence alignment.\nAlign the sequences from the FASTA file generated in step 3 to an alignment database. Using your alignments, sequences that do not align to the desired 16S region can be determined and removed with the screen.seqs step and filter.seqs steps. The following command removes (1) homopolymers of length >8 using the option maxhomop=8 and (2) start, end, and minimum lengths that fall outside the 90th percentile bracket using the options optimize=start-end-minlength and criteria=90. Alternatively, a threshold can be set for each metric. The filter.seq command trims the gap ends of the alignment.\n         \n> align.seqs(fasta=microbiome.trim.contigs.good.unique.fasta, reference=template.align)\n> screen.seqs(fasta=microbiome.trim.contigs.good.unique.align, count=microbiome.trim.contigs.good.count_table, summary=microbiome.trim.contigs.good.unique.summary, optimize=start-end-minlength, criteria=90, maxhomop=8)\n>\nfilter.seqs(fasta=microbiome.trim.contigs.good.unique.good.align, vertical=T, trump=.)\n5. Reduce sequence redundancy.",
    "The unique.seqs command reduces the number of sequences for analysis, while maintaining them in the sequences count. The pre.cluster command uses the fasta file to cluster the sequences with a maximum number of base differences and collapses possible PCR error.\n         \n>\nunique.seqs(fasta=microbiome.trim.contigs.good.unique.good.filter.fasta,count=microbiome.trim.contigs.good.good.count_table)\n>\npre.cluster(fasta=microbiome.trim.contigs.good.unique.good.filter.unique.fasta,\ncount=microbiome.trim.contigs.good.unique.good.filter.count_table, diffs=2)\n6. Identify and remove chimeras.\nChimeras, which are single DNA sequences arising from multiple parent sequences, can exist in your sequencing reads because of laboratory manipulation or PCR artifacts. Potential chimeras can be identified using the chimera.vsearch command and they can be removed using the remove.seqs command.\n         \n>\nchimera.vsearch(fasta=microbiome.trim.contigs.good.unique.good.filter.unique.precluster.fasta,\ncount=microbiome.trim.contigs.good.unique.good.filter.unique.precluster.count_table, dereplicate=t)\n>\nremove.seqs(fasta=microbiome.trim.contigs.good.unique.good.filter.unique.precluster.fasta,\naccnos=microbiome.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.accnos)\n>\nrename.file(fasta=microbiome.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta,\ncount=microbiome.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.count_table, prefix=final)",
    "The purpose of this protocol is to determine the taxonomic classification of the sequences passing quality control filters from Basic Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-prot-0001]. Classification is based on a reference phylogenetic tree and variability of sequences in a taxonomic group can be classified at the phylum, class, order, family, genus, or species rank. Species classification is difficult with only a proportion of the 16S rRNA gene.\nNecessary Resources\nHardware\n64-bit computer running Linux, Mac OS X, or Windows operating system (use the name software and datafiles shown in Basic Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-prot-0001])\nSoftware\nMothur (mothur, RRID:SCR_011947; program downloaded from the software git repo: https://github.com/mothur/mothur/releases[href=https://github.com/mothur/mothur/releases], where software executables are available for Windows, Linux, and Macintosh computers)\nFiles\nName software and datafiles (produced in Basic Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-prot-0001])\nFasta and count files (generated in Basic Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-prot-0001])\nReference database of 16S rRNA sequences\nTaxonomic classification of the sequences in the reference database (Taxonomies and reference sequences can be obtained at https://mothur.org/wiki/Taxonomy_outline[href=https://mothur.org/wiki/Taxonomy_outline]. We recommend the taxonomy file downloaded in Basic Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-prot-0001].)\n1. Classify sequences.\nTaxonomic classification is based on a database of reference sequences and a phylogenetic tree. There are available methods: Wang and kNN. Wang uses the profile of k-mers to match sequences into taxonomic groups using the k-mers profiles of each classification in the reference tree. The kNN method assigns taxonomy by the taxonomic assignments of the k-Nearest-Neighbors. Therefore, a sequence classification can differ based on the method and phylogenetic tree. There are three widely used taxonomic classification phylogenies: (1) Ribosomal Database Project (RDP; https://mothur.org/w/images/d/dc/Trainset16_022016.rdp.tgz[href=https://mothur.org/w/images/d/dc/Trainset16_022016.rdp.tgz]), (2) SILVA (https://mothur.org/w/images/3/32/Silva.nr_v132.tgz[href=https://mothur.org/w/images/3/32/Silva.nr_v132.tgz]), and (3) Greengenes (http://www.mothur.org/w/images/6/68/Gg_13_8_99.taxonomy.tgz[href=http://www.mothur.org/w/images/6/68/Gg_13_8_99.taxonomy.tgz]). While most of these taxonomies overlap well, differences can affect taxonomic classification (Balvočiute & Huson, 2017[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-bib-0001]). The program classify.seqs is used to predict the taxonomic classification for each read or contig.\n         \n> classify.seqs(fasta=final.fasta,count=final.count_table, reference=reference.fasta, taxonomy=reference.tax, cutoff=80)\n2. Remove sequences based on taxon.",
    "False positive classification can be removed. Because this example is targeting 16S rRNA from eubacteria, we are removing all non-bacterial classifications.\n         \n> remove.lineage(fasta=final.fasta, count=final.count_table, taxonomy=final.reference.wang.taxonomy, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota)\n3. Get summary of taxonomy.\nTo create a data matrix table that has the count of each taxonomic classification for each sample, use the summary.tax command. The resulting data matrix can be used for plotting the taxonomic profiles (see Support Protocol[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-prot-0003]).\n         \n>\nsummary.tax(taxonomy=final.reference.wang.taxonomy,count=final.pick.count_table)",
    "In order to assess the taxonomic composition of samples, the taxonomic profiles can be plotted in order to compare samples. The purpose of this protocol is to (1) open the taxonomy table from the above protocol, (2) select the abundances of the taxa in a particular rank (kingdom to genus), (3) normalize the counts, and (4) create a stacked barplot.\nNecessary Resources\nR (https://cloud.r-project.org[href=https://cloud.r-project.org])\nR Libraries from CRAN reshape2, tidyverse, RColorBrewer, installed using the following command:\n               \ninstall.packages(c(\"reshape2\",\"tidyverse\",\"RColorBrewer\"))\n1. Prepare a table of taxonomic abundance of the family level.\nThe tax summary table uses a column called taxlevel to indicate the distance from the root of the phylogenetic tree where 1 =Kingdom, 2=Phylum, 3=Class, 4=Order, 5=Family, 6=Genus, and 7=Species. The following code can be run using the output tax summary table. The code generates a plot of the phylum (Fig. 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-fig-0001]).\nOpen an R interactive session using your favorite environment such as R Studio.\n         \n> tsum <- read.table(file=’ final.reference.wang.tax.summary’,header=TRUE)\n> header <- names(tsum)\n> dds <- tsum[rowMax(tsum[c(6:length(header))]) > 10, ]\n> dds.header <- names(dds)\n> keepcols <- header[c(6:length(names(dds)))]\n> tlevel <- select(filter(dds,taxlevel == 2),keepcols)\n> libSizes <- melt(colSums(tlevel))\n> colnames(libSizes) <- c('SampleCt')\n> tlevel$taxon <- as.character(filter(dds,taxlevel == 2)$taxon)\n> temp <- melt(tlevel,id.vars='taxon')\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/1be9799d-8c90-4880-b681-58390dcad099/cpbi83-fig-0001-m.jpg</p>\nFigure 1\nTaxonomic profile at the family level of four mock community samples.\n2. Determine a normalized count.\n         \n> temp2 <- unique(merge(libSizes,temp, by.y=‘variable', by.x=‘row.names'))\n> temp2$normct <- round(10000*(1e-6+(temp2$value/temp2$SampleCt)),0)\n> taxontbl<-\nmerge(sgroups,temp2,by.y=‘Row.names',by.x=‘SampleID')\ntbl <- unique(select(taxontbl,‘SampleName', ‘SampleGroup', ‘taxon',‘normct'))\n3. Create a PDF file containing a stacked bar plot of phyla by sample.\n         \n> pdf(file=paste(study,\".taxon_barchart\",levelname[i],‘.pdf', sep=''), paper=‘USr')\n> p2 <- ggplot(data=tbl, aes(x=SampleName, y=normct, fill=taxon)) + geom_bar(stat=\"identity\") + guides(guide = guide_legend(ncol=2)) +theme(axis.text.x=element_text(angle=45, hjust=1, size = 5)) + theme(legend.title=element_text(size=8), legend.text = element_text(size=8))\n> print(p2)\n> dev.off()",
    "Operational taxonomic units (OTUs) are clusters of similar sequences that represent a taxonomic unit such as species or genus. Due to the lack of consistent prokaryotic taxonomies and reliance on a reference database to calculate diversity and assess differentially abundance taxa, it is more beneficial to use OTUs rather than taxonomic assignment. Alpha and beta diversity could be used to explain biological diversity of OTUs. Alpha diversity is diversity within a specific sample whereas beta diversity represents the diversity between samples within a microbial community structure. The diversity can be explained using richness, the number of different species, and evenness, distribution of species in OTU.\nNecessary Resources\nHardware\n64-bit computer running Linux, Mac OS X, or Windows operating system\nSoftware\nMothur (mothur, RRID:SCR_011947)\nFiles\nName software and datafiles (produced in Basic Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-prot-0001] and Basic Protocol 2[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-prot-0002])\nFasta and count files (from Basic Protocol 1[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-prot-0001])\nTaxonomic assignment (from Basic Protocol 2[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-prot-0002])\n1. Determine OTU abundances and taxonomically classify OTUs.\nOTU classification requires that (1) a distance matrix is calculated between sequence pairs and (2) sequences are clustered by distance. The dist.seqs command creates a distance matrix and any distances >0.03 will not be included in matrix. The cluster command determines the OTUs at difference distances. A shared file provides the abundance of each OTU by sample and is produced using the make.shared command. The classify.otu command identifies the consensus taxonomic classification for OTUs.\n         \n> dist.seqs(fasta=final.fasta, cutoff=0.03)\n> cluster(column=final.dist, count=final.count_table)\n> make.shared(list=final.opti_mcc.list,count=final.count_table, label=0.03)\n> classify.otu(list=final.opti_mcc.list,count=final.count_table, taxonomy=final.reference.wang.pick.taxonomy, label=0.03)\n2. Create a file for input into applications for visualization.",
    "There are programs that will allow for further analysis and visualization of the results. The make.biom files creates a biom file using your shared file and the OTU taxonomic classification. Biom files can be imported into external programs such as MEGAN (RRID:SCR_011942; Huson & Weber, 2013[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-bib-0008]; Huson et al., 2016[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-bib-0007]) to perform additional analysis and create plots.\n         \n> make.biom(shared= final.opti_mcc.shared, constaxonomy=final.opti_mcc.0.03.cons.taxonomy)\n3. OTU richness estimation:\nWhen sampling a new environment, in order to get a sense of the richness, you can calculate the number of new OTUs observed with each new sample. With a small number of samples, you would expect many new OTUs added. As number of OTUs levels offs and few new species are detected, the accuracy of your species richness increases. Generate a rarefaction curve to estimate the OTUs richness with this command:\n         \n> rarefaction.single(shared=final.opti_mcc.shared)\n4. Diversity calculation:\nAlpha diversity combines OTU richness and evenness to determine the diversity of a sample. Samples with a few dominating OTUs will have a lower diversity than samples with the same number of OTUs with equally distributed abundances. To determine the OTU diversity we use the summary.single command. The calc option determines the diversity distance metrics to be calculated including Shannon and Inverse-Simpson (Fig. 2[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-fig-0002]).\n         \n> summary.single(shared= final.opti_mccshared, calc=npshannon-invsimpson)\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/3fe71bfe-2926-41eb-9239-2f1579c279ee/cpbi83-fig-0002-m.jpg</p>\nFigure 2\nOperational taxonomic unit (OTU) diversity. Diversity of mock community samples using the (A) Inverse-Simpson and (B) Shannon calculation methods.\n5. Sample comparison:\nPairwise distances can be calculated pairwise between samples using the dist.shared command. The calc option determines the diversity distance metrics to be calculated. In this example, we are using Jaccard coefficient, the Yue and Clayton theta, and the Bray-Curtis index to determine OTU diversity. Using the resultant distance matrixes, samples can be visualized by plotting principal coordinates (PCoA) or non-metric multidimensional scaling (NMDS; Fig. 3[href=https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpbi.83#cpbi83-fig-0003]).",
    "> dist.shared(shared=final.opti_mcc.shared, calc=thetayc-braycurtis)\n> pcoa(phylip=final.opti_mcc.thetayc.0.03.lt.dist)\n> nmds(phylip=final.opti_mcc.thetayc.0.03.lt.dist, mindim=2, maxdim=5)\n<p>imgsrc:https://currentprotocols.onlinelibrary.wiley.com/cms/asset/586cc10f-b50f-408e-9c48-d83ba53776d0/cpbi83-fig-0003-m.jpg</p>\nFigure 3\nPlot of (A) the principal coordinates (PCoA) and (B) non-metric multidimensional scaling (NMDS) of the 4 mock community samples."
  ],
  "subjectAreas": [
    "Bioinformatics"
  ],
  "bigAreas": [
    "Bioinformatics & Computational Biology"
  ]
}