{
  "id": 19479,
  "origin_website": "Jove",
  "title": "Group Synchronization During Collaborative Drawing Using Functional Near-Infrared Spectroscopy",
  "procedures": [
    "The methodology was approved by the Hospital Israelita Albert Einstein (HIAE) Ethics Committee and is based on a procedure for collecting neural data (fNIRS), as well as gaze behavior data, with young adults during a collaborative drawing experience. All collected data were managed on the Redcap platform (see Table of Materials). The project was audited by the Scientific Integrity Committee of the Hospital Israelita Albert Einstein (HIAE). Young adults, 18-30 years old, were selected as subjects for the present study. Written informed consent was obtained from all participants.\n1. Preparation for the study\nSubjects\n\t\nDetermine the target study sample.\nInform all volunteers about the experimental protocol and their rights, prior to the game. Ensure that they sign an informed consent form and an image use consent form (not mandatory), fill in a registration form, and answer psychological questionnaires and scales.\nControl the level of relationship between participants of the quartet (strangers, friends, partners, etc.), as previous knowledge may interfere. In this study, the quartets were composed of strangers.\nCompose quartets of same-gender individuals.\n\t\tNOTE: This gender criterion avoids social interaction interferences34,35.\nSetting\n\t\nRemove all potential eye distractors from the scene.\nTo set up, include a square table, four stools (measuring 18.11 in x 14.96 in), and two wire supports (e.g., tripod) (Figure 1).\nTurn off all electrical devices such as air conditioning during the experimental condition. Ensure that the room has sufficient lighting for people to observe and draw and that the room temperature is pleasant.\nConsider the extent of fNIRS wires (see Table of Materials), position all cables so that they remain stable during the experimental task.\nConsider space for two researchers to move along the setting.\nEnsure that experimenters follow their scripts and movement schemes.",
    "Position the quartet on the square table, two by two, so that each individual can observe the other three individuals.\nGive each quartet participant a tag with a number (1 to 4). Ensure Subject 1 sits across from Subject 3 and next to Subject 2.\n\t\tNOTE: The tag number corresponded to subjects position on the table and their previously prepared cap (Table of Materials).\nDrawing paradigm\n\t\nCollaborative face drawing-the social condition\n\t\tNOTE: This game's goal is to direct the visual attention of the subjects to their partners' faces, inducing them to more conscious observation among themselves. By connecting feelings and visual perception, the collaborative face drawing technique is a valuable way to activate empathic responses, interpersonal curiosity, and connectivity among participants. It requires theory of mind capacity, which includes imitation and anticipating others' behavior19. Use the following steps:\n\t\t\nInstruct the participants about the game rules.\nDivide each paper into three horizontal strips, namely drawing strips.\nHave each strip correspond to a social drawing condition (e.g., C1, C2.). After every social drawing condition, change papers among the quartet.\nHave participants draw the forehead and eye area, on the top strip of all paper sheets.\n\t\t\tNOTE: The middle strip is for depicting the nose and mouth area. The bottom strip is for depicting the chin, neck, and shoulder area.\nInclude instructions of who to draw (e.g., S1/S3 meaning that participant 1 draws participant 3 and vice versa) in all paper strips.\nHave each paper representing a fully drawn portrait of a participant.\n\t\t\tNOTE: Consider different pastel writing paper colors for the different game phases.\nHave each participant's face depicted in a collaborative way by their partners. (Figure 2)\nConnect the dots game-the non-social condition",
    "NOTE: The control drawing condition is a game of connecting the dots. Each participant is invited to connect the dots of ascendent serial numbers to form a drawing. The connect the dots game is used as a neuropsychological instrument to measure cognitive domains such as mental flexibility and visual-motor skills36. The game stimulates visuospatial skills, increases mental activity37, and enhances mental abilities38. Use the following steps:\nInstruct the participants.\n\t\t\nOnce the cap is in position, instruct the participants about fNIRS, the equipment, the caps, the wires, and the possible risks or discomforts involving the procedure.\nRemind them again about their right to leave the experiment at any time.\nExplain the two different drawing tasks.\nFor the collaborative drawing, explain the horizontal strips and how to know where and who to draw in each strip.\nFor the connect dots game, explain that they will have to connect the numbers in ascending order until the figure is revealed.\nExplain about the resting period and the recorded task commands.\nEngage the participants to observe their partners and the details that differentiate them. Indicate that, at the end of the study, the quartet that follows the rules and draws the most detailed figures will be rewarded.\nimgsrc://cloudfront.jove.com/files/ftp_upload/63675/63675fig01.jpg\nFigure 1: The setting. The setup includes a squared table, four stools, and two wire supports (e.g., tripod), fNIRS equipment, a computer, and the cameras. (A) The setting scheme: Green numbers (1-4) correspond to the participants' labels and their stools/positioning at the table during the experimental run. Yellow numbers: 1 = fNIRS wiring supports, 2 = fNIRS signals' notebook receiver, 3 = NIRSport, 4 = 360° camera, 5 = support cameras. (B) Setting ready for the experimental run. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/63675/63675fig01large.jpg]\nimgsrc://cloudfront.jove.com/files/ftp_upload/63675/63675fig02.jpg",
    "Figure 2: Collaborative portraits-examples of portraits drawn in a collaborative way. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/63675/63675fig02large.jpg]\n2. Experimental paradigm\nAdapt the game for fNIRS acquisition\n\tNOTE: Adapt the game so that it is possible to capture the functional image of the brain through fNIRS and that data has a significant quality.\n\t\nDefine the number of blocks.\n\t\tNOTE: The conditions must be repeated an adequate number of times to reduce the margin of error in the results. However, many repetitions can lead participants to automate tasks.\nPlan the duration of each block.\n\t\tNOTE: Consider the hemodynamic caption response time (on average 6 s after the beginning of a task). Also, consider the influence of block sizes to determine the filter for the following steps.\nAdd a resting state period at the end of each block of both conditions (so that the hemodynamic signal decays before the start of the next block).\nPlan the order of blocks and create pseudo-randomized block sequences to reduce anticipatory effects.\nPlan the total duration of the game.\n\t\tNOTE: Consider participants' possible discomfort regarding the fNIRS tight caps and their proximity to each other. The blocks and conditions used in this protocol were designed as follows: nine blocks of the social condition of collaborative drawing (Table 1) and nine blocks of the non-social condition of connecting dots were created (duration = 40 s each); A resting period of 20 s between each of the blocks; three different sequences (Table 2) to perform the tasks (to avoid a condition being performed more than two times in a row). The experimental task duration was approximately 18 min.\nParadigm programming software\n\t\nUse a software to assist in creating and organizing paradigm blocks and signaling to the participants when to start a new task.",
    "NOTE: The NIRStim software (see Table of Materials) was used in this case. Create the block sequences and program their distribution over the time during the experiment.\nDefine events with visual (text and images) or auditory contents to indicate to the participants when to begin each task. In the Events tab, click on the button Add Event. Name the event in Event Name, select the event type in Stim Type, and define a color to represent the event in a presentation overview on Color-ID. Create markers to send to the acquisition software at the beginning of these tasks on Event Marker.\nDetermine the task execution order and the number of repetitions of each one of them in the Trials tab. Also, insert rest periods. Determine the duration of both. Randomizing or not randomizing the trials is possible by selecting On/Off on Randomize Presentation; save the settings on the Save button.\nDuring the experimental run, display all the stimuli programmed in a black window (to prevent participant distraction) by pressing Run.",
    "Table 1: Collaborative drawing condition. S1 = Subject 1, S2 = Subject 2, S3 = Subject 3 and S4 = Subject 4. Drawing dyads represents who is drawing who, and the drawing strip represents the writing paper's position for drawing in each condition. For example, for the first Block, use a blue paper sheet. C1, C2, and C3 represent 40 s of the paradigm of drawing social conditions that complete one portrait. C1 (drawing the forehead area, drawing dyads: S2 and S4; S1 and S3), C2 (drawing the nose area, drawing dyads: S1 and S4; S2 and S3) and C3 (drawing the chin area, drawing dyads: S3 and S4; S1 and S2). Follow the diagram for Blocks 2 and 3. This randomization maintains the order of drawing among volunteers (drawing the frontal partner, then the front-side partner, and lastly, the partner sitting next to them) and alters the order of the sheet strips to be drawn. Please click here to download this Table.[href=https://www.jove.com/files/ftp_upload/63675/63675_Table 1.xlsx]\nTable 2: Sequence 1-task randomization (social, non-social, and resting). Please click here to download this Table.[href=https://www.jove.com/files/ftp_upload/63675/63675_Table 2.xlsx]\n3. Video setup and data acquisition\nCameras and video recording\n\t\nSelect a commercially available scene camera (360°, see Table of Materials). Position that on the table so that all the participants' eye and head movements can be perceived simultaneously.\nClean and check the memory card and battery. Check the brightness of the image. Test these items before the participants are located.\nCheck for possible interferences on fNIRS reception. If so, increase the space between the equipment and its receiver.\nThe equipment receiver must be independent of the fNIRS data receiver. Consider a notebook or a tablet located as far as possible from the table setting.\nStart the equipment, check the interface, and set the recording mode before fNIRS calibration.",
    "Consider one or two adjacent or supporting cameras that can be placed after both edges of the table.\nVideo analysis\n\t\nFor valuable statistical results, select a synchronized view/analysis software or platform that allows the transcription and coding of several video contents simultaneously, like INTERACT (see Table of Materials).\nSet parameters that enable the search for patterns/sequences to refine observational data to the research questions, e.g., individual gaze behavior metrics, head and eye movement, hand movement, facial expressions, and talking behavior.\nIf one plans to record physiological measures, consider a software (see Table of Materials) that allows the integration of measured data from other acquisition systems.\nIn the analysis process, consider not only the duration of events but also the sequence, their position in time, and how they relate to each other.\nData extraction\n\t\nStart by downloading the video from all cameras (MP4 format). Load them into INTERACT. Segment the video data for coding and further analysis. For data extraction, mark the video sections manually and provide them with codes.\n\t\tNOTE: The purpose of segmenting and coding is to provide data categories so that the researcher can highlight and analyze different target behaviors.\nSegmentation\n\t\t\nBy pressing Code Settings, create a first tier by dividing the block sections into social and non-social conditions and resting period. Create a second tier by dividing participants' behavioral data along with social conditions (face drawing). Align them by using the audio trigger timeline. Manually mark the start and end of each condition. Define the coding scheme following the guidelines (steps 3.3.2.2.-3.3.2.6.).\nEnsure that the coding scheme tracks behavior cues (duration and quantity) for each face drawing section (social condition) from all participants individually.\nCode for object-related attention-participant's gaze toward the drawing partner.",
    "NOTE: Gaze behavior has a dual function: gathering information from others (encoding), as well as communicating to others (signaling)39,40.\nCode for mutual gaze (when both partners that are drawing one another share visual contact).\n\t\t\tNOTE: Recent studies revealed increased activity in the anterior rostral medial prefrontal cortex (arMPFC) and its coupling with the inferior frontal gyrus (IFG) when partners established mutual gaze41.\nCode for associated behaviors during gaze behavior (single or mutual) such as smiling, direct speech, facial expressions, and laughs, indicating higher attentiveness to the drawing partner (Supplementary Figure 1).\nTranscribe and subdivide into categories the group participants' gaze behavioral data. Create interaction codes for each participant by labeling them. Make explicit the target behavior and tag number while coding.\nCoding and analyses\n\t\tNOTE: One of the researchers must undertake the behavioral coding task and analysis, since they are easily identified in the video. Observe the following:\n\t\t\nThe extraction of the information must occur manually; mark on the timeline of each condition the observed behaviors according to the coding scheme. Mark the duration of each behavior. Do this for each participant separately.\nCross-reference the participants' timelines to look for shared behaviors. Return to the video observation to analyze the quality of sharing (Supplementary Figure 2).\nUsing the Export key, export the raw data as a text file or table file so that data can be sorted along the timeline, selected, counted, and tabled.\n\t\t\tNOTE: In this protocol, the sequential analysis function was not used due to the small number of coded event sequences42.\nDrawing metrics\n\tNOTE: This protocol uses drawing metrics to study possible correlations between participants' gaze behavior and the applied psychological tests. The following criteria were determined:\n\t\nStroke quantity: Manually count the number of drawing strokes made by each participant in every face drawing section.",
    "Line continuity: Subdivide categories of long and short drawn lines. Manually count participants' long and short drawn lines.\n\t\tNOTE: Observational drawing results from direct observation of a chosen real object. Some recent studies found a correlation between line length and tracing or drawing tasks. Tracing task lines tend to be longer than drawing task lines43. This protocol associates tracing with memorized images that the individual has made stable and carries as drawing references in his/her symbolic system18.\nDrawing patterns: Relate to individual drawing patterns18 (Figure 3).\n\t\tNOTE: This protocol considers a binary classification for drawing pattern: 0, when the participant is in observational drawing mode (i.e., when the participant observes his/her drawing object and copies what he/she sees); and 1, when the drawing reflects internal stable memorized images (when there is a pattern of repeating shapes such as eyes, mouth, and hair throughout the drawing conditions).\nObserve details, including counting drawn details during the experiment (example.g., wrinkles, spots, eye shape, and eyebrow size, among others).\n\t\tNOTE: Drawn details may indicate greater attention to the object of drawing.\nPsychological tests\n\t\nScreen for symptoms of anxiety and depression, attention-deficit/hyperactivity disorder, and social skills when conducting group studies. Use free or commercially available scales.\n\t\tNOTE: This protocol suggests using the following: the Hospital Anxiety and Depression Scale44; the Social Skills Inventory45 (an inventory that evaluates the individual's social skills repertoire); and the Adult Self-Report Scale (ASRS-18) for the assessment of attention-deficit/hyperactivity disorder (ADHD) in adults46.\nimgsrc://cloudfront.jove.com/files/ftp_upload/63675/63675fig03.jpg\nFigure 3: Examples of individual drawing patterns. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/63675/63675fig03large.jpg]\n4. fNIRS setup and data acquisition\nData acquisition hardware",
    "Ensure to use acquisition hardware for the fNIRS registrations. The recordings must be performed by a combination of systems that can be read in the same recording program, totaling 16 channels.\n\t\tNOTE: Data acquisition was carried out using two continuous-wave systems (NIRSport, see Table of Materials) for the present study. Each piece of equipment has eight LED illumination sources emitting two wavelengths of near-infrared light (760 nm and 850 nm) and eight optical detectors (7.91 Hz).\nfNIRS optode channel configuration\n\t\nUse the NIRSite tool to locate the optodes over the PFC regions (see Table of Materials). Configure the distribution of optodes on the caps in a way that the channels are positioned above the regions of interest on all the participants' heads.\nDivide the optodes among the four participants for the simultaneous acquisition of signals.\n\t\tNOTE: The caps must have a configuration based on the international 10-20 system, and the anatomical areas of interest include the most anterior portion of the bilateral prefrontal cortex. For this protocol, optode placement was guided by the fNIRS Optodes' Location Decider (fOLD) toolbox47. The ICBM 152 head model (see Table of Materials) parcellation generated the montage. The recruitment of the prefrontal cortex region in social interaction tasks has been explained as a correlate of behavior control processes, including self-regulation48. Figure 4 represents the position of the sources and detectors.\nPreventing artifacts\n\t\nRemove distractors from the room where the game will take place.\nAdvise the volunteers to move only as necessary.\nDuring the experiment, disconnect the NIRSport amplifier and the laptop from the electrical network.\nTurn any other equipment that works near the infrared spectrum off, such as air conditioning equipment. Turn off electrical devices present in the environment.\nSetting the fNIRS apparatus",
    "Previously, measure the brain perimeters of the four participants as follows: measure the distances between the nasion and the inion around the head to determine each participant's cap size. Always use a cap of a smaller size in relation to the perimeter of the head in order to give more stability to the optodes.\nOn the day of the acquisition, instruct the participants to sit on the stool and then explain the expected process of placing the cap on the head.\nFit the sources and detectors to the cap according to the predetermined settings. As a matter of organization, follow the pattern of using the optodes 1 to 4 on Subject 1, from 5 to 8 on Subject 2, from 9 to 12 on Subject 3, and from 13 to 16 on Subject 4.\nPut the caps on the participants' heads and position them so that the central midline (Cz) is at the top of the head. To check if Cz is at the central position, certify that it is located at half the distance between the nasion and inion.\n\t\t\nAlso, measure the distance between the left and right ear (Crus of Helix) above the top of the head and Position Cz.\nUse overcaps to prevent ambient lights from interfering with the data acquisition.\nConnect the wires of the optodes to the amplifiers. As a matter of organization, follow the pattern of connecting optodes 1 to 8 to NIRSport 1 and optodes 9 to 16 to NIRSport2.\nConnect both NIRSport 1 and 2 to the computer via a USB cable.\nData acquisition software\n\t\nAfter setting up the equipment, enable a software to acquire the fNIRS data. In this study, the NIRStar (see Table of Materials) software was used. On NIRStar, carry out the following steps:",
    "Click on Configure Hardware on the menu bar. Select the option Tandem Mode on the Hardware Specification tab so the hyperscanning can be performed.\nOn the Configure Hardware tab, select a montage from among the predefined common montages or from the customized ones, and check the settings in Channel Setup and Topo Layout.\nPerform an automatic calibration by clicking Calibrate on the Display Panel. The signal quality indicator allows the verification of the integrity of the received data. Assess whether the quality of the data is enough to start the acquisition; that is, see if the channels are signaled as green or yellow.\n\t\t\tNOTE: If the directed channels are represented in red or white, remove them from the cap, check that there is no hair preventing the light from reaching the head, and clean the optodes with a cloth or towel. Connect them again to the cap and repeat the calibration.\nWhen ready to start the procedure, have a preview of how the signals are being received by clicking on Preview. Then, start recording the signals on Record.\nOpen NIRStim, the blocks programming software (see Table of Materials), and start the presentation of the programmed blocks. The markers must be registered automatically, and their marking must be seen on the fNIRS data acquisition software.\nAfter the end of the procedure, stop recording by clicking on Stop, close the software, and verify if the file is saved in the chosen directory.\nfNIRS data analysis\n\t\nPreprocess the signals using NIRSLAB software49 (see Table of Materials). Follow the steps below:\n\t\t\nApply a band-pass temporal filter (0.01-0.2 Hz) to the raw intensity data to remove cardiac and respiratory frequencies, as well as very low-frequency oscillations.\nFor signal quality control, determine exclusion criteria for each channel gain above eight and coefficient of variation above 7.5%.",
    "Compute the changes in HbO2 and HHb by applying the modified Beer-Lambert law with the whole time series as a baseline.\n\t\t\tNOTE: In this study, HbO2 and HHb time series were segmented into blocks (social and non-social) and exported as text files for subsequent analysis in the R platform8 for statistical computing (see Table of Materials).\nAnalyze separately the social and control conditions. Construct a correlation matrix for each of the nine blocks of each condition so that its elements correspond to the correlation (Spearman) between each pair of subjects in the evaluated channel. For the statistical significance of the correlations between individuals across the task, use the t-test8 for a one-sample mean, considering a significance level of 5%.\nimgsrc://cloudfront.jove.com/files/ftp_upload/63675/63675fig04.jpg\nFigure 4: Distribution of optodes on the Subject 1 cap. The letters S and D represent the sources and detectors, respectively. S1 on AF7 coordinate of the 10-20 system; S2 on AF3; S3 on AF8; S4 on AF4; D1 on Fp1; D2 on F5; D3 on Fp2; and D4 on F6. The channels are placed in the following configuration: channel 1 between S1-D1; 2 between S1-D2; 3 between S2-D1; 4 between S2-D2; 5 between S3-D3; 6 between S3-D4; 7 between S4-D3; and 8 between S4-FD4. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/63675/63675fig04large.jpg]Subscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Neuroscience"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research"
  ]
}