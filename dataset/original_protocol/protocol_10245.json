{
  "id": 10656,
  "origin_website": "Jove",
  "title": "An Experimental Protocol for Assessing the Performance of New Ultrasound Probes Based on CMUT Technology in Application to Brain Imaging",
  "procedures": [
    "All biological specimens shown in this video have been acquired through the standard food supply chain. These specimens have been treated in accordance with the ethical and safety regulations of the institutions involved.\nNOTE: The diagram in Figure 4 summarizes the 8 main stages of this protocol. Stages 1 to 4 involve initial activities, to be carried out just once before the beginning of US image acquisition and processing stages. These initial stages are as follows: 1. preliminary design of the experimental setup and an agar phantom (to be used in calibration procedures); 2) preparation of the ex vivo bovine brain; 3. acquisition of MR images of the brain; 4. definition of qualitative poses to be used as target for US image acquisition. Stages 5 to 8 relate to the acquisition and processing of US images. These stages are: 5. experimental setup, in which all instruments are connected and integrated, and all targets are positioned and verified; 6. calibration of the US probe equipped with passive markers for navigation; 7. acquisition of US images of the bovine brain immersed in water, both in predefined poses and in \"freehand mode\"; 8. post-processing and visualization of the combined MR/US image dataset. While stage 5 can be performed just once, at the beginning of experimental activities, stages 6 and 7 must be repeated per each US probe involved. Step 8 can be performed just once on the entire combined dataset, when all acquisitions are completed.\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig4.jpg",
    "Figure 4: Experimental protocol workflow. The block diagram illustrates the main steps of the protocol, including a list of the main operations in each step. Steps 1-5 involve initial activities and setup preparation for US acquisitions; thus, they are to be carried out just once. Stages 6 and 7 involve US acquisitions and must be repeated for each probe. Step 8, which is image post-processing, can be performed just once at the end. Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig4large.jpg]\n1. Preliminary design\nDesign and validation of landmark positioning\n\tNOTE: The following procedure defines a consistent strategy for the positioning of landmarks, to be used for the calibration of the motion tracking system described in Section 6.\n\t\nPrepare a polystyrene head mannequin by cutting out a shape approximately similar to that of the bovine brain (height = 180 mm, width = 144 mm, length = 84 mm) using a knife.\nInsert 6 patterns of 3 Flint glass spheres (3 mm diameter) into the polystyrene brain, arranged at the vertices of an equilateral triangle with side of approximately 15 mm, and not farther than 1 mm from the external surface (see Figure 5).\nConnect the motion tracking system to the notebook via USB. Open the tracking tool, start motion tracking and check that when touching the glass spheres in the polystyrene brain, the pointer tool remains within the tracking field of view, to verify visibility and effective accessibility during the experiments.\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig5.jpg",
    "Figure 5: Polystyrene model of the brain used during the preliminary design stage. The polystyrene mannequin head, properly cut to mimic the bovine brain dimensions, was used to choose the positioning of the glass sphere patterns in the brain. Six triangular patterns of spheres, with a 3-mm diameter, have been implanted in the polystyrene model as shown in the picture, i.e. three patterns on the right and three on the left brain hemispheres. Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig5large.jpg]\nAgar phantom preparation\n\tNOTE: These steps allow to prepare a laboratory-made agar phantom to be used for calibration procedures (Section 6.1).\n\t\nIn a beaker, dilute 100 g of glycerine and 30 g of agar in 870 g of distilled water. Stir the mixture, while increasing its temperature up to 90 °C, for 10-15 min. Pour the mixture to fill a 13x10x10 cm food container and keep it in the refrigerator for at least one day.\nRemove the agar phantom from the refrigerator. Color 6 glass spheres with a yellow enamel (for better visibility) and insert 2 patterns of 3 glass spheres each in the agar phantom (i.e. one per major side of the block), not farther from the surface than 1 mm (Figure 6).\nFor preservation when not in use, immerse the agar phantom in a solution of water and benzalkonium chloride, using a sealed plastic food container, and keep it in the refrigerator.\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig6.jpg",
    "Figure 6: Agar phantom. The figure shows the agar phantom, in which an implanted pattern of three yellow-painted glass spheres (indicated by the black arrows) is clearly visible in the lower edge. The pointer tool tip, used to measure the sphere positions during the calibration phase, is also shown near the phantom. Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig6large.jpg]\n2. Bovine brain preparation and fixation\nAcquire the ex vivo bovine brain from the standard food supply chain. Transport it on ice (for preservation). Typically, as in this case, the ex vivo brain is made available after having been removed from the animal.\nRemove the brain from ice and place it in an aspirating hood. Keep it in the hood for the subsequent preparation steps. Isolate the cerebral hemispheres, by separating cerebellum, mesencephalon, pons, and brainstem with a surgical blade, cutting through the structures on the ventral surface of the brain.\nUsing the polystyrene mannequin as a reference for positioning, implant 6 triangular patterns of 3 spheres each in the cortex of frontal, temporal and occipital lobes. Ensure that the predefined conditions (i.e. distances from the surface and among spheres) are met. For visibility, mark the positions of all the spheres on brain surface with a green tissue marking dye for histology (Figure 7).\nImmerse the brain in 10% buffered formalin solution. Use a plastic container for anatomical parts (Figure 8). Leave the brain in the container with formalin for at least 3 weeks, until the fixation process is complete.\n\tCAUTION: formalin is a toxic chemical substance and must be handled with care; specific regulations may also apply, for instance US OSHA Standard 1910.1048 App. A.\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig7.jpg",
    "Figure 7: Bovine brain preparation and implantation of the glass spheres. The bovine brain is prepared by an expert pathologist by removing the anatomical parts in excess and then implanting the glass sphere patterns, according to the previously designed configuration (a). The sphere positions are then marked with a green dye on the brain surface (b). Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig7large.jpg]\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig8.jpg\nFigure 8: Bovine brain fixation in formalin. The bovine brain with the implanted glass spheres is immersed in 10% buffered formalin solution inside a plastic container for anatomical parts (a). After a period of at least 3-weeks, the fixation process is complete (b) and the brain can be used for image acquisitions. Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig8large.jpg]\n3. MR image acquisition\nExtract the brain from formalin solution, wash it in water overnight, place it in a clean plastic container, and seal it.\nPut the container into the MR head coil and place it into the MR scanner.\nPerform MR scans employing a 3 T MR scanner endowed with a 32-channel head coil (Figure 9). Acquire three sets of images using T1, T2 and CISS sequences with a resolution of 0.7x07x1 mm3 and 0.5x0.5x1 mm3 for T1/T2 and CISS sequences, respectively. Save the MR images in DICOM format using the software tools of the MR scanner.\nAfter usage, immerse the brain in 10% buffered formalin. Transfer the acquired MR images from the MR scanner to a processing workstation.\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig9.jpg\nFigure 9: MR image acquisition. The bovine brain, sealed in a clean plastic container, is put into the 3 T MR scanner for MR image acquisitions. Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig9large.jpg]\n4. Definition of qualitative poses for US image acquisitions",
    "NOTE: This procedure defines a set of qualitative poses, with respect to MR images, in which the visibility of brain regions that contain clearly recognizable anatomical structures and well-differentiated tissues (particularly white and grey matter) is maximized in US images.\nOpen the MR images in DICOM format with Paraview software tool (henceforth, visualization software). Have an expert visualize the images both as slices and 3D volume, as required.\nInspect each MR image in the dataset to assess the visibility of anatomical structures and tissues (e.g. lateral ventricles, corpus callosum, gray matter of basal ganglia).\nSelect 3D spatial subregions from the reference MR image containing the best recognizable visual features and approximately define the cutting planes of maximal visibility. Identify 12 predefined poses for US image acquisition, each involving a significant set of visual features.\nFor each virtual pose, use \"Sources > Cone\" to create a 3D Cone as a visual landmark. Adapt each cone height to 40 mm and radius to 2 mm and manually position the cone in the 3D visual field (Figure 10). Save the complex of MR image, 3D regions, planes, and landmarks as a Paraview state file.\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig10.jpg\nFigure 10: Predefined poses for US image acquisition. The markers in (a) show the positions of the 12 selected poses in the 3D MR image frame to be reached by the operator for US image acquisition. In (b) the MR planes corresponding to the selected poses are shown; the red marker represents the US probe position (represented in the MR image space) moving in real-time, until one of the white markers is reached and the desired US image can be acquired by the system. Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig10large.jpg]\n5. Experimental setup\nEnvironment and targets",
    "NOTE: This step describes the preparation of the setup and instruments for US acquisition experiments.\n\t\nPosition a 50x50x30 cm plastic tank on a table and fill it with degassed water up to a height of 15 cm. Position the motion tracking system so that the water tank is visible from above and entirely within its field of view (Figure 11) and connect the motion tracker to the notebook via USB.\nPerform the pivoting procedure to calibrate the pointer using the tracking tool of the motion tracking system34.\nPosition the ULA-OP system on the table and connect it to the notebook via USB, making sure that the computer screen is clearly visible to the US probe operator. Position the workstation on the table and make sure that its screen is clearly visible to the operator.\nExtract the brain from formalin solution and wash it in water. Immobilize it onto a plate of synthetic resin, using segments of sewing thread and adhesive stripes (Figure 12).\nImmerse the plate with the brain into the tank and verify that the entire working space around the brain fits within the field of view of the motion tracker, using the pointer and the software tracking tool.\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig11.jpg\nFigure 11: Setup of the experimental acquisitions with the motion tracking system. The motion tracking sensor is placed above the water tank in which the bovine brain is immersed, so that the target and the probe with the clamped reflecting markers entirely fit within its measurement field of view. Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig11large.jpg]\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig12.jpg",
    "Figure 12: Positioning of the bovine brain in the water tank. The bovine brain is immobilized on a synthetic resin plate by means of two sewing threads (placed along the longitudinal fissure) and fixed on the plate with adhesive stripes. The plate and the bovine brain are then immersed in the water tank. Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig12large.jpg]\nConnecting the US probe and configuring ULA-OP to perform the scans.\nConnect the US probe to the ULA-OP system.\nConfigure the ULA-OP system through its configuration files and its software interface from the computer (Figure 13).\n\t\t\nDefine a duplex-mode consisting of two interleaved B-modes employing two different operating frequencies (7 MHz and 9 MHz). Set a 1-cycle bipolar burst for each mode. Set the transmission focus at 25 mm depth and dynamic focusing in reception with F#=2 sinc apodization function.\nConfigure the system to record beamformed and in-phase and quadrature (I/Q) demodulated data.\nPerform a few acquisition tests to ensure full operativity.\n\t\t\nFreeze the system, by clicking on the \"Freeze\" toggle button in the ULA-OP software. Enable the autosave mode by clicking on the toggle button that appears as three floppy disks. On the popup window, that appears at the end of the acquisition, write the filename and click \"Save\".\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig13.jpg\nFigure 13: Experimental setup for US image acquisition. The ULA-OP system is connected to the notebook placed near the water tank, so that its display is clearly visible to the US probe operator during acquisitions. Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig13large.jpg]\nClamping the passive reflective markers onto the US probe\n\tNOTE: Following this procedure, a solid assembly of the US probe and the passive reflective markers is created for subsequent acquisitions of image and position data.",
    "Find a suitable position for the clamp on the US probe handle. Clamp the passive reflective markers on the US probe handle (Figure 14).\nPerform a few acquisition tests (see step 5.2.3) to ensure that the clamp is stable, the markers are clearly visible by the motion tracking system, while the US probe is being held in the expected working postures.\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig14.jpg\nFigure 14: Passive tool with reflecting markers clamped on the 3D-imaging piezoelectric probe. The tool with markers is properly clamped and fixed on the 3D-imaging piezoelectric probe handle, so that they form a united assembly to be used for US image and position data acquisition at the same time. Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig14large.jpg]\n6. Calibration\nNOTE: This section describes the experimental part of the protocol that gathers the information to compute the required transformations among the different spatial reference frames involved. See Section 9 for mathematical details about the computation method. The software routines in the MATLAB programming language for calibration are available as open-source at https://bitbucket.org/unipv/denecor-transformations.\nFrom US image frame to the passive tool frame clamped onto the US probe\n\tNOTE: The following calibration procedure is used to compute the rigid transformation that allows to assign spatial positions to US image voxels in the local frame of reference of the passive tool clamped on the probe. It must be repeated for each mounting of a passive tool onto an US probe.\n\t\nPosition the agar phantom in full immersion inside the water tank. Start the logging application that records position data and collect the positions of each of the 6 glass spheres in the agar phantom with the pointer tool, while tracking its motion.",
    "Acquire one US image per each pattern of 3 spheres in the agar phantom (Figure 15) (step 5.2.3). Position the US probe via the mechanical arm using the pre-visualization function of the ULA-OP system, so that a complete pattern of three spheres is within the field of view. Acquire and save the corresponding US image.\nTransfer all US images in ULA-OP format, together with the motion tracker log-files, to the workstation.\nOpen each US image in the visualization software, manually mark the position of the 3 glass spheres in each of them, and transcribe the 3D positions into a .csv file.\nCompute the US-to-marker rigid transformation between the two reference frames (see the open-source code provided and Section 9).\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig15.jpg\nFigure 15: Acquisition of US images of the agar phantom for calibration. The operator moves the US probe (the CMUT probe) over the agar phantom to acquire two US images containing the two embedded sphere patterns, as shown in real-time by the ULA-OP software on the computer display. The acquired images are then used to compute the transformation from the US image space to the space of the passive tool with markers clamped on the probe. Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig15large.jpg]\nFrom the motion tracker space to the MR image space\n\tNOTE: The following calibration operations are used to compute the rigid transformation from the motion tracking system reference frame to the MR image reference frame and must be repeated for each placement of the brain inside the operational range of the motion tracker. The last two steps in this procedure must be repeated for each distinct MR image.",
    "Position the brain in full immersion inside the water tank. Start the logging application and collect the positions of each of the 18 glass spheres with the pointer tool (Figure 16). Transfer the motion tracker log files onto the workstation.\nOpen each MR image of the brain in the visualization software, manually mark the position of each of the 18 glass spheres, and save the corresponding 3D coordinates as .csv files.\nCompute the motion tracker-to-MR rigid transformation between the two reference frames (see the open-source code and Section 9).\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig16.jpg\nFigure 16: Acquisition of the positions of the glass spheres implanted in the bovine brain for calibration. The pointer tool tip is used to acquire, one by one, the positions of the 18 glass spheres implanted into the bovine brain immersed in water. These positions are used to compute the transformation from the motion tracking system space to the MR image space. Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig16large.jpg]\n7. Ultrasound acquisition\nNOTE: The software routines in Python for Paraview, for the real-time visualization procedure, are available as open-source at https://bitbucket.org/unipv/denecor-tracking.\nAcquisition of US images of the predefined poses\nClamp the markers onto the US probe and execute the calibration procedure (Sections 5.3 and 6.1). Position the brain and execute the calibration procedure (Sections 5.1 and 6.2).\nCollect the two rigid transformation parameters (US-to-marker and motion tracker-to-MR) computed in steps 6.1.5 and 6.2.3 and transfer these files into the folder of the real-time visualization procedure implemented in Python and the visualization software (Figure 10b).\nStart the real-time visualization procedure using the visualization software (see the open-source code) and verify that the actual position of the US probe is displayed correctly (Figure 17).",
    "Start the logging application for recording the position of the probe. Manually match each qualitatively predefined position, as displayed in the visualization software, with the US probe and acquire the corresponding image with the ULA-OP system (step 5.2.3). Stop the two applications and transfer all US images in ULA-OP format and motion tracker log files to the workstation.\nimgsrc://cloudfront.jove.com/files/ftp_upload/55798/55798fig17.jpg\nFigure 17: Acquisition of US images of the predefined poses. The operator moves the US probe to reach the predefined poses; the procedure is supported in real-time by a Python routine, which shows the probe position over the 3D MR image of the brain on the workstation display, using the visualization software. Please click here to view a larger version of this figure.[href=https://www.jove.com//cloudfront.jove.com/files/ftp_upload/55798/55798fig17large.jpg]\nAcquisition of freehand, moving poses with linear US probes for 3D image reconstruction\n\tNOTE: The following steps are intended for linear US probes only and allow the acquisition of sequences of 2D planar US images which, together with positioning data from the motion tracking system, are needed for 3D volume reconstruction.\n\t\nClamp the markers onto the US probe and execute the calibration procedure (Sections 5.3 and 6.1). Position the brain and execute the calibration procedure (Sections 5.1 and 6.2).\nManually position the US probe at the intended initial pose (e.g. the frontal end of each hemisphere). Start the acquisition of each US image sequence with the ULA-OP system (step 5.2.3) and the logging application for probe position recording.\nApply a slow, freehand motion to the US probe towards the intended final pose (e.g. the distal end of each hemisphere of the brain). Stop the acquisition of US images with the ULA-OP system and stop the probe tracking. Transfer all US images in ULA-OP format and motion tracker log files to the workstation.\n8. Post-processing and visualization",
    "Post-processing of freehand sequences of US image\n\tNOTE: This procedure is implemented in MATLAB programming language and is applied to each freehand sequence of 2D US images in the ULA-OP format, to produce complete 3D images.\n\t\nLoad the sequence of US images in the ULA-OP format. Match the sequence of US images with the motion tracker log files. Extract a sequence of timed positions from the log files that are included in the temporal interval going from the start to the end of the acquisition process, as recorded by the ULA-OP system.\nCompute the exact timing of each US image in the sequence using the parameters recorded by the ULA-OP system.\nCompute the position associated to each US image in the sequence, by interpolating between the two closest timed positions recorded by the motion tracking system. Use linear interpolation between translation vectors and spherical linear interpolation (SLERP) between rotations, expressed as quaternions.\n\t\tNOTE: Assume the median US image in the sequence - i.e. the image at the position that best partitions the sequence in two halves of (approximately) equal length - as a reference for defining the 3D US image frame.\nApply a logarithmic compression, normalize the image to its maximum, and apply a threshold (typically -60 dB) to each plane in the US image.\nWith respect to the reference frame, compute and apply a relative spatial transform to each of the other US images in the sequence to obtain a bundle of spatially-located planes.\nApply a linear interpolation routine to the structure of spatially-located planes to produce a Cartesian 3D array of voxels. Save the Cartesian 3D array of voxels as a .vtk file and record the interval timestamps that correspond to acquisition timing.\nPost-processing of other US images (not freehand sequences)",
    "NOTE: The following procedure is applied to each US image in the ULA-OP format except to freehand sequences (Section 8.1).\n\t\nLoad the US image in the ULA-OP format. Apply a logarithmic compression, normalize the image to its maximum, and apply a threshold (typically -60 dB) to each plane in the US image.\nFor 3D US images only, apply a linear interpolation routine (i.e. scan conversion) to the structure of spatially-located planes to produce a Cartesian 3D array of voxels.\nSave the image plane or the Cartesian 3D array of voxels as a .vtk file, recording the interval timestamps that correspond to acquisition timing.\nRegistration of US images\n\tNOTE: This section describes the procedures to perform the final registration of US and MR images, using the two transformations computed during previous calibration steps, and the position data of the US probe recorded during acquisitions. The software routines in the MATLAB programming language for registration of US images are available as open-source at https://bitbucket.org/unipv/denecor-transformations.\n\t\nLoad the US image in .vtk format.\nMatch the timing of the US image with motion tracker log files. Extract a sequence of timed positions from the log files that are included in the temporal interval going from the start to the end of the acquisition process, as recorded in the .vtk image.\nCompute an average position for the US image. Use linear averaging for translation vectors and apply the algorithm described in reference35 for rotations, expressed as quaternions.\nLoad the US-to-marker transformation that corresponds to the specific US image. Load the motion tracker-to-MR transformation which corresponds to the specific US image and the MR image of choice.",
    "Use the average position together with the above two transformations to compute the US-to-MR rigid registration transformation, and save the latter in different formats, including the translation and Euler angles that allow visualizing the US image in the MR image frame of choice.\nVisualization of registered US images\n\tNOTE: These are the final steps to visualize the acquired US and MR images and to show them after superposition in the visualization software, using the previously computed transformations.\n\t\nStart the visualization software and load the MR image of choice. Load all relevant US images. For each US image, create a Paraview Transform and apply the computed US-to-MR registration transformation (Figure 18) to the image data.\n9. Calibration Models and Transformations\nNOTE: This section describes the mathematical details of the calibration and transformation techniques used in the protocol presented. The experimental protocol involves four different frames of reference that have to be properly combined: 1) the US image frame, which depends on both the physical characteristics of the US probe and the scanner configuration, that associates spatial coordinates (x, y, z) to each voxel in an US image (for uniformity, all 2D planar images are assumed to have y=0); 2) the Marker (M) frame, which is inherent to the passive marker tool that is clamped to the US probe (Section 6.1); 3) the motion Tracking System (TS) frame, which is inherent to the tracking instrument; 4) the MR image (MRI) frame, which is defined by the scanner, that associates spatial coordinates (x, y, z) to each voxel in an MR image. For convenience and simplicity of notation, the procedures in this section are described using rotation matrices (i.e. direction cosine matrices) and not quaternions36.\nFrom US to M frame",
    "NOTE: The experimental calibration procedure in Section 6.1 produces the following information: 1) 3D positions (p1, … , p6)TS of the 2 patterns of 3 spheres each, included in the agar phantom and measured in the motion tracker frame; 2) 3D positions of each of the same two patterns (p1, … , p3)US and (p4, … , p6)US measured in each of the two US images acquired; 3) one transformation (RM>TS, tM>TS), where R is a rotation matrix and t is a translation vector, measured by the positioning instrument, which describes the relative position of the passive marker tool (all rotations measured by the motion tracking system are reported as quaternions, which have to be translated into rotation matrices).\n\t\nApply the algorithm in reference37 to each of the two pairs of lists (p1, … , p3)US, (p1, … , p3) TS and (p4, … , p6)US, (p4, … , p6)TS, to obtain two transformations of the type (RUS>TS, tUS>TS), each corresponding to one specific US image space.\n\t\t\nCompute an estimate of the desired transformation (RUS>M, tUS>M) from each of the above transformations in the following way:\nRUS>M = RTM>TS RUS>TS\ntUS>M = RTM>TS (tUS>TS - tM>TS)\n\t\t\tNOTE: The two estimates are combined by arithmetic averaging of the vectors tUS>M and averaging the rotation matrices RUS>M using the method in reference35, after having first translated matrices into quaternions and the resulting quaternions back into a rotation matrix.\nFrom motion tracking system to MRI frame\n\tNOTE: The procedure in Section 6.2 produces the following information: 1) 3D positions (p1, … , p18)TS of the 6 patterns of 3 spheres each included in the bovine brain, measured in the motion tracking system frame; 2) 3D positions of the same 18 spheres (p1, … , p18)MRI measured in the target MR image.",
    "Directly compute the desired transformation (RTS>MRI, tTS>MRI) by applying the algorithm in37 to the two lists of positions.\nFrom US to MRI frame\n\tNOTE: The US image acquisition procedure described in Section 7 produces images for which, after resolving the timestamps associated against the motion tracker log-files, the transformation (RM>TS, tM>TS) is computed directly.\n\t\nCompute the desired transformation in the following way:\nRUS>MRI = RTS>MRI RM>TS  RUS>M\ntUS>MRI = RTS>MRI (RM>TS  tUS>M + tM>TS) + tTS>MRI\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Bioengineering"
  ],
  "bigAreas": [
    "Bioengineering & Technology"
  ]
}