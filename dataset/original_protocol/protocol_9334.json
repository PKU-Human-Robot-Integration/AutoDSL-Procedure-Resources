{
  "id": 9745,
  "origin_website": "Jove",
  "title": "VisualEyes: A Modular Software System for Oculomotor Experimentation",
  "procedures": [
    "An overview of the key elements needed to conduct an oculomotor experiment is shown in figure 1. Each block in the flow chart will be discussed in detail below.\n1. \tINSTRUMENTATION SET-UP:\nAny type of eye movement monitor can be used for this system. We will demonstrate an infrared limbus tracking and a video monitoring system.\nFor tandem tracking movements such as saccadic or smooth pursuit, a single computer can be used for the visual display.  To study opposing eye movements such as vergence or the interaction of vergence with tandem version movements (ie, vergent with saccadic stimuli) a haploscope is needed with two computer monitors for visual display, see figure 2.\n2. \tCALIBRATION:\nCalibration is needed to convert one set of metrics into another.  Eye movements are typically indicated in degrees (°) of rotation shown in figure 3. However, computer monitors use pixel values compared to vision researchers who often denote the visual stimuli in degrees. Hence, a conversion is needed to convert the pixel values to degrees. One can use trigonometry to calculate where to place the physical targets to calibrate the visual displays. For example, if the stimulus on the computer screen aligns with a 2° physical target (see figure 2) then that pixel value corresponds to a 2° stimulus.",
    "To calibrate the system, the operator needs to open Pixel2Deg.vei within the VisualEyes directory. First, define the monitor to calibrate using the stretch mode field. Enter number 1 for the left eye monitor and number 2 for the right eye monitor. Then, run the program and move the green line stimulus until the green line is superimposed on top of the physical target. Enter the known position of the physical target in degrees and press the save button. Then, click on the green line. The degree and pixel value will be shown on the display in the bottom left corner. The operator should collect a minimum of three calibration points.\nAfter saving all the calibration points, open the D2P output file in the VisualEyes directory to obtain the calibration points. Plot the calibration points to attain a linear regression equation. Use the equation to calculate the initial and final position of the visual stimulus the operator desires to program in pixel values. An example of the left eye and right eye calibration curve obtained using five calibration points for a vergence stimulus is shown in figure 4.\nRepeat steps 2.2 and 2.3 for the other monitor if the stimulus requires an additional monitor.\n3. \tVISUALEYES SOFTWARE:",
    "Define A Stimulus: The operator needs to define the initial and final position of left and right eye stimulus prior to the experiment. First, open a new text file and on the first row, define the initial time and position values of the stimulus. Four parameters need to be defined 1) time (seconds), 2) the horizontal position (pixel), 3) the vertical position (pixel), and 4) the rotation (°) separated by a tab. Likewise, define the four parameters of the final time and position of the stimulus. Save the stimulus in the VisualEyes directory as a stimulus_name.vei (VEI=VisualEyes Input) file and repeat this step for the other eye stimulus.\nThe movement of the stimulus can be generalized into two types of movement: an abrupt step or a continuous ramp. A step allows the stimulus to abruptly move or jump from the initial position to the final position. The operator should note that the change in time is 0.001 seconds for a step stimulus. In the next row, define how long you want the stimulus to reside in the initial position as well as the final position. Stimuli are defined using four fields within one row. An example of a saccadic step, smooth pursuit ramp, vergent step and vergent ramp are shown in Table 1.\nFor stimuli, you can have a single stimulus such as a step or a sequence of visual tasks such as a multiple steps.",
    "Save Stimulus into Stimuli Library: There are several default settings in the dc1.txt (left eye stimulus / monitor) and dc2.txt (right eye stimulus / monitor) files within the VisualEyes directory. The first line is the percentage of the screen within the horizontal direction. The second line is the percentage of the screen within the vertical direction. The third is the background image and the fourth is the foreground or target image. The fifth line indicates the computer to work in independent mode. The 6th signifies which monitor (1 is right eye and 2 is left eye). The 7th line is the aspect ratio of the monitors.  The rest of the lines are the different type of stimuli the operator can use within an experimental session.  \nOpen the dc1.txt and dc2.txt from the VisualEyes directory. These two files contain the library stimuli for left eye and right eye respectively. On the last row, write the file name of the stimulus that has been generated from step 3.1. The profile number refers to the mth row corresponding to the stimulus file name. For example, in figure 1, the profile number of the stimulus is 8.\nOne can repeat steps 3.1 to 3.2 to create as many stimuli that are needed for an experiment.",
    "Write Script for the Experimental Protocol: Open a text file to type the experimental protocol commands. This file is called the script file which signifies that the VisualEyes System will read and execute each command from the script found in this file. The ability to create a script file for an experimental protocol allows the user to conduct repeated experimental sessions using the same protocol. Furthermore, numerous scripts can be written to vary the type and sequence of experimental commands. This file can be saved into the VisualEyes directory as a script_name.ves file. (VES = VisualEyes Script)\nThe VisualEyes functions have input and output arguments. Table 2 shows all the functions in the VisualEyes software.\nExpTrial: This function is used to call the stimulus that has been saved in the stimulus library from step 3.2. The length of the data is the time it will allow the function to execute the stimulus. The tempfile.lwf allows the VisualEyes software to temporarily store the incoming data and output it into an output buffer. When the tempfile.lwf is not defined, during the execution of this function, it will not store any incoming data for digitization.\nLogFile: This function outputs strings or the input buffer defined from ExpTrial into the out.txt file in the VisualEyes directory. When the experiment is complete, the operator must change the name of the out.txt file to another name. Otherwise, the data will be overwritten during the next experiment.\nTriggerWait: This function waits for the subject to push a trigger button to start the ExpTrial and digitize the data.  This is a channel in on the digital acquisition card that is waiting for the signal to change from a digital high (5 V) to low (0 V).",
    "RandomDelay: This function generates a random delay to prevent prediction or anticipation of the next stimulus.\nWaveMSD: This function calculates the mean and standard deviation of the data.\n4. \tPLACE THE EYE MOVEMENT MONITOR & RUN EXPERIMENT:\nDifferent eye movement monitors such as the corneal reflection video imaging system, limbus tracking system or sclera search coil may be used to collect and record eye movements.\nBefore a subject can participate, the experiment must be explained and the subject must read and sign an informed consent form approved by the Institutional Review Board.\nThe operator must adjust the eye movement monitor on the subject. First, the subject is asked to fixate on a target. The operator adjusts the eye movement monitor to capture the anatomical attributes of the eye such as the limbus (boundary between the iris and sclera) or the pupil and corneal reflection depending on the eye movement monitor used.\nOnce the eye movement monitor is properly adjusted on the subject, the operator should validate that the eye movement monitor is capturing the eye movements by asking the subject to make vergent or saccadic movements.\nOpen the program ReadScript.vei in the VisualEyes directory. On the upper right corner, type in the file name of the experimental protocol script file created from step 3.4. Then, run the ReadScript.vei program by pushing the red arrow on top left corner.\nGive the subject the trigger button and explain that when the subject pushes the button, the data collection will begin. Another Acquire.vei file will automatically appear on the screen which will plot the incoming data. Data are sampled at 500Hz.",
    "When the experiment is complete, the ReadScript.vei will automatically stop. At this time, go into the VisualEyes directory and find the Out1.txt file. Rename the file otherwise the next time the operator runs the experiment, the data file will be overwritten.\n5. \tOFF-LINE DATA ANALYSIS:\nThe operator can analyze the data by using different software packages (ie MatLab or Excel). Latency, peak velocity, or amplitude may be of interest depending on the study.\nAn example of a Matlab analysis code is provided in the VisualEyes directory to plot saccades, vergence steps and vergence ramps. Examples of the ensemble saccade, vergence step and vergence ramp position traces with the corresponding velocity responses are shown in figure 5.\n6.  Representative Results:",
    "Examples of the ensemble of eye movements recorded using the VisualEyes System is shown in Figure 5.  Typical 10° saccadic movements are shown in plot 4A. Antisaccades are saccadic responses when the subject is told to make a saccade in the opposite direction of the visual stimulus and are shown in plot 4B.  This is a more cognitively demanding task; hence one can observe that the latency or the time to begin the movement is longer for antisaccades (plot 4B) compared to saccades towards a visual stimulus also called prosaccades (plot 4A).  Vergence responses to 4° steps are shown in plot 4C and vergence responses to 5 °/s ramps stimuli are shown in plot 4D.  Each trace is an individual eye movement where the upper row is position denoted in degrees as a function of time.  Eye movements are calibrated in the units of degrees, meter angles, or prism diopters.  Our research uses degree of rotation.  The bottom row is the velocity plotted in °/ s as a function of time and is the speed of the movement.  The scale for each ensemble data differs depending on the movement.\nimgsrc://cloudfront.jove.com/files/ftp_upload/2530/2530fig1.jpg\nFigure 1. Flow chart of key elements to conduct an oculomotor experiment. Examples of steps needed to generate a stimulus using the VisualEyes software and conduct an experiment for offline data analysis are shown. Part A shows the Pixel2Deg.vei window. Part B demonstrates the four parameters needed to define a stimulus. Part C is the stimuli library where the black text lines within the stimulus library are example stimuli files and the red text defines each line. Part D is an example of an experimental script protocol.\nimgsrc://cloudfront.jove.com/files/ftp_upload/2530/2530fig2.jpg",
    "Figure 2. VisualEyes System Haploscope Experimental Set-Up. Three CRT monitors are used: 1) A control panel is needed to view stimuli and responses 2) a CRT monitor for the right eye (RE) visual stimuli and 3) a CRT monitor the left eye (LE) visual stimuli. A half-silvered mirror is placed 30 cm away from the two visual stimuli CRT monitors. This is to insure that the stimuli on the CRT monitors are projected onto the half silvered mirror (50% transmission and 50% reflectance mirror). The mirror allows the subject to view stimuli from the computer screens superimposed onto targets located at measured distances from the subject which is needed for calibration. With a haploscope, the accommodation demand to both eyes is held constant. The distance between the subject's eyes and the mirror is 10 cm. The system can be adjusted to accommodate different inter-pupillary distances (IPD) but for this demonstration we will assume the IPD to be 6 cm.\nimgsrc://cloudfront.jove.com/files/ftp_upload/2530/2530fig3.jpg\nFigure 3. Calculations of Saccadic (left) and Vergent (right) movement from targets A to B are shown. IPD is the inter-pupillary distance.\nimgsrc://cloudfront.jove.com/files/ftp_upload/2530/2530fig4.jpg\nFigure 4. Calibration curve of the left eye (top plot) and right eye (bottom plot) stimulus.  A similar procedure would be conducted for saccadic or smooth pursuit stimuli.\nimgsrc://cloudfront.jove.com/files/ftp_upload/2530/2530fig5.jpg\nFigure 5. Examples of saccades (A) antisaccades (B), vergence steps (C) and vergence ramps (D) using the VisualEyes system and analyzed using a custom MATLAB program. Ensemble position traces (° as a function of time in sec) are plotted in the upper row where each colored line represents a different eye movement. The corresponding velocity traces (°/s as a function of time in sec).\ntable:\n﻿0,1,2,3,4,5,6,7,8\nStimulus Type,Stimulus_Name_Left Eye.vei,Stimulus_Name_Left Eye.vei,Stimulus_Name_Left Eye.vei,Stimulus_Name_Left Eye.vei,Stimulus_Name_Right_Eye.vei,Stimulus_Name_Right_Eye.vei,Stimulus_Name_Right_Eye.vei,Stimulus_Name_Right_Eye.vei\n,Time (s),x-position (pixel),y-position (pixel),Rotation (°),Time (s),x-position (pixel),y-position (pixel),Rotation (°)\nSmooth Pursuit Ramp,0,100,0,0,0,100,0,0\nSmooth Pursuit Ramp,10,200,0,0,10,200,0,0",
    "Saccade Step,0,100,0,0,0,100,0,0\nSaccade Step,0.5,100,0,0,0.5,100,0,0\nSaccade Step,0.501,200,0,0,0.501,200,0,0\nSaccade Step,3,200,0,0,3,200,0,0\nVergence Ramp,0,452,0,0,0,973,0,0\nVergence Ramp,10,370,0,0,10,1044,0,0\nVergence Step,0,452,0,0,0,973,0,0\nVergence Step,0.5,452,0,0,0.5,973,0,0\nVergence Step,0.501,416,0,0,0.501,1002,0,0\nVergence Step,3,416,0,0,3,1002,0,0\nTable 1. An Example of Smooth Pursuit Ramp, Saccadic Step, Vergence Ramp and Vergence Step Stimuli\ntable:\n﻿0,1\nFunction,Syntax\nExpTrial,\"Output Buffer # = ExpTrial (\"\"Length of Data: LE Profile: RE Profile\"\");  Example: 2=ExpTrial(\"\"13:3:3\"\");\"\n,\"Output Buffer # = Exo Trial (\"\"Length of Data: LE Profile: RE Profile: tempfile. lwf\"\") ;  Example: 2=ExpTrial(\"\"13:3:3:templfile.lwf\"\");\"\nLogFile,\"Output Buffer # = LogFile(\"\"TEXT\"\");  Example: 0=LogFile(\"\"Experiment 1\"\");\"\n,0=LogFile( Input Buffer #);  Example: 0=LogFile(2);\nTriggerWait,0=TriggerWait(Buffer Number);  Example: 0=TriggerWait(0);\nRandomDelay,\"0=RandomDelay(\"\"t2:t1\"\");  Example: 0=RandomDelay(\"\"2000:500\"\");\"\nWaveMSD,Output Buffer #= WaveMSD(Input Buffer #);\nTable 2. Functions Used to Write the Experimental Protocol in the VisualEyes ProgramSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Neuroscience"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research"
  ]
}