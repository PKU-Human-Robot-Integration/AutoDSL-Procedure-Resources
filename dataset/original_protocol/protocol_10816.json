{
  "id": 11227,
  "origin_website": "Jove",
  "title": "Comparing Eye-tracking Data of Children with High-functioning ASD, Comorbid ADHD, and of a Control Watching Social Videos",
  "procedures": [
    "Parental and participant consent was obtained during the recruitment process in a primary school and a children service center for ASD in Hong Kong and the study was approved by the university ethical review committee of the Education University of Hong Kong.\n1. Use of a Video-based Assessment\nProduce several social videos, about one minute long, that consist of daily life scenarios involving several people in a social context (Figure 1).\n\t\nProduce several social videos, about one minute long, that consist of daily life scenarios involving several people in a social context. For the three children in our case study, each child watched the same three videos. The first video demonstrates the following social scenario. In a crowded cafeteria, a student spots an unoccupied seat that is simultaneously occupied by a lady who is talking on the phone and places her bag on the seat with no awareness of his request (Figure 1). The second video demonstrates the following social scenario. Students are playing a chess game while an unfamiliar student comes too close to watch them playing the game. The third video demonstrates the following social scenario. A boy’s painting is ruined when his friend accidentally spills water from a cup on the table. \nConduct expert reviews of all the videos. Select those social scenarios that are agreed on the most by the experts as containing the actors’ intention, emotions, and thoughts through their expressions and gestures.\n2. Recruitment of the Participants\nFrom the pool of participants who satisfied the research inclusion criteria, select and match participants with ASD, with ASD-ADHD, and neurotypical controls using their medical diagnostic reports and the percentile scores of Raven’s Standard Progressive Matrices16.",
    "Convert their Raven percentile scores to five percentile ranks. Select participants who perform at ranks II or III (average) and exclude those who scored above rank I (above average) or at rank IV (below average).\n3. Eye-tracking Experiment\nExperimental set-up\nOn one side of the eye-tracking room, display the videos on a 23-inch color LCD monitor with a screen resolution of 1920 x 1080 pixels, using an eye tracker at a distance of approximately 60 cm from the participant. Have a research investigator operate the eye tracker from the other side of the eye-tracking room (Figure 2).\nHave another research investigator sit next to the participant and instruct the participant to look at the screen of the monitor. Place the monitor in front of the child on the other side of the partition and connect to the eye tracker. The choice of eye-tracking equipment, testing environment, and the set-up procedures are previously discussed17.\nCalibration process\nInstruct the participants to watch the calibration dots that set the viewing boundaries across the screen by capturing the eye movements using infrared corneal reflectance technology. The calibration is properly done if all the green dots or lines fall within the grey circle dots.\nRepeat the calibration if some of the green dots or lines do not fall within the grey circle dots.\nViewing of the videos\nInstruct the participant to view the social videos one after another, and capture their eye movement data during viewing using the eye tracker.\n4. Data Analysis\nDefine and set up the first-moment fixation within AOIs.\n\t\nChoose context-relevant targets (face, hands, targeted objects, etc.) in their initial 500 ms of appearance in each scene of the video as AOIs (Figure 3) and label the AOIs in the information box on the left panel.",
    "Upon the completion of the addition and selection of the AOIs in the current frame, move the cursors in the timeline bar at the bottom panel to the next frame.\nAdjust the location and boundary of the AOIs in each frame of the video in the presentation video software of the eye tracker manually as the target areas change in each time frame of the video due to the movement of the people or objects as the story of the social video develops.\nClick the Select button on the top panel and add new AOIs to the new scene if necessary. If some existing AOIs are present for 500 ms in the current scene (the timestamp of the video can be checked in the bottom left panel) or if they are not relevant in the new frame in the video, right-click on these AOIs to deactivate them in the new frame.\nRun a statistical analysis of the eye-tracking indices. Follow the steps of statistical data processing on the eye tracker as described below.\n\t\nChoose the recordings of the children.\nSelect the Media file for analysis.\nSelect from the available videos.\nClick Analyze selected media.\nChoose the Descriptive statistics (e.g., Sum).\nChoose the dependent measures in Metrics (e.g., First fixation duration, visit count).\nChoose Recordings in Rows.\nSelect AOI Media Summary in Columns.\nClick Update to analyze the eye-tracking patterns. The results of the eye-tracking pattern metrics are shown on the screen.\nCreate the scanpath of a scene from the eye-tracking data.\n\t\nChoose Visualization and GazePlot in the software.\nSelect the Media and Recordings in the left panel for visualization.\nIn the bottom timeline, move the lower cursor to the beginning of the target scene and move the upper cursor to the end of the target scene.",
    "Make sure Accumulate is chosen for the Data field to show the accumulative scanpath.\nClick Export and Visualization image to save the scanpath as a separate image file.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}