{
  "id": 4053,
  "origin_website": "Cell",
  "title": "Timesias: A machine learning pipeline for predicting outcomes from time-series clinical records",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nDownload our package and install the prerequisites\nTiming:  <5 min\ninstall the latest version of Timesias via pip: pip install timesias or clone the whole package from our GitHub repository using the following command to your local directory using the following command (Figure 1[href=https://www.wicell.org#fig1]): git clone https://github.com/GuanLab/timesias.git[href=https://github.com/GuanLab/timesias.git]\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/765-Fig1.jpg\nFigure 1. Model installation from GitHub and the required dependencies.\nCritical: check if all required dependencies listed in key resources table[href=https://www.wicell.org#key-resources-table] are correctly downloaded and installed. Originally, installing Timesias via pip will automatically check for and install the required dependencies. However, errors during installation could occur when installing on computational environments (Troubleshooting 1[href=https://www.wicell.org#sec7.1]).\nPrepare data\nTiming:  <10 min\nTwo types of data should be prepared for model training and prediction: 1) gold standard file, which contains the names of the record file from patients and the corresponding gold standard (clinical outcome of that patient). 2) time-series records files, which are “|” delimited time series records. The two types of data mentioned above should follow the following formats:\nGold standard file (for example: example.gs.file): a ‘,’ delimited table with two columns. Each row in the gold standard file represents a sample. The details of gold standard file are described below (Table 2[href=https://www.wicell.org#tbl2]):\ntable:files/protocols_protocol_765_2.csv\nfirst column: path of the time-series record files. the details of the time-series record files which will be detailed later.\nThe second column: gold standard, or label for the time-series record files. In the example data, we use binary label 1/0 to indicate failure/survival, which is the status of sepsis onset of the patients.",
    "Record files (for example: ∗.psv): “|” delimited time series records. The record files should be corresponding to the first column in the gold standard file, which are the time-series records for each individual sample/patient. Each individual sample should have one record file. The record file should be in the following format (Table 3[href=https://www.wicell.org#tbl3]):\ntable:files/protocols_protocol_765_3.csv\nThe first row, or the header: the clinical measurements (Features). The first header should be the time point, and from the second column to the end, the header should be the clinical measurements recorded at each time point.\nThe first column, or the row names: the exact time points in ascending order.\nFrom the second column to the last, the values should be the observed values for each clinical measurement at the nth time point.\nIt is worth noting that, for some time points, some features might be missing. Therefore, it is recommended that researchers fill the missing values as ‘NaN’ instead of leaving them blank. The demonstrated datasets can be found in our Timesias GitHub repository (https://github.com/GuanLab/timesias/tree/master/data[href=https://github.com/GuanLab/timesias/tree/master/data]).\nCritical: 1. Both types of datasets should follow the format described above. 2. Make sure that the first column in the gold standard file matches the file name of the records. Namely, the total number of rows in the gold standard file is always equal to the total number of records.\nTrain models, evaluate results, and visualize top features\nTiming: ∼0.5 h (depending on your data)\nOur package provides a one-line command to perform feature construction, model training and five-fold cross-validation at the same time, followed by the SHAP analysis with a visualization report of top contributing features (Figure 2[href=https://www.wicell.org#fig2]).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/765-Fig2.jpg\nFigure 2. The workflow of the main program using a one-line command\nThis includes model training, validation and SHAP analysis.",
    "To start training the LightGBM regression model, five-fold cross-validation and top feature analysis on your data, simply run the following command: timesias -g [GS_FILE_PATH] -t [LAST_N_RECORDS] -f [EXTRA_FEATURES] -e [EVA_METRICS] --shap The arguments are defined as follows:\n-g [GS_FILE_PATH]: the path to the gold standard file (example.gs.file) you prepared in step 2.\n-t [LAST_N_RECORDS]: the last n records you want to use for prediction, default is 16.",
    "Note: The missing values contain critical information for outcome predictions. Here we introduce a specific feature construction method implemented in Timesias to preserve the missing value information (Figure3[href=https://www.wicell.org#fig3]). First, for each feature in a certain time point, we add an additional value to annotate the binary status if it is missing or not (1/0). This will double the total number of features in the matrix. For example, if we use the last   i   time points of the record of   j   features, the original feature matrix would be an   i × j   matrix. After the missing value annotation step, the processed feature matrix will be   i × 2 j  . At the same time, the missing values in the original feature matrix will be replaced by an arbitrary constant, here we set it to ‘−3000’ as default. As we have designated a fixed length   n   for all timely records by using the argument -t [LAST_N_RECORDS], if the provided record (with   i   timepoints) is shorter than   n  , we will fill the missing earliest timepoints of the original record with another arbitrary constant. Here we use ‘−5000’ as default. Otherwise, the record will be cropped to the last   n  timepoints. The replacement values of the above missing information can also be changed according to your own data (Troubleshooting 2[href=https://www.wicell.org#sec7.3]). The above are the feature preprocessing step, which generates a   n × 2 j   matrix, from which extra features can be generated as described next.\n-f [EXTRA_FEATURES]: additional features you want to include for prediction. We provide four additional features to construct based on your original data: norm, std, missing portion and baseline.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/765-Fig3.jpg\nFigure 3. Overview of the feature construction process",
    "First, the missing information will be replaced by different replacement values (for missing feature values (gray), replace with −3000; for missing timepoints (green), replace with −5000). Then we compute four types of characteristics for each feature: ‘std’, ‘norm’, ‘missing portion’ and ‘baseline’. Then the final feature matrix will be generated by concatenating all generated features together.\nNote: These additional features will capture the temporal changes as well as the patterns of missing values in the timely records. The details of the extra features are described here:\n1) ‘norm’: normalized feature values. For each column   q   in the   n × 2 j   matrix, we calculate the mean and standard deviation across all rows. The normed new feature value   f  ′  p , q     will be\n   f  p , q  ′  =    f  p , q   −  μ q    σ q    p ∈  {  1 , … , n  }  , q ∈  {  1 , … 2 j  }  ,  \nwhere    f  p , q    is value of the   p  th timepoint in the   q   th column,    μ q   is the mean for the   q   th column through the timeline;    σ q    is the standard deviation for the   q   th column through the timeline;   n  : total number of time points; and   j   is the total number of features. 2) ‘std’: as mentioned above, is the standard deviation (  σ  ) of each feature throughout the whole time-course:\n   σ q  =     ∑ n    (   f  p , q   −  μ q   )  2   n   p ∈  {  1 , … , n  }  , q ∈  {  1 , ..2 j  }  ,",
    "where    f  p , q     is the value of the   p  th feature in the   q   th column; is mean for the   q   th feature through the timeline; and   n   is the total number of time points. 3) ‘missing portion’: the percentage of missing points for each feature, which is calculated as:\n    m i s sin g  (  f q  )   n  ,  \nwhere   m i s s i n g  (  f q  )    is the number of missing values of the   q   th feature. 4) ‘baseline’: for each feature, we record the earliest time point for each feature to be collected and the corresponding feature value.\n-e [EVA_METRICS]: evaluation metrics you choose. Our program primarily provides five options: AUROC, AUPRC, C-index, Spearman’s r and Pearson’s r, which are used for different prediction tasks (binary/multiclass classification and regression). The details for the above metrics are described in Quantification and Statistical Analysis[href=https://www.wicell.org#quantification-and-statistical-analysis].\n--shap: an optional argument. If used, SHAP analysis (Lundberg and Lee, 2017[href=https://www.wicell.org#bib13]) will be carried out, using the trained model from five-fold cross-validation on the test set to visualize the top measurements and time points.\nNote: Our program also provides an option to analyze the top features by SHAP analysis by using the --shap argument. If additional features were constructed from the original features, we group the corresponding values of the original feature to analyze its overall importance. According to the additivity of SHAP values, the grouped SHAP values of features and time points can be computed following the formula below:\n   S X  =  |  ∑  x ∈ X    S x  |  ,",
    "where X is all features of interests. For example, if we want to know the aggregated SHAP importance of the last 6th time point,   X  can be all features from the last 6th timepoint. The top features (clinical measurements and timepoints) are visualized in bar graphs.\nThen the program will start training the prediction model using the arguments you specified. When model training is finished, the models will be automatically saved to ‘./model’, and the evaluation on the test set will be automatically performed. Also, if --shap is used, the program will start SHAP analysis after prediction performance evaluation.",
    "Critical: 1. To successfully run through the model training and cross-validation process, make sure the gold standard file path (-g) is correct (Troubleshooting 3[href=https://www.wicell.org#sec7.5]). Also, check if the time-series records are correctly formatted. Problems with time-series records could lead to aborted programs (See Troubleshooting 4[href=https://www.wicell.org#sec7.7] and Troubleshooting 5[href=https://www.wicell.org#sec7.9]). Additionally, we require all feature values in the time-series data to be numeric, and categorical features need to be encoded in advance (See Troubleshooting 6[href=https://www.wicell.org#sec7.11]). 2. The default length of the last n records (-t) is 16. However, the choice of -t can affect the model performance, CPU occupancy and training time. We recommend different trials of -t for a proper choice (See Troubleshooting 7[href=https://www.wicell.org#sec7.13]). 3. While the default settings of the hyperparameters of the LightGBM models are the same as the winning algorithm in the DII Data Science Challenge, we also encourage the users to adjust the model hyperparameters in respect to their own dataset (See Troubleshooting 8[href=https://www.wicell.org#sec7.15]). 4. While the example only presents the prediction of binary outcomes, our model also can take continuous values as gold standards. However, suitable evaluation metrics should be selected per prediction task. For example, in the demonstrated binary classification task, AUROC and AUPRC were selected. For regression tasks, C-index, Pearson’s correlation or Spearman’s correlation can be used. The users can also use their own customized evaluation metrics on the prediction results by modifying the code in statistics.py (https://github.com/GuanLab/timesias/blob/master/src/statistics.py[href=https://github.com/GuanLab/timesias/blob/master/src/statistics.py])."
  ],
  "subjectAreas": [
    "Clinical Protocol",
    "Health Sciences",
    "Bioinformatics"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research",
    "Bioinformatics & Computational Biology"
  ]
}