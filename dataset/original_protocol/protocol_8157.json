{
  "id": 8568,
  "origin_website": "Jove",
  "title": "Characterizing the Relationship Between Eye Movement Parameters and Cognitive Functions in Non-demented Parkinson's Disease Patients with Eye Tracking",
  "procedures": [
    "This research project was approved by the Joint Chinese University of Hong Kong-New Territories East Cluster Clinical Research Ethics Committee (CREC Ref. No.: 2015.263).\n1. Participants Recruitment and Baseline Assessment\nRecruit Parkinson's disease patients aged less than or equal to 70 from a neurology specialist clinic with the diagnosis made based on the United Kingdom Parkinson's Disease Society (UKPDS) Brain Bank Diagnostic Criteria12.\nExclude subjects with psychiatric illnesses, ophthalmological diseases that would impair eye movement, or other neurological disorders. Also, exclude cases using anticholinergics as they are known to affect cognitive performance and eye movement.\nRecruit healthy controls on a 1:1 basis matched by sex, age, and education.\nObtain informed consent from the subject.\nConduct a clinical diagnostic interview with the subject and, if available, their relatives, to exclude dementia and screen for cognitive impairment with Mini-Mental State Examination (MMSE)13 and Montreal Cognitive Assessment (MoCA)14. Exclude dementia cases from the study or if the subject’s scores of either MMSE or MoCA is <22/30.\nAssess the visual acuity with a Snellen chart. Exclude the subject if the visual acuity is less than 20/40.\nAssess motor severity and staging of Parkinson's disease using the Unified Parkinson's Disease Rating Scale (UPDRS) Part II & III15 and Modified Hoehn and Yahr (H&Y) Staging16, respectively. Also, obtain information about the current medications taken by the subject.\nAssess the depressive mood state by the Beck Depression Inventory-II (BDI-II)17.\n2. Experimental Setup\nConduct the experiment in a quiet room with an adequate light source.\nConduct the experiment for Parkinson's disease subjects when they are on medication with optimal motor function.\nPrepare the setup that consists of a screen-based eye tracker, a computer, a mouse, a standard keyboard, a chin rest, and cognitive assessment tools (Table of Materials).",
    "Use an eye tracker with a sampling rate of at least 300 Hz.\nPlace the chin rest 60 cm in front of the eye tracker screen.\n3. The Flow of the Cognitive Assessment and the Visual Search Task\nCarry out the Chinese Categorical Verbal Fluency Test18. Instruct the subject to name as many animals as possible in a minute. Record the number of answers and perseverative error. Then repeat the same in the category of fruits and vegetables.\nConduct the registration part (Trial 1, 2 and 3) of the Hong Kong List Learning Test (HKLLT)19 by reading out a pre-defined 16-vocabulary word list and instruct the subject to remember them. Afterwards ask the subject to do free recall of the word list and record the answer (Trial 1).\nRepeat step 3.2 twice for Trial 2 and Trial 3.\nWait 10 min and 30 min after the registration part of the HKLLT for the 10 and 30 min delay recall.\nBefore the 10 min delayed recall of the HKLLT, perform the Pattern Recognition Memory (PRM) from Cambridge Neuropsychological Test Automated Battery (CANTAB)20 (Table of Material).\nUsing the tablet computer, present 24 visual patterns, one at a time, at the center of the screen. Instruct the subject to remember the pattern.\nAfter the presentation, in a 2-choice force discrimination paradigm, instruct the subject to choose the pattern that he/she can recognize.\nPerform the 10 min delay recall of HKLLT by asking the subject to do free recall of the 16-vocabulary word list.\nBefore the 30 min delayed recall of the HKLLT, perform Spatial Span (SSP) from CANTAB20.\nUse the tablet computer to show a pattern of white boxes which change in color, one by one, in variable sequences.",
    "Afterwards instruct the subject to touch the boxes in the same sequence they were presented and record the spatial span length that the subject could attain as the difficulty (number of boxes change in color) of the task increases.\nCarry out the 30 min delay recall by asking the subject to do free recall of the 16-vocabulary word list.\nConduct the recognition and discrimination part of the HKLLT by reading out another pre-defined 32-vocabulary word list, of which half of the vocabularies are from the original word list in 3.2. Instruct the subject to determine whether each vocabulary read out is from the original word list or not.\nAllow the subject to rest quietly if they finish the tasks in 3.4 and 3.6 before the 10- and 30-min delay recall, respectively.\nPerform the Stocking of Cambridge (SOC) from CANTAB20.\nUsing the tablet computer, present 20 scenarios of two parallel displays of 3 balls held in 3 vertical stockings, of which the arrangement of the balls in the displays varies in each scenario.\nInstruct the subject to determine, in each scenario, the least number of moves required to rearrange the balls in the lower display in order to copy the pattern shown in the upper display. Record the mean number of choices to correct answer.\nPerform the Stroop Test21.\nGive the subject 3 cards consecutively; the first card contains dots printed in different colors, the second card contains Chinese characters printed in different colors while the last card has Chinese characters denoting different colors (e.g., Chinese words of \"blue\", \"yellow\", \"green\", or \"red\") but printed in a color not denoted by the name (e.g., the word \"red\" printed in blue ink).",
    "Ask the subject to read out the printed color of the dots/Chinese characters as quickly as possible and record the time required for each card (T1, T2, and T3).\nCalculate the interference index with the formula (T3-T1)/T1.\nProceed to the visual search task after completing the cognitive tests.\nNOTE: Do not carry out any verbal cognitive task after the registration part of HKLLT until the end of the whole HKLLT (3.7) to prevent interference effect on verbal memory performance.\n4. Visual Search Task\nPosition the subject on a chair and place their chin on the chin rest with their forehead against a bar to minimize head movement. Align the subject's eyes to approximately the center of the computer screen. Begin by clicking the Start Recording button in the computer program.\nCalibration\nCalibrate the eye tracker with the in-built calibration program by clicking the Start button in the calibration interface.\nAsk the subject to gaze at a red dot moving across the screen with 9 fixation points, while keeping the head still.\nCheck for the quality of the calibration by viewing the calibration plot (Figure 1). Make sure that the length of the green lines, which represent the error vectors, fall within the grey circles for an acceptable quality of the calibration. Redo the calibration if there is any missing point or the green lines fall outside the grey circles. Click Accept to proceed to the visual search task.\nInstruction\nProvide verbal instruction to the subject and start with 5 practice runs to familiarize the subject with the task.",
    "Instruct the subject to fixate their gaze on the central fixation cross at the beginning of each trial. Then, press Enter on the keyboard to begin a trial, at which the computer screen will display a single number and 79 distracter alphabets scattered randomly (Figure 2).\nInstruct the subject to look as quickly as possible for the number and then simultaneously click on the mouse and state the number aloud as soon as the number is located.\nCross check if the number stated is correct or not.\nAdminister a total of 40 trials after the 5 practice runs.\nDesign of the trial images in the visual search task\n\tNOTE: The program code, written in PHP, for this section can be found in Supplement File 1.\n\t\nUse the numbers 4, 6, 7 and 9 exclusively (Supplementary File 1 - Line 5).\n\t\tNOTE: The pilot study11 showed that these numbers are most easily discriminated from the alphabets.\nEnsure that the location of the target number is randomized from trial to trial with the rule that it could not be in the same visual quadrant for more than three successive trials (Supplementary File 1 - Line 48-52).\nDo not use ambiguous alphabets such as \"I\" and \"O\" (Supplementary File 1 - Line 76-78).\nSet the size of the fixation cross, alphabets, and numbers at 0.85° visual angle (equivalent to around 0.9 cm on a 23 inches computer screen).\nNOTE: Numbers and alphabets are used because these are easily recognizable visual stimuli yet require foveation for identification.\nAllow a time lapse of 1.5 s after the investigator has pressed Enter in 4.3.2 and before the display of the central fixation cross is switched to a trial image to begin a trial (Supplementary File 2 - Line 71; 156-158).",
    "Ensure that the screen will go blank with the fixation cross reappearing as the mouse is clicked or after 10 s have elapsed since the beginning of a trial, whichever that is earlier (Supplementary File 2 - Line 72; 162-180).\nAs the task is finished, generate a .csv file that contains the timestamps of the beginning and the end of each trial (Supplementary File 2 – line 48-59; 199-208). Use this file in the data analysis in section 5.\n5. Eye Tracking Data Processing and Analysis\nIn the Replay section of the computer program, check the Samples Percentage of the eyes during the visual search task (Figure 3). Discard the subject’s data if more than 20% missing data are observed.\nNOTE: Samples Percentage denotes the percentage of time the eyes are successfully located by the eye tracker during the visual search task.\nClick on the Play button for the recording to check the quality of the data by eyeballing the visualized scan path video generated (Figure 4). Discard the whole subject's data if it is grossly erroneous (Figure 5).\nDiscard any trial(s) in which the subject pressed the mouse accidentally and prematurely.\nIn the Data Export section of the program, select GazePointX (ADCSpx) and GazePointY (ADCSpx) and the subject of interest (Figure 6). Click Export Data to export each subject’s data and save as a .csv file. The file contains the x and y coordinates of the subject's eyes position on the computer screen, in pixels, at every time point.",
    "Use the Visual Search Analyzer and in the interface (Figure 7), select the data exported in 5.4 as the input of Eye Data and the .csv file generated in 4.4.7 as the input of Action data. Select ST DBScan as the classification algorithm and click on Run. Then, click on Summary to generate a spreadsheet file containing the mean saccade amplitude and the mean fixation duration of the subject.\nDesign of the visual search analyzer\n\tNOTE: The coding for the design of the analyzer could be found at https://github.com/lab-viso-limited/visual-search-analyzer. Its program code can be found in Supplementary File 3.\nProgram the analyzer such that it extracts and analyzes only the data from the beginning to the end of the trial (i.e., from the display of the number and alphabets until the mouse is clicked or 10 s have elapsed), using the .csv file generated in 4.4.7 (Supplementary File 3 - Line 6-173).\nProgram the analyzer such that it fills in the data loss due to eye-blinking by averaging the x and y coordinates of the gaze point immediately before and after the blinking (Supplementary File 3 - Line 176-260).\nProgram the analyzer such that it classifies the raw data into either saccade or fixation by using the algorithm developed based on ST-DBSCAN22 (Program code in Supplementary File 4). \nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Neuroscience"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research"
  ]
}