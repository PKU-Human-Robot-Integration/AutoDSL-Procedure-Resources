{
  "id": 4229,
  "origin_website": "Cell",
  "title": "Single-cell lactate production rate as a measure of glycolysis in endothelial cells",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nIntroduce laconic genetically: Day 1\nTiming: 1–1.4 h with overnight (12–24 h) incubation\nIn order to have cells expressing Laconic at highest levels, introduce laconic adenovirus vector (ad-Lac) 2 days prior to imaging.\nPlating cells\nAspirate media from T75 containing HAEC that is ∼80–100% confluent and wash flask with warmed, sterile 5 mL PBS and aspirate.\nAdd 1mL TrypLE and incubate in 37°C, 5% CO2 with humidity incubator for 1–2 min.\nCheck cells under microscope. If cells have become rounded, tap flask gently 10–20 times so that they come off. If cells have not become rounded, wait 1 min. Do not exceed 3 min total. Aim for ∼80% of cells to detach.\nAdd 5 mL EGM2 complete media to flask, washing the bottom of the flask to remove any adherent cells.\nAspirate cells and spin at 100 g, 5 min at room temperature.\nAspirate supernatant and resuspend cells in 1mL of EGM2 complete media.\nCount cells.\nSeed cells into wells so that there are ∼200,000 cells/well (in 12 well plate) with enough time before transduction for the cells to adhere (1 day for HAECs).\nPrepare reagents\nWarm viral media and complete media in 37°C water bath\nDefrost adenovirus laconic stock from −80°C on ice\nPrepare transduction master mix for half culture volume (500 μL for 12 well)\nMultiplicity of infection (MOI) = Plaque forming units (PFU) of virus used for infection / number of cells. We recommend starting with a MOI of 50:1.\nE.g.: for a virus of 3.40E+10 pfu/mL to be used at 50:1 MOI used in 200,000 cells/12 well, use 0.29 μL virus and 1.5 μL GeneJammer in 500 μL viral media per well\nMake master mix if using multiple wells\nMix by gentle swirling/pipetting. Do not vortex.",
    "Aspirate viral media and apply transduction mixture to each well\nIncubate for 1 h in 37°C at 5% CO2\nRemove viral media gently and replace with complete media\nIncubate overnight (12–24 h) at 37°C, 5% CO2, humidified.\nVisualize transfection efficiency on a fluorescence microscope (Figure 1[href=https://www.wicell.org#fig1]). Transfection efficiency can be roughly estimated by using a microscope and looking for signs of altered cell morphology which signals unhealthy cells. Every cell should be fluorescent with enough signals to obtain an accurate intracellular lactate calibration curve using a reasonable camera integration time (Figure 3[href=https://www.wicell.org#fig3]). Too much adenovirus (in our hands, 200:1 MOI) results in altered cell morphology and cell death.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/986-Fig3.jpg\nFigure 3. Laconic calibration curve\nmTFP/Venus (or 1/FRET) change is linearly correlated over 6 orders of magnitude of log lactate (n = 287 cells; black line is semilog fit with R2 = 0.96, gray dotted lines are 95% confidence interval); error bars are SEM. Standard deviation of regression coefficients for R2 for is 0.049.\nCritical: Virus must be kept on ice to ensure transduction efficiency. Virus should be aliquoted appropriately so that each tube isn’t thawed more than twice.\nCritical: Anything containing virus must be used with caution according to BSL-2 guidelines. Disposables and solutions containing virus must be disposed of separately from other reagents in 10% bleach.\nNote: GeneJammer is not necessary but will improve expression.\nNote: Solution changes must be done gently following transduction as the cells are especially sensitive to lifting off the plate.\nmRNA transfection of laconic (alternative to adenovirus)\nTiming: 1 h with overnight (12–24 h) incubation\nFor mRNA transfection using LipofectamineTM MessengerMax TM reagent:\nPrepare cells",
    "Seed adherent cells into wells so that there are ∼200,000 cells/well (in 12 well plate) with enough time before transduction for the cells to adhere (1 day for human aortic endothelial cells). See above on plating cells for directions.\nPrepare reagents\nWarm Opti-MEM and EGM2 complete media in 37°C water bath\nDefrost mRNA stock from −80°C on ice\nMake master mix of lipofectamine MessengerMax reagent (Link to manufacturer's protocol)\nfor 12 well plate: 50 μL total solution = 3 μL MessengerMax into 47 μL Opti-MEM.\nCreate master mix for multiple wells\nVortex master mix and incubate at room temperature for 10 min while you prepare mRNA mixes\nPrepare mRNA solutions so that final concentration is 160 ng/cm2\nFor 4 cm2 well (12 well), 50 μL solution = 7.1 μL mRNA (100 ng/cm2) into 42.8 μL Opti-MEM\nMix by triturating\nAdd Master mix of lipofectamine reagent to mRNA solutions in 1:1 volume ratio (50 μL:50 μL for 12 well)\nMix by triturating\nIncubate at room temperature for 5 min\nDuring incubation in step 12b, replace media in wells containing cells to 900 μL complete media total\nAdd 100 μL transfection solution to each well\nIncubate overnight for a minimum of 12 h up to 24 h.\nVisualize transfection efficiency on a fluorescence microscope (Figure 1[href=https://www.wicell.org#fig1]). In HAECs, mRNA transfection is noticeably less efficient than using adenovirus (Figure 1[href=https://www.wicell.org#fig1]) but still useable from a data acquisition standpoint. Too little mRNA and fluorescence is not enough, but too much mRNA causes cell death.\nCritical: mRNA must be kept on ice to minimize mRNA degradation. mRNA should be aliquoted so that each aliquot isn’t thawed more than twice.\nNote: mRNA transfections can be further optimized for your cells by a dose titration. We typically try a range of 25–200 ng/cm2.",
    "Plate cells into imaging chambers: Day 2\nTiming: 1 h\nFor ease of solution switching, cells must be plated into Ibidi flow chambers. However, this environment is slightly hypoxic with a smaller volume than traditional cell culture plates so cells must have media changes every 24 h (Figure 2[href=https://www.wicell.org#fig2]).\nWarm PBS, TrypLE, and cell media in 37°C water bath\nFor adherent cells, wash cells twice with PBS and remove by aspiration.\nAdd TrypLE to virally transduced cells (50 μL per 12-well), incubate for 2 min at 37°C and 5% CO2\nCheck for adequate detachment after 1 min, can tap dish to mechanically dislodge cells\nWhen 80% cells have detached, halt trypsinization by adding at least 3× volume complete media\nSpin cells down at 900 g at room temperature and resuspend to 75,000 cells/50 μL (for Ibidi 6-well plate) complete media\nTip Ibidi plate and add 50 μL into the elevated port, pipetting as close to the plate as possible, to ensure the cells spread between ports, incubate for 20 min at room temperature in the sterile hood.\nAdd 60 μL complete media to each port to prevent drying\nIncubate overnight (12–24 h) to ensure attachment\nCritical: When plating cells, make sure the solution of suspended cells is adequately mixed. This will ensure the sample number of cells makes it into each well and therefore the cells will be at the same density. We note changes in cell density may have an effect on their metabolism.\nPrepare injection solutions: Day 3\nTiming: 15 min\nPharmacological perturbation requires two solutions which must be made fresh before each experiment. Since Laconic measures glycolysis, it is important to block any mitochondrial consumption of pyruvate which is accomplished with rotenone. Nigericin is an ionophore used to clamp the intracellular pH.",
    "Warm Fluorobrite media and ICB in 37°C water bath.\nThaw stock solution of pCMBA and nigericin on ice.\nMix calibration curve solutions via dilution series (Table 2[href=https://www.wicell.org#tbl2]; Example calibration curve, Figure 3[href=https://www.wicell.org#fig3]).\ntable:files/protocols_protocol_986_4.csv\nSolutions for the calibration curve should be made the same day as imaging. Intracellular buffer (ICB) will be used as the solvent with varying concentrations of lactate in the presence of nigericin and rotenone for permeabilization. Lactate should first be serial diluted 1:10 5× then used to make to the following solutions.\nMake 10 μM nigericin and 2 μM of rotenone in 10 mL of ICB\nUse stock solution of lactate to generate 2 mL of 10 mM lactate\n10-fold Dilution series from 10 mM to 0.0001 mM (dilute 6×) with each solution at 1 mL final volume in ICB with rotenone and nigericin\nMix MCT blockade solution for LPR (lactate production rate) assay (Table 3[href=https://www.wicell.org#tbl3])\ntable:files/protocols_protocol_986_5.csv\nSolutions should be prepared fresh on the same day as imaging. Extracellular buffer (ECB) or glucose-free Fluorobrite can be used as the solvent which should be warmed prior to solution preparation. If using glucose-containing Fluorobrite, glucose does not need to be added. The example calculations are dependent on 1 mL solution injections which should be adjusted depending on the length (and therefore volume) of the tubing.\n500 μM pCMBA in Fluorobrite with glucose or ECB with glucose, 1 mL per well of cells\nBring 1 mL of Fluorobrite or ECB per well to wash cells prior to imaging\nNote: Calibration curve only needs to be performed once. When performing LPR experiments, calibration curve can be omitted (step 24).\nPause point: Solutions can stay at room temperature for up to an hour.\nPerform imaging of intracellular lactate or lactate production rate (LPR): Day 3\nTiming: 2–3 h",
    "Injection of solutions and data acquisition at the microscope. This section can be used with any data acquisition, including calibration curve of intracellular lactate and measurement of intracellular glycolysis (lactate production rate, LPR). Calibration curve only needs to be performed once unless the optical set-up is changed (filter sets, for example).\nTurn on light source, microscope, computer, imaging software (such as Micromanager), and additional controls such as stage, CO2, and temperature. Wait at least 1 h for the microscope to thermally stabilize.\nSerum starve the cells in the Ibidi plate prior to imaging\nWarm imaging solution (Fluorobrite or ECB) to 37°C\nReplace complete media in Ibidi plate containing cells with imaging solution\nOn the left port of the Ibidi plate, remove 90 μL of media. To the right port, add 90 μL of imaging solution. Perform 3 exchanges in total to completely remove the complete media.\nIncubate for at least one hour prior to imaging at 37°C\nWash the tubing with at least 5× volume with a 10 mL syringe filled with PBS then assemble imaging chamber.\nConnect input port before output port.\nAfter the final rinse, inject imaging solution (Tables 2[href=https://www.wicell.org#tbl2] and 3[href=https://www.wicell.org#tbl3]) into the input line using a needle and 1 mL syringe through the in-line injection port, holding the male elbow connector end at the same height as the injection port in order to ensure the entire tubing contains imaging solution liquid before adding the cap (Figure 2[href=https://www.wicell.org#fig2]). Capping the input line to close the input port will prevent fluid from leaking out of the input line into the imaging chamber. However, some diffusion is inevitable. Therefore, perform imaging away from the input port.",
    "Fill the ports on the Ibidi plate with the imaging solution using a 200 μL pipette so that there is no air within the port.\nAttach the input line first, press down firmly to ensure attachment. Then repeat attaching the output line.\nEnsure waste line is securely placed into waste container and that the input line is accessible without disturbing the imaging focus.\nSet imaging parameters\nExposure should be set to 100–200 milliseconds at a frame rate of 1 frame/2 s in both donor and FRET channels to minimize photobleaching.\nChoose a representative field of view away from the injection port and edges of well or multiple fields of view if you have stage control. Troubleshooting 1[href=https://www.wicell.org#troubleshooting], Troubleshooting 2[href=https://www.wicell.org#troubleshooting].\nStart imaging with injections\nAttach a 25g needle to a new 1 mL syringe, used for injecting drugs\nPull liquid up into the syringe slowly to avoid bubble formation\nFlick syringe as needed to eliminate bubbles\nUse a different needle/syringe for each subsequent injection\nStart imaging. Pause image acquisition if necessary to inject each subsequent solution. We perform this action slowly (1 mL over 5 s) to avoid cavitation and bubble formation. If doing the intracellular lactate calibration curve, perform those injections in increasing lactate concentration. Otherwise, follow the injection protocol for LPR. See Tables 2[href=https://www.wicell.org#tbl2] and 3[href=https://www.wicell.org#tbl3] for defined solutions. Troubleshooting 3[href=https://www.wicell.org#troubleshooting], Troubleshooting 4[href=https://www.wicell.org#troubleshooting]\nAcquire at least 2 min of data after each injection.\nAt the end of the assay, dispose of the cells unless using them for further analysis.\nWash the tubing 3× with 10× volume using 70% ethanol\nTransfer data and turn off imaging equipment\nCritical: The complete media contains growth factors that can activate the cells, thus changing their metabolism. Therefore, cells must be starved for at least one and up to two hours prior to imaging.",
    "Critical: Assembly requires attention to eliminating air bubbles. Additionally, if you connect the waste line first, you may pull liquid from the plate out, leaving the cells dry and the plate susceptible to bubble formation. If a bubble is injected into the imaging chamber, cells could be ripped off the plate.\nNote: To prevent bubble formation, place Ibidi chamber and tubing in incubator for 10 min prior to starting injections to bring everything to the same temperature. Make sure all solutions are at 37°C.\nNote: Exposure time will be dependent on the expression level, light source strength, objective, and camera sensitivity. We suggest that the histogram of intensities fills at least ¼ the dynamic range of the camera. Troubleshooting 1[href=https://www.wicell.org#troubleshooting]\nNote: After each injection, check focus to ensure that there has not been any focus drift. Troubleshooting 4[href=https://www.wicell.org#troubleshooting]\nPause point: Data can be analyzed at any time.\nConstruct deep learning network for semantic segmentation\nTiming: 3–7 days, depending on size of data set, computer memory and speed",
    "For successful discrimination of metabolic subpopulations, accurate cell segmentation is critical. We therefore employed semantic segmentation for endothelial cells which have complex morphology. One increasingly powerful method for rapid segmentation is the use of artificial intelligence which has achieved human-level performance (Ronneberger et al., 2015[href=https://www.wicell.org#bib5]). A subset of AI is deep learning, in which convolutional neural networks are used to perform recognition tasks, where many of the rules governing object assignment are hidden, as opposed to rule-based segmentation where all rules must be a priori explicitly laid out. For accurate Deep Learning to perform semantic segmentation, having a large ground truth dataset for network training is essential. A sample ground truth dataset can be downloaded at (Harrison, Devin et al., 2021[href=https://www.wicell.org#bib4]), ground truth_v2.zip. Code for this section can be downloaded and followed along at: https://github.com/wulab-code/STAR_methods[href=https://github.com/wulab-code/STAR_methods]. Please open “code_testing_new.m” for sample code. Be sure all scripts are in the same directory to eliminate path issues.\nGenerate ground truth dataset: Try to make conditions of ground truth dataset as close to how data will be taken so that the AI can do the least amount of guessing. Transfect with laconic as above on a glass substrate such as Ibidi 8-well or Labtek 8 well to facilitate high resolution microscopy. The goal here is to generate microscopy datasets that will be easily labeled as cell body (using transfected Laconic), cell boundaries (using VE-CADH antibody), nuclei (with Hoechst dye), and background.\nFix cells: After cells have grown to confluency and are appropriately expressing Laconic, wash cells with PBS at 37°C once and immediately fix using 4% PFA for 10 min at room temperature.\nAfter fixation, wash with PBS 3×, 5 min each, on a rocking platform at room temperature.\nWash 3× with PBS, 5 min each, shaking, room temperature.",
    "Block with blocking buffer for 30 min at room temperature, shaking\nPrimary antibody overnight (12–24 h) 1:100 VE-CADH in blocking buffer on a rocking platform at 4°C.\nWash with PBS 3×, 5 min each, shaking, room temperature.\nSecondary antibody: 1:1000 goat anti-rabbit 549 for 1 h in blocking buffer at room temperature, shaking\nWash with PBS 3×, 5 min each, shaking, room temperature.\nStain nucleus: treat samples with 1:1000 Hoechst dye in PBS for 10 min at room temperature, then rinse with PBS once.\nPause point: After cells have been fixed, they can be stored at 4°C in PBS for imaging later. If the chambers are properly sealed to prevent drying out (plastic wrap or parafilm) then cells can be imaged months later. Mounting media can be added as a preservative and cells can be stored at 4°C for years.\nTake images at same magnification / settings as experiment, as many as possible – green channel which will see laconic and label cytoplasm, red channel which will image VE-CADH and the cell boundary and blue channel which will image Hoechst and hence the nucleus of the cell. Troubleshooting 5[href=https://www.wicell.org#troubleshooting]\nLabel ground truth images: After generation of ground truth data set (Harrison, Devin et al., 2021[href=https://www.wicell.org#bib4]) now we have to label all the pixels in the ground truth images. There are many ways to do this, including by manual inspection, or with custom image segmentation software. One highly accessible approach is to use free, open-source software such as CellProfiler (Carpenter et al., 2006[href=https://www.wicell.org#bib1]). CellProfiler can use the nuclei as seeds for the cells then use the gradient of Laconic towards the cell edge as a marker for the boundary of the cell.\nDownload CellProfiler (key resources table[href=https://www.wicell.org#key-resources-table]) and load images according to your folder and file structure",
    "Calculate the illumination function for your microscope. Use “CorrectIlluminationCalculate” function. Select the input image and name the output image. Calculate the Background image and do not dilate the objects in the final averaged image. Select a block size which is larger than the object (a cell); in this case, 150 is sufficient. Do not rescale the illumination function. Calculate the function based for each image. Smooth the background image with a Gaussian function.\nPerform background correction on all images. Use the “CorrectIlluminationApply” function to perform background correction. Select the input images (these are your original images) and name the output image. Use the illumination function calculated in step 34b. The illumination function should be subtracted from the input image.\nIdentify primary objects (nuclei). Use the “IdentifyPrimaryObjects” function. Select input image for Hoechst based images. Enter the typical diameter of the object in pixel units. Discard objects outside the diameter range; discard objects touching the border of the image. Use an adaptive thresholding strategy with Otsu thresholding method, with three-class thresholding. Assign pixels in the middle intensity range to the foreground. Threshold smoothing scale and correction factor can be modified but default settings work. Choose adaptive window of 50 and distinguish clumped objects by shape. Use propagation method to draw dividing lines between clumped objects. Automatically calculate the size of the smoothing filter for declumping, automatically calculate the minimum allowed distance between local maxima, and speed up by using a lower-resolution image to find local maxima. Fill holes in identified objects after both thresholding and declumping. Typically, this will result in detection of nuclei that are bigger than what is perceived by the user.",
    "Shrink the nuclei. Use the “ExpandOrShrinkObjects” function. Select the input object for nuclei and shrink the objects by a specified number of pixels. This has to be eyeballed, but 3 is sufficient.\nNow identify the cell bodies. Use “IdentifySecondaryObjects.” Select input image for Laconic based images, and select the shrunken nuclei as the input objects. Select propagation as the method to be used to identify secondary objects. Use an adaptive thresholding strategy with Otsu thresholding method, with three-class thresholding. Assign pixels in the middle intensity range to the foreground. Threshold smoothing scale and correction factor can be modified but default settings work. Choose adaptive window of 50 and regulation factor of 0.05. Fill holes in identified objects and do not discard objects touching the border of the image.\nNow identify cytoplasm. Use “IdentifyTertiaryObjects.” Select the cell body objects from step 34f. Select the smaller identified objects (shrunken nuclei). And do not shrink smaller objects prior to subtraction.\nFill objects. Now that the cytoplasm has been identified, use “FillObjects”. This function will fill in any unmarked cytoplasm, using a minimum hole size of 54 and planewise fill.\nTo create cell boundaries, shrink the cytoplasm by 1 using the “ExpandOrShrinkObjects” function.\nShrink the nuclei by 1 pixel using the “ExpandOrShrinkObjects” function.\nNow using the shrunken cytoplasm, identify the cytoplasm object by using “IdentifyTertiaryObjects.”\nNow using the shrunken nuclei, identify the nuclei object by using “IdentifyTertiaryObjects.”\nNow using the cytoplasm with nuclei, identify the cytoplasm object by using “IdentifyTertiaryObjects” and smaller object is new shrunken nuclei.\nConvert the following objects to image using “ConvertObjectsToImage” function: Filled cytoplasm, cytoplasm with nuclei, cytoplasm outlier, shrunken nuclei, shrunken nuclei_1 and shrunken cytoplasm",
    "Save images to disk as Portable Network Graphics (png) using “SaveImages” function. The rest of the protocol assumes that images are saved in png format.\nConstruct deep learning algorithm using the Deep Learning toolbox in MATLAB: MATLAB is advantageous in that minimal computer programming is required. Smallest feature size will determine how many convolutions you need to perform. The idea is to use deconvolutions to increase the receptive field for each neuron and then localize where the neurons fire using upconvolutions. Finally, an inverse weight function will be used to account for unequal distributions of the pixel classes (background pixels are usually overrepresented, compared to boundary, cytoplasm, and nuclei, and could therefore bias the network). The first part will involve creating a datastore and using augmentation to increase the effective size of the dataset. The second part involves creating the segmentation network and assessing its performance.\nDownload and install latest version of MATLAB with Deep Learning toolbox. Download the scripts from GitHub (Link to code[href=https://github.com/wulab-code/STAR_methods]). Open sample code “code_testing_new.m” in MATLAB.\nCreate a new script. All code referenced below are in “code_testing_new.m”. The code is either directly shown below or referenced by line number. For each new line in the script, there will be a double arrow “>>” and can be typed directly into the script\nThis script assumes you are on a Windows PC. In this example, the “basedir” is the location of the groundtruth images with are .png format files. This script also assumes that you are using MATLAB 2018b although the script should be compatible with newer versions.\n>> clear\n>> addpath('C:∖Program\n  Files∖MATLAB∖R2018b∖examples∖images∖main')\n>> basedir = 'D:∖images∖';\n>> ground_truth = 'D:∖images∖groundtruth';\nDefine classes.\n>> classNames = [\"background\",\"border\",\"cell\",\"nuclei\"];",
    "Randomize into training and validation datasets. Pick the fraction of images you wish to use for training (frac_training) from the total number of groundtruth images (num_images), which the computer is blinded to when performing validation and testing. The script automatically divides the remaining non-training images into validation and testing evenly. A good starting point is 70% of images devoted to training. Num_images defines the number of groundtruth images.\n>> num_images = 1000;\n>> frac_training = 0.7;\n>> [training, validation, testing] = ...\n  randomize_images(num_images,frac_training);\nMake and store training, validation, and testing datasets into different directories: one for the labeled images and one for the images themselves\n>> divide_images(...\nbasedir,ground_truth,training,validation,testing);\nCreate image and pixel datastore for training and validation.\n>> imds = imageDatastore(fullfile(basedir,'training'),\n  ... 'FileExtensions',{'.png'});\n>> classNames =\n  [\"background\",\"border\",\"cell\",\"nuclei\"];\n>> pixelLabelIds = [0 1 2 3];\n>> pxds = pixelLabelDatastore(fullfile(basedir, ...\n  'training_label'),classNames,pixelLabelIds);\n>> imds_validation = imageDatastore(fullfile(basedir, ...\n  'validation'),'FileExtensions',{'.png'});\n>> pxds_validation = pixelLabelDatastore(fullfile(...\n  basedir,'validation_label'),classNames,pixelLabelId\n  s);\n>> pximds_validation = pixelLabelImageDatastore(...\n  imds_validation,pxds_validation);\nAugmentation can be used to increase the amount of data available to the network. Define augmentation function.\n>> augmenter = imageDataAugmenter('RandRotation',[-180\n      180],...\n    'RandXReflection',true,...\n    'RandYReflection',true,...\n    'RandXShear',[0 10],...\n    'RandYShear',[0 10]);\nDefine patch extraction datastore\n>> patchds = randomPatchExtractionDatastore(...\n  imds,pxds,128,'PatchesPerImage',256, ...\n  'DataAugmentation',augmenter);\n>> patchds_validation =\n  randomPatchExtractionDatastore(...\n  imds_validation,pxds_validation,128,'PatchesPerImag\n  e',256);\nPreview the augmented patches\n>> minibatch = preview(patchds);\n>> montage(minibatch.InputImage,'DisplayRange',[0 255])\nCreate inverse weighting function.\n>> tbl = countEachLabel(pxds);\n>> totalNumberOfPixels = sum(tbl.PixelCount);\n>> frequency = tbl.PixelCount / totalNumberOfPixels;\n>> classWeights = 1./frequency;\nGenerate graph of the network (Figure 4[href=https://www.wicell.org#fig4]). “numFilters” determines the number of channels in the output of the convolutional layer. “filterSize” is the size of the local regions that are convoluted and should therefore be matched to the smallest feature which in our case is a few pixels. 3 is the smallest filter size.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/986-Fig4.jpg\nFigure 4. Deep learning architecture for semantic segmentation",
    "Deep learning architecture for semantic segmentation, which consists of a contracting path (encoder) and an expansive path (decoder), forming a U-Net.\nLines 43–174\nSet options for the training. These are trial and error, but below are some starting points.\n>> initialLearningRate = 0.05;\n>> maxEpochs = 50;\n>> minibatchSize = 16;\n>> l2reg = 0.0001;\n>> options = trainingOptions('sgdm',...\n    'InitialLearnRate', initialLearningRate, ...\n    'Momentum',0.99,...\n    'L2Regularization',l2reg,...\n    'MaxEpochs',maxEpochs,...\n    'MiniBatchSize',minibatchSize,...\n    'VerboseFrequency',20,...\n    'LearnRateSchedule','piecewise',...\n    'LearnRateDropFactor',0.1, ...\n    'LearnRateDropPeriod',20, ...\n    'Shuffle','every-epoch',...\n    'Plots','training-progress',...\n    'GradientThresholdMethod','l2norm′,..\n    'CheckpointPath',fullfile(basedir,'checkpoint'),...\n    'GradientThreshold',0.05, ...\n    'Verbose',true, ...\n    'ExecutionEnvironment','multi-gpu');\nTrain algorithm and save the network (Figure 5[href=https://www.wicell.org#fig5]). This can take anywhere from overnight (12 h) to 1 week depending on the speed of your computer. You should see the accuracy increase and the loss decrease as the training attempts to converge. Accuracy should be above 80% and loss should be below 1 to have acceptable results. Troubleshooting 6[href=https://www.wicell.org#troubleshooting]\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/986-Fig5.jpg\nFigure 5. Training and validation of the convolutional neural network\nAccuracy (A) and loss (B) as a function of training epoch. Training was stopped when there was no further change to loss or accuracy.\n>> [net,info] = trainNetwork(patchds,lgraph2,options);\n>> save network.mat net\nCritical: We suggest imaging at least 20,000 cells for deep learning but any additional images will help. Only 70% of images will be used for training. The remaining 30% will be split evenly for validation and testing of the deep learning network.\nAlternatives: Although we did not specify in the CellProfiler section (27), it is possible to use the VE-CADH signal as the boundary and the Laconic and Hoechst signal as markers for the cell body and nucleus when labeling cells for ground truth.",
    "Note: If the computer runs out of memory, try reducing the minibatch size. If the learning rate is not fast enough, adjust the momentum, LearnRateDropFactor and LearnRatePeriod. While these are good starting points, this is entirely trial and error. Typically, the accuracy should increase almost immediately in an upward trajectory from 0 to 60% within one 50 iterations with slow improvement afterwards. While the speed of calculation depends ultimately on the amount, quality of data, and computer specifications, a typical run on a fast computer with 3 GPUs (circa 2018) takes 24 h.\nAlternatives: It may be possible to use transfer learning using a published network to avoid creating one’s own deep learning network.\nTroubleshooting 7[href=https://www.wicell.org#troubleshooting]: MATLAB code has difficulty executing\nPause point: As this all takes place in a computer, resuming can happen at any time.\nSemantic segmentation\nTiming: [4 h - days], depending on computer memory and speed, and size of dataset",
    "Pre-processing images after imaging Laconic. Pre-processing images is important to remove imaging artifacts such as vignetting or uneven illumination, in order to have the best performance (assuming that the ground truth dataset is ideal). The network will likely perform well on unoptimized images as well. One can in theory test this under quantification and statistical analysis below. It is possible to take experiment images and process them first in CellProfiler, but here we opt to use MATLAB so that everything is “one-click”. The first step is to eliminate vignetting and uneven illumination, using a tophat filter. However, to specify filter properties, one needs to know the imaging properties of the microscope. Start a new script. Specify the camera and magnification parameters including pixel size (in real space). Specify the approximate size of a cell. A good rule of thumb is to make the tophat filter about 3× the size of a cell (Crocker and Grier, 1996[href=https://www.wicell.org#bib2]). Specify the expected input image size for the network and bit depth. Make sure that the image size and bit depth are the same as that which was used in creating the deep learning network above (here, the image size was 1200×1200 and the bit depth was 8 bit).\n>> pixel_size = 11e-6;\n>> magnification = 10;\n>> cellsize = 11e-6;\n>> tophatw = 3∗round(cellsize/(pixel_size/magnification));\n>> h = fspecial('disk',tophatw);\n>> thresh = 0;\n>> targetimsize = [1200 1200];\n>> targetbitsize = 8;\nResize image and use tophat to get rid of long wavelength intensity fluctuations where venusimage and tfpimage are the files of the Venus image and the mTFP image, respectfully, although in principle it doesn’t matter.\n>> venusimage = 'venus.tif';\n>> tfpimage = 'tfp.tif';\n>> [venus_orig tfp_orig thresh_venus thresh_tfp] = ...\n    resizetophatim(venusimage,tfpimage,...\n    targetimsize,h,thresh,targetbitsize);",
    "Perform semantic segmentation of images: It doesn’t matter if you do it on the background corrected Venus image or mTFP image. Here it is done on the Venus image\nLoad the network:\n>> segnet = load('network.mat');\nSegment the image. It is much faster with a GPU than using a CPU.\n>> output = semanticseg(venus_orig,segnet.net,... ’ExecutionEnvironment’,’gpu’);\nPost-processing of images\nTiming: [2–16 h], depending on computer memory and speed, and size of dataset\nPost-processing after semantic segmentation: The output is a categorical array (1–4). The segmentation needs to be cleaned up as artifacts can be introduced. This script filters out small cells and small nuclei and saves the output. Convert the output image to a labeled image (see Figure 6[href=https://www.wicell.org#fig6] for example of original image, after semantic segmentation, and after additional post processing). See how well the segmented image compares to the original. In this example, the post processed image (‘Additional filtering’) has interpreted some noise as cells. This can be improved by increasing the size and/or accuracy of the ground truth data set.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/986-Fig6.jpg\nFigure 6. Single field-of-view segmentation example\nThe contrast adjusted original Venus image (left) undergoes semantic segmentation (center) which classifies cell boundaries but must be filtered additionally to remove non-cell objects (right). Scale bar is 264 μm.\n>> [filtered_image filtered_nuclei] =\n  filter_network_output(output);\n>> bw_filtered_image = bwlabel(filtered_image);\n>> bw_filtered_nuclei = bwlabel(filtered_nuclei);\n>> figure\n>> output_im = double(output);\n>> bw_im = double(bw_filtered_image);\n>> venus_im = imread(venusimage);\n>> J = imadjust(venus_im,stretchlim(venus_im),[]);\n>> [X2]= output_im/max(output_im(:));\n>> [X3]= bw_im/max(bw_im(:));\n>> map = jet;\n>> subplot(1,3,1)\n>> imshow(J)\n>> title('Contrast adjusted Venus image')\n>> subplot(1,3,2)\n>> imshow(X2,'Colormap',map)\n>> title('Semantic segmentation')\n>> subplot(1,3,3)\n>> imshow(X3,'Colormap',map)\n>> title('Additional filtering')",
    "Decompose the segmented image into individual cells: The images have been segmented, but each pixel in each image is just now a number – 1–4 indicates background, cell boundary, cytoplasm, and nuclei. The cells have to be individually identified, which is the purpose of this part. Using parallel processing significantly speeds up the time required.\n>> expand = 3;\n>> venusresize = imresize(imread(venusimage),targetimsize);\n>> tfpresize = imresize(imread(tfpimage),targetimsize);\n>> imdata = cell_decomposition(bw_filtered_image,...\n  bw_filtered_nuclei,venusresize,tfpresize,expand);\nAbove, everything was done on one single image. Now we will put it into a loop using parallel processing. Place all variables that don't change outside the loop. We recommended that you use GPUs to do semantic segmentation first, then use regular CPUs (in parallel) for the rest. Use the demo_images.zip located here (Harrison, Devin et al., 2021[href=https://www.wicell.org#bib4]). Unzip them into a directory titled “demo_images”.\nFirst loop the part that requires GPU Lines 227–248.\nNext loop the part that requires CPU\nLines 250–278.\nNote: A sample data set (in addition to the one referenced explicitly in the code above) is located at (Wu et al., 2021b[href=https://www.wicell.org#bib8]) corresponding with figures in (Wu et al., 2021a[href=https://www.wicell.org#bib7]). We recommend using the dataset corresponding to Figure 1e. Sample 1 is control and sample 2 is with DMOG. Injections for pCMBA occur at frame 120.\nLink cell trajectories\nTiming: 15 min\nLinking together cell trajectories: Now that all images have been segmented, the next task is to link the intensities of each cell into a trajectory which is accomplished below by creating a matrix of cell positions and finding the nearest cell in an adjacent image. Save the output.\n>> input_directory = 'singlecell_output';\n>> [venus tfp venus_bg tfp_bg linkage] = ...\n    cell_linking(input_directory,targetimsize);\n>> output_directory = 'singlecell_links';\n>> mkdir(output_directory);\n>> save(fullfile(output_directory,'linkvenus.mat'),'venus');\n>> save(fullfile(output_directory,'linktfp.mat'),'tfp');\n>> save(fullfile(output_directory,'linkvenusbg.mat'),'venus_bg');\n>> save(fullfile(output_directory,'linktfpbg.mat'),'tfp_bg');\n>> save(fullfile(output_directory,'linkage.mat'),'linkage');\nAnalysis of data",
    "Timing: 30 min\nNow that the experiment is complete, we need to analyze the data and calculate the rate of intracellular glycolysis or the lactate production rate (LPR). To obtain the LPR, calculate the slope of the mTFP/Venus signal (the lactate signal) over a 40 s trajectory and fit it against a linear model during the portion of the time the cells were exposed to MCT1 inhibitor according to the following equation (Equation 1):\n  L P R =   Δ L o  g 10  L a c t a t e   Δ t   .  \nLoad the linked trajectories: At this point the segmented images in each channel (mTFP, Venus) have been linked through time in “linktfp.mat”, “linkvenus.mat” which contains the mean intensity of the segmented cell in each respective channel. Background of the channels has been saved in “linktfpbg.mat” and “linkvenusbg.mat”. These are loaded by selecting the appropriate directory and subdirectory containing the linked files:\n>> load(fullfile(output_directory,'linktfp.mat'));\n>> load(fullfile(output_directory,'linkvenus.mat'));\n>> load(fullfile(output_directory,'linktfpbg.mat'));\n>> load(fullfile(output_directory,'linkvenusbg.mat'));\nCalculate the inverse FRET ratio. Inverse FRET ratio is calculated by dividing the mTFP by Venus, which were determined from the total cytoplasmic intensity. One can also check the background doesn’t contribute significantly to the (inverse) FRET signal by calculating the FRET of the background. Each row of the “fret” or “fret_bg” matrix is the single cell inverse FRET ratio (Figure 7[href=https://www.wicell.org#fig7]).\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/986-Fig7.jpg\nFigure 7. LPR single-cell trace\nExample of the 1/FRET trace of an individual cell during the LPR assay. Arrows indicate solution changes.\n>> fret = tfp./venus;\n>> fret_bg = (tfp-tfp_bg)./(venus - venus_bg);",
    "Load the image data and set the LPR calculation over 40 s: Next, we calculate the LPR by fitting the rate of increase in mTFP/Venus signal over 40 s specified by dist (here, dist = 20 since we took 1 frame every 2 s).\n>> imdata = load(fullfile('singlecell_output', ...\n    [zerostr(5,0) '_data.mat']));\n>> dist = 20;\nCalculate the LPR for each solution change. Iterate through the fret variable, which is a matrix containing in each row the average fret value of a cell, and in each column the fret value of that cell as a function of time. The signal is filtered with a median filter of width 5. We look for changes in solution that tells us when to start calculating the slope. Keep on looking for changes in solution until you have run out (“solution_changes”, specified a priori). Fit the relevant data with a line and calculate the slope. Save this variable. In this example (from the demo images dataset), solutions were injected in frame 150 (glucose) and frame 300 (glucose and pCMBA).\n>> solution_changes = [150 300];\n>> clear slope gof_r2 cellsize cells\n>> for i = 1:size(fret,1)\n  mfret = medfilt1(fret(i,:),5);\n  for h = 1:length(solution_changes)\n        if h ∼= length(solution_changes)\n                vec =\n    mfret(solution_changes(h):solution_changes(h+1));\n      else\n          vec = mfret(solution_changes(h):length(mfret));\n      end\n      idx = find(vec == min(vec));\n      if h == length(solution_changes)\n            if length(mfret)-\n    (solution_changes(h)+min(idx)) < dist\n              idx = 1;\n        end\n      end\n      x = solution_changes(h)+min(idx)-1;\n        [fitobj gof] =\n    fit((x:x+dist)',mfret(x:x+dist)','poly1′);\n      slope(i,h) = fitobj.p1;\n      gof_r2(i,h) = gof.rsquare;\n        end\n    end",
    "Now go through the fitted slopes and filter it for fit slopes that have an R2 value that is high enough to ensure that the fit parameters correspond will with the data (specified by “filter” parameter). In our hands, R2 values > 0.8 are sufficient. Here, the slope has been fit into another variable. In the code below, we use R2 value of 0.9 (‘filter’ variable).\n>> filter = 0.9;\n>> slope_n(1).slope = [];\n>> for m = 1:length(slope (1,:))\n  c = 1;\n  for i = 1:size(slope,1)\n    if gof_r2(i,m) > filter\n      slope_n(m).slope(c) = slope(i,m);\n      slope_n(m).r2(c) = gof_r2(i,m);\n      slope_n(m).index(c) = i;\n      c = c+1;\n    end\n  end\nAt this point, save the results in a file.\n>> save results.mat slope_n\nThe LPR can be plotted either in MATLAB or another plotting program. The factor 0.01221 is the slope of the semilog change in lactate, as generated from the calibration curve (Figure 3[href=https://www.wicell.org#fig3]), divided by the inverse frame rate (Equation 1). Sample data for Laconic calibration can be downloaded from (Wu et al., 2021b[href=https://www.wicell.org#bib8]), Figure Extended Data 1a (Wu et al., 2021a[href=https://www.wicell.org#bib7]). Injection times for different concentrations of lactate during calibration process are available here (Harrison, Devin et al., 2021[href=https://www.wicell.org#bib4]).\n>> glucose = slope_n(1).slope /0.01221);\n>> lactate = slope_n(2).slope /0.01221);\nInspect a good trace (Figure 7[href=https://www.wicell.org#fig7] demonstrates a single cell trace of 1/FRET):\n>> plot(fret(slope_n(2).index(50),1:450),'k.')\n>> text(150,0.6075,'∖leftarrow Glucose injection')\n>> text(300,0.6075,'∖leftarrow pCMBA injection')\n>> xlabel('Frame')\n>> ylabel('1/FRET′)\nOptional: Instead of calculating LPR (step 44), one can also directly compute the intracellular lactate concentration if there is a permeabilization step used as a reference (as for determining the inverse FRET/lactate calibration).\nTroubleshooting 8[href=https://www.wicell.org#troubleshooting]: Low number of useable FRET traces"
  ],
  "subjectAreas": [
    "Molecular/Chemical Probes",
    "Bioinformatics",
    "Metabolism",
    "Microscopy",
    "Cell Biology",
    "Single Cell"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics",
    "Bioinformatics & Computational Biology",
    "Bioengineering & Technology"
  ]
}