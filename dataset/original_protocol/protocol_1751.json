{
  "id": 1860,
  "origin_website": "Cell",
  "title": "A protocol for working with open-source neuroimaging datasets",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nFind open-source dataset\nTiming: 1 day to 1 week\nThere are many open-source samples available; it is first necessary to identify a dataset, or datasets, of interest.\nDetermine the research question(s) to be addressed.\nDetermining the population of interest (i.e., infants, children, young adults, aging adults, individuals with a disorder, etc.) will help hone in on the appropriate sample.\nSpecify what sorts of data are needed from this sample.\nFor example, in a study to address the neural correlates of autism spectrum disorder (ASD), are neuroimaging data and clinical labels sufficient (i.e., case/control status)? Alternatively, are continuous symptom scores necessary?\nNote that samples with many contributing sites may not have standardized data across all sites (e.g., ABIDE I/II) (Di Martino et al., 2014[href=https://www.wicell.org#bib12], 2017[href=https://www.wicell.org#bib11]), whereas other studies with many sites may have harmonized measures (i.e., ABCD (Casey et al., 2018[href=https://www.wicell.org#bib9]) and UK-Biobank (Miller et al., 2016[href=https://www.wicell.org#bib31])).\nFind the dataset(s) of interest.\nThere are many samples openly available; we list some of the large samples (i.e., those with 700+ participants) in Figure 1[href=https://www.wicell.org#fig1].\nSamples consist of a variety of data modalities, including imaging, genetics, and phenotypic data.\nMost have raw imaging data; some have data that have been minimally or fully processed (see ‘troubleshooting[href=https://www.wicell.org#troubleshooting]’ below for what to do if a dataset of interest cannot be accessed).\nSamples differ with respect to access.\nSome datasets, like those hosted on OpenNeuro (Poldrack et al., 2013[href=https://www.wicell.org#bib36]; Poldrack and Gorgolewski, 2017[href=https://www.wicell.org#bib37]), do not require an application; download and use of data are available to anyone.\nOther datasets, like ABCD (Casey et al., 2018[href=https://www.wicell.org#bib9]), require a formal data usage agreement (DUA) to be approved by the organization hosting the dataset.",
    "It is often useful to access multiple datasets that contain the variables of interest to assess the replicability/generalizability of any significant findings.\nInvestigators may wish to preregister their study and analysis plan at this stage (see ‘troubleshooting[href=https://www.wicell.org#troubleshooting]’ below for how to preregister a study).\nCritical: DUAs must be approved prior to working with the data. Requirements vary by sample, but most DUAs require that all individuals in contact with the data be on the DUA and approved to work with the sample (including rotating graduate students, visiting scholars, etc.). Some datasets require a new DUA to be approved annually. DUAs often must be signed by an institutional signing official.\nInvestigators should confer with their institutional review board (IRB) and/or human investigation committee (HIC) before downloading the data, as human research exceptions or data-sharing agreements might be required.\nCritical: Because the data are already collected, obtaining IRB/HIC approval is often (erroneously) neglected. Regulations with respect to using open data vary by institution and by country or region. Due to data anonymization concerns, regulations will continue to evolve. It is therefore essential that investigators consult with their institutional regulatory bodies prior to beginning work with these samples and, if necessary, once they have obtained the data.\nDatasets differ with respect to participant preferences about data usage.\nFor instance, participants in the UK-Biobank (Miller et al., 2016[href=https://www.wicell.org#bib31]) may withdraw their data at any time (or request that research teams delete it).\nAlternatively, participants in the National Institute of Mental Health Data Archive can request to have their data withdrawn for future download but are unable to request that research teams with the data delete it.\nResearchers should be aware of privacy standards with their dataset and ensure that they are compliant with participant requests.",
    "For the remainder of this protocol, we will focus on data obtained from OpenNeuro, but, where appropriate, we will highlight points of divergence from other open-source samples.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1340-Fig1.jpg\nFigure 1. An overview of open-source datasets and open repositories\n(A) For each dataset listed in the leftmost column, sample size is indicated, along with the type of data included (‘Data modalities’). ‘Data level’ refers to the level of preprocessing: white circle, raw data; gray circle, some level of preprocessed data; black, processed data (for example, statistical maps, connectivity matrices, etc.).\n(B) For each open repository (i.e., a collection of open datasets) listed in the leftmost column, an estimate of the number of open datasets is listed. Datasets of interest are highlighted (‘Featured large datasets’). Sample sizes and the number of open datasets are current as of September 2021. Users are encouraged to visit the website associated with each dataset before use, as sample sizes, access conditions, etc. may change. Figure adapted with permission from (Horien et al., 2021[href=https://www.wicell.org#bib23]).\nDownload, store, and manage data\nTiming: 1 week to 1 year\nIn this section, we will discuss how to download, store, and manage data from an example dataset (Yale Resting State fMRI/Pupillometry: Arousal Study. https://openneuro.org/datasets/ds003673/[href=https://openneuro.org/datasets/ds003673/]) (Lee et al., 2021[href=https://www.wicell.org#bib28]). This dataset includes resting-state fMRI data that were acquired with simultaneous pupillometry from 27 healthy adults (26.5 ± 4 years old; 16 females). We will focus on imaging data in this example.\nDownloading data",
    "Check the version of the dataset: Visiting the dataset link (https://openneuro.org/datasets/ds003673/[href=https://openneuro.org/datasets/ds003673/]) from your browser will take you to the latest available version of this dataset (Figure 2[href=https://www.wicell.org#fig2]). At this time, you can see version 1.0.1 published on 2021-08-21, as shown in the left panel. If this is not the version you are looking for, navigate the left panel to select the right one.\nNote: Open-source datasets often have multiple releases, and researchers should check the study website to see which version they want. This is important to check because 1) sample size and/or the number of follow-up time points tends to increase with the version and 2) there might have been processing errors in prior releases that have been corrected.\nCheck the information of the dataset in the README and CHANGE files to review the history and data information provided by the authors.\nYou can download the full dataset by clicking the DOWNLOAD button below the title panel. Several download options will appear (e.g., Download with your browser, Node.js, S3, or DataLad).\nOr, you can manually download parts of the dataset depending on your interest.\nClick the subject data directory (e.g., sub-pa1372) you wish to download to view the list of files.\nClick each DOWNLOAD button below the name of the file to download the anatomical and functional MRI images.\nOr, click each VIEW button below the name of the file, to view the image.\nYou can download the image after viewing.\nCheck if the downloaded files match with the original data.\nMake sure you cite the dataset or related publications when you use the dataset. The citation information is usually provided on the title page and README files provided by the authors.\nStorage",
    "Brain imaging data structure (BIDS) (Gorgolewski et al., 2016[href=https://www.wicell.org#bib21]) is a common data organizational standard in neuroimaging that helps facilitate use and reuse by investigators.\nFor help with BIDS, see https://github.com/bids-standard/bids-starter-kit[href=https://github.com/bids-standard/bids-starter-kit]\nAll datasets from OpenNeuro are organized according to BIDS.\nRaw anatomical and functional data are stored in specific folders per subject (Figure 3[href=https://www.wicell.org#fig3]A).\nData derived from each subject over the course of the study are stored in a subject-specific folder in the derivatives directory.\nFor example, pupillometry data are shown in the derivatives folder for a representative participant (Figure 3[href=https://www.wicell.org#fig3]B).\nSome legacy, open-source datasets (i.e., early HCP releases) might not be organized according to BIDS.\nInvestigators can restructure their dataset to match BIDS standards or retain the original data structure.\nThe main goal is to have consistent organization across all participants.\nData management\nWhen working with the data, depending on a team member’s experience/role, raw data files can be made read-only (so that they cannot be accidentally modified or deleted).\nFor example, if a team member has little experience coding and is tasked with performing QC on image registration, read-only privileges are sufficient.\nKeep track of what was done to the data\nDocumentation should enable a knowledgeable researcher within the field to exactly recreate the workflow.\nThis includes what was done to the data, why it was done, the code/software used, and who performed each step.\nResources like Google Docs and Jupyter (https://jupyter.org/[href=https://jupyter.org/]) can be used as virtual lab notebooks if desired.\nResources like Slack and Microsoft Teams can be helpful to facilitate communication among team members when managing the data (as well as during all aspects of a project).",
    "Critical: Maintaining a well-documented lab notebook is critical, particularly for larger datasets that might take up to a year to process and involve many team members. Given that junior personnel are often tasked with managing these large samples, keeping a clear, concise record can help maintain progress if/when lab members move on with their training.\nCritical: An important aspect of data management that is often overlooked is checking for updates to a dataset. Oftentimes, issues are discovered by the team collecting the data that can significantly affect processing and analyses. Most teams hosting the data have a QC page, a wiki, or a point person responsible for fielding issues. These resources should be frequently consulted as soon as downloading the data.\nAfter data download, it can be helpful to have a lab member designated to managing data and watching for updates.\nFor instance, this lab member could be responsible for maintaining documentation, managing which team members have access to the data, and checking to see if data/QC updates are available for the sample.\nIn terms of updates, be on the lookout for new data releases, scanner/software upgrades, different behavioral indices being used, and basic QC issues.\nSocial network services, such as Twitter, can also be a useful resource for obtaining advice from colleagues working with the same data or determining if other groups have noticed a QC issue. Neurostars.org[href=http://Neurostars.org] can also be a helpful resource for posting questions/issues.\nMost databases have listservs that email about new data releases and bugs that might have been discovered in previously released data.\nCritical: If issues are discovered, researchers should share this information with the team hosting the data, so fixes can be put into place.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1340-Fig2.jpg\nFigure 2. Steps to download data from OpenNeuro\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1340-Fig3.jpg\nFigure 3. BIDS format",
    "(A) Each participant has folders containing raw anatomical and functional data.\n(B) Data generated during the course of the study are stored in a derivatives folder.\nGet to know data, begin analyses\nTiming: 1 month to 1 year\nGetting to know your dataset is crucial, especially as a user who did not participate in data collection.\nInvestigate how many subjects have the data of interest.\nMissing imaging and behavioral data can affect analyses and should be investigated to arrive at a final sample ready for analysis.\nIf data are missing, determine how this will affect analyses.\nThere are multiple ways to handle missing data (i.e., listwise deletion, pairwise deletion, imputation) (Kang, 2013[href=https://www.wicell.org#bib26]).\nResearchers may want to consult a statistician for assistance, given the complexity of missing data.\nIn terms of the imaging data, some participants may have incomplete scans, some may be missing scans, and some may have repeated scans.\nA full discussion of imaging QC is outside the scope of this protocol, but we note that automated QC tools exist to aid users (https://mriqc.readthedocs.io/en/stable/[href=https://mriqc.readthedocs.io/en/stable/]) (Esteban et al., 2017[href=https://www.wicell.org#bib14]).\nIn addition, if QC info is made available by the data collection team (or other labs), researchers could use this information about which subjects to exclude.\nFor the behavioral data, the same steps should be completed: determine if all demographic/behavioral/clinical data is available, reasons data might be missing, or if the desired versions of behavioral indices were used.\nIf raw data are available, it might also be advisable to determine if scores were computed correctly.\nDetermine if aspects of study design will affect analyses\nFor example, the scans in the young adult HCP (Van Essen et al., 2013[href=https://www.wicell.org#bib47]) study were collected on back-to-back days.",
    "In the Philadelphia Neurodevelopmental Cohort (PNC) (Satterthwaite et al., 2014[href=https://www.wicell.org#bib40]), all scans were collected on the same day.\nIn addition, similar tasks (i.e., a working memory task) can differ substantially across datasets.\nThese differences can impact analyses within samples and can also affect analyses if one is planning to use certain datasets as test samples (i.e., to determine if an effect observed in one sample is also observed in another, independent sample; see ‘expected outcomes[href=https://www.wicell.org#expected-outcomes]’ for more about using multiple samples to assess generalizability).\nAlso investigate scanner type, software, and acquisition sequences.\nDetermine if these parameters are consistent across participants or if any of these parameters were updated in between data releases.\nImaging task-data can contain errors impacting analyses.\nIf block order in a task is counterbalanced, ensure it is consistent across all participants.\nFor example, approximately 30 subjects in the S900 release in the young adult HCP sample have a different block order in the working memory task than is reported for most participants (Horien et al., 2021[href=https://www.wicell.org#bib23]).\nInvestigate task timing; task regressors can fail to match overall task duration (as is the case for some subjects in the emotion task in the young adult HCP sample; http://protocols.humanconnectome.org/HCP/3T/task-fMRI-protocol-details.html[href=http://protocols.humanconnectome.org/HCP/3T/task-fMRI-protocol-details.html]).\nTask stimuli may occasionally be missed or presented for different durations (as is the case for the stop-signal task in ABCD) (Bissett et al., 2021[href=https://www.wicell.org#bib5]).\nCritical: Issues like these may or may not be reported with the data release. Block order and task timing are only a few examples of issues to be aware of; it is crucial to determine if other issues are present in the data.\nAfter obtaining the final sample for analysis, perform basic steps to get to know the data.\nFirst investigate basic demographics, like age, sex, and handedness.\nFamily structure should also be considered.",
    "The young adult HCP sample and the ABCD sample consists of many twins and siblings; these should be accounted for when working with the data (e.g., (Winkler et al., 2015[href=https://www.wicell.org#bib48])).\nCritical: These basic steps are essential. Because they are somewhat obvious, however, they are often overlooked. After performing QC and excluding subjects, distributions of basic demographic variables can be skewed, and this can negatively impact analyses.\nSome open samples contain many contributing sites (e.g., ABIDE I/II (Di Martino et al., 2017[href=https://www.wicell.org#bib11]; Di Martino et al., 2014[href=https://www.wicell.org#bib12]), ABCD (Casey et al., 2018[href=https://www.wicell.org#bib9]), UK-Biobank (Miller et al., 2016[href=https://www.wicell.org#bib31])); determine if sites differ in systematic ways that will affect analyses (see ‘troubleshooting[href=https://www.wicell.org#troubleshooting]’ section below for what to do when confounds are present in the data).\nIf available, also investigate what time of day participants were scanned (Orban et al., 2020[href=https://www.wicell.org#bib34]; Trefler et al., 2016[href=https://www.wicell.org#bib46]), what time of year, smoking status, etc. In larger samples, these factors could amplify uninteresting sources of variance in datasets and act as confounds.\nThe following site contains examples of basic visualizations that can be performed to get to know a dataset, along with R packages and toy data (http://uc-r.github.io/gda[href=http://uc-r.github.io/gda]).\nInvestigate behavioral measures.\nParticipant measures beyond basic demographic information should be examined prior to use (i.e., performance on cognitive tests, self-report measures, clinician assessments)\nA good place to start is to determine if data were collected in a similar manner across participants. Measures within a dataset might differ, particularly in multi-site data.\nFor instance, in ABIDE, sites used different versions of the Autism Diagnostic Observation Schedule (ADOS), and only some sites had research-certified clinicians administer ADOS.\nIssues like these can impact other behavioral metrics.\nBehavioral data can also be released as summary scores for a measure, standardized scores, subscale-specific scores, etc.",
    "Ensure you are using the behavioral score you intended to use.\nConduct analyses.\nThinking carefully about reproducible inference is key when using open samples.\nParticularly with larger samples, small correlations that might bear little practical importance can become statistically significant.\nIt is therefore useful to define what effect size would be meaningful for this particular study before beginning analyses.\nReporting multiple lines of converging evidence can increase confidence that a given result is replicable.\nUsing multiple open-source samples in a given study is one way to test if results are convergent (see ‘expected outcomes[href=https://www.wicell.org#expected-outcomes]’ for examples of using multiple open samples in a study).\nNegative results should be reported.\nThe literature as a whole can be skewed by not doing so (Easterbrook et al., 1991[href=https://www.wicell.org#bib13]; Rosenthal, 1979[href=https://www.wicell.org#bib39]).\nOther labs may be planning similar analyses, so the reporting of negative results could ensure duplicate efforts are not being conducted.\nInvestigators might be tempted to cherry-pick positive findings within their sample or search for a sample that gives positive results (both examples of “p-hacking”; see ‘troubleshooting[href=https://www.wicell.org#troubleshooting]’ for tips on ways to reduce the inclination to p-hack).\nSee (Smith and Nichols, 2018[href=https://www.wicell.org#bib42]) for more on statistical issues that might be encountered when working with large, open-source datasets.\nShare code, materials, and results\nTiming: 1–6 months\nTo contribute to the open-science ecosystem, investigators should openly share code, materials, and results.\nProcessing and analysis code should be shared.\nCode can be shared while the project is ongoing or when a paper is submitted/published.\nGitHub is a popular option for sharing code (https://github.com/[href=https://github.com/]).\nGitHub Guides is a helpful resource for getting started (https://guides.github.com/[href=https://guides.github.com/]).\nAdditionally, adopting the standards used by popular open-source projects can be helpful (https://github.com/scikit-learn/scikit-learn[href=https://github.com/scikit-learn/scikit-learn]).",
    "Code should be well-documented and well-organized. Ideally, code should also be bug-free and efficient (in terms of time to run and overall structure).\nIncluding readme files, adding comments to code, and fixing any bugs that are discovered by other users is good practice.\nSee https://code.tutsplus.com/tutorials/top-15-best-practices-for-writing-super-readable-code--net-8118[href=https://code.tutsplus.com/tutorials/top-15-best-practices-for-writing-super-readable-code--net-8118] for more recommendations for structuring code.\nNote: While ideally code will be well-documented and polished, it does not have to be perfect to share.\nShare materials generated from working with the sample.\nThere are many repositories to share materials (Table 1[href=https://www.wicell.org#tbl1]).\ntable:files/protocols_protocol_1340_1.csv\nTable adapted with permission from (Horien et al., 2021[href=https://www.wicell.org#bib23]).\nPreprocessed data (i.e., skull-stripped anatomical images, motion-corrected functional data) can be shared.\nDerived, statistical data (i.e., parametric brain maps, parcellations) can also be shared.\nData should be shared with a clear license so that other researchers know what usage restrictions accompany reuse of the data (if any).\nSee https://creativecommons.org/about/cclicenses/[href=https://creativecommons.org/about/cclicenses/] for more about Creative Commons licenses.\nCritical: Before sharing materials, researchers should check their DUA to determine what can be shared. Some datasets (for example, those obtained through the Consortium for Reliability and Reproducibility; Figure 1[href=https://www.wicell.org#fig1]) allow materials to be shared openly, whereas others are more restrictive and do not permit the sharing of materials. Investigators should also consult with their IRB/HIC to determine if participants consented to data sharing when they took part in the original study.\nResults can be shared via preprint servers\nThese services are free and allow the dissemination of results prior to publication.\nDifferent preprint servers exist and can be used depending on the nature of a study\nbioRxiv (https://www.biorxiv.org/[href=https://www.biorxiv.org/]) can be used to share papers in the life sciences (i.e., neurotypical participants are studied).\nmedRxiv (https://www.medrxiv.org/[href=https://www.medrxiv.org/]) can be used to share papers in the medical sciences (i.e., patients are studied).\nPsyArXiv (https://psyarxiv.com/[href=https://psyarxiv.com/]) hosts papers in the psychological sciences.",
    "Other preprint servers (arXiv: https://arxiv.org/[href=https://arxiv.org/] and OSF Preprints: https://osf.io/preprints/[href=https://osf.io/preprints/]) are available for posting preprints as well.\nUpon manuscript acceptance, many journals have an open-access option (for a fee).\nFunding agencies also may require posting papers to publicly available servers (e.g., PubMed).\nWhen writing up results, consult the Committee on Best Practices in Data Analysis and Sharing (COBIDAS) (Nichols et al., 2017[href=https://www.wicell.org#bib32]) guidelines about what to include in a manuscript.\nCOBIDAS includes ‘mandatory’ and ‘not mandatory’ recommendations.\nThe full list of mandatory recommendations is outside the scope of this paper but can be viewed here: http://www.humanbrainmapping.org/files/2016/COBIDASreport.pdf[href=http://www.humanbrainmapping.org/files/2016/COBIDASreport.pdf]\nSpecial considerations about what to report for open datasets include participant IDs, the data release used, the date the data were accessed, and the URL from where the data were obtained.\nStandards regarding participant IDs can differ across datasets.\nFor example, ABIDE participant IDs are the same for all researchers across downloads.\nFor UK-Biobank, unique participant IDs are generated for each group working with the data.\nPrior to sharing participant IDs, researchers should determine if this is allowed in their DUA.\nIf no official data release is available, researchers should include as much information about the data as possible, as well as where the data were obtained.\nIf data are released in a continuous fashion (i.e., the ABCD Fast Track data releases new imaging data monthly), reporting the date the data were downloaded can be helpful.\nWhen working with open samples, some of the details of the dataset being used may have been reported in previous papers, so it might be sufficient to include a reference to these original studies.\nNevertheless, providing a concise summary of critical details is still advised.",
    "For example, providing a summary of imaging acquisition parameters, the preprocessing pipeline, and behavioral measures should be included, along with a description of how the data were used and analyzed."
  ],
  "subjectAreas": [
    "Bioinformatics",
    "Neuroscience",
    "Behavior",
    "Cognitive Neuroscience"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research",
    "Ecology & Environmental Biology",
    "Bioinformatics & Computational Biology"
  ]
}