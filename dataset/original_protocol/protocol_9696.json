{
  "id": 10107,
  "origin_website": "Jove",
  "title": "Quantifying Cytoskeleton Dynamics Using Differential Dynamic Microscopy",
  "procedures": [
    "NOTE: A Jupyter Notebook file containing the code to go along with each step in the following protocol can be found on the following GitHub repository, https://github.com/rmcgorty/PyDDM/tree/main/Examples. A PDF of that file is included in Supplementary File 1. Additionally, a walkthrough of the code and documentation of each function and class can be found on the website, https://rmcgorty.github.io/PyDDM/.\n1. Software installation\nTo follow along with the example DDM analysis files, install Jupyter Notebook for running the code. Install other required common Python packages, including NumPy and Matplotlib as well. These packages all come bundled with the Anaconda distribution (see https://www.anaconda.com/products/individual). \nInstall the Python package xarray63. This package is necessary for organizing and storing metadata and analysis parameters. If using the Anaconda distribution, install xarray (along with its recommended dependencies) using the command:\nconda install -c conda-forge xarray dask netCDF4 bottleneck\nInstall the PyYAML package using the command:\nconda install -c anaconda yaml\n\tThis package is necessary for reading metadata about the images to analyze and the parameters set by the user for analysis and fitting.\nInstall the PyDDM package, by downloading from the GitHub repository or using the git command:\ngit clone https://github.com/rmcgorty/PyDDM.git\n2. Planning the imaging sessions\nChoose the optimal available imaging modality and optical settings. As mentioned, DDM can be used with a number of microscopy methods.",
    "To assist in planning the appropriate objective lens and image size to use, determine the range of wavenumbers, q, that will be probed based on the pixel size and total image size. Confirm that the choice of magnification and field of view are optimal for the experiment, based on these calculations. For the images analyzed here, a 60x 1.4 NA objective and an image size of 256 x 256 pixels with a pixel size of 0.83 µm were used for the active actin-microtubule composite network. For the images of beads embedded in a vimentin network, a 100x 1.4 NA objective and an image size of 512 x 512 pixels with a pixel size of 0.13 µm were used.\n\tNOTE: The minimum q is set by 2π/NΔx, where the image size (assumed to be square) is N × N pixels with a pixel size of Δx. The maximum q is the minimum of π/Δx and 2π NA/λ, where NA is the imaging objective's numerical aperture, and λ is the wavelength of light (for brightfield imaging, one can replace NA with (NAobjective + NAcondenser)/2).\nNext, consider the range of timescales to investigate. Typically, DDM analysis is done on sequences of at least 1000 frames.\n\t\nTo determine the appropriate frame rate, consider the expected time it will take for features in the sample to move a distance on the order of the minimum resolvable length scale (corresponding to the maximum q).\nIn considering the upper limit of the range of timescales probed, recognize that, typically, the power spectrum of hundreds of image differences of a given lag time Δt are averaged together to provide sufficient statistics to reduce noise. Hence, acquire image sequences longer than the maximum timescale probed.",
    "​NOTE: If an expected diffusion coefficient, D, or velocity, v, is known, then one can estimate expected characteristic decay times using τ = 1/Dq2 or τ = 1/vq along with the range of q, which was determined based on the field of view and pixel size. The range of expected τ values over the accessible q-range can help guide the choice of frame rate and the number of frames to acquire.\n3. Sample preparation and image acquisition\nNOTE: For details of the sample preparation and imaging settings used for the data presented in the representative results section, see previous publications from the authors11,51,64 and Supplementary File 2.\nBased on the consideration of the time and length scales to probe, acquire image sequences of, ideally, over 1000 frames.\n\tNOTE: The code will analyze square images or square regions of interest within the image, so adjust the frame size accordingly.\nSave image sequences as a three-dimensional greyscale TIFF stack. Alternatively, the format used by Nikon Instruments systems, ND2 format, can be read by the installed package. If images are saved in some different format, use ImageJ or another imaging processing program to convert the images to a TIFF stack.\n\t​NOTE: If using ND2 files, the package nd2reader from https://github.com/Open-Science-Tools/nd2reader must be installed.\n4. Parameter setup\nMake a copy of the parameter file example_parameter_file.yml provided in the PyDDM code repository under the examples folder. Open this YAML file with a text editor like NotePad++ or the text editor in JupyterLab. See Supplementary File 2 for an example YAML parameters file used in the analysis of data presented in the representative results section.\nIn the copied YAML file, provide the data directory and file name corresponding to the image sequence to be analyzed. Under the metadata section, provide the pixel size and frame rate.",
    "Under the Analysis_parameters section, provide details for how the DDM matrix should be calculated. Some parameters here are optional.\n\t\nAt a minimum, provide values for the parameters number_lag_times and last_lag_time. These correspond to the number of different lag times for which to calculate the DDM matrix and the longest lag time (in frames) to use, respectively. For the data of tracer beads in vimentin networks used here, the parameters number_lag_times and last_lag_time were 60 and 1000, respectively. The code will compute the DDM matrix for lag times from 1 frame (or some other minimum lag time if the optional parameter first_lag_time is specified) to the last_lag_time with logarithmic spacing.\n\t\tNOTE: If M frames were acquired, one could calculate the DDM matrix for a lag time as large as M-1. However, with poor statistics at such a large lag time, the data is likely to be noisy. The longest lag time for which to calculate the DDM matrix will depend on the details of the data, but we suggest trying around one-third of the total image series duration.\nProvide details for how the DDM matrix or the intermediate scattering function (ISF) should be fit in the Fitting_parameters section. Give the name of the model under the model parameter. Provide the initial guess, lower bound, and upper bound for each of the fitting parameters in the chosen model.\n\t​NOTE: To display a list of the possible fitting models, run the function print_fitting_models. The models can also be found in the online documentation on the PyDDM website.\n5. Calculating the DDM matrix",
    "Initialize an instance of the DDM_Analysis class. To do so, provide the metadata and analysis parameters discussed above by passing the filename, with the full file path included, of the YAML file to DDM_Analysis. Alternatively, pass the metadata and parameters as a Python dictionary data structure.\nRun the function calculate_DDM_matrix to calculate the DDM matrix. This calculation may take several minutes or longer depending on the frame size and the number of lag times. See Figure 2 for typical run times.\nInspect the returned data, which will be in a data structure from the xarray package known as a Dataset. This data structure is stored under the attribute ddm_dataset.\n\tNOTE: Not only the DDM matrix but also associated variables and metadata will be stored in this data structure. It will also be saved to disk in a Network Common Data Form (netCDF) format.\nInspect the plots and figures, which will be generated and displayed. These figures are also saved as a PDF file in the data directory.\n\t\nSee that one of the generated plots shows the ensemble-averaged squared modulus of the Fourier-transformed images, imgsrc://cloudfront.jove.com/files/ftp_upload/63931/63931eq031.png as a function of q. By default, the code uses this to estimate the background parameter B. Estimate the background from imgsrc://cloudfront.jove.com/files/ftp_upload/63931/63931eq031.png by assuming that, in the limit of large q, it will approach B/2, where B is the background.\nIf imgsrc://cloudfront.jove.com/files/ftp_upload/63931/63931eq031.png is not reaching a plateau at large q, then use another method for estimating B. To accomplish this, set the parameter background_method in either the YAML file or as an optional keyword argument to the function calculate_DDM_matrix. More details about the methods for estimating B are presented in the representative results section.\nimgsrc://cloudfront.jove.com/files/ftp_upload/63931/63931fig2v2.jpg",
    "Figure 2: Computation time for calculating the DDM matrix. In (A) and (B) the time for calculating the DDM matrix, imgsrc://cloudfront.jove.com/files/ftp_upload/63931/63931eq009.png, is shown. The data used in all cases is a movie of 5000 frames with an image size of 512 x 512 pixels. The DDM matrix was calculated for 30 lag times, logarithmically spaced between 1 frame (0.01 s) and 1000 frames (10 s). The code was run on an Intel i7-10700 2.90 GHz desktop computer with 32 GB RAM. In (A), the effect of varying how many image differences are used in computing the DDM matrix for each lag time is shown. For this, the images are binned to result in an image size of 256 x 256. For each lag time Δt, images separated by that Δt are subtracted and the resulting matrix is Fourier transformed. For a given Δt, all pairs of images separated by that Δt can be used (shown in blue), only non-overlapping image pairs can be used (e.g., frames 1 and 10, 10 and 19, etc.; shown in brown), or 300 image pairs or fewer can be used for each Δt. In (B), the effect of changing the image size on the computation time is shown. The images were binned either by grouping 2 x 2, 4 x 4, or 8 x 8 pixels, resulting in image sizes of 256 x 256, 128 x 128, or 64 x 64, respectively. For each, about 300 image pairs are used in computing the DDM matrix for each Δt. (C) From the DDM matrix, the intermediate scattering function (ISF) can be extracted. This is shown for the three cases in (A).",
    "The blue data points (with no offset) correspond to the ISF when the maximum number of image pairs are used for each Δt; the brown data points (with an offset of 0.1) correspond to the ISF when non-overlapping image pairs are used for each Δt; and the pink data points (with an offset of 0.2) correspond to the ISF when at most 300 image pairs are used for each Δt. The ISF found using non-overlapping image pairs shows noisiness at long Δt. For that case, few image pairs are used at long Δt (e.g., for Δt of 1000 frames, only 4 image pairs are used). (D) By fitting the ISF to an exponential function, the characteristic decay time, τ, for each wavenumber, q, is determined. In pink, results are shown after binning the original images by 2 x 2, resulting in an image size of 256 x 256. In gray, results are shown after binning by 8 x 8, resulting in an image size of 64 x 64. By binning the data, information about the dynamics at higher wavenumbers is lost, but calculating the DDM matrix for the 64 x 64 images is about 16x faster than for the 256 x 256 images. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/63931/63931fig2v2large.jpg]",
    "6. Fitting the DDM matrix or the ISF\nInitialize an instance of the DDM_Fit class. To do so, pass to DDM_Fit the filename of the YAML file containing the image metadata and parameters for fitting.\nDecide which model for the DDM matrix or the ISF to use for fitting the data. List the available models by executing the function print_fitting_models. Specify the model to be used in the YAML parameter file or by using the function reload_fit_model_by_name.\nSet the initial guesses and bounds for each parameter in the chosen model in the provided YAML parameter file. To change the initial guess for any parameter, use the function set_parameter_initial_guess. Set bounds for the parameters with the function set_parameter_bounds. For example, as seen in Supplementary File 2, for the data of tracer beads in the vimentin network, the initial guess for the decay time was 1 s and the bounds on that parameter were 0.01 s and 2000 s.\nExecute the fit with the function fit. Assign a variable to the output of this function to easily access the results.\n\t​NOTE: This function can take many optional arguments. See the code documentation and provided examples for a list of such arguments and when to consider setting them to non-default values.\n7. Interpreting the fit results\nGenerate plots for inspecting the fits and the q-dependence of the fit parameters with the function fit_report.\n\tNOTE: This function will generate a series of plots, which will also be saved as a PDF. Optional arguments to this function can be used to modify the plots produced.",
    "Among the generated plots will be a figure with 2 x 2 subplots showing the DDM matrix or ISF (depending on the chosen fitting model) at four q-values (specified as an optional argument to fit_report), along with the calculated DDM matrix or ISF using the model and best fit parameters. To plot the DDM matrix or ISF along with the best fit in an interactive way, use the class Browse_DDM_Fits as shown in the provided examples when the Jupyter Notebook environment is used.\nFrom the plot of the characteristic decay time τ vs. the wavenumber q, determine whether the dynamics follow diffusive, subdiffusive, ballistic, or some other type of motion. This can be done by looking for the power law relationship between τ and q.\n\t​NOTE: On the log-log plot of τ vs. q generated by the function fit_report, three lines will be shown, corresponding to power law fits over a specified range of q values. The solid black line corresponds to fitting τ vs. q to a power law, τ = 1 / Kqβ, where K and β are free parameters. The dashed line in orange corresponds to fitting to simple diffusion, τ = 1 / Dq2, where D is a diffusion coefficient. The dot-dashed line in blue corresponds to fitting to τ = 1 / vq, where v is a velocity.\n8. Saving the results\nThe results of the fit will be saved in a xarray dataset. Use the xarray function to_netcdf or Python's built-in pickle module to save this data structure to disk. Use the xarray function open_dataset to load these netCDF files.\nUse the function save_fit_results_to_excel to save the fit results, along with the data, to a worksheet file."
  ],
  "subjectAreas": [
    "Bioengineering"
  ],
  "bigAreas": [
    "Bioengineering & Technology"
  ]
}