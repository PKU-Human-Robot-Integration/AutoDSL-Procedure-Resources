{
  "id": 1887,
  "origin_website": "Cell",
  "title": "Protocol for integrative subtyping of lower-grade gliomas using the SUMO pipeline",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nA typical workflow to subtype a cohort using SUMO requires four steps, and each of the steps corresponds to a `mode` in SUMO. The first step in the analysis is the construction of patient-similarity networks from the pre-processed feature matrices (sumo prepare). Next, the multiplex similarity network is jointly factorized to identify the molecular subtypes (sumo run). We can then assess the importance of each feature (e.g., genes and methylation probes) in driving each of the identified subtypes (sumo interpret). If another set of labels for the same patients is known, for example, based on the International Statistical Classification of Diseases and Related Health Problems (ICD), then we can compare the labels assigned by SUMO to those labels using several external evaluation metrics including purity, normalized mutual information (NMI), and adjusted Rand index (ARI) (sumo evaluate).\nStep 1: Package installation\nTiming: 1 min\nThe SUMO command-line tool can be installed from the Python Packaging Index (PyPI), by executing the command below. Note that SUMO requires a Python 3.6+ version and corresponding pip (package installer), distributed together with Python. Here, we refer to pip as pip3 to avoid confusion with the default Python 2 specific version of pip.\nUpgrade pip3 (to a >19.0 version) and the setuptools package:\npip3 install --upgrade pip setuptools\nInstall SUMO, by running the following command-line command:\npip3 install python-sumo\nStep 2: Data preparation\nTiming: 9 min",
    "See before you begin[href=https://www.wicell.org#before-you-begin] for an explanation of data pre-processing steps. In this protocol, the gene expression and miRNA expression feature matrices downloaded from XENA have already been log-normalized to remove the dependence of the variance on the mean of the counts. So, we omit the data transformation step in the vignette below. Here, we use R to pre-process the dataset (see SUMO documentation for examples of pre-processing scripts in python). In this protocol, we assume that the user has set their working directory to the directory with the files downloaded from Xena (See the key resources table[href=https://www.wicell.org#key-resources-table]). The working directory can be set by using the ‘setwd’ command in R.\nInstall and load the required R packages:\n>install.packages(c(\"devtools\", \"tidyverse\",\n          \"reticulate\", \"survival\", \"survminer\"))\n>devtools::install_github(\"stephenturner/annotables@v0.1.90\")\n>library(annotables)\n>library(tidyverse)\nPre-processing of miRNA expression data:\nLoad the data:\n>data <-\nread.table(\"TCGA.LGG.sampleMap%2FmiRNA_HiSeq_gene.gz\",\nrow.names = 1, header = TRUE, check.names = FALSE)\nSUMO calculates the distance between each pair of samples using the normalized counts assigned to the miRNAs. Since we are typically dealing with high-dimensional datasets, we filter out features with several missing values. Here, we remove features with more than 10 % missing values:\n>data <- data[rowSums(is.na(data)) <=\nround(dim(data)[2]∗0.1),]\nScale the features to have zero-mean and unit variance. Also, remove the features with zero standard deviation:\n>normalize.matrix <- function(data.matrix) {\nnum = data.matrix - rowMeans(data.matrix,\n  na.rm = TRUE)\nshould.keep = (apply(num, 1, function(x) sd(x,\n      na.rm=TRUE)) != 0)\nreturn ((num / apply(num, 1, function(x) sd(x,\nna.rm=TRUE)))[should.keep,])\n}\n>data.norm <- normalize.matrix(data)\nWrite the data matrix into a tab-delimited file:\n>write.table(data.norm, file=\"TCGA.LGG.miRNAexp.tsv\",\nsep=\"\\t\", col.names = TRUE, row.names = TRUE)\nPre-processing of gene expression data:\nLoad the data:\n>data <- read.table(\"TCGA.LGG.sampleMap%2FHiSeqV2.gz\",\nrow.names = 1, header = TRUE, check.names = FALSE)",
    "Filter out non-informative features and features with several missing values. Here, we remove features with more than 10 % missing values and features where less than two samples have FPKM over zero:\n>data <- data[rowSums(is.na(data)) <=\n      round(dim(data)[2]∗0.1),]\n>data <- data[rowSums(data > 1) > 1,]\n(optional) Limit the feature matrix to protein-coding genes:\n>protein_coding <- tibble(symbol=rownames(data)) %>%\n    left_join(grch38, by = \"symbol\") %>%\n    select(symbol, biotype) %>%\n    filter(biotype == \"protein_coding\") %>% pull(symbol) %>% unique()\n>data <- data[rownames(data) %in% protein_coding,]\nScale the features to have zero-mean and unit variance:\n>data.norm <- normalize.matrix(data)\nWrite the data matrix into a tab-delimited file:\n>write.table(data.norm, file=\"TCGA.LGG.mRNAexp.tsv\",\nsep=\"\\t\", col.names = TRUE, row.names = TRUE)\nPre-processing of methylation data:\nLoad the data:\n>data <-\nread.table(\"TCGA.LGG.sampleMap%2FHumanMethylation450.gz\",\nrow.names = 1, header = TRUE, check.names = FALSE)\nFilter out features with several missing values. Here, we remove features with more than 10 % missing values:\n>data <- data[rowSums(is.na(data)) <=\nround(dim(data)[2]∗0.1),]\nConvert the beta values to corresponding M values, as M values have reduced heteroscedasticity in the low and high methylation range (Du et al., 2010[href=https://www.wicell.org#bib4]):\n>dataM <- log2(data + .Machine$double.eps)/(1 - data +\n.Machine$double.eps)\nScale the features to have zero-mean and unit variance. Also, remove the features with zero standard deviation:\n>dataM.norm <- normalize.matrix(dataM)\nWrite the data matrix into a tab-delimited file:\n>write.table(dataM.norm, file=\"TCGA.LGG.met.tsv\",\nsep=\"\\t\", col.names = TRUE, row.names = TRUE)\nStep 3: Creating similarity networks\nTiming: 11 min\nIn this step, each of the pre-processed feature matrices is used to calculate data-type-specific distances between the samples. Next, the distances are converted to similarities between samples. Each similarity matrix corresponding to a different data type is then used as an adjacency matrix to construct a “layer” of a multiplex similarity network (see (Sienkiewicz et al., 2020) for more details about the method).",
    "Note: We assume that SUMO is run in the directory with the pre-processed files.\nUse the following command to run SUMO on the pre-processed files:\nsumo prepare\nTCGA.LGG.mRNAexp.tsv,TCGA.LGG.met.tsv,TCGA.LGG.miRNAexp.tsv\nprepared.LGG.npz\nThe required positional arguments of SUMO are:\n“prepare” - selected sumo `mode` which uses the pre-processed feature matrices to construct the similarity networks,\n“infile1,infile2,…” - comma-delimited list of files containing standardized feature matrices, with samples in columns and features in rows (here: TCGA.LGG.mRNAexp.tsv,TCGA.LGG.met.tsv,TCGA.LGG.miRNAexp.tsv),\n“outfile.npz” - path to the output file in .npz format, which is a zipped archive of files named after the variable they contain (here: prepared.LGG.npz).\nSome of the optional arguments for SUMO in `prepare` mode include:\n“-atol” - SUMO checks if the data was standardized by assessing the mean and standard deviation of each feature. This parameter allows the user to specify an allowed tolerance level in this test. In this protocol, we increase it to include the sparse miRNA expression matrix, with a smaller number of features (see Troubleshooting problem 1[href=https://www.wicell.org#sec6.1] for more details).\n“-method” – distance to be used in calculation of sample-sample similarity (here we use the default Euclidean distance, which is appropriate for log-normalized counts and M-values used in methylation data),\n“-k” and “-alpha” – hyperparameters that affect the distribution of values in the similarity matrix (see (Sienkiewicz et al., 2020) for more details),\n“-log” and “-logfile” - arguments governing the logging level and the optional path to save the logging file,\n“-plot” - path to save the heatmaps that show the similarity matrix for each data type (the default behavior is to display these plots in an interactive mode on the screen).\nThe above command creates a multiplex network file in form of a zipped NumPy archive containing:",
    "the pairwise sample similarity matrices organized as network adjacency matrices in order of input files (arrays indexed: “0”, “1”, “2”),\ninput feature matrices, after additional internal sumo filtering (arrays indexed: “f0”, “f1”, “f2”),\nan organized list of sample identifiers in the order corresponding to rows/columns of adjacency matrices (the “sample” array).\nStep 4: Detecting molecular subtypes\nTiming: 37 min\nThe goal of this step is to determine the molecular subtypes in the cohort using the sample similarities encoded in the three data types. SUMO performs a joint non-negative matrix tri-factorization of the similarity networks to determine a representation of the samples in a lower rank subspace, which is then used to assign class labels. The factorization is performed several times on various subsets of samples, and SUMO uses consensus clustering to determine the final labels. Non-negative factorization assumes that a single basis vector can represent each cluster and different clusters correspond to different basis vectors. This makes estimating the optimal factorization rank (equivalent to the number of clusters in the dataset) a challenging problem. We recommend running SUMO on a range of possible values and utilizing clustering metrics calculated by SUMO to select the optimal number, as detailed below.\nUse the following command to run SUMO on the output from the last step:\nsumo run prepared.LGG.npz 2,10 LGG\nThe required positional arguments of SUMO are:\n“run” - selected sumo `mode` to subtype samples,\n“infile.npz” - output .npz file from the last step,\n“k” - either one value when the number of clusters is known or a comma-delimited range of values to run SUMO on a range of possible values for the number of clusters (here: 2,10 which will run SUMO for 2, 3, 4, …, 10 clusters),\n“outdir” - path to the output directory (here: “LGG”).",
    "Some of the optional arguments in this mode include:\n“-log” and “-logfile” - arguments governing the logging level and optional path to save the logging file (using “-log DEBUG” flag results in saving additional arrays in the output files),\n“-max_iter“ and “-tol” - parameters governing the stopping criterion for the factorization: the maximum number of steps that should be taken by the solver in an attempt to minimize the cost function, and the minimum difference in the costs determined in consecutive steps before stopping,\n“-sparsity” - either one value or comma-delimited list of sparsity penalty (“ɳ”/”eta”) values (if multiple values are specified, SUMO runs factorization with different values and automatically select the best, by assessing within-cluster similarities; see (Sienkiewicz et al., 2020) for more details),\n“-t” number of computational threads.\nThe output directory includes a sub-directory with the cluster assignments and information for each “k” (see Figure 1[href=https://www.wicell.org#fig1]A). Every sub-directory contains:\na .log file and a .npz file with factorization results for each “eta” value,\n“sumo_results.npz” - a hyperlink to factorization result corresponding to the best “eta”,\n“clusters.tsv” - a file with the assigned sample labels. Additionally, SUMO creates a sub-directory “plots” with several plots that can assist in the selection of the optimal number of subtypes in the dataset.\nEach .npz file with the factorization results for given (“k”, “eta”) pair contains:\ntwo internal metrics, namely the proportion of ambiguously clustered pairs (PAC) (Şenbabaoğlu et al., 2014[href=https://www.wicell.org#bib10]) and cophenetic correlation coefficient (Hutchins et al., 2008[href=https://www.wicell.org#bib5]). Each metric is calculated multiple times on subsets of samples and the results are saved in the “pac” and “cophenet” arrays,\nquality metric assessing the within-cluster similarities of final sample groups (“quality” array), used for sparsity parameter selection,",
    "consensus matrix resulting from running the factorization multiple times on subsets of samples (“unfiltered_consensus” array) and its filtered copy used for assignment of final sample labels (“consensus” array)\nSelect the optimal number of clusters/factorization rank.\n(recommended) Inspect the “cophenet.png” and “pac.png” files in created “LGG/plots” sub-directory. The created plots show the distribution of two popular clustering metrics: the cophenetic correlation coefficient (CCC) and the proportion of ambiguously clustered pairs (PAC). We recommend selecting the factorization rank for which the CCC is high (over 0.95) and PAC score is less than 0.1.\n(extended) Use the following commands to plot both ranks together in R (see Figure 1[href=https://www.wicell.org#fig1]B):\nload required R packages:\n>library(tidyverse)\n>library(reticulate)\niterate through the sub-directories of “LGG” and read the PAC and CCC values. SUMO utilizes a re-sampling approach, there are multiple values for each clustering rank “k”, crated by calculating metrics on subsets of samples in consensus matrix:\n>np <- import(\"numpy\")\n>sumo_run_dir <- \"LGG\"\n>dir_names <- dir(sumo_run_dir)[grepl(\"ˆk[0-9]\",\n          dir(sumo_run_dir))]\n>pac_tbl <- sapply(dir_names, function(x)\n      np$load(file.path(sumo_run_dir, x,\n      \"sumo_results.npz\"),\n      allow_pickle = TRUE)$f['pac']) %>%\n  as_tibble() %>%\n  mutate(rep = row_number()) %>%\n  gather(\"dir_name\", \"PAC\", -rep)\n>ccc_tbl <- sapply(dir_names, function(x)\n  np$load(file.path(sumo_run_dir, x,\n  \"sumo_results.npz\"),\n  allow_pickle = TRUE)$f['cophenet']) %>%\n  as_tibble() %>%\n  mutate(rep = row_number()) %>%\n  gather(\"dir_name\", \"CCC\", -rep)\ncalculate median, minimum, and maximum for the two metrics corresponding to each clustering rank:\n>metric_tbl <- ccc_tbl %>%\n      left_join(pac_tbl,\n        by = c(\"rep\", \"dir_name\")) %>%\n      separate(dir_name, c(NA, 'k'),\n            sep=\"k\") %>%\n  mutate(k=as.factor(as.numeric(k))) %>%\n  gather(metric, value, -k, -rep) %>%\n  group_by(metric, k) %>%\n  summarise(median_value=median(value),\n      min_value=min(value),\n      max_value=max(value))\nplot the metrics together:\n>metric_tbl %>%\nggplot() +\n    geom_line(aes(x=k, y=median_value,\n    color=metric, group=metric), size=1) +\n    geom_ribbon(aes(x=k, ymin=min_value,\n    ymax=max_value, group=metric, fill=metric),\n    alpha=0.3) +\n    theme_bw() +\n    labs(y=\"metric value\") +\n    theme(legend.position = \"bottom\")\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1367-Fig1.jpg\nFigure 1. Output of `sumo run`\n(A) The structure of the output directory generated in Step 4 of the protocol.",
    "(B) Two internal clustering stability metrics calculated by SUMO: proportion of ambiguously clustered pairs (PAC) and cophenetic correlation coefficient (CCC). The optimal cluster rank is characterized by a low PAC value and a high CCC value.\nStep 5: Identifying potential biomarkers\nTiming: 13 h 30 min\nIn this step, we identify the features that are predictive of the subtypes determined in the last step. These features are potential biomarkers that can be used to assign new samples to the determined subtypes. We train a tree-based LightGBM model (Ke et al., 2017[href=https://www.wicell.org#bib8]) using the feature matrices and the assigned labels from the last step, though this sort of feature importance can be determined using other approaches such as support vector machines. We then calculate the Shapley values (Lundberg and Lee, 2017[href=https://www.wicell.org#bib9]) for each feature in the resulting model. The Shapley value is the average marginal contribution of a feature, and the features with Shapley values greater than one are considered to be important in driving the separation of that cluster.\nUse following command to run SUMO in the `interpret` mode:\nsumo interpret LGG/k5/sumo_results.npz\nTCGA.LGG.mRNAexp.tsv,TCGA.LGG.met.tsv,TCGA.LGG.miRNAexp.tsv\nLGG_interpret_k5\nThe required positional arguments of SUMO are:\n“interpret” - selected sumo `mode` which determines the importance of features,\n“sumo_results.npz” - path to selected factorization results from the `run` mode of SUMO (here we selected 5 as the optimal number of clusters although 2 is also a good choice, see expected outcomes[href=https://www.wicell.org#expected-outcomes] for more details),\n“infile1,infile2,…” - a comma-delimited list of files containing standardized feature matrices,\n“output_prefix”- prefix of the output files.\nSome of the optional arguments in this mode include:\n“-log” and “-logfile” - arguments governing the logging level and optional path to save the logging file,\n“-max_iter“ and “-n_folds” - the model parameters that govern the search through hyperparameter space and model cross-validation,",
    "“-t” number of computational threads.\nThe outputs of this step are two files with feature importance in form of SHAP (Shapley Additive exPlanations) values calculated using the trained model. The .tsv file contains a matrix of values, with features represented in rows, and the clusters represented in columns. The value of each cell corresponds to the importance of a given feature in that cluster. The .hits.tsv file is a summary of the most important features for each cluster.\nStep 6: Examples of downstream analyses\nTiming: 14 s\nIn the previous steps, we identified five different subtypes using the TCGA-LGG data. We also identified genes, methylation probes, and microRNAs that could be potential biomarkers for each of the five subtypes. Now, several downstream analyses can be performed to evaluate the identified subtypes and important features. One such analysis is to determine whether there is a significant difference in prognosis for at least one of the detected subtypes. See expected outcomes[href=https://www.wicell.org#expected-outcomes] for the discussion of results.\nLoad required R packages:\n>library(tidyverse)\n>library(survival)\n>library(survminer)\nSurvival analysis:\nLoad the sample labels (for the selected number of clusters) produced by SUMO:\n>labels <- read_tsv(\"LGG/k5/clusters.tsv\")\nDownload the survival data to the working directory (see key resources table[href=https://www.wicell.org#key-resources-table]) and load it with the following command:\n>data <- read_tsv(\"survival%2FLGG_survival.txt\") %>%\nselect(sample, OS, OS.time) %>% right_join(labels, by =\n\"sample\")\nPlot the Kaplan-Meier curves (Figure 2[href=https://www.wicell.org#fig2]):\n>ggsurvplot(survfit(Surv(OS.time, OS) ∼ label,\ndata=data), data=data, palette = \"npg\", pval = TRUE,\nggtheme = theme_bw(), risk.table = TRUE)\nNote: Crossing hazard rates can lead to loss of power in log-rank tests. The assumptions of proportional hazard should be tested using the Schoenfeld residuals and alternative approaches such as weighted log-rank tests should be used in case of violations (Bouliotis and Billingham, 2011[href=https://www.wicell.org#bib2]).\nEvaluation of potential biomarkers for a selected subtype of interest:",
    "Load the sample labels, produced by `sumo run`, and corresponding `sumo interpret` results:\n>data <- read_tsv(\"LGG_interpret_k5.tsv\") %>%\ngather(group, importance, -feature)\n>labels <- read_tsv(\"LGG/k5/clusters.tsv\")\nAssign the label of a subtype of interest. Here, we supply the label for the cluster with a worse prognosis compared to the other subtypes. In our run, this label was 3, though it might be a different label in another run:\n>selected_label <-3\nFind the most important features for the subtype:\n>top_features <- data %>%\nfilter(group == paste0(\"GROUP_\",selected_label)) %>%\narrange(desc(importance)) %>% top_n(6, importance)\nExtract the values of top features from pre-processed feature matrices:\n>patterns <- paste('-w', paste0('-e ',\ntop_features$feature %>%\n    unique(), collapse = ' '), collapse = '')\n>infiles <- c(\"TCGA.LGG.mRNAexp.tsv\",\n      \"TCGA.LGG.miRNAexp.tsv\",\n      \"TCGA.LGG.met.tsv\")\n>data <- NULL\n>for (fname in infiles){\nsamples <- colnames(read_tsv(pipe(paste(\"head -n 1\",\n        fname)),\n      col_types =c(col_character())))\nthe_pipe <- pipe(paste(\"grep\", patterns, fname))\nrlines <- readLines(the_pipe)\nif (length(rlines) > 0){\n  for(read_line in rlines){\n  split_line <- strsplit(read_line, '\\t')[[1]]\n  feature <- strsplit(split_line[1], '\"')[[1]][-1]\n  feature_tbl <- tibble(sample=samples,\n    feature=feature, fname=fname,\n  value=as.numeric(split_line[2:length(split_line)]))\n  if(is.null(data)){\n    data <- feature_tbl\n  } else {\n    data <- data %>%\n      full_join(feature_tbl,\n      by=c(\"sample\",\"feature\",\"fname\",\"value\"))\n  }\n}\n}\nclose(the_pipe)\n}\n>data <- data %>%\n    left_join(labels, by = \"sample\") %>%\n    left_join(top_features, by = \"feature\")\nConfirm if each feature of interest has significantly different values for the cluster of interest using the Kruskal-Wallis test:\n>test_feature <- function(value, label, group){\n  the_group <- group[1]\n  res <- tibble(value=value,\n        label=as.character(label))%>%\n  mutate(group=ifelse(label==strsplit(the_group,\n      \"_\")[[1]][-1], the_group, \"OTHER_SAMPLES\"))\n  pval <- kruskal.test(value ∼ group,data=res)$p.value\n  return(pval)\n}\n>data <- data %>%\ngroup_by(feature) %>%\nsummarise(pval=test_feature(value, label, group)) %>%\nright_join(data, by = \"feature\")\nPlot values of each feature of interest across the clusters/subtypes (Figure 3[href=https://www.wicell.org#fig3]):\n>data %>%\nseparate(group, c(NA, \"group\"), sep=\"_\") %>%\nmutate(group=as.numeric(group),\n    selected_group=as.factor(label==group),\n    label=as.factor(label)) %>%\n    ggplot() +\n      geom_violin(aes(x=label, y=value,\n            fill=selected_group,\n            color=selected_group),\n            alpha=0.3) +\n      geom_text(data=data %>%\n          select(feature, group,\n              importance, pval) %>%\n      distinct(),\n      aes(x = -Inf, y = -Inf, label=paste(\"p-\n      value\",",
    "ifelse(pval > 0.0001, round(pval, 4), \"<\n      0.0001\"))), hjust = -0.05, vjust = -0.5, size=4) +\n      facet_wrap(paste(feature, \"(importance:\",\n      round(importance, 3),\")\")∼.,\n      scales=\"free\") +\n      theme_bw(base_size = 12) +\n      theme(legend.position =\n      \"null\") +\n      labs(y=\"feature value\", x=\"subtype\")\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1367-Fig2.jpg\nFigure 2. Kaplan-Meier survival analysis for the five subtypes detected by SUMO\nWe report the p-value of the log-rank test.\nimgsrc:https://prod-shared-star-protocols.s3.amazonaws.com/protocols/1367-Fig3.jpg\nFigure 3. Evaluation of important features for differentiation of subtype 3\nWe show the top six candidate features identified, by `sumo interpret`. The reported p-value is calculated using the Kruskal-Wallis test."
  ],
  "subjectAreas": [
    "Genomics",
    "Bioinformatics",
    "Health Sciences",
    "Cancer",
    "Gene Expression"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research",
    "Molecular Biology & Genetics",
    "Bioinformatics & Computational Biology"
  ]
}