{
  "id": 2214,
  "origin_website": "Cell",
  "title": "A computational approach to generate highly conserved gene co-expression networks with RNA-seq data",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nStep 1: Construction of co-expression networks\nTiming: 1 day\nIn this step, consensus co-expression networks will be constructed using interactions (significant gene-gene correlations) found conserved across all iterations of the network construction pipeline.\nFor next steps in the pipeline (network construction, analysis, and visualization) we switched to Python. Alternately, packages from R may also be used here.\nWe will utilize functions from the following python packages:\n> import pandas as pd\n> import networkx as nx\nIn this step we use the gene expression matrix to calculate pair-wise correlation between all gene pairs using pandas.DataFrame.corr with the method argument set to ‘pearson’. The returned object is an adjacency matrix (n by n) where each cell represents the correlation coefficient between a gene pair, with an associated p-value.\n> from scipy.stats import pearsonr\n> corr = data.corr()\n> corr_pval = data.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(∗corr.shape)\nNext, we select a threshold(r) for the correlation coefficient to define significant gene relationships to be included in our networks. Previous work from the McDonald lab found, after evaluating different values of correlation thresholds (0.70–0.99), that networks of random signals could appear to be connected for values of r < 0.85 (Hill and McDonald, 2015[href=https://www.wicell.org#bib10]). Hence, we select gene pairs satisfying |r| > 0.85, p-value < 0.05.\n> corr = corr.mask(corr_pval >= 0.05)\n> links = corr.stack().reset_index()\n> links = links[(links[0] >= 0.85)|(links[0] <= -0.85)]\nSave the network as an adjacency list of edges with three columns (1) node 1, (2) node 2 and (3) correlation strength.\n> links.columns = ['node 1', 'node 2','correlation strength']\n> links.to_csv('adjacency_list.csv', index=False)",
    "The number of edges in a co-expression matrix is highly dependent on the number of samples in small datasets. Therefore, to ensure fair comparison between datasets with variable sample sizes, we used a consensus approach to define our signal networks. For this:\nBoth normal and cancer datasets are randomly down sampled to a hundred subsets each consisting of a hundred samples.\n> normal_data = normal_data.sample(n = 100)\n> cancer_data = cancer_data.sample(n = 100)\nNext, we generate a network for each data subset following steps 3–5. Links from each of the 100 networks are combined into a single list called links_100_iterations, for normal and cancer data independently.\nA frequency is assigned to each unique interaction from all hundred networks, based on their occurrence across the hundred iterations, for cancer and normal individually. Save each of these interactions along with their frequencies in a csv file for use during the protocol.\n> link_frequency = links_100_iterations.value_counts()\nFinally, network edges found in each of the hundred iterations are used to define the final networks. Save the final networks as dataframes with two columns (1) node 1 and (2) node 2, for normal (df_normal) and cancer (df_cancer) individually.\n> consensus_edges = list(link_frequency [link_frequency >= 100].keys())\n> df_normal = pd.DataFrame([[i.split(' ')[0],i.split(' ')[1]] for i in consensus_edges], columns=['node 1', 'node 2'])\n# Repeat these steps (6 b to d) for cancer_data and store the corresponding consensus links in df_cancer\nAll relationships (correlations) are treated as unsigned in all downstream analyses because nearly 100% of the correlations in the dataset are positive values.\nStep 2: Network structural analysis\nTiming: 30 min",
    "In this step, consensus co-expression networks from the previous step will be analyzed to identify and compare network connectivity and network similarity between normal and cancer networks. Additionally, network hub nodes will be defined for use later in the protocol.\nFor a quantitative comparison of overall network connectivity and to explore relative changes in network connectivity between normal and cancer, record and compare:\ntotal number of gene correlations (network vertices) found in any of the hundred iterations of network construction from step 6b, for normal and cancer samples.\nfully conserved network connections found in all hundred iterations of the pipeline from step 6d, for normal and cancer samples.\nBesides the quantitative comparison of network structures described above, a more literal way to calculate network similarity is a node by node and edge by edge comparison. Jaccard similarity can be used as a measure of network similarity between normal and cancer networks using sklearn.metrics.jaccard_score based on shared network nodes and edges.\nRead the networks saved in step 5 into dataframes each with three columns: node 1, node 2 and correlation strength. Next, load these co-expression networks into Networkx using the following code:\n> G_normal = nx.from_pandas_edgelist(df_normal,'node 1','node 2')\n> G_cancer = nx.from_pandas_edgelist(df_cancer,'node 1','node 2')\nGet the set of unique (1) nodes and (2) edges from normal and cancer networks and calculate their Jaccard similarities. The following code implements network similarity between cancer and normal networks based on node overlap:\n> list1 = G_cancer.nodes()\n> list2 = G_normal.nodes()\n> intersection = len(list(set(list1).intersection(list2)))\n> union = (len(list1) + len(list2)) - intersection\n> Jaccard_similarity = return float(intersection) / union",
    "We defined network hub nodes as the top 2% most connected nodes in the network. In the literature, hub nodes have been defined anywhere from the top 1%–10% of network nodes with highest connectivity. For this protocol we choose to restrict hub nodes to a conservative cutoff of 2%.\nSort network nodes based on their degree and select the top 0.02∗n genes as hubs, where n is the total number of genes:\n> n_genes = sorted(G_normal.degree, key=lambda x: x[1], reverse=True)\n> threshold = int(len(n_genes)∗0.02)\n> n_hubnodes = pd.DataFrame(n_genes,columns=['GeneId','Degree'])[0:threshold]['GeneId']\nStep 3: Identify differentially co-expressed gene lists\nTiming: 15 min\nComparing network connectivity in normal and cancer datasets, we found that while a large percentage of network nodes are lost in cancer, some of these interactions are also conserved in disease state. Additionally, cancer networks also acquire some unique interactions not previously found in normal tissue. In this step, we will identify the proportions of normal nodes lost and conserved in cancer, as well as the proportion of acquired cancer nodes.\nFor comparative analysis, network nodes were divided into three differential cases of interest (1) lost nodes, (2) conserved nodes and (3) acquired nodes, where:\nLost nodes represent genes displaying significant correlations across normal samples that are not co-expressed in cancer samples. This is calculated as:\n> lost_nodes = G_normal.nodes() - G_cancer.nodes()\nConserved nodes are genes with connections in both normal and cancer samples that are calculated as:\n> conserved_nodes = G_normal.nodes().intersection(G_cancer.nodes())\nAcquired nodes are genes that display gene-gene correlations in cancer samples only and are calculated as:\n> Acquired_nodes = G_cancer.nodes() - G_normal.nodes()\nThe proportion of network nodes in each of these categories is recorded.\n> lost_normal_nodes = len(lost_nodes)/len(G_normal.nodes())\n> conserved_normal_nodes = len(conserved_nodes)/len(G_normal.nodes())\n> acquired_cancer_nodes = len(acquired_nodes)/len(G_cancer.nodes())",
    "In addition to this, we also record network nodes that are differentially expressed and network nodes that are cancer drivers (COSMIC).\nStep 4: Gene enrichment analysis\nTiming: 30 min\nIn this step, we use functional enrichment analysis to determine if genes (nodes) that are lost, conserved, or acquired in cancer networks are differentially enriched for biological functions.\nThere are a number of tools available for conducting gene ontology analysis that can be used here. For this project we used GSEApy, which is an Enrichr pathway analysis package within the Python wrapper. GSEApy is a popular tool for the gene enrichment analysis of gene lists, based on Fisher’s exact test, that includes more than a hundred gene set databases with over 180,000 gene sets in multiple categories.\nSubmit these gene lists (lost, conserved and acquired nodes) for genome ontology (GO) enrichment analysis using the function gseapy.enrichr as follows:\n> import gseapy\n> enr = gseapy.enrichr(gene_list = nodes,\n              description = 'pathway',\n              gene_sets = ['GO_Biological_Process'], organism='Human',\n              cutoff=0.5)\nBiological process terms with adjusted p < .05 were considered significant and recorded.\n> enr[enr.results['Adjusted p-value']<0.05]"
  ],
  "subjectAreas": [
    "Rnaseq",
    "Gene Expression",
    "Bioinformatics",
    "Cancer"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research",
    "Molecular Biology & Genetics",
    "Bioinformatics & Computational Biology"
  ]
}