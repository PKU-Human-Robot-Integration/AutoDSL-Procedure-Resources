{
  "id": 19418,
  "origin_website": "Jove",
  "title": "Using the MouseWalker to Quantify Locomotor Dysfunction in a Mouse Model of Spinal Cord Injury",
  "procedures": [
    "All handling, surgical, and post-operative care procedures were approved by Instituto de Medicina Molecular Internal Committee (ORBEA) and the Portuguese Animal Ethics Committee (DGAV) in accordance with the European Community guidelines (Directive 2010/63/EU) and the Portuguese law on animal care (DL 113/2013) under the license 0421/000/000/2022. Female C57Bl/6J mice aged 9 weeks were used for the present study. All efforts were made to minimize the number of animals and to decrease the suffering of the animals used in the study. The MATLAB script and the standalone version of the MW software are open-source and are available at the GitHub\nrepository (https://github.com/NeurogeneLocomotion/MouseWalker[href=https://github.com/NeurogeneLocomotion/MouseWalker]). While the MW software was developed in MATLAB R2012b, it has been adapted to run in MATLAB R2022b. Figure 1 illustrates the analysis workflow of the MW.\n1. Setting up the MouseWalker (MW) apparatus\nAssemble the MW apparatus as described previously23, or adapt to the specific needs of the experimental design (see Table of Materials and Supplementary Figure 1 for more details on the setup).\n\tNOTE: The walking arena can be made wider to accommodate larger animals, such as rats.\nVerify that the plexiglass where the animals walk is clean and scratch-free. Use a smooth cleaning cloth, and minimize the use of organic solvents such as ammonia or ethanol in high concentrations, which can damage the plexiglass (3% hydrogen peroxide, 7% ethanol, or any compatible and appropriate disinfectant for plexiglass is recommended). If necessary, replace the plexiglass.\nSet up the high-speed camera with a fast lens and a large aperture (i.e., smaller F-stop values) to capture a large amount of light, as this helps to record the fTIR signals (see Table of Materials).",
    "NOTE: The lens should not generate optical distortions, particularly at the edges of the image. Optical distortions can be tested by recording a known pattern (e.g., stripes or squares) and then measuring the size of the blocks on ImageJ/FIJI24 (use the line tool, and then click on Analyze > Measure). For example, a 1 cm sized square should have the same pixel dimensions both at the center of the image and on the edges. Variations should be smaller than 5%.\nLight up the multicolored LED light strip from the background light box.\nLight up the white LED light strip from the walkway light box.\n\tNOTE: A colored LED can also be used25 to facilitate the distinction of the footprint/body/background.\nWith the room lights off, verify the light intensity of the background light box and walkway. Adjust the intensity, if necessary, using a potentiometer or semi-opaque plastic. These must be optimized so that pixel intensity increases in the following order: animal's body < background < footprints.\n\t\nTo check the pixel intensity of the animal's body/background/footprints, open the image sequence on ImageJ/FIJI24, and click on Analyze > Measure. The footprint signal should not be oversaturated, as this will prevent the boundaries of the footprint from being defined (i.e., toes and foot pads) (Supplementary Figure 2).\nAdjust the image contrast of the walkway on the video recording software. The contrast can be adjusted in two ways: by dimming or increasing the lighting on the LED strip or by adjusting the camera lens aperture.\nPosition the lens correctly to be at the same height and in the center of the 45° reflecting mirror and perpendicular (90°) to the walkway. This will generate a constantly proportional image along the left-right walkway.",
    "NOTE: Avoid changing the camera position (distance, height, and orientation) across the multiple recording sessions. If necessary, mark the floor where the tripod should be placed. This will maintain the image features.\nFocus the lens on the surface of the plexiglass. This can be tested using a non-damaging object touching the surface of the plexiglass.\n\t​NOTE: With lower F-stop lens values, the depth of field will become smaller, thus making focusing harder.\nEnsure all the settings remain unaltered during the assay, as they may change the pixel intensity of the recorded videos.\n2. Video acquisition\nEnsure the mice are familiar with the room and apparatus prior to testing. Save at least 1 day for habituation (day 0). To avoid excessive training, perform the MW test on a different day from the other behavioral tests (preferably the day after).\nIn the video recording software, ensure at least 50 cm of the walkway is visible.\nAdjust the recording settings to truncate the walkway region. This will reduce the video size and optimize the video acquisition.\nTake a picture or a short video of a regular ruler before each session. The number of pixels per centimeter will later be used in the \"settings window\" to calibrate the videos.\nStart the video acquisition, and place the animal on the edge of the walkway by grasping the base of the tail to avoid injuries. Ensure the animals move forward to the extreme edge of the platform. Perform the video recordings with at least 100 frames/s to ensure smooth gait transitions.\n\t\nIf needed, motivate the animals to move by gently tapping the walkway wall or snapping/clapping the fingers. However, avoid physical nudging, as this may affect the results.",
    "Save the videos directly as image sequences in TIFF (with LZW compression), JPEG, or PNG format. In case the camera records as a raw MOV file, convert the videos into image sequences by opening the file in ImageJ/FIJI24 and clicking on File > Save as > Image sequence (or by using other software, such as LosslessCut25).\n\t\t​NOTE: Most animals start walking immediately after being put in the walkway; therefore, it is recommended to start the video acquisition before placing the animal.\n3. Preparing the videos for the MW tracking software\nFilm enough complete runs of each individual mouse. The number of animals to film per condition and the number of complete runs must be decided according to each experimental design. A complete run is when the mouse walks the complete 50 cm of the walkway without prolonged stops (in this experiment, three complete runs were selected).\n\tNOTE: Depending on the image acquisition software, videos may need to be cropped to the smallest ROI. This will increase the speed of tracking and output generation.\nIn ImageJ/FIJI24, select the frames in which the mouse is on the screen by clicking on Image > Stack > Tools > Make a substack. The tracking on the MW requires the head and the tail to be visible in all the frames. It is possible, however, to make several substacks from a single video recording, which will later represent each run.\nSave each substack separately in different folders by clicking on File > Save as > Image sequence. The MW software later creates a subfolder automatically in each directory every time one starts analyzing a run.\n4. Tracking\nOpen MATLAB, add the folder containing the MW script to the working directory, and run \"MouseWalker.m\" on the main command line.",
    "NOTE: Using the MW software under MATLAB allows tracking error messages to be viewed on MATLAB's main console and the desired output data to be selected (by opening the main script file \"MouseEvaluate.m\" and changing the outputs to either 1 or 0: the excel file, footstep plots, stance traces, and gait patterns).\nLoad the video folder as the \"Input directory\". One can also choose the output folder; however, this is not a requirement as the MW software creates a new folder called \"Results\" automatically inside the \"Input directory\".\nUsing the arrows \"<<\", \"<\", \">>\", and \">\" check if the video frames are all loaded correctly inside the MW software.\nGo to the \"Settings window\" where all the calibration and threshold parameters are located. These settings can change depending on the pixel intensity of the background and footprints, as well as the minimal size of the body and footprints, amongst other factors (see example in Supplementary Figure 2). Test the effect of changing some parameters by clicking on the Preview button.\n\t\nUse the different plot styles, including \"body + feet + tail\", \"body only\", \"feet only\", and \"tail only\", to help discriminate body parts after adjusting the threshold parameters.\nTake advantage of the tools on the right-side panel to take measurements of the brightness or size (using the \"brightness\" and \"ruler\" buttons, respectively). All settings can be saved as \"default\" as long as the camera distance remains the same.\nAfter adjusting the threshold parameters, check that the video is ready for automated tracking. Go to the first frame, and click on Auto to start tracking. This step can be followed in real time, and it takes a few minutes, depending on the size of the video and the computer's performance.",
    "If the auto-tracking incorrectly labels the body features, cancel the auto-tracking, enter new settings, and restart the process.\nAfter the tracking is completed, check if a manual correction is needed. To correct, use the middle panel to select or deselect, and indicate the location of the right fore (RF), right hind (RH), left fore (LF), and left hind (LH) paw footprints, head, nose, body (divided into two segments), and tail positions (divided into four segments). Save the changes by pressing the Save button.\n\tNOTE: All buttons and most commands have a key shortcut (check the associated manual for details23). To facilitate video scrolling and the execution of keyboard shortcuts, a hardware controller with programmable buttons and a shuttle wheel like the Contour ShuttlePro V2 can be used.\nClick on Evaluate to generate the output files from the tracked video. Depending on the desired output selected (see step 4.1), this step can take a few minutes.\nCheck that all the graphical output data plots are saved in the \"Results\" folder. Verify the accuracy of the tracking by examining some of the graphical outputs, such as the \"Stance traces\", where one can check if all the paw positions are consistent.\n\t\nIf an error is identified, manually correct the tracking (if possible; otherwise, eliminate the \"Results\" folder, and perform the auto-tracking again with new settings), and click on the Evaluate command again.\nCheck that all the quantitative measurements generated by the MW software are saved on an Excel spreadsheet and summarized on \"1. Info_Sheet\". Ensure that the excel options for the formula delimitations match the script. The decimal separator must be \",\", and the thousand separators must be \";\".\nUse the \"MouseMultiEvaluate.m\" script to congregate the measurements from all the runs into a new file for analysis.",
    "To begin, generate a .txt file containing the folder paths for all the videos (e.g. \"Videofiles.txt\"). Ensure that each line corresponds to a single video.\nThen, write \"MouseMultiEvaluate('Videofiles.txt')\" into the command line. An excel file named \"ResultSummary.xls\" will be generated in the working directory (see an example in the GitHub repository).\n\t\t​NOTE: Figure 2 represents the graphical outputs obtained by the MW software from the videos of one recorded animal.\n5. Kinematic data analysis workflow\nEdit the excel sheet generated in step 4.10, which contains the data for processing using the supplied Python scripts, according to the following prerequisites.\n\t\nIn the first column header, specify the experimental condition. Name each line following the group/condition name (individuals from the same groups must have the same name). The first group must be the control or baseline (this is only mandatory for heatmap plotting, step 5.6).\nIn the second column, specify the animal ID. This is mandatory, although this information will not be used for plot generation.\nIn the third column onward, choose the motor parameters that will be used for the analysis. Ensure that the first line is the name of the parameter (these names will later appear in the plots).\nOpen Anaconda Navigator, and execute Spyder to open the supplied Python scripts.\n\tNOTE: All the scripts were developed with Python 3.9.13, were executed with Spyder 5.2.2 in Anaconda Navigator 2.1.4, and are available in the Table of Materials and the GitHub repository (where additional materials are included, such as a video example, an excel example file, and an FAQs document). It is possible to execute the scripts outside the Anaconda Navigator; however, this graphical user interface is more user-friendly.\nUse the \"Rawdata_PlotGenerator.py\" to generate the raw data plots. This will allow the visualization of each parameter as a function of speed.",
    "Open \"Rawdata_PlotGenerator.py\" in Spyder, and run the code by clicking on the Play button.\nSelect the Excel file to analyze and the sheet name in the automatic window. If the sheet name was not altered, write \"Sheet1\".\nThe raw data plots will appear in the plot console (upper right panel). To save the plots, click on the Save image or Save all images button in the plot console.\nUse the script \"Residuals_DataAnalysis\" to calculate the residuals for data analysis. This script will generate a CSV file with the calculations of the residuals for all the motor parameters.\n\tNOTE: Many of the measured gait parameters extracted by the MW vary with speed (e.g., swing speed, step length, stance duration, stance straightness, and gait indexes). Therefore, it is recommended to perform a best-fit regression model of each individual parameter versus speed for the baseline experiment and to then determine the residual values for each experimental group in relation to this regression model. The data are then expressed as the difference from the residual normalized line26.\n\t\nOpen \"Residuals_DataAnalysis.py\" in Spyder, and run the code by clicking on the Play button.\nSelect the Excel file to analyze and the sheet name in the automatic window. If the sheet name was not altered, write \"Sheet1\".\nSave the CSV file in the same folder as the data. It is mandatory that the control (or baseline) is the first group in the Excel file.\nUse the \"PCA_PlotGenerator.py\" script to perform a principal component analysis (PCA).",
    "NOTE: This unsupervised dimensionality reduction method is used to generate a more succinct representation27,28,29 of the data (Figure 3A, B). The PCA script includes the following steps. The data is first pre-processed by centering and scaling, after which the PCA algorithm computes the covariance matrix to determine the correlations between the variables and calculate the eigenvectors and eigenvalues of the covariance matrix to identify the principal components. The first two or three principal components are chosen for the representation of the data in 2D or 3D plots, respectively. Each dot in the plots corresponds to an animal and represents a different abstract variable. Color-coded dots are used to distinguish the specific groups. As such, clusters of dots reflect similar walking patterns shared by the corresponding individuals.\n\t\nOpen \"PCA_PlotGenerator.py\" in Spyder, and run the code by clicking on the Play button.\nSelect the Excel file to analyze and the sheet name in the automatic window. If the sheet name was not altered, write \"Sheet1\".\nEnsure that the PCA 2D and 3D plots appear in the plot console (upper-right panel). Each color represents a different group, and the legend appears next to the plot. To save the plot, click on Save image in the plot console.\nUse \"Heatmap_PlotGenerator.py\" to generate a heatmap. Ensure that the heatmap generator creates a table showing the statistical differences between the baseline group (or control group) and the other groups for each motor parameter27 (Figure 4). Each column depicts one group, and each line relates to a specific motor parameter.",
    "NOTE: Statistical analysis was conducted with a one-way ANOVA followed by Tukey's post hoc test (for normal distributions) or a Kruskal-Wallis ANOVA followed by Dunn's post hoc test (for non-normal distributions). Outliers were excluded from the analysis. P-values are represented by a color code, with red and blue shades indicating an increase or decrease relative to control (or baseline), respectively. The color shade represents the statistical significance, with darker colors showing a higher significance, and lighter colors showing a lower significance. *** corresponds to P < 0.001; ** corresponds to P < 0.01; and * corresponds to P < 0.05. White indicates no variation.\n\t\nOpen \"Heatmap_PlotGenerator.py\" in Spyder, and run the code by clicking on the Play button.\nSelect the Excel file to analyze and the sheet name in the automatic window. If the sheet name was not altered, write \"Sheet1\".\nSelect the type of data in the second automatic window: raw data or residuals data. If an option is not selected, residuals data is the default.\nThe heatmap will appear in the plot console (upper-right panel). To save the plot, click on Save image in the plot console.\n\t\tNOTE: It is mandatory that the control (or baseline) is the first group in the Excel file.\nUse \"Boxplots_PlotGenerator.py\" to generate the boxplots. This tool will allow the generation of boxplots that represent the distribution of values for all the motor parameters for each group (Figure 5, Figure 6, and Figure 7).",
    "NOTE: Each box contains the median as the middle line, and the lower and upper edges of the boxes represent the 25% and 75% quartiles, respectively. The whiskers represent the range of the full data set, excluding outliers. Outliers are defined as any value that is 1.5 times the interquartile range below or above the 25% and 75% quartiles, respectively.\n\t\nOpen \"Boxplots_PlotGenerator.py\" in Spyder, and run the code by clicking on the Play button.\nSelect the Excel file to analyze and the sheet name in the automatic window. If the sheet name was not altered, write \"Sheet1\".\nSelect the type of data in the second automatic window: raw data or residuals data. If an option is not selected, residuals data is the default.\nThe boxplots will appear in the plot console (upper-right panel). To save the plots, click on the Save image or Save all images button in the plot console.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Neuroscience"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research"
  ]
}