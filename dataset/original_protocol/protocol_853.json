{
  "id": 910,
  "origin_website": "Nature",
  "title": "Expression and network analysis of Illumina microarray data",
  "procedures": [
    "1. ###This code is for analyzing the SH-SY5Y data from Illumina Human Ref8-v2 arrays using R\n  ###The following abbreviations are used: V= control cells; WT= cells overexpressing human FOXP2; M12= cells overexpressing chimp FOXP2\nLoad packages\nlibrary \\(Biobase)\nlibrary\\(marray)\nlibrary \\(limma)\nlibrary\\(RColorBrewer)\nlibrary\\(MASS)\nlibrary\\(gplots)\n###Read in the dataset\n###samples not included in this paper are excluded\nload\\(“line1367_noM125_justdata.R”)\nmydata<-mydata\\[,-c\\(13:24)] #excluding line3\ndetsco<-detsco\\[,-c\\(13:24)] #excluding line3\nsds<-sds\\[,-c\\(13:24)] #excluding line3\nbeads<-beads\\[,-c\\(13:24)] #excluding line3\nSamples<-Samples\\[-c\\(13:24),] #excluding line3\nmatriz <- as.matrix\\(mydata)\nROWlabels<-as.character\\(paste\\(Samples$Condition, Samples$CellLine, Samples$Replicate, sep=”_”))\nphD <- Samples\\[,c\\(1,3,4,5)]\nrownames\\(phD)<-ROWlabels\nmetadata<-data.frame\\(labelDescription=c\\(“Array”, “Condition”, “Replicate”, “CellLine”), row.names=c\\(“Array”, “Condition”, “Replicate”, “cellLine”))\npD<-new\\(\"AnnotatedDataFrame\",data=phD, varMetadata=metadata)\n###Load the Illumina microarray annotations\nill.array <- read.csv\\(file=\"C:/Documents and Settings/dhglab.NEURODH/Desktop/Chip info/HumanRef-8_V2_11223162_B.csv\", header=T)\n###Normalize between arrays\nmatrizQ <-normalizeBetweenArrays\\(matriz,method=\"quantile\")\n###Apply Combat\nsamName<-labls\ncombat.list<- as.data.frame\\(cbind\\(samName, Samples\\[,9], Samples\\[,3]))\ncolnames\\(combat.list)<- c\\(\"Sample\", \"Batch\", “Condition”)\nwrite.xls\\(matrizQ,file=\"ComBatExpr.xls\", quote=F)\nwrite.xls\\(combat.list,file=\"ComBatList.txt\",quote=F)\nsource\\(\"C:/Documents and Settings/dhglab.NEURODH/Desktop/Study/ComBat.R\",local=T)\nComBat\\(\"ComBatExpr.xls\",\"ComBatList.txt\")\n###Create the exprSet object\n#Read in Combat adjusted data\nmatrizQ_adj<-read.table\\(\"Adjusted_ComBatExpr_1cond.xls\", header=T)\nrownames\\(matrizQ_adj)<- rownames\\(matriz)\nmatrizQ_adj<-as.matrix\\(matrizQ_adj)\neSet <- new\\(\"ExpressionSet\", exprs=matrizQ_adj, phenoData=pD)\neSet\nftdexp<-exprs\\(eSet)\n###Compare experimental conditions\n#all samples\nall.samples<-as.data.frame\\(ftdexp)\n#ratios for heatmap and ratio output\n#selecting the coefficients for single arrays\n#1. Controls\nall.contr.wt<-all.samples\\[,Samples$Condition ==”WT”]\nall.contrM.wt<-rowMeans\\(all.contr.wt)\nall.contr.v<-all.samples\\[,Samples$Condition ==”V”]\nall.contrM.v<-rowMeans\\(all.contr.v)\n#2. Exp\nall.exp.wt<-all.samples\\[,Samples$Condition ==”WT”]\nall.exp.m12<-all.samples\\[,Samples$Condition ==”M12”]\n#3. Ratios\nall.coef.WTV <-all.exp.wt-all.contrM.v\ncolnames\\(all.coef.WTV)<-paste\\(“vsV”, colnames\\(all.coef.WTV), sep=”.”)\nall.coef.M12V<-all.exp.m12-all.contrM.v\ncolnames\\(all.coef.M12V)<-paste\\(“vsV”, colnames\\(all.coef.M12V), sep=”.”)\nall.coef.M12WT<-all.exp.m12-all.contrM.wt\ncolnames\\(all.coef.M12WT)<-paste\\(“vsWT”, colnames\\(all.coef.M12WT), sep=”.”)\n#export the data\nmydata2<-cbind\\(rownames\\(all.coef.WTV), all.coef.WTV, all.coef.M12V, all.coef.M12WT)\nill.array.nodup<-ill.array\\[\\!duplicated\\(ill.array$Target),]\nmy.all.data<- merge\\(mydata2,ill.array.nodup, by.x=\"Target\",by.y=\"Target\")\nmydata3<-cbind\\(rownames\\(all.samples),all.samples)\ncolnames\\(mydata3)1<-\"Target\"\ncolnames\\(mydata3)\\[2:length\\(mydata3)]<- paste\\(colnames\\(mydata3)\\[2:length\\(mydata3)],\"exp\",sep=\".\")\nmy.all.data.new<-merge\\(my.all.data,mydata3,by.x=\"Target\",by.y=\"Target\")\nwrite.xls\\(my.all.data.new,\"Line167/rm_alldata_ratio_line167.xls\",quote=F)\n###Fit the data to a linear model\nTS<- Samples$Condition\nTS <- factor\\(TS, levels=unique\\(TS))\ndesign <- model.matrix\\(~0+TS)\ncolnames\\(design) <- levels\\(TS)\nfit<- lmFit\\(eSet, design)\ncont.anova <- makeContrasts\\(WTvsV.L167= WT – V,\nM12vsV.L167= M12 – V,\nM12vsWT.L167= M12 – WT,\nlevels=design)\nfit2.anova<- contrasts.fit\\(fit, cont.anova)\nfitb<- eBayes\\(fit2.anova)\n###Implement a statistical threshold:\nchosen.adjust<-\"none\"\nchosen.p<-0.05\ncurrent.contrast<-\"contrast\"\nresults<-decideTests\\(fit2.anova,adjust.method=chosen.adjust,p=as.numeric\\(chosen.p))\nwrite.fit\\(fitb,file=\"dummy.xls\",adjust=chosen.adjust,results=results)\ntreat.de<-read.table\\(file=\"dummy.xls\",head=T)\n###Output the data for comparisons\nmyNames<-names\\(treat.de)\nres.col<- which\\(regexpr\\(\"Res.\",myNames)>0)\nanovalist<- which\\(apply\\(treat.de\\[,res.col],1,function\\(x)any\\(x,na.rm=T)))\ntreat.de.anova<-treat.de\\[anovalist,]\nfitsel.tre2<-merge\\(treat.de.anova, ill.array.nodup, by.x=\"ID\",by.y=\"Target\")\ncolnames\\(fitsel.tre2)1<-\"Target\"\nfitsel.ratio<-merge\\(fitsel.tre2,my.all.data.new)\ncolnames\\(fitsel.ratio)\nmyNames <-names\\(fitsel.ratio)\n#selects the relevant columns for output\nres.col<- which\\(regexpr\\(\"Res.\",myNames)>0)\ncoefs.col <- which\\(regexpr\\(\"Coef.\",myNames)>0)\nts.col<- coefs.col+length\\(coefs.col)\npvals.col <- which\\(regexpr\\(\"p.value.\",myNames)>0)",
    "endcolumns.start<-length\\(fitsel.ratio)-\\(length\\(mydata2)-2)\nendcolumns.end<-length\\(fitsel.ratio)\nfitsel.ratio2<-cbind\\(\nTarget= fitsel.ratio$Target,\nTranscript=fitsel.ratio$Accession,\nSymbol=fitsel.ratio$Symbol,\nDefinition=fitsel.ratio$Definition,\nfitsel.ratio\\[,coefs.col],\nfitsel.ratio\\[,pvals.col],\nF=fitsel.ratio$F,\nF.p.value=fitsel.ratio$F.p.value,\nfitsel.ratio\\[,res.col],\nfitsel.ratio\\[,ts.col],\nProbeSequence=fitsel.ratio$Probe_Sequence,\nOntology=fitsel.ratio$Ontology,\nSynonym=fitsel.ratio$Synonym,\nfitsel.ratio\\[,29: 100]\n)\nfitsel.ratio2<-fitsel.ratio2\\[order\\(fitsel.ratio2$F,decreasing=T),]\nout.file<-paste\\(paste\\(current.contrast,chosen.adjust,chosen.p,sep=\"_\"),\"xls\",sep=\".\")\nwrite.xls\\(fitsel.ratio2,file=paste\\(”rm2BE_covariate_”, out.file,sep=\"\"),quote=F)\n###Output the complete list of genes\nfitsel.treAll<-merge\\(treat.de, ill.array, by.x=\"ID\",by.y=\"Target\")\ncolnames\\(fitsel.treAll)1<-\"Target\"\nfitsel.ratioAll<-merge\\(fitsel.treAll,my.all.data.new)\nmyNames <-names\\(fitsel.ratio)\n#selects the relevant columns for output\nres.col<- which\\(regexpr\\(\"Res.\",myNames)>0)\ncoefs.col <- which\\(regexpr\\(\"Coef.\",myNames)>0)\nts.col<- coefs.col+length\\(coefs.col)\npvals.col <- which\\(regexpr\\(\"p.value.\",myNames)>0)\nendcolumns.start<-length\\(fitsel.ratio)-\\(length\\(mydata2)-2)\nendcolumns.end<-length\\(fitsel.ratio)\nfitsel.ratioN<-cbind\\(\nTarget= fitsel.ratioAll$Target,\nTranscript=fitsel.ratioAll$Accession,\nSymbol=fitsel.ratioAll$Symbol,\nDefinition=fitsel.ratioAll$Definition,\nfitsel.ratioAll\\[,coefs.col],\nfitsel.ratioAll\\[,pvals.col],\nF=fitsel.ratioAll$F,\nF.p.value=fitsel.ratioAll$F.p.value,\nfitsel.ratioAll\\[,res.col],\nfitsel.ratioAll\\[,ts.col],\nProbeSequence=fitsel.ratioAll$Probe_Sequence,\nOntology=fitsel.ratioAll$Ontology,\nSynonym=fitsel.ratioAll$Synonym,\nfitsel.ratioAll\\[,29:100]\n)\nfitsel.ratioN<-fitsel.ratioN\\[\\!duplicated\\(fitsel.ratioN$Target),]\nfitsel.ratioN<-fitsel.ratioN\\[order\\(fitsel.ratioN$F,decreasing=T),]\nwrite.xls\\(fitsel.ratioN,file=paste\\(\"rm2BE_covariate_genelist_all.xls\",sep=\"/\"),quote=F)\n2. ###This code is for analyzing the brain tissue data from Illumina Human Ref8-v3 arrays using R\n  ###The following abbreviations are used: FP=frontal pole; caud=caudate nucleus; hipp=hippocampus\nLoad packages\nlibrary \\(Biobase)\nlibrary\\(marray)\nlibrary \\(limma)\nlibrary\\(RColorBrewer)\nlibrary\\(MASS)\nlibrary\\(gplots)\n###Read in the dataset\nSamples<-read.delim\\(file=\"E:/Study/Human_Solexa_number2/Human_Solexa_Illumina_targets2.txt\", header=T)\nlabls<-as.character\\(paste\\(substr\\(Samples$Status,1,2), Samples$ConditionS, Samples$Replicate, sep=”_”))\nphD <- Samples\\[,c\\(1,2,3,5)]\nrownames\\(phD)<-labls\nmetadata<-data.frame\\(labelDescription=c\\(“ArrayID”, “Genotype”,“Condition”, “Status”), row.names= c\\(“ArrayID”, “Genotype”,“Condition”, “Status”))\npD<-new\\(\"AnnotatedDataFrame\",data=phD, varMetadata=metadata)\nillumina71<- read.delim \\(file=\"2008_071A_Sample_probe_profile.txt\", header=TRUE)\nrownames\\(illumina71)<-illumina71$PROBE_ID\nillumina71<-illumina71\\[,3:74]\nillumina43<- read.delim \\(file=\"Sample Probe profile 2008-043.txt\", header=TRUE)\nrownames\\(illumina43)<-illumina43$PROBE_ID\nillumina43<-illumina43\\[,11:12]\nillumina61<- read.delim \\(file=\"Sample probe profile 2008-061A.txt\", header=TRUE)\nrownames\\(illumina61)<-illumina61$PROBE_ID\nillumina61<-illumina61\\[,3:50]\nillumina2<-cbind\\(illumina61, illumina71) #add 43 later as it has 2 columns\n#signal values\nnsampl<-40\ncolnames\\(illumina2)\\[seq\\(1,\\(nsampl*3),3)]\nmydata<-illumina2\\[,seq\\(1,\\(nsampl*3),3)]\nmydata2<-cbind\\(mydata\\[,1:16], illumina43\\[,1], mydata\\[, 17:40])\ncolnames\\(mydata2)<-labls\nmydata<-mydata2\n#detction scores\ncolnames\\(illumina2)\\[seq\\(1,\\(nsampl*3),3)+1]\ndetsco<-illumina2\\[,seq\\(1,\\(nsampl*3),3)+1]\ndetsco2<-cbind\\(detsco\\[,1:16], illumina43\\[,2], detsco\\[, 17:40])\ndetsco<- detsco2\ncolnames\\(detsco)<-labls\ndetsco<-1- detsco #pvalue to real\nmydata.notlog<-mydata\nmydata=log2\\(mydata)\nmatriz <- as.matrix\\(mydata)\n###Load the Illumina microarray annotations\nill.array <- read.csv\\(file=\"C:/Documents and Settings/dhglab.NEURODH/Desktop/Chip info/HumanRef-8_V3_0_R0_11282963_A.csv\", header=T)\n#remove probes that are not a perfect match to either human or chimp genome\nbad.probe<-read.table\\(“E:/Study/Human_Solexa_number2/Bad_Illumina_probes_for_Chimp_comp.txt”, header=T)\ndim\\(bad.probe)\n#1 9305 1\ndim\\(mydata)\n#1 24526 41\nremoveProbes = match\\(bad.probe$PSID, rownames\\(mydata))\nmydata.g<-mydata\\[-removeProbes,]\ndetsco.g<-detsco\\[-removeProbes,]\ndim\\(mydata.g)\n# 15221 41\ndim\\(detsco.g)\nsave\\(mydata.g, detsco.g, bad.probe, mydata, file=”good_probes_data”)\nmatriz<- as.matrix\\(mydata.g)\n###Normalize between arrays\nmatrizQQ <-normalizeBetweenArrays\\(matriz,method=\"quantile\")\n###Apply Combat\nsamName<-labls\ncombat.list<- as.data.frame\\(cbind\\(samName, Samples\\[,7], Samples\\[,4], Samples\\[,5]))\ncolnames\\(combat.list)<- c\\(\"SampleName\", \"Batch\", “Condition”)\nwrite.xls\\(matrizQ,file=\"ComBatExpr.xls\", quote=F)\nwrite.xls\\(combat.list,file=\"ComBatList.txt\",quote=F)\nsource\\(\"C:/Documents and Settings/dhglab.NEURODH/Desktop/Study/ComBat.R\",local=T)\nComBat\\(\"ComBatExpr.xls\",\"ComBatList.txt\")\n###Create the exprSet object\n#Read in Combat adjusted data\nmatrizQ_adj<-read.table\\(\"Adjusted_ComBatExpr.xls\", header=T)\nrownames\\(matrizQ_adj)<- rownames\\(matriz.g)\nmatrizQ_adj<-as.matrix\\(matrizQ_adj)\neSet <- new\\(\"ExpressionSet\", exprs=matrizQ_adj, phenoData=pD.g)\neSet\nftdexp<-exprs\\(eSet)",
    "###Compare experimental conditions\n#all samples\nall.samples<-as.data.frame\\(ftdexp)\n#1. Controls, each condition as a control\nall.contr.h <-all.samples\\[,Samples$Status==”human” ]\nall.contrM.h <-rowMeans\\(all.contr.h)\nall.contr.hh <-all.samples\\[,Samples$Status==”human” & Samples$ConditionS==”hipp”]\nall.contrM.hh <-rowMeans\\(all.contr.hh)\nall.contr.hc <-all.samples\\[,Samples$Status==”human” & Samples$ConditionS==”caud”]\nall.contrM.hc <-rowMeans\\(all.contr.hc)\nall.contr.hf <-all.samples\\[,Samples$Status==”human” & Samples$ConditionS==”FP”]\nall.contrM.hf <-rowMeans\\(all.contr.hf)\nall.contr.cc <-all.samples\\[,Samples$Status==”chimp” & Samples$ConditionS==”caud”]\nall.contrM.cc <-rowMeans\\(all.contr.cc)\nall.contr.cf <-all.samples\\[,Samples$Status==”chimp” & Samples$ConditionS==”FP”]\nall.contrM.cf <-rowMeans\\(all.contr.cf)\nall.contr.caud <-all.samples\\[,Samples$ConditionS==”caud”]\nall.contrM.caud <-rowMeans\\(all.contr.caud)\nall.contr.fp <-all.samples\\[,Samples$ConditionS==”FP”]\nall.contrM.fp <-rowMeans\\(all.contr.fp)\n#2. Exp, each condition as a treatment\nall.exp.c<- all.samples\\[,Samples$Status==”chimp”]\nall.exp.hipp<- all.samples\\[,Samples$ConditionS==”hipp”]\nall.exp.caud<- all.samples\\[,Samples$ConditionS==”caud”]\nall.exp.hh<- all.samples\\[,Samples$Status==”human” & Samples$ConditionS==”hipp”]\nall.exp.hc<- all.samples\\[,Samples$Status==”human” & Samples$ConditionS==”caud”]\nall.exp.ch<- all.samples\\[,Samples$Status==”chimp” & Samples$ConditionS==”hipp”]\nall.exp.cc<- all.samples\\[,Samples$Status==”chimp” & Samples$ConditionS==”caud”]\nall.exp.cf<- all.samples\\[,Samples$Status==”chimp” & Samples$ConditionS==”FP”]\n#3. Ratios\nall.coef.hhc<- all.exp.hh - all.contrM.hc\ncolnames\\(all.coef.hhc)<-paste\\(“vsCAUD”, colnames\\(all.coef.hhc), sep=”.”)\nall.coef.hhf<- all.exp.hh - all.contrM.hf\ncolnames\\(all.coef.hhf)<-paste\\(“vsFP”, colnames\\(all.coef.hhf), sep=”.”)\nall.coef.hcf<- all.exp.hc - all.contrM.hf\ncolnames\\(all.coef.hcf)<-paste\\(“vsFP”, colnames\\(all.coef.hcf), sep=”.”)\nall.coef.chc<- all.exp.ch - all.contrM.cc\ncolnames\\(all.coef.chc)<-paste\\(“vsCAUD”, colnames\\(all.coef.chc), sep=”.”)\nall.coef.chf<- all.exp.ch - all.contrM.cf\ncolnames\\(all.coef.chf)<-paste\\(“vsFP”, colnames\\(all.coef.chf), sep=”.”)\nall.coef.ccf<- all.exp.cc - all.contrM.cf\ncolnames\\(all.coef.ccf)<-paste\\(“vsFP”, colnames\\(all.coef.ccf), sep=”.”)\nall.coef.ch.hipp<- all.exp.ch - all.contrM.hh\ncolnames\\(all.coef.ch.hipp)<-paste\\(“CHvsHUM”, colnames\\(all.coef.ch.hipp), sep=”.”)\nall.coef.ch.caud<- all.exp.cc - all.contrM.hc\ncolnames\\(all.coef.ch.caud)<-paste\\(“CHvsHUM”, colnames\\(all.coef.ch.caud), sep=”.”)\nall.coef.ch.fp<- all.exp.cf - all.contrM.hf\ncolnames\\(all.coef.ch.fp)<-paste\\(“CHvsHUM”, colnames\\(all.coef.ch.fp), sep=”.”)\nall.coef.hipp.caud<- all.exp.hipp - all.contrM.caud\ncolnames\\(all.coef.hipp.caud)<-paste\\(“HippvsCaud”, colnames\\(all.coef.hipp.caud), sep=”.”)\nall.coef.hipp.fp<- all.exp.hipp - all.contrM.fp\ncolnames\\(all.coef.hipp.fp)<-paste\\(“HippvsFP”, colnames\\(all.coef.hipp.fp), sep=”.”)\nall.coef.caud.fp<- all.exp.caud - all.contrM.fp\ncolnames\\(all.coef.caud.fp)<-paste\\(“CaudvsFP”, colnames\\(all.coef.caud.fp), sep=”.”)\nall.coef.CH<- all.exp.c - all.contrM.h\ncolnames\\(all.coef.CH)<-paste\\(“CHvsHUM”, colnames\\(all.coef.CH), sep=”.”)\n#export the data\nmydata2<-cbind\\(rownames\\(all.coef.hhc), all.coef.hhc, all.coef.hhf, all.coef.hcf, all.coef.chc, all.coef.chf, all.coef.ccf, all.coef.ch.hipp, all.coef.ch.caud, all.coef.ch.fp, all.coef.hipp.caud, all.coef.hipp.fp, all.coef.caud.fp, all.coef.CH)\ncolnames\\(mydata2)1<-“Target”\nill.array.nodup<-ill.array\\[\\!duplicated\\(ill.array$Probe_Id),]\nmy.all.data<- merge\\(mydata2,ill.array.nodup, by.x=\"Target\",by.y=\"Probe_Id\")\nmydata3<-cbind\\(rownames\\(all.samples),all.samples)\ncolnames\\(mydata3)1<-\"Target\"\ncolnames\\(mydata3)\\[2:length\\(mydata3)]<- paste\\(colnames\\(mydata3)\\[2:length\\(mydata3)],\"exp\",sep=\".\")\nmy.all.data.new<-merge\\(my.all.data,mydata3,by.x=\"Target\",by.y=\"Target\")\nratio_exp<-merge\\(mydata2,mydata3,by.x=\"Target\",by.y=\"Target\")\nwrite.xls\\(my.all.data.new,\"alldata_ratio.xls\",quote=F)\n###Fit the data to a linear model\nTS<- paste\\(Samples$Status, Samples$ConditionS, sep=”_”)\nTS <- factor\\(TS, levels=unique\\(TS))\ndesign <- model.matrix\\(~0+TS)\ncolnames\\(design) <- levels\\(TS)\nfit<- lmFit\\(eSet, design)\ncont.anova <- makeContrasts\\(HIPPvsCAUD_human= human_hipp – human_caud,\nHIPPvsFP_human= human_hipp – human_FP,\nCAUDvsFP_human= human_caud – human_FP,\nHIPPvsCAUD_chimp= chimp_hipp – chimp_caud,\nHIPPvsFP_chimp= chimp_hipp – chimp_FP,\nCAUDvsFP_chimp= chimp_caud – chimp_FP,\nCHvsHUM_hipp= chimp_hipp – human_hipp,\nCHvsHUM_caud= chimp_caud – human_caud,\nCHvsHUM_FP= chimp_FP – human_FP,\nHIPPvsCAUD = \\(human_hipp + chimp_hipp)/2 – \\(human_caud + chimp_caud)/2,\nHIPPvsFP = \\(human_hipp + chimp_hipp)/2 – \\(human_FP + chimp_FP)/2,\nCAUDvsFP = \\(human_caud + chimp_caud)/2 – \\(human_FP + chimp_FP)/2,",
    "CHIMPvsHUMAN = \\(chimp_hipp+ chimp_caud+ chimp_FP)/3 -\\(human_hipp+ human_caud+ human_FP)/3,\nlevels=design)\nfit2.anova<- contrasts.fit\\(fit, cont.anova)\nfitb<- eBayes\\(fit2.anova)\n###Implement a statistical threshold:\nchosen.adjust<-\"none\"\nchosen.p<-0.05\ncurrent.contrast<-\"contrast\"\nresults<-decideTests\\(fitb,adjust.method=chosen.adjust,p=as.numeric\\(chosen.p))\nwrite.fit\\(fitb,file=\"dummyrr.xls\",adjust=chosen.adjust,results=results)\ntreat.de<-read.table\\(file=\"dummyrr.xls\",head=T)\nmyNames<-names\\(treat.de)\nres.col<- which\\(regexpr\\(\"Res.\",myNames)>0)\nanovalist<- which\\(apply\\(treat.de\\[,res.col],1,function\\(x)any\\(x,na.rm=T)))\ntreat.de.anova<-treat.de\\[anovalist,]\nill.array.nodup<-ill.array\\[\\!duplicated\\(ill.array$Probe_Id),]\nfitsel.tre2<-merge\\(treat.de.anova, ill.array.nodup, by.x=\"ID\",by.y=\"Probe_Id\")\ncolnames\\(fitsel.tre2)1<-\"Probe\"\nfitsel.ratio<-merge\\(fitsel.tre2,ratio_exp, by.x=”Probe”, by.y=”Target”)\n###Output the data for comparisons\nmyNames <-names\\(fitsel.ratio)\n#selects the relevant columns for output\nres.col<- which\\(regexpr\\(\"Res.\",myNames)>0)\ncoefs.col <- which\\(regexpr\\(\"Coef.\",myNames)>0)\nts.col<- coefs.col+length\\(coefs.col)\npvals.col <- which\\(regexpr\\(\"p.value.\",myNames)>0)\nendcolumns.start<-length\\(fitsel.ratio)-\\(length\\(mydata2)-2)\nendcolumns.end<-length\\(fitsel.ratio)\nfitsel.ratio2<-cbind\\(\nProbe= fitsel.ratio$Probe,\nAccession=fitsel.ratio$Accession,\nSymbol=fitsel.ratio$Symbol,\nDefinition=fitsel.ratio$Definition,\nfitsel.ratio\\[,coefs.col],\nfitsel.ratio\\[,pvals.col],\nF=fitsel.ratio$F,\nF.p.value=fitsel.ratio$F.p.value,\nfitsel.ratio\\[,res.col],\nfitsel.ratio\\[,ts.col],\nA= fitsel.ratio$A,\nfitsel.ratio\\[,84:226],\nfitsel.ratio\\[,57:66],\nfitsel.ratio\\[,69:77],\nfitsel.ratio\\[,79:83]\n)\nfitsel.ratio2<-fitsel.ratio2\\[order\\(fitsel.ratio2$F,decreasing=T),]\nout.file<-paste\\(paste\\(current.contrast,chosen.adjust,chosen.p,sep=\"_\"),\"xls\",sep=\".\")\nwrite.xls\\(fitsel.ratio2, “combat_significant_genelist_0.05.xls”, quote=F)\n###Output the complete list of genes\nfitsel.treAll<-merge\\(treat.de, ill.array.nodup, by.x=\"ID\",by.y=\"Probe_Id\")\ncolnames\\(fitsel.treAll)1<-\"Probe\"\nfitsel.ratioAll<-merge\\(fitsel.treAll, ratio_exp, by.x=”Probe”, by.y=”Target”)\nmyNames <-names\\(fitsel.ratioAll)\n#selects the relevant columns for output\nres.col<- which\\(regexpr\\(\"Res.\",myNames)>0)\ncoefs.col <- which\\(regexpr\\(\"Coef.\",myNames)>0)\nts.col<- coefs.col+length\\(coefs.col)\npvals.col <- which\\(regexpr\\(\"p.value.\",myNames)>0)\nendcolumns.start<-length\\(fitsel.ratio)-\\(length\\(mydata2)-2)\nendcolumns.end<-length\\(fitsel.ratio)\nfitsel.ratioN<-cbind\\(\nProbe= fitsel.ratioAll$Probe,\nAccession=fitsel.ratioAll$Accession,\nSymbol=fitsel.ratioAll$Symbol,\nDefinition=fitsel.ratioAll$Definition,\nfitsel.ratioAll\\[,coefs.col],\nfitsel.ratioAll\\[,pvals.col],\nF=fitsel.ratioAll$F,\nF.p.value=fitsel.ratioAll$F.p.value,\nfitsel.ratioAll\\[,res.col],\nfitsel.ratioAll\\[,ts.col],\nA= fitsel.ratioAll$A,\nfitsel.ratioAll\\[,84:226],\nfitsel.ratioAll\\[,57:66],\nfitsel.ratioAll\\[,69:77],\nfitsel.ratioAll\\[,79:83]\n)\ndim\\(fitsel.ratioN)\nfitsel.ratioN<-fitsel.ratioN\\[order\\(fitsel.ratioN$F,decreasing=T),]\nwrite.xls\\(fitsel.ratioN,file= \"combat_complete_genelist.xls\",quote=F)\n3. ###This code is for analyzing the SH-SY5Y microarray data using WGCNA \\(weighted gene coexpression network analysis) using R\n  ###Paste the following functions into R\nPickSoftThreshold=function\\(datExpr1,RsquaredCut=0.85, powervector=c\\(seq\\(1,10,by=1),seq\\(12,20,by=2)),removeFirst=FALSE,no.breaks=10) \\{\nno.genes <- dim\\(datExpr1)\\[2]\nno.genes <- dim\\(datExpr1)\\[2]\nno.samples= dim\\(datExpr1)\\[1]\ncolname1=c\\(\"Power\", \"scale law R2\" ,\"slope\", \"truncated R2\",\"mean\\(k)\",\"median\\(k)\",\"max\\(k)\")\ndatout=data.frame\\(matrix\\(666,nrow=length\\(powervector),ncol=length\\(colname1) ))\nnames\\(datout)=colname1\ndatout\\[,1]=powervector\nif\\(exists\\(\"fun1\")) rm\\(fun1)\nfun1=function\\(x) \\{\ncorx=abs\\(cor\\(x,datExpr1,use=\"p\"))\nout1=rep\\(NA, length\\(powervector) )\nfor \\(j in c\\(1:length\\(powervector))) \\{out1\\[j]=sum\\(corx^powervector\\[j])}\nout1\n} # end of fun1\ndatk=t\\(apply\\(datExpr1,2,fun1))\nfor \\(i in c\\(1:length\\(powervector) ) )\\{\nnolinkshelp <- datk\\[,i]-1\ncut2=cut\\(nolinkshelp,no.breaks)\nbinned.k=tapply\\(nolinkshelp,cut2,mean)\nfreq1=as.vector\\(tapply\\(nolinkshelp,cut2,length)/length\\(nolinkshelp))\n# The following code corrects for missing values etc\nbreaks1=seq\\(from=min\\(nolinkshelp),to=max\\(nolinkshelp),length=no.breaks+1)\nhist1=hist\\(nolinkshelp,breaks=breaks1,equidist=F,plot=FALSE,right=TRUE)\nbinned.k2=hist1$mids\nbinned.k=ifelse\\(is.na\\(binned.k),binned.k2,binned.k)\nbinned.k=ifelse\\(binned.k==0,binned.k2,binned.k)\nfreq1=ifelse\\(is.na\\(freq1),0,freq1)\nxx= as.vector\\(log10\\(binned.k))\nif\\(removeFirst) \\{freq1=freq1\\[-1]; xx=xx\\[-1]}\nplot\\(xx,log10\\(freq1+.000000001),xlab=\"log10\\(k)\",ylab=\"log10\\(p\\(k))\" )\nlm1= lm\\(as.numeric\\(log10\\(freq1+.000000001))~ xx )\nlm2=lm\\(as.numeric\\(log10\\(freq1+.000000001))~ xx+I\\(10^xx) )\ndatout\\[i,2]=summary\\(lm1)$adj.r.squared\ndatout\\[i,3]=summary\\(lm1)$coefficients\\[2,1]\ndatout\\[i,4]=summary\\(lm2)$adj.r.squared\ndatout\\[i,5]=mean\\(nolinkshelp)\ndatout\\[i,6]= median\\(nolinkshelp)\ndatout\\[i,7]= max\\(nolinkshelp)\n}\ndatout=signif\\(datout,3)\nprint\\(data.frame\\(datout));\n# the cut-off is chosen as smallest cut with R^2>RsquaredCut\nind1=datout\\[,2]>RsquaredCut\nindcut=NA\nindcut=ifelse\\(sum\\(ind1)>0,min\\(c\\(1:length\\(ind1))\\[ind1]),indcut)\n# this estimates the power value that should be used.\n# Don't trust it. You need to consider slope and mean connectivity as well\\!",
    "power.estimate=powervector\\[indcut]\\[1]\nlist\\(power.estimate, data.frame\\(datout));\n}\nTOMdist1=function\\(adjmat1, maxADJ=FALSE) \\{\ndiag\\(adjmat1)=0;\nadjmat1\\[is.na\\(adjmat1)]=0;\nmaxh1=max\\(as.dist\\(adjmat1) ); minh1=min\\(as.dist\\(adjmat1) );\nif \\(maxh1>1 | minh1 < 0 ) \\{print\\(paste\\(\"ERROR: the adjacency matrix contains entries that are larger than 1 or smaller than 0\\!\\!\\!, max=\",maxh1,\", min=\",minh1)) } else \\{\nif \\( max\\(c\\(as.dist\\(abs\\(adjmat1-t\\(adjmat1)))))>0 ) \\{print\\(\"ERROR: non-symmetric adjacency matrix\\!\\!\\!\") } else \\{\nkk=apply\\(adjmat1,2,sum)\nmaxADJconst=1\nif \\(maxADJ==TRUE) maxADJconst=max\\(c\\(as.dist\\(adjmat1 )))\nDhelp1=matrix\\(kk,ncol=length\\(kk),nrow=length\\(kk))\ndenomTOM= pmin\\(as.dist\\(Dhelp1),as.dist\\(t\\(Dhelp1))) +as.dist\\(maxADJconst-adjmat1);\ngc\\();gc\\();\nnumTOM=as.dist\\(adjmat1 %*% adjmat1 +adjmat1);\n#TOMmatrix=numTOM/denomTOM\n# this turns the TOM matrix into a dissimilarity\nout1=1-as.matrix\\(numTOM/denomTOM)\ndiag\\(out1)=1\nout1\n} \n}\n}\nmakeNetwork = function\\(dat,beta,signed=0)\\{\nif\\(signed==0)\\{\na = abs\\(cor\\(dat,use=\"p\")^beta)\nt = TOMdist1\\(a)\nreturn\\(hclust\\(as.dist\\(t),method=\"av\"))\n}else\\{\na = cor\\(dat,use=\"p\")\nb = a < 0\na\\[b] = 0\na = a^beta\nt = TOMdist1\\(a)\nreturn\\(hclust\\(as.dist\\(t),method=\"av\"))\n}\n}\ncutreeDynamic = function\\(hierclust, maxTreeHeight=1, deepSplit=TRUE, minModuleSize=50, minAttachModuleSize=100, nameallmodules=FALSE, useblackwhite=FALSE)\n\\{\nif\\(maxTreeHeight >=1)\\{\nstaticCutCluster = cutTreeStatic\\(hiercluster=hierclust, heightcutoff=0.99, minsize1=minModuleSize)\n}else\\{\nstaticCutCluster = cutTreeStatic\\(hiercluster=hierclust, heightcutoff=maxTreeHeight, minsize1=minModuleSize)\n}\n#get tree height for every singleton\n#node_index tree_height\ndemdroHeiAll= rbind\\( cbind\\(hierclust$merge\\[,1], hierclust$height), cbind\\(hierclust$merge\\[,2], hierclust$height) )\n#singletons will stand at the front of the list\nmyorder = order\\(demdroHeiAll\\[,1])\n#get # of singletons\nno.singletons = length\\(hierclust$order)\ndemdroHeiAll.sort = demdroHeiAll\\[myorder, ]\ndemdroHei.sort = demdroHeiAll.sort\\[c\\(1:no.singletons), ]\ndemdroHei = demdroHei.sort\\[seq\\(no.singletons, 1, by=-1), ]\ndemdroHei\\[,1] = -demdroHei\\[,1]\n# combine with prelimilary cluster-cutoff results\ndemdroHei = cbind\\(demdroHei, as.integer\\(staticCutCluster))\n# re-order the order based on the dendrogram order hierclust$order\ndemdroHei.order = demdroHei\\[hierclust$order, ]\nstatic.clupos = locateCluster\\(demdroHei.order\\[, 3])\nif \\(is.null\\(static.clupos) )\\{\nmodule.assign = rep\\(0, no.singletons)\ncolcode.reduced = assignModuleColor\\(module.assign, minsize1=minModuleSize, anameallmodules=nameallmodules, auseblackwhite=useblackwhite)\nreturn \\( colcode.reduced )\n}\nstatic.no = dim\\(static.clupos)1\nstatic.clupos2 = static.clupos\nstatic.no2 = static.no\n#split individual cluster if there are sub clusters embedded\nmcycle=1\nwhile\\(1==1)\\{\nclupos = NULL\nfor \\(i in c\\(1:static.no))\\{\nmydemdroHei.order = demdroHei.order\\[ c\\(static.clupos\\[i,1]:static.clupos\\[i,2]), ] #index to \\[1, clusterSize]\nmydemdroHei.order\\[, 1] = mydemdroHei.order\\[, 1] - static.clupos\\[i, 1] + 1\n#cat\\(\"Cycle \", as.character\\(mcycle), \"cluster \\(\", static.clupos\\[i,1], static.clupos\\[i,2], \")\\n\")\n#cat\\(\"i=\", as.character\\(i), \"\\n\")\niclupos = processInvididualCluster\\(mydemdroHei.order,\ncminModuleSize = minModuleSize,",
    "cminAttachModuleSize = minAttachModuleSize)\niclupos\\[,1] = iclupos\\[,1] + static.clupos\\[i, 1] -1 #recover the original index\niclupos\\[,2] = iclupos\\[,2] + static.clupos\\[i, 1] -1\nclupos = rbind\\(clupos, iclupos) #put in the final output buffer\n}\nif\\(deepSplit==FALSE)\\{\nbreak\n}\nif\\(dim\\(clupos)1 \\!= static.no) \\{\nstatic.clupos = clupos\nstatic.no = dim\\(static.clupos)1\n}else\\{\nbreak\n}\nmcycle = mcycle + 1\n#static.clupos\n}\nfinal.cnt = dim\\(clupos)1\n#assign colors for modules\nmodule.assign = rep\\(0, no.singletons)\nmodule.cnt=1\nfor \\(i in c\\(1:final.cnt ))\n\\{\nsdx = clupos\\[i, 1] #module start point\nedx = clupos\\[i, 2] #module end point\nmodule.size = edx - sdx +1\nif\\(module.size <minModuleSize)\\{\nnext\n}\n#assign module lable\nmodule.assign\\[sdx:edx] = rep\\(module.cnt, module.size)\n#update module label for the next module\nmodule.cnt = module.cnt + 1\n}\ncolcode.reduced.order = assignModuleColor\\(module.assign, minsize1=minModuleSize, anameallmodules=nameallmodules, auseblackwhite=useblackwhite)\nrecov.order = order\\( demdroHei.order\\[,1])\ncolcode.reduced = colcode.reduced.order\\[recov.order]\nif\\(1==2)\\{\naveheight = averageSequence\\(demdroHei.order\\[,2], 2)\nprocHei = demdroHei.order\\[,2]-mean\\(demdroHei.order\\[,2])\npar\\(mfrow=c\\(3,1), mar=c\\(0,0,0,0) )\nplot\\(h1row, labels=F, xlab=\"\",ylab=\"\",main=\"\",sub=\"\",axes = F)\nbarplot\\(procHei,\ncol= \"black\", space=0,\nborder=F,main=\"\", axes = F, axisnames = F)\nbarplot\\(height=rep\\(1, length\\(colcode.reduced)),\ncol= as.character\\(colcode.reduced\\[h1row$order]), space=0,\nborder=F,main=\"\", axes = F, axisnames = F)\npar\\(mfrow=c\\(1,1), mar=c\\(5, 4, 4, 2) + 0.1)\n}\ncolcode.reduced\n}\ncutTreeStatic = function\\(hiercluster,heightcutoff=0.99, minsize1=50) \\{\n# here we define modules by using a height cut-off for the branches\nlabelpred= cutree\\(hiercluster,h=heightcutoff)\nsort1=-sort\\(-table\\(labelpred))\nsort1\nmodulename= as.numeric\\(names\\(sort1))\nmodulebranch= sort1 >= minsize1\nno.modules=sum\\(modulebranch)\ncolorhelp = rep\\(-1, length\\(labelpred) )\nif \\( no.modules==0)\\{\nprint\\(\"No module detected\")\n}\nelse\\{\nfor \\(i in c\\(1:no.modules)) \\{\ncolorhelp=ifelse\\(labelpred==modulename\\[i],i ,colorhelp)\n}\n}\ncolorhelp\n}\nlocateCluster = function\\(clusterlabels)\n\\{\nno.nodes = length\\(clusterlabels)\nclusterlabels.shift = c\\(clusterlabels1, c\\(clusterlabels\\[1:\\(no.nodes-1)]) )\n#a non-zero point is the start point of a cluster and it previous point is the end point of the previous cluster\nlabel.diff = abs\\(clusterlabels - clusterlabels.shift)\n#process the first and last positions as start/end points if they belong to a cluster instead of no cluster \"-1\"\nif\\(clusterlabels1 >0) \\{label.diff1=1}\nif\\(clusterlabels\\[no.nodes]>0) \\{label.diff\\[no.nodes]=1}",
    "flagpoints.bool = label.diff > 0\nif\\( sum\\(flagpoints.bool) ==0)\\{\nreturn\\(NULL)\n}\nflagpoints = c\\(1:no.nodes)\\[flagpoints.bool]\nno.points = length\\(flagpoints)\nmyclupos=NULL\nfor\\(i in c\\(1:\\(no.points-1)) )\\{\nidx = flagpoints\\[i]\nif\\(clusterlabels\\[idx]>0)\\{\nmyclupos = rbind\\(myclupos, c\\(idx, flagpoints\\[i+1]-1) )\n}\n}\nmyclupos\n}\nprocessInvididualCluster = function\\(clusterDemdroHei, cminModuleSize=50, cminAttachModuleSize=100, minTailRunlength=12, useMean=0)\\{\n#for debug: use all genes\n#clusterDemdroHei =demdroHei.order\nno.cnodes = dim\\(clusterDemdroHei)1\ncmaxhei = max\\(clusterDemdroHei\\[, 2])\ncminhei = min\\(clusterDemdroHei\\[, 2])\ncmeanhei = mean\\(clusterDemdroHei\\[, 2])\ncmidhei = \\(cmeanhei + cmaxhei)/2.0\ncdwnhei = \\(cmeanhei + cminhei)/2.0\nif \\(useMean==1)\\{\ncomphei = cmidhei\n}else if \\(useMean==-1)\\{\ncomphei = cdwnhei\n}else\\{ #normal case\ncomphei = cmeanhei\n}\n# compute height diffrence with mean height\nheidiff = clusterDemdroHei\\[,2] - comphei\nheidiff.shift = shiftSequence\\(heidiff, -1)\n# get cut positions\n# detect the end point of a cluster, whose height should be less than meanhei\n# and the node behind it is the start point of the next cluster which has a height above meanhei\ncuts.bool = \\(heidiff<0) & \\(heidiff.shift > 0)\ncuts.bool1 = TRUE\ncuts.bool\\[no.cnodes] = TRUE\nif\\(sum\\(cuts.bool)==2)\\{\nif \\(useMean==0)\\{\nnew.clupos=processInvididualCluster\\(clusterDemdroHei=clusterDemdroHei, cminModuleSize=cminModuleSize,\ncminAttachModuleSize=cminAttachModuleSize,\nuseMean=1)\n}else if\\(useMean==1)\\{\nnew.clupos=processInvididualCluster\\(clusterDemdroHei=clusterDemdroHei, cminModuleSize=cminModuleSize,\ncminAttachModuleSize=cminAttachModuleSize,\nuseMean=-1)\n}else\\{\nnew.clupos = rbind\\(c\\(1, no.cnodes))\n}\nreturn \\(new.clupos)\n}\n#a good candidate cluster-end point should have significant # of ahead nodes with head < meanHei\ncutindex =c\\(1:no.cnodes)\\[cuts.bool]\nno.cutps = length\\(cutindex)\nrunlens = rep\\(999, no.cutps)\ncuts.bool2 = cuts.bool\nfor\\(i in c\\(2:\\(no.cutps-1)) )\\{\nseq = c\\( \\(cutindex\\[i-1]+1):cutindex\\[i] )\nrunlens\\[i] = runlengthSign\\(heidiff\\[seq], leftOrright=-1, mysign=-1)\nif\\(runlens\\[i] < minTailRunlength)\\{\n#cat\\(\"run length=\", runlens\\[i], \"\\n\")\ncuts.bool2\\[ cutindex\\[i] ] = FALSE\n}\n}\n#attach SMALL cluster to the left-side BIG cluster if the small one has smaller mean height\ncuts.bool3=cuts.bool2\nif\\(sum\\(cuts.bool2) > 3) \\{\ncurj = 2\nwhile \\(1==1)\\{\ncutindex2 =c\\(1:no.cnodes)\\[cuts.bool2]\nno.clus = length\\(cutindex2) -1\nif \\(curj>no.clus)\\{\nbreak\n}\npre.sdx = cutindex2\\[ curj-1 ]+1 #previous module start point\npre.edx = cutindex2\\[ curj ] #previous module end point\npre.module.size = pre.edx - pre.sdx +1",
    "pre.module.hei = mean\\(clusterDemdroHei\\[c\\(pre.sdx:pre.edx) , 2])\ncur.sdx = cutindex2\\[ curj ]+1 #previous module start point\ncur.edx = cutindex2\\[ curj+1 ] #previous module end point\ncur.module.size = cur.edx - cur.sdx +1\ncur.module.hei = mean\\(clusterDemdroHei\\[c\\(cur.sdx:cur.edx) , 2])\n#merge to the leftside major module, don't change the current index \"curj\"\n#if\\( \\(pre.module.size >minAttachModuleSize)&\\(cur.module.hei<pre.module.hei)&\\(cur.module.size<minAttachModuleSize) )\\{\nif\\( \\(cur.module.hei<pre.module.hei)&\\(cur.module.size<cminAttachModuleSize) )\\{\ncuts.bool2\\[ cutindex2\\[curj] ] = FALSE\n}else\\{ #consider next cluster\ncurj = curj + 1\n}\n}#while\n}#if\ncutindex2 =c\\(1:no.cnodes)\\[cuts.bool2]\nno.cutps = length\\(cutindex2)\n#we don't want to lose the small cluster at the tail, attch it to the previous big cluster\n#cat\\(\"Lclu= \", cutindex2\\[no.cutps]-cutindex2\\[no.cutps-1]+1, \"\\n\")\nif\\(no.cutps > 2)\\{\nif\\( \\(cutindex2\\[no.cutps] - cutindex2\\[no.cutps-1]+1) < cminModuleSize )\\{\ncuts.bool2\\[ cutindex2\\[no.cutps-1] ] =FALSE\n}\n}\nif\\(1==2)\\{\nmyseqnce = c\\(2300:3000)\ncutdisp = ifelse\\(cuts.bool2==T, \"red\",\"grey\" )\n#re-order to the normal one with sequential signleton index\npar\\(mfrow=c\\(3,1), mar=c\\(0,0,0,0) )\nplot\\(h1row, labels=F, xlab=\"\",ylab=\"\",main=\"\",sub=\"\",axes = F)\nbarplot\\(heidiff\\[myseqnce],\ncol= \"black\", space=0,\nborder=F,main=\"\", axes = F, axisnames = F)\nbarplot\\(height=rep\\(1, length\\(cutdisp\\[myseqnce])),\ncol= as.character\\(cutdisp\\[myseqnce]), space=0,\nborder=F,main=\"\", axes = F, axisnames = F)\npar\\(mfrow=c\\(1,1), mar=c\\(5, 4, 4, 2) + 0.1)\n}\ncutindex2 = c\\(1:no.cnodes)\\[cuts.bool2]\ncutindex21=cutindex21-1 #the first\nno.cutps2 = length\\(cutindex2)\nif\\(no.cutps2 > 2)\\{\nnew.clupos = cbind\\( cutindex2\\[c\\(1:\\(no.cutps2-1))]+1, cutindex2\\[c\\(2:no.cutps2)] )\n}else\\{\nnew.clupos = cbind\\( 1, no.cnodes)\n}\nif \\( dim\\(new.clupos)1 == 1 )\\{\nif \\(useMean==0)\\{\nnew.clupos=processInvididualCluster\\(clusterDemdroHei=clusterDemdroHei, cminModuleSize=cminModuleSize,\ncminAttachModuleSize=cminAttachModuleSize,\nuseMean=1)\n}else if\\(useMean==1)\\{\nnew.clupos=processInvididualCluster\\(clusterDemdroHei=clusterDemdroHei, cminModuleSize=cminModuleSize,\ncminAttachModuleSize=cminAttachModuleSize,\nuseMean=-1)\n}\n}\nnew.clupos\n}\nshiftSequence = function\\(mysequence, delta)\\{\nseqlen = length\\(mysequence)\nif\\(delta>0)\\{\nfinalseq=c\\(mysequence\\[1:delta], mysequence\\[1:\\(seqlen-delta)])\n}else\\{\nposdelta = -delta\nfinalseq=c\\(mysequence\\[\\(posdelta+1):seqlen], mysequence\\[\\(seqlen-posdelta+1):seqlen])\n}\nfinalseq\n}\nrunlengthSign = function\\(mysequence, leftOrright=-1, mysign=-1)\\{\nseqlen = length\\(mysequence)\nif\\(leftOrright<0)\\{\npseq = rev\\(mysequence)\n}else\\{\npseq = mysequence\n}\nif\\(mysign<0)\\{ #see where the first POSITIVE number occurs\nnonezero.bool = \\(pseq > 0)\n}else\\{ #see where the first NEGATIVE number occur\nnonezero.bool = \\(pseq < 0)\n}\nif\\( sum\\(nonezero.bool) > 0)\\{\nrunlength = min\\( c\\(1:seqlen)\\[nonezero.bool] ) - 1\n}else\\{\nrunlength = 0\n}\n}",
    "assignModuleColor = function\\(labelpred, minsize1=50, anameallmodules=FALSE, auseblackwhite=FALSE) \\{\n# here we define modules by using a height cut-off for the branches\n#labelpred= cutree\\(hiercluster,h=heightcutoff)\n#cat\\(labelpred)\n#\"0\", grey module doesn't participate color assignment, directly assigned as \"grey\"\nlabelpredNoZero = labelpred\\[ labelpred >0 ]\nsort1=-sort\\(-table\\(labelpredNoZero))\nsort1\nmodulename= as.numeric\\(names\\(sort1))\nmodulebranch= sort1 >= minsize1\nno.modules=sum\\(modulebranch)\n# now we assume that there are fewer than 10 modules\n#colorcode=c#\\(\"turquoise\",\"blue\",\"brown\",\"yellow\",\"green\",\"red\",\"black\",\"purple\",\"orange\",\"pink\",\n#\"greenyellow\",\"lightcyan\",\"salmon\",\"midnightblue\",\"lightyellow\",\"chartreuse\",\n\"chocolate\",\"gold\",\"springgreen\",\"tan\",\"violet\",\"plum\",\"aliceblue\",\"aquamarine\",\n\"azure\",\"bisque\",\"burlywood\",\"coral\",\"cornsilk\",\"cyan\",\"darkorchid\",\"deeppink\",\n\"firebrick\",\"forestgreen\",\"gainsboro\",\"wheat\")\norderofcolors = order\\(runif\\(length\\(colors\\())))\ncolorcode = colors\\()\ncolorcode = colorcode\\[orderofcolors]\nnotgrey = substr\\(colorcode,1,4) \"gray\" | substr\\(colorcode,1,4) \"grey\"\ncolorcode = colorcode\\[\\!notgrey]\n#\"grey\" means not in any module;\ncolorhelp=rep\\(\"grey\",length\\(labelpred))\nif \\( no.modules==0)\\{\nprint\\(\"No module detected\\n\")\n}\nelse\\{\nif \\( no.modules > length\\(colorcode) )\\{\nprint\\(length\\(colorcode))\nprint\\( paste\\(\"Too many modules \\n\", as.character\\(no.modules)) )\n}\nif \\( \\(anameallmodules==FALSE) || \\(no.modules <=length\\(colorcode)) )\\{\nlabeledModules = min\\(no.modules, length\\(colorcode) )\nfor \\(i in c\\(1:labeledModules)) \\{\ncolorhelp=ifelse\\(labelpred==modulename\\[i],colorcode\\[i],colorhelp)\n}\ncolorhelp=factor\\(colorhelp,levels=c\\(colorcode\\[1:labeledModules],\"grey\"))\n}else\\{#nameallmodules==TRUE and no.modules >length\\(colorcode)\nmaxcolors=length\\(colorcode)\nlabeledModules = no.modules\nextracolors=NULL\nblackwhite=c\\(\"red\", \"black\")\nfor\\(i in c\\(\\(maxcolors+1):no.modules))\\{\nif\\(auseblackwhite==FALSE)\\{\nicolor=paste\\(\"module\", as.character\\(i), sep=\"\")\n}else\\{#use balck white alternatively represent extra colors, for display only\n#here we use the ordered label to avoid put the same color for two neighboring clusters\nicolor=blackwhite\\[1+\\(as.integer\\(modulename\\[i])%%2) ]\n}\nextracolors=c\\(extracolors, icolor)\n}\n#combine the true-color code and the extra colorcode into a uniform colorcode for\n#color assignment\nallcolorcode=c\\(colorcode, extracolors)\nfor \\(i in c\\(1:labeledModules)) \\{\ncolorhelp=ifelse\\(labelpred==modulename\\[i],allcolorcode\\[i],colorhelp)\n}\ncolorhelp=factor\\(colorhelp,levels=c\\(allcolorcode\\[1:labeledModules],\"grey\"))\n}\n}\ncolorhelp\n}\nhclustplot1=function\\(hier1,couleur,title1=\"Colors sorted by hierarchical clustering\") \\{\nif \\(length\\(hier1$order) \\!= length\\(couleur) ) \\{\nprint\\(\"ERROR: length of color vector not compatible with no. of objects in the hierarchical tree\")};\nif \\(length\\(hier1$order) == length\\(couleur) ) \\{\nbarplot\\(height=rep\\(1, length\\(couleur)), col= as.character\\(couleur\\[hier1$order]),border=NA, main=title1,space=0, axes=F)}\n}\nplotDend=function\\(clust,colorh)\\{\npar\\(mfrow=c\\(2,1),mar=c\\(2,2,2,2))\nplot\\(clust,labels=F)\nhclustplot1\\(clust,colorh)\n}\nMakeVis = function\\(data,colorMod,vis.dir,pwr1,symbols)\\{\nq = table\\(colorMod)\nn = length\\(q)\nfor\\(i in c\\(1:n))\\{\nif\\(names\\(q\\[i]) \\!= \"grey\")\\{\ncollect_garbage\\()\nnewNet = pairwiseCode\\(data\\[,colorMod==names\\(q\\[i])],filename=paste\\(vis.dir,names\\(q\\[i]),\".txt\",sep=\"\"),pwr=pwr1,geneAnnot=symbols,this.col=names\\(q\\[i]))\nprint\\(q\\[i])\nif\\(\\!exists\\(\"newNetwork\"))\\{\nnewNetwork = newNet\n} else \\{\nnewNetwork = rbind\\(newNetwork,newNet)\n}\n}\n}\nreturn\\(newNetwork)\n}\nMakePlots = function\\(data,colorMod,plots.dir)\\{\nPC = ModulePrinComps1\\(data,colorMod)",
    "q = table\\(colorMod)\nn = length\\(q)\nu = q > 1\nfor\\(i in c\\(1:n))\\{\nif\\(u\\[i])\\{\nc = dimnames\\(PC\\[1])\\[2]\nindC = substr\\(c\\[i],3,25)\nfilename = paste\\(plots.dir,indC,\".png\",sep=\"\")\npng\\(filename)\nshowHeat\\(indC,data,colorMod,PC)\ndev.off\\()\nprint\\(paste\\(filename,\" printed to file\"))\n}else\\{\nindC = substr\\(c\\[i],3,25)\nprint\\(paste\\(filename,\" only contains 1 gene\"))\n}\n}\n}\nshowHeat = function\\(color,data,colorh,PC)\\{\nq = table\\(colorh)\nz = names\\(q) == color\nProbe_sets = dimnames\\(data)\\[2]\npar\\(mfrow=c\\(2,1),mar=c\\(2,2,2,2))\npar\\(mar=c\\(2,3,7,3))\npar\\(oma=c\\(0,0,2,0))\ndatcombined=data.frame\\(rbind\\(data\\[,colorh==color]))\nsamplelabel=as.character\\(dimnames\\(data)\\[1])\nplot.mat\\(t\\(scale\\(datcombined)), rlabels=as.character\\(Probe_sets\\[colorh==color]), clabels=samplelabel, rcols=color)\npar\\(mar=c\\(2,2,0,2))\nbarplot\\(PC\\[1]\\[,z],space=0,beside=TRUE,axes=FALSE,col=color)\n}\nModulePrinComps1=function\\(datexpr,couleur) \\{\nmodlevels=levels\\(factor\\(couleur))\nPrinComps=data.frame\\(matrix\\(666,nrow=dim\\(datexpr)\\[1],ncol= length\\(modlevels)))\nvarexplained= data.frame\\(matrix\\(666,nrow= 5,ncol= length\\(modlevels)))\nnames\\(PrinComps)=paste\\(\"PC\",modlevels,sep=\"\")\nfor\\(i in c\\(1:length\\(modlevels)) )\\{\nprint\\(i)\nmodulename = modlevels\\[i]\nrestrict1= as.character\\(couleur)== modulename\n# in the following, rows are genes and columns are samples\ndatModule=t\\(datexpr\\[, restrict1])\ndatModule=impute.knn\\(as.matrix\\(datModule))\ndatModule=t\\(scale\\(t\\(datModule)))\nsvd1=svd\\(datModule)\nmtitle=paste\\(\"PCs of \", modulename,\" module\", sep=\"\")\nvarexplained\\[,i]= \\(svd1$d\\[1:5])2/sum\\(svd1$d2)\n# this is the first principal component\npc1=svd1$v\\[,1]\nsignh1=sign\\(sum\\(cor\\(pc1, t\\(datModule))))\nif \\(signh1 \\!= 0) pc1=signh1* pc1\nPrinComps\\[,i]= pc1\n}\nModuleConformity= rep\\(666,length=dim\\(datexpr)\\[2])\nfor\\(i in 1:\\(dim\\(datexpr)\\[2])) ModuleConformity\\[i]=abs\\(cor\\(datexpr\\[,i], PrinComps\\[,match\\(couleur\\[i], modlevels)], use=\"pairwise.complete.obs\"))\nlist\\(PrinComps=PrinComps, varexplained=varexplained, ModuleConformity=ModuleConformity)\n}\npairwiseCode = function\\(vals,filename=\"forvis.txt\",pwr,geneAnnot,links=1000,this.col)\\{\nn = dimnames\\(vals)\\[2]\nnewPC = ModulePrinComps1\\(vals,rep\\(\"black\",dim\\(vals)\\[2]))\nnewSim = cor\\(vals,use=\"p\")\nnewAdj = abs\\(newSim^pwr)\ndiag\\(newAdj) = 0\nnewDeg = apply\\(newAdj,1,sum)\nnewDeg = newDeg/max\\(newDeg)\nnewKme = cor\\(vals,newPC\\[1]\\[,1],use=\"p\")\nnewTom = TOMdist1\\(newAdj)\nnewTom = 1-newTom\nsz = dim\\(newAdj)\\[1]\nTomList = vector\\(\"logical\",sz^2)\nfor\\(j in c\\(1:sz))\\{\nTomList\\[ \\(\\(\\(j-1)**sz)+1) : \\(\\(j**sz)) ] = newTom\\[,j]\n}\nord = order\\(TomList,decreasing=TRUE)\nif\\(length\\(n) > 33)\\{\nlen = links\n} else \\{\nlen = length\\(n)^2\n}\nfirst = ord\\[1:len] %/% sz + 1\nsecond = ord\\[1:len] %% sz\nsec = second == 0\nfirst\\[sec] = first\\[sec]-1\nsecond\\[sec] = sz\nid = geneAnnot\\[n,2]\ndatout = matrix\\(0,len,6)\nfor\\(j in c\\(1:len))\\{\ndatout\\[j,1] = paste\\(id\\[first\\[j]])\ndatout\\[j,2] = paste\\(id\\[second\\[j]])\ndatout\\[j,3] = 0\nif\\(newSim\\[first\\[j],second\\[j]] > 0)\\{\ndatout\\[j,4] = as.character\\(\"M0011\")\n} else \\{\ndatout\\[j,4] = as.character\\(\"M0015\")\n}\ndatout\\[j,5] = TomList\\[ord\\[j]]\ndatout\\[j,6] = newSim\\[first\\[j],second\\[j]]\n}\nwrite.table\\(datout,file=filename,sep=\"\\t\")\nreturn\\(cbind\\(n,newDeg\\[n],as.numeric\\(newKme\\[n,1]),as.character\\(geneAnnot\\[n,2]),this.col))\n}\nmodpcas = function\\(dat,mod)\\{\nq = names\\(table\\(mod))\nu = vector\\(\"list\",length\\(q))\nd = vector\\(\"list\",length\\(q))\nv = vector\\(\"list\",length\\(q))\nnames\\(u) = q\nnames\\(d) = q\nnames\\(v) = q",
    "for\\(i in c\\(1:length\\(q)))\\{\nb = mod == q\\[i]\nimpDat = impute.knn\\(as.matrix\\(dat\\[names\\(mod\\[b]),]))\nsclDat = t\\(scale\\(t\\(impDat)))\nsvdDat = svd\\(sclDat)\nfor\\(j in c\\(1:min\\(dim\\(dat)))\\{\nsignh1 = sign\\(sum\\(cor\\(svdDat$v\\[,j],t\\(sclDat))))\nif\\(signh1 \\!= 0)\\{\nsvdDat$v\\[,j]=signh1*svdDat$v\\[,j]\nsvdDat$u\\[,j]=signh1*svdDat$u\\[,j]\n}\nu\\[\\[i]] = svdDat$u\ndimnames\\(u\\[\\[i]])\\[1] = names\\(mod\\[b])\nd\\[\\[i]] = svdDat$d\nv\\[\\[i]] = svdDat$v\n}\n}\nreturn\\(list\\(u=u,d=d,v=v))\n}\nremovePC = function\\(pc,start)\\{\ndat = vector\\(\"logical\",dim\\(pc$v\\[1])\\[1])\nfor\\(i in c\\(1:length\\(pc$u)))\\{\nend = dim\\(pc$u)\\[2]\nD = diag\\(pc$d\\[\\[i]])\ne = pc$u\\[\\[i]]\\[,start:end] %**% D\\[start:end,start:end] %**% t\\(pc$v\\[\\[i]]\\[,start:end])\ndat = rbind\\(dat,e)\n}\nreturn\\(dat\\[2:dim\\(dat)\\[1],])\n}\n###Description of variables\nnormalizedData – the normalized microarray data with genes in rows and samples in columns, should also have gene identifiers for row names\npower_to_scale_connections – obtained with guidance from PickSoftThreshold \\(below), see Zhang et al., \\(2005) for more information\ngeneAnnotation – matrix with gene names in the second column and gene identifiers as row names\n###Create the co-expression network\nPickSoftThreshold\\(t\\(normalizedData))\npower_to_scale_connections = 6\ngenesClusteredOnTO = makeNetwork\\(t\\(normalizedData),power_to_scale_connections)\n###Identify modules and plot dendrogram\ngenesAssignedToModules = cutreeDynamic\\(genesClusteredOnTO)\nplotDend\\(genesClusteredOnTO,genesAssignedToModules)\n###Plot module heatmaps and make files for VisAnt\nMakePlots\\(normalizedData,genesAssignedToModules,”./heatmaps/”)\nNetwork = MakeVis\\(normalizedData,genesAssignedToModules,”./visant/”,geneAnnotation,power_to_scale_connections)\nwrite.table\\(Network,file=”network.csv”,sep=”,”)\n###Remove first principal component\nnames\\(genesAssignedToModules) = dimnames\\(normalizedData)\\[1]\nprincipalComponents = modpcas\\(normalizedData,genesAssignedToModules)\ndataWithoutFirstPrincipalComponent = removePC\\(principalComponents,2)\n4. ###This code is for calculating the hypergeomtric probability of the overlap of two datasets with permutations using R\n  hyperFast = function\\(pop1,subpop1,pop2,subpop2,perm,b=0)\\{\nif\\(b==1)\\{browser\\()}\np1 = seq\\(1,pop1,by=1)\np2 = seq\\(1,pop2,by=1)\nout = vector\\(mode=\"logical\",perm)\ni = 1\nwhile\\(i < perm)\\{\nover = sample\\(p1,subpop1) %in% sample\\(p2,subpop2)\nif\\(length\\(table\\(over)) > 1)\\{\nout\\[i] = table\\(over)\\[2]\n} else \\{\nout\\[i] = 0\n}\ni = i + 1\n}\nreturn\\(out)\n}\nx=hyperFast\\(a,b,c,d,e)\n#a=the total number of probesets in the first gene list\n#b=the total number of differentially expressed genes in the first gene list\n#c=the total number of probesets in the second gene list\n#d=the total number of differentially expressed genes in the second gene list\n#e=the number of permutations",
    "#to calculate Z-score, use the following, where f=the number of overlapping genes in the two lists:\ny=\\(f-mean\\(x))/sd\\(x)\n#to calucate a PValue for the Z-score:\nz=pnorm\\(y,log=TRUE)\n1-\\(2^z)"
  ],
  "subjectAreas": [
    "Biotechnology",
    "Biochemistry"
  ],
  "bigAreas": [
    "Bioengineering & Technology",
    "Molecular Biology & Genetics"
  ]
}