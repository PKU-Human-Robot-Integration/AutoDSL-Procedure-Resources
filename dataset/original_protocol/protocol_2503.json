{
  "id": 2642,
  "origin_website": "Cell",
  "title": "Computational workflow for integrative analyses of DNA replication timing, epigenomic, and transcriptomic data",
  "procedures": [
    "Step-by-step method details\nStep-by-step method details\nMap sequencing reads from Repli-seq, ATAC-seq, ChIP-seq, CUT&RUN platforms\nTiming: 1–3 h per sample\nSequencing reads from FASTQ files are mapped to the reference genome of choice and alignment files in BAM format are generated along with basic data quality metrics.\nPerform alignment using bwa aln command:\nbwa aln path_to_reference_genome exp_R1.fq > exp_R1.sai\nbwa aln path_to_reference_genome exp_R2.fq > exp_R2.sai\nwhere path_to_reference_genome is the location of the pre-computed BWA index file, exp_R1.fq and exp_R2.fq are the names of the input fastq files with read 1 and read 2, respectively, exp_R1.sai and exp_R2.sai are the output files in the SAI format.\nWith .sai files generated at the previous step, produce genomic alignment in the SAM format using either\nbwa sampe command for paired-ended reads:\nbwa sampe path_to_reference_genome -f exp.sam exp_R1.sai exp_R2.sai exp_R1.fq exp_R2.fq\nor\nbwa samse for single-ended reads:\nbwa samse path_to_reference_genome -f exp.sam exp_R1.sai exp_R1.fq\nwhere exp.sam is the output alignment file in the SAM format.\nCompress and sort the resulting SAM alignment file into a BAM file exp.bam using samtools:\nsamtools view -bS -o exp.bam exp.sam\nUsing alignment BAM files, calculate read mapping rates for each sample:\nsamtools flagstat exp.bam\nSort the BAM file:\nsamtools sort -o exp.sort.bam exp.bam\nRemove duplicate reads and calculate duplication rates for each sample:\nsamtools rmdup exp.sort.bam exp.rmdup.bam\nwhere exp.rmdup.bam is the output BAM file with duplicates removed.\nGenerate bigwig files of genome-wide read density for each sample and input-normalized density for ChIP-seq samples.\nGenerate bigwig files with read density normalized by total number of reads for each alignment file:\nbamCoverage -b exp.bam -o exp.bw -e –normalizeUsingRPKM\nwhere exp.bw is the output bigwig file.\nCalculate genome-wide bigwig tracks of input-normalized ratio for ChIP-seq experiments:\nbamCompare -b1 ChIP.bam -b2 input.bam –ratio ratio -o ChIP.ratio.bw",
    "where ChIP.bam and input.bam are BAM alignment files generated at steps 4–6 for ChIP and input samples, respectively.\nMap RNA-seq sequencing reads\nTiming: 1–4 h per sample\nSequencing reads from FASTQ files are mapped to the reference genome of choice in a splice-aware fashion.\nRun STAR aligner to produce alignment BAM files using the following command:\nSTAR --genomeDir path_to_reference_genome \\\n--twopassMode Basic \\\n--readFilesIn path_to_fastq \\\n--outFileNamePrefix path_to_output \\\n--outSAMtype BAM SortedByCoordinate \\\n--outSAMstrandField intronMotif \\\nNote: Consecutive STAR jobs with the same reference genome can be run using shared memory using --genomeLoad LoadAndKeep command option, which saves the time required to load the reference index for each job.\nCalculate Repli-seq, ATAC-seq, ChIP-seq, CUT&RUN, and RNA-seq read density across the genome\nTiming: 0.5–1 h per sample\nReads mapped to the genome at the previous steps are counted in 50 Kb genomic bins across the genome, at the genomic resolution identical to the resolution of Repli-seq.\nCalculate coverage over 50 Kb genomic bins across the genome.\nDownload reference genome chromosome sizes and create 50 kb genomic bin file in BED format:\nmysql --user=genome --host=genome-mysql.cse.ucsc.edu -A -e “select chrom, size from hg19.chromInfo” > hg19.genome\nbedtools makewindows -g hg19.genome -w 50000 -s 50000 > hg19.50kb.bed\nwhere reference genome hg19 can be replaced by your reference genome.\nCalculate coverage over these genomic bins using all previously generated BAM alignment files with removed duplicates from step 6:\nmultiBamSummary BED-file –BED hg19.50kb.bed -b bam_list -out results.npz –outRawCounts output_rawCount.txt\nBam_list can be either single bam files (“chip1.bam”) or multiple space-delimited BAM file names from a batch of multiple samples (e.g., “chip1.bam chip2.bam”). For example, to simultaneously process Repli-seq samples from four time points S1-S4 in two replicate experiments sample1 and sample2, one can supply the list of eight BAM files:",
    "“RT_sample1_S1.bam RT_sample1_S2.bam RT_sample1_S3.bam RT_sample1_S4.bam RT_sample2_S1.bam RT_sample2_S2.bam RT_sample2_S3.bam RT_sample2_S4.bam”.\noutput_rawCount.txt is a tab-delimitated read count table with columns of all sample from bam_list coverage and rows of genomic bins from hg19.50 kb.bed.\nSort output count table by chromosome and starting positions of each genomic bin:\ncat output_rawCount.txt | sort -k1,1 -k2,2n > output_rawCount.sort.txt\nCritical: This step ensures the consistency of genomic bins in all rows in the integrated count tables of multiple samples that are used in downstream steps.\nRepeat steps 9 and 10 to calculate similar genomic coverage tables for ChIP-seq, ATAC-seq and RNA-seq samples.\nNote: To integrate RNA-seq into genomic analysis with ChIP-seq and Repli-seq data, we calculated RNA-seq reads density over genomic bins in addition to a more standard quantification of RNA-seq read density over transcripts.\nCall peaks of focused chromatin marks and chromatin accessibility regions, calculate peak density across the genome\nTiming: 0.5–1 h per sample\nUsing genome-wide alignments of ChIP-seq reads from ChIP and input DNA samples for focused chromatin marks (H3K27ac, H3K4me1-3 etc), define narrow peaks of mark enrichment across the genome. Run the HOMER tool using commands\nmakeTagDirectory HOMER_tag_directory path_to_bam_file\nfindPeaks HOMER_tag_directory -style histone\nTo quantify large-scale genomic density of these narrow peaks, calculate the number of peaks within +/-250 kb window near each original 50 kb genomic bin.\ncat peaks.txt | grep -v “#” | cut -f2-4 |bedtools window -w 250000 -a bin.bed -b - -c > peakCount.mark.txt\nRepeat steps 12 and 13 for bam files of all narrow histone marks and ATAC-seq data from steps 4–6.\nAssessment of quality and replicate consistency of Repli-seq, ATAC-seq, ChIP-seq, CUT&RUN data\nTiming: 1 h per replicate set",
    "Using alignments and read counts produced at the previous steps, basic data quality metrics are generated, replicates are assessed for the consistency of read counts over genomic bins and PCA plots were generated showing similarity between samples.\nOpen R and load the ‘preprocessCore’ package using the following command:\n> library(preprocessCore)\nRead the file with a table of read counts in genomic bins (produced at step 10), for example from file output_RT_rawCount.txt, and normalize these counts to produce the matrix of counts per million (CPM):\n> setwd(“path/to/files/”)\n> tab <- read.table(“output_RT_rawCount.txt“ , header=TRUE)\n> RT.bin.cnt <- as.matrix(tab[,-(1:3)])\n> bin.bed = tab[,1:3]\n> rownames(bin.bed) <- paste(“bin”,1:dim(bin.bed)[1],sep=””)\n> bin.bed$binID <- rownames(bin.bed)\n> RT.bin.cpm <- t(t(RT.bin.cnt)/(colSums(RT.bin.cnt)/1e6))\nUse the CPM matrix produced at the previous step to generate pairwise scatter plots comparing read counts over genomic bins between pairs of replicates, and calculate Pearson correlation coefficients between replicates:\n> plot(RT.bin.cpm[,”sample_1_S1”], RT.bin.cpm[,”sample_2_S1”],log=”xy”)\n>cor(log10(RT.bin.cpm[,”sample_1_S1”]+0.01), log10(RT.bin.cpm[,”sample_1_S1”]+0.01))\nUse the CPM matrix produced at step 15 to perform PCA analysis over all samples\n> pca <- prcomp(t(log10(RT.bin.cpm+0.01)))\n> plot(pca$x[,1],pca$x[,2],type=”n”,xlab=”PC1”,ylab=”PC2”)\n> text(pca$x[,1],pca$x[,2],rownames(pca$x))\nPerform steps 15–17 to import and analyze genomic coverage tables produced at steps 9 and 10 for Repli-seq, ChIP-seq, and ATAC-seq samples.\nPerform quantile normalization of Repli-seq, ATAC-seq, ChIP-seq, CUT&RUN signals across the genome\nTiming: 0.5–1 h per sample",
    "To allow for the comparison between conditions and mitigate possible differences in the dynamic range of individual samples, we recommend quantile normalization similar to (Marchal et al., 2018[href=https://www.wicell.org#bib8]). For the analyses at the resolution of 50 Kb similar to the resolution of Repli-seq, this normalization is followed by Loess smoothing of the genomic tracks. Quantile normalization is based on the assumption that signal intensity is not being systematically increased or reduced across the bulk of the genome in one condition compared to the other. Therefore, it is not appropriate to apply quantile normalization when this assumption is violated, for example, when a chromatin mark is expected to be systematically depleted compared to control across the genome.\nPerform quantile normalization on multiple samples of the same nature (e.g., replicate Repli-seq experiments). We recommend normalizing different RT time points separately:\n> RT.bin.S1.norm <- normalize.quantiles(RT.bin.cpm[,c(“RPE.ct1.S1”,”RPE.ct2.S1”,”RPE.4A1.S1”,”RPE.4A2.S1”)])\n> RT.bin.S2.norm <- normalize.quantiles(RT.bin.cpm[,c(“RPE.ct1.S2”,”RPE.ct2.S2”,”RPE.4A1.S2”,”RPE.4A2.S2”)])\nRepeat step 18 to normalize Repli-seq coverage for each time point, then combine all quantile-normalized Repli-seq counts (for example, counts for four time points S1-S4) into a single matrix:\n> RT.bin.norm <- cbind(RT.bin.S1.norm, RT.bin.S2.norm, RT.bin.S3.norm, RT.bin.S4.norm)\nRun Loess smoothing of the resulting normalized tracks and write smoothened values in the output wig files, separate for each sample:\n> RT.bin.loess <- RT.bin.norm #initialization\n> for(i in 1:dim(RT.bin.norm)[2]){\n  for(chr in unique(bin.bed[,1])){\n    idx <- which(bin.bed[,1]==chr)\n    x <- RT.bin.bed[idx,2]\n    y <- RT.bin.norm[idx,i]\n    lspan <-500000/(max(bin_crd[idx])-min(bin_crd[idx]))\n    Rpla <- loess(y ∼ x, span=lspan)\n    RT.bin.loess[idx,i] <- Rpla$fitted\n  }\n}\n> RT.bin.loess [RT.bin.loess <0]=0\n(Optional) If necessary, perform quantile normalization steps 18–20 for the data from any other experimental platform (ChIP-seq, ATAC-seq, or RNA-seq), using the corresponding CPM file generated at step 15 as input.\nAnnotate chromatin states across the genome\nTiming: 2–4 h per dataset",
    "Aggregate analyses of multiple chromatin marks across the genome reveal recurring combinations of co-localized marks that often correspond to specific genomic elements and functions, such as active or repressed promoters, enhancers, actively transcribed gene bodies, regions of compacted heterochromatin, etc. These combinatory patterns of chromatin marks are termed “chromatin states”.\nBased on the combinations of levels of histone marks, define and annotate chromatin states at a standard 1 Kb resolution and a lower 50 Kb resolution similar to the resolution of Repli-seq. In Linux, use chromHMM command:\nBinarize genome coverage from multiple ChIP-seq BAM files for histone marks into the presence/absence calls at either 50 kb or 1 kb resolution.\njava -mx4000M -jar ChromHMM.jar BinarizeBam -b bin_size ChromHMM/CHROMSIZES/hg19.txt path_to_BAM_files_folder cell_mark_file_table path_to_binarized_coverage_folder\nwhere bin_size could be either 1,000 (1 Kb) or 50,000 (50 Kb) and cell_mark_file_table is a tab-delimited table with columns of cell type, name of the histone mark, the corresponding ChIP BAM file and the ChIP-seq input DNA BAM file, for example:\nRPE  H3K9me1H3K9me1.bam  Input.bam\nRPE  H3K9me2H3K9me2.bam  Input.bam\nRPE  H3K9me3H3K9me3.bam  Input.bam\nLearn chromatin states using ChromHMM.\n$ java -mx4000M -jar ChromHMM.jar LearnModel -b bin_size path_to_binarized_coverage_folder path_to_output_folder number_of_state hg19",
    "Critical: It is important to perform manual inspection of genomic tracks in a genomic viewer, for example, IGV (https://software.broadinstitute.org/software/igv/[href=https://software.broadinstitute.org/software/igv/]), to assess regions in various chromatin states (∗_dense.bed files generated at step 22) called by chromHMM (Ernst and Kellis, 2017[href=https://www.wicell.org#bib4]) and annotate these states (e.g., heterochromatin, active state, etc.) based on the observed combinations of chromatin marks (bigWig files generated at step 7) and the overlap with functional genomic elements (active or silent gene bodies, promoters, enhancers etc.). chromHMM requires a predefined number of states as input; therefore, multiple runs with various state numbers may be necessary to arrive at the optimal set of biologically relevant states at a given genomic resolution. For example, at the standard higher resolution, n=18 states was optimal, whereas at the Repli-seq (50 Kb) resolution, the optimal number of states was n=4 (Van Rechem et al., 2021[href=https://www.wicell.org#bib10]).\nSub-clustering genomic regions with the same chromatin state by their replication timing\nTiming: 1 h per group of datasets\nTo understand the general replication behavior of regions under specific chromatin states, it is useful to analyze these chromatin states separately. Within each chromatin state, it is informative to define and analyze subgroups of regions sharing similar replication timing.\nCluster genomic bins in a given chromatin state by the patterns of Repli-seq signal across profiled time points.\nIn R, load chromHMM state annotation and cluster genomic bins within each state by their replication timing patterns.\n> chromHMM.bed <- read.table(\"path_to_chromHMM_state_bed\",sep=\"\\t\",skip = 1)[,1:4]\n> colnames(chromHMM.bed) <- c(\"chr\",\"start\",\"end\",\"state\")\n> target.state <- \"1\"\n> target.state.bins <- bedtoolsr::bt.intersect(bin.bed,chromHMM.bed[chromHMM.bed$state==target.state,],wa=T)[,4]\n> state.RT <- log10(RT.bin.norm[target.state.bins,c(\"RPE.ct1.S1\",\"RPE.ct1.S2\",\"RPE.ct1.S3\",\"RPE.ct1.S4\")]+1e-3)\n> km <- kmeans(state.RT,4)\n> ComplexHeatmap::Heatmap(state.RT,\n                  use_raster=TRUE,\n                  show_row_names = FALSE,\n                  show_column_names = FALSE,\n                  show_row_dend = FALSE,\n                  cluster_columns=FALSE,\n                  split = km$cluster,\n                  cluster_row_slices=T,\n                  name='RPE')",
    "Critical: K-means clustering requires a pre- defined number of clusters. It is important to inspect the resulting clustered heatmap of Repli-seq intensities across time points to determine the optimal number of clusters for each chromatin state. In the example above, 4 clusters produced an optimal partitioning of replication patterns among all regions in the given chromatin state.\nAssessing the average temporal dynamics of replication, chromatin marks, chromatin accessibility, and transcription in individual subclusters\nTiming: 2 h per group of datasets\nBased on the subgrouping of genomic regions by their RT produced at the previous step, it is useful to focus on each subgroup and graphically compare the average patterns of the temporal progression of replication signal against the progression of ChIP-seq enrichment of individual chromatin marks or ATAC-seq chromatin accessibility across the cell cycle. Based on our observations (Van Rechem et al., 2021[href=https://www.wicell.org#bib10]), many of these patterns are consistent with a dilution of chromatin marks as the new DNA copy is synthesized during replication (Alabert et al., 2014[href=https://www.wicell.org#bib1]; Reverón-Gómez et al., 2018[href=https://www.wicell.org#bib11]; Stewart-Morgan et al., 2020[href=https://www.wicell.org#bib15]), however, the patterns in some regions deviate from these associations, suggesting a more complex and active relationship between histone modifications and RT.\nTo investigate these temporal dynamics throughout cell cycle, normalized Repli-seq tag density, input-normalized ChIP-seq tag density of broad histone marks, lower-resolution ATAC-seq tag density, and RNA-seq signal are calculated in each 50 Kb bin at each profiled time point (G1, ES, LS, G2/M), and then normalized as a log2 ratio to the average of all time points for the given bin.\nThe calculation of these average-normalized values is performed using these commands (with H3K36me3 ChIP-seq coverage as an example):\n> H3K36me3.bin.enrich <- log2(H3K36me3.bin.cpm+pseudo)-log2(Input.bin.cpm+pseudo)\n> rownames(H3K36me3.bin.enrich) <- rownames(bin.bed)\n> H3K36me3.ctrl.enrich <- (H3K36me3.bin.enrich[,c(\"ct1-G1-K36me3\",\"ct1-ES-K36me3\",\"ct1-LS-K36me3\",\"ct1-G2-K36me3\")]+\n            H3K36me3.bin.enrich[,c(\"ct2-G1-K36me3\",\"ct2-ES-K36me3\",\"ct2-LS-K36me3\",\"ct2-G2-K36me3\")])/2\n> H3K36me3.cycle <- H3K36me3.ctrl.enrich-rowMeans(H3K36me3.ctrl.enrich)",
    "These normalized values across cell cycle can be visualized as a heatmap using this command:\n> ComplexHeatmap::Heatmap(H3K36me3.cycle[target.state.bins,],\n                  use_raster=TRUE,\n                  show_row_names = FALSE,\n                  show_column_names = FALSE,\n                  show_row_dend = FALSE,\n                  cluster_columns=FALSE,\n                  cluster_rows=FALSE,\n                  split = km$cluster)\nCalculate replication timing index (RTI) as a measure of RT based on Repli-seq data at multiple time points across cell cycle\nTiming: 0.5 h per set of Repli-seq profiles\nUsing counts of Repli-seq reads at 50 Kb genomic bins for multiple profiling S-phase time points (n ≥ 2) produced at step 20, calculate the Replication Timing Index (RTI, (Van Rechem et al., 2021[href=https://www.wicell.org#bib10])) as the estimate of replication timing for each genomic locus across the genome. RTI calculation is based on a weighted sum of normalized replication signals (Repli-seq read densities Dn) from each time point n:\n  R T I =     ∑   n = 1  N  n   D n      ∑   n = 1  N   D n     \nwhere n is the time point of the S-phase (for example 1–4 corresponding to time points S1 to S4 in (Van Rechem et al., 2021[href=https://www.wicell.org#bib10])) and Dn is the density of BrdU reads (per bp) within the given region at this time point.\nFrom the table of normalized and smoothened Repli-seq coverage across the genome (produced at step 20), calculate RTI at all genomic bins and average RTI across biological replicates:\nCalculate RTI at all genomic bins across the genome using the following R function:\n> calc_rt_index <- function(dat) {\n  dat.norm <- dat/rowSums(dat)\n  for(i in 1:dim(dat.norm)[2]){\n    sum = sum+i∗dat.norm [,i]\n  }\n  RTI = (sum-1)/(dim(dat.norm)[2]-1) # scale from 0 to 1 instead or 1 to 4\n  return(RTI)\n}\n> RTI.ctrl1 <- calc_rt_index(RT.bin.loess[,c(“ctrl1_S1”, “ctrl1_S2”, “ctrl1_S3”, “ctrl1_S4”)])\n> RTI.ctrl2 <- calc_rt_index(RT.bin.loess[,c(“ctrl1_S1”, “ctrl1_S2”, “ctrl1_S3”, “ctrl1_S4”)])\nwhere calc_rt_index function calculated RTI using columns S1, S2 … S4 in LOESS smoothen RT coverage.",
    "Calculate average RTI values among biological replicates:\n> RTI.ctrl <- rowMeans(cbind(RTI.oe.1, RTI.oe.2))\nQuantify the magnitude and statistical significance of RTI differences between biological conditions\nTiming: 0.5 h\nUse genome-wide RTI values in two conditions, e.g., in control vs perturbation (gene overexpression, knockdown etc), to estimate the magnitude of changes in RT and their statistical significance at each genomic locus. Call statistically significant RT differences.\nCalculate RTI differences between replicate RTI samples and between two conditions using this R command:\n> RTI.diff <- rowMeans(cbind(RTI.oe.1, RTI.oe.2)) - rowMeans(cbind(RTI.ctrl.1, RTI.ctrl.2))\nBased on RTI differences between biological Repli-seq replicates, build a genome-wide distribution of random RTI differences. Estimate mean and standard deviation and then define the difference cutoff corresponding to two standard deviations away from the mean. This approach is conceptually similar to the traditionally used approach for the differences in Early-to-Late ratios (Marchal et al., 2018[href=https://www.wicell.org#bib8]; Rivera-Mulia et al., 2015[href=https://www.wicell.org#bib12]; Sarni et al., 2020[href=https://www.wicell.org#bib14]), but applied to RTI differences:\n> RTI.rep.sd <- sd(c(RTI.oe.1- RTI.oe.2, RTI.ctrl.1- RTI.ctrl.1),na.rm=T)\nBased on these cutoffs, identify genomic bins with significant RTI changes and merge adjacent bins into larger regions of RT change:\n> RTI.diff.pval <- 2∗pnorm(-abs(RTI.diff/RTI.rep.sd))\n> RTI.diff.bins <- RT.bin.bed[abs(RTI.diff)>0.05 & RTI.diff.pval<0.01,]\n> RTI.diff.region <- bedtoolsr::bt.merge(RTI.diff.bins)\nTrain and evaluate computational models for the prediction of RT from the combined dynamics of ATAC-seq, ChIP-seq/CUT&RUN, and RNA-seq signals across the genome\nTiming: 5 h per group of datasets",
    "One way to quantitatively assess the association between RT and chromatin modifications, chromatin accessibility, and gene expression is to train and evaluate genome-wide computational models of RTI as a function of the combination of ChIP-seq, ATAC-seq, and RNA-seq signals at a given genomic region. Assessment of the predictive power of these models may help quantify the functional link between RT and chromatin remodeling, chromatin accessibility, transcription, and compare the contributions of each individual component to this link. Either basic linear regression or more advanced machine learning approaches, e.g., random forest techniques, can be used to build these quantitative models.\nHere we perform training and validation of linear regression models using the leave-one-out cross-validation approach, where in multiple repetitions, a randomly sampled quarter of all 50 Kb genomic bins was used as the testing set after the other three quarters were used as the training set.\nLoad and combine multiple predictive features for each genomic bin (ChIP-seq, ATAC-seq, RNA-seq read density from step 15, number of peaks in the vicinity of genomic bins from step 13) and RTI for each bin from step 25.\n> peak.num.ATAC <- read.table(\"peakCount.ATAC.txt\" , header=TRUE)\n> peak.num.H3K27ac <- read.table(\"peakCount.H3K27ac.txt\" , header=TRUE)\n…\n> dat <- data.frame(rt=RTI.ctrl, ChIP.bin.CPM, ATAC.bin.CPM, peak.num.ATAC, peak.num.H3K27ac,…)\nSelect a random subset of chromosomes whose total length amounts to ∼25% of the genome. Leave genomic bins within these chromosomes for the later testing, and use the rest of the genomic bins as a training set:\n> rand.chr.list <- sample(unique(bin.bed[,1]))\n> inp_idx <- c()\n> for(chr in rand.chr.list){\n  inp_idx <- c(inp_idx,which(bin.bed[,1]==chr))\n  if(length(inp_idx) > floor(nrow(bin.bed)/4)){\n    break\n  }\n}\n> dat_trn = dat[-inp_idx,]\n> dat_tst = dat[inp_idx,]\nUse the training set, generate a linear regression model of RTI as a function of multiple ChIP-seq, ATAC-seq, and RNA-seq values:\n> fit <- lm(rt ∼ .,data = dat_trn)",
    "Assess the accuracy of the resulting model using the testing set, with Pearson R between predicted and observed RTI values as the accuracy measure:\n> pred <- predict(fit, newdata = dat_tst)\n> cor(dat_tst$rt, pred)\nGenerate a scatter plot of observed vs predicted RTI:\n> plot(pred, dat_tst$rt, xlab = \"Predicted\", ylab = \"Actual\")\nTo assess the contributions of various combinations of predictive variables (various combinations of enrichment of ChIP-seq marks, ATAC-seq, RNA-seq) as well as each individual value by itself), one can train and evaluate the accuracy of partial models based on these variables.\nPerform training and validation of random forest models using leave-one-out cross-validation approach identical to steps 29–33, with the exception of step 31 where the modeling is changed to the random forest technique:\n> library(randomForest)\n> fit <- randomForest(rt ∼ ., data = dat_trn, mtry = round(sqrt(dim(dat_trn)[2]-1)), importance = TRUE, ntrees = 500)\nNote: As additional approaches to assess the importance of individual features (individual chromatin marks, ATAC-seq, RNA-seq) in predicting RT, one can use various metrics of feature importance developed for random forest models: Gini importance, permutation feature importance, Drop Column feature importance etc.\nTrain and evaluate computational models for the prediction of RTI changes from the combined ATAC-seq, ChIP-seq/CUT&RUN, and RNA-seq signals across the genome\nTiming: 5 h per group of datasets",
    "A direct approach to assess the causal effect of a specific protein or cellular function on RT is to experimentally perturb this protein or function and analyze the resulting changes in RT across the genome. A genome-wide approach to this analysis is to train and evaluate computational models of quantitative RTI changes as a function of the combination of ChIP-seq, ATAC-seq, and RNA-seq signals and their changes at each genomic region. As in steps 29–34, these models can be based on simpler and tractable linear regression or more advanced machine learning approaches (e.g., random forest techniques).\nPerform training and validation of linear regression models using the leave-one-out cross-validation approach, where in multiple repetitions, a randomly sampled quarter of all 50 Kb genomic bins was used as the testing set after the other three quarters were used as the training set.\nLoad and combine multiple predictive features for each genomic bin (ChIP-seq, ATAC-seq, RNA-seq read density from step 15, number of peaks in the vicinity of genomic bins from step 13) and RTI for each bin from step 25. Similar to step 29.\n> pseudo <- 0.01\n> log2.ATAC.bin <- log2(ATAC.bin.CPM[,”OE”]+pseudo)- log2(ATAC.bin.CPM[,”ctrl”] +pseudo)\nOr:\n> log2.ATAC.bin <- log2(ATAC.bin.CPM[,c(”OE-S1” ,”OE-S2” ,”OE-S3” ,”OE-S4”)]+pseudo)- log2(ATAC.bin.CPM[,c(“control-S1” ,”control-S2” ,”control -S3” ,”control-S4”)] +pseudo)\n…\n> dat <- data.frame(drt=diff.RTI, log2.ChIP.bin, log2.ATAC.bin)\nSelect a random subset of chromosomes whose total length amounts to ∼25% of the genome. Leave genomic bins within these chromosomes for the later testing, and use the rest of the genomic bins as a training set:\n> rand.chr.list <- sample(unique(bin.bed[,1]))\n> inp_idx <- c()\n> for(chr in rand.chr.list){\n  inp_idx <- c(inp_idx,which(bin.bed[,1]==chr))\n  if(length(inp_idx) > floor(nrow(bin.bed)/4)){\n    break\n  }\n}\n> dat_trn = dat[-inp_idx,]\n> dat_tst = dat[inp_idx,]",
    "Using the training set, generate a linear regression model of RTI change as a function of chromatin state annotation, multiple ChIP-seq, ATAC-seq, and RNA-seq values and their changes:\n> fit <- lm(drt ∼ .,data = dat_trn)\nPerform steps 32 and 33 to assess the accuracy of the resulting model using the testing set, with Pearson R between predicted and observed RTI values as the accuracy measure, and generate a scatter plot of observed vs predicted differential RTI.\nTo assess the contributions of various combinations of predictive variables (combinations of enrichment of ChIP-seq marks, ATAC-seq, RNA-seq) as well as each value by itself), one can train and evaluate the accuracy of partial models based on these variables.\nPerform step 34 to train and validate random forest models using the leave-one-out cross-validation approach.\nNote: As additional approaches to assess the importance of individual features (individual chromatin marks, ATAC-seq, RNA-seq) in predicting RT, one can use various metrics of feature importance developed for random forest models: Gini importance, permutation feature importance, Drop Column feature importance etc.\nDefine genomic regions with specific types of local replication patterns\nTiming: 2 h per RTI dataset\nUsing genome-wide RTI values calculated at the previous step, define genomic locations of initiation zones, termination sites, initiation constant timing regions, and termination constant timing regions (Van Rechem et al., 2021[href=https://www.wicell.org#bib10]; Zhao et al., 2020[href=https://www.wicell.org#bib17]).\nDefine initiation zones (IZ) as local minima, termination sites (TS) as local maxima in RTI profile and constant timing regions (CTRs) as wide regions of > 500 Kb with almost constant RTI profile using these commands:\n> library(runner)\n> library(tidyverse)\n> w <- 10\n> var.cutoff<-1e-3\n> bs <- head(bin.bed[,3]-bin.bed[,2],1)\n> dist <- floor(w/2)∗bs\n> rti = RTI.ct\n> win.stat <- data.frame(max=runner(rti,k=w,f=max),\n            min=runner(rti,k=w,f=min),\n            var=runner(rti,k=w,f=var),\ncnt.noneNA=runner(rti,k=w,f=function(x){sum(!is.na(x))}),\ncnt.chr=runner(bin.bed[,1],k=w,f=function(x){length(unique(x))}))",
    "> win.stat <- win.stat[-(1:floor(w/2)),] # sliding window center at current position\n> win.stat[win.stat$cnt.noneNA<w | win.stat$cnt.chr>1,c(\"max\",\"min\",\"var\")] <- NA\n> bin.min.bed <- bin.bed[which(rti==win.stat$min & win.stat$var>var.cutoff),]\n> bin.max.bed <- bin.bed[which(rti==win.stat$max & win.stat$var>var.cutoff),]\n> bin.const.bed <- bin.bed[which(win.stat$var<var.cutoff),]\n> bin.min.bed %>% bedtoolsr::bt.merge(d=dist) %>%\n  bedtoolsr::bt.window(b=bin.const.bed,w=dist,v=T) %>%\n  write.table(file=\"RT.IZ.bed\",row.names = F,col.names = F,sep=\"\\t\",quote=F)\n> bin.max.bed %>% bedtoolsr::bt.merge(d=dist) %>%\n  bedtoolsr::bt.window(b=bin.const.bed,w=dist,v=T) %>%\n  write.table(file=\"RT.TS.bed\",row.names = F,col.names = F,sep=\"\\t\",quote=F)\n> bedtoolsr::bt.merge(bin.const.bed) %>%\n  write.table(file=\"RT.CTR.bed\",row.names = F,col.names = F,sep=\"\\t\",quote=F)\nNote: Specific parameter values in these definitions may be adjusted depending on the number of time points, genomic resolution, quality, structure of Repli-seq data, as well as the specific biological goals of the study."
  ],
  "subjectAreas": [
    "Genomics",
    "Rnaseq",
    "Sequence Analysis",
    "Bioinformatics",
    "Chipseq",
    "Sequencing"
  ],
  "bigAreas": [
    "Molecular Biology & Genetics",
    "Bioinformatics & Computational Biology"
  ]
}