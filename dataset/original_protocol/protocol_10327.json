{
  "id": 10738,
  "origin_website": "Jove",
  "title": "Exploring Infant Sensitivity to Visual Language using Eye Tracking and the Preferential Looking Paradigm",
  "procedures": [
    "The following procedure, which involves human participants, was approved by the Human Research Protections Program at University of California, San Diego.\n1. Participant screening and preparation\nRecruit infants in the defined age range of interest (e.g., 5 to 14 months old). Use multiple methods, including social media, flyers, postal mail. Consider making agreements with local hospitals or governmental offices to retrieve records listing newborns, their parents, and their mailing addresses, allowing to reach out directly to them via postal mail.\nScreen the infants when interested parents call the lab for scheduling. Ensure that the infants are free of any complications during pregnancy or delivery, of any neurological disorders, and have normal hearing and vision.\n\tNOTE: In our experiment7, because we were interested in nascent sensitivity to sign language, we made sure our participating infants had not seen any sign language in the home and had not been shown any baby sign instruction videos (based on parent reports). To further reduce unintended variability in language experiences, we also recruited infants who had only been exposed to English at home.\nSchedule testing soon after the infant's regular feeding or napping times to ensure minimal fussiness. Inform the parents that there are private feeding and/or napping spaces available in the laboratory. Compensate parents for participation via payment or gifting a laboratory t-shirt, onesie, or a small toy.\n2. Looking preference paradigm and experimental design\nEmploy a looking preference paradigm with a condition in which two different video stimuli are shown simultaneously, each on one half of the screen. Ensure both stimuli differ along exactly one dimension or feature and are otherwise identical for all other visual elements.",
    "NOTE: In our protocol, we focused on infant sensitivity to sonority-based phonological cues in sign language7, but this protocol is readily generalized to other infant eyetracking studies involving visual stimuli. Our main repeated-subjects experimental condition was the sonority condition (see Figure 1). This condition contained two different lexicalized fingerspelling sequences, one \"well-formed\" (i.e., it obeyed sonority-based phonological restrictions) and the other \"ill-formed.\"\nDesign a second \"control\" condition with two video stimuli that is expected to elicit looking preferences in infants. Again, ensure both stimuli differ along exactly one dimension or feature, and are controlled for all other visual elements.\n\tNOTE: In our protocol7, this second condition was the \"video orientation\" condition. This condition contained two videos, both showing the same fingerspelling sequence as used for the sonority condition, but one side was flipped vertically and horizontally (see Figure 1). The design of the \"control\" condition depends on the research question, and it may be either a non-language control with which to contrast the language condition, or a confirmatory condition in which infants are expected to show a preference.\n3. Stimuli construction\nDefine the language items based on the specific experimental question. Aim for items that are short in duration (typically 4-10 s), because while infants generally tolerate between 6 to 10 min of experimentation, there must also be sufficient trials and repetitions.\n\tNOTE: Our protocol7 used 4 fingerspelling sequences with well-formed and ill-formed variants (eight sequences total) in 32 randomized ten-second trials, 16 sonority condition trials and 16 video orientation condition trials. The total length, not counting calibration (less than 1 min) or attention-grabber segments (about 3-5 s each), was 5.3 min.",
    "Define the randomization scheme. Randomly intermix the conditions, and randomize the language items appearing on the screen’s left and right sides such that there is an equal number of, for example, A vs. B items and B vs. A items.\nDefine the counterbalancing scheme. Construct two different randomized experimental sequences, or runs, and assign equal numbers of participants to each experimental sequence, controlling for age, gender, and any other factors of interest.\nIf creating videos with people in them, use a well-provisioned photography/filming studio with the person standing in front of a blue or green chromakey background.\n\tNOTE: In our protocol7, we focused on fingerspelling sequences, so we did not use faces or bodies in our videos. However, this protocol is written assuming that you may select to show people in full-body or head-only view.\nPosition lighting evenly across all parts of the image, with no strong shadows on either the person or the background.\nUse a high-definition video camera placed on a tripod and raised to the height of the person's neck. Turn off auto-focus to prevent focus changes during recording. Use tape to mark where the person's feet should be placed during filming and minimize any walking around during the filming session.\nSelect a native user of the language being investigated and who is able to reproduce the language items naturally and without effort. Clothing should be contrastive with skin tone and not contain any colors similar to the chromakey background. Remove any jewelry or adornments. Any loose hair should be combed or bound.\n\tNOTE: Before testing infants, it is recommended to conduct a companion \"confirmatory\" experiment to verify that the stimuli and experimental conditions are accepted by native language users.",
    "Ask the person to naturally reproduce each language item a few times while the camera records all reproductions in a single video clip. Because these video clips may be played in loops, ensure that the beginning and end of the video clip both show the person in the same body position for a seamless transition between loops.\nAfter filming, import the videos in a video editing program. Select the best reproduction for each language item and trim the clips to these items. Insert an equal number of leading and trailing frames around each language item. If necessary, apply transformation tools to enlarge or center the person's image, but apply them equally across all stimuli.\nUse high contrast stimuli whenever possible. Use the video editing program’s chromakey function to change the background to white in order to maximize the corneal reflection, allowing for the best conditions for capturing gaze data.\nIf looping the stimuli, make sure the duration of loops is equal for any two pairs of video stimuli shown together (i.e., the lengths of the language items on both sides needs to be the same). To achieve this, slightly adjust the video speed of each language item.\n\tNOTE: Bear in mind that infants need slower rates of presentation to effectively process moving stimuli. Any adjustments must be subtle and not significantly alter or distort the language item. In our protocol7, the speed of the stimuli was slowed down by 50%, and we confirmed that this manipulation was not noticeable by adult observers.",
    "Place pairs of language items side by side in a composite clip. Remember that these pairs will have already had their video lengths equalized in the previous step. Make sure the position of each language item is identical for both sides (e.g., the left item is not higher, lower, bigger, or off-center compared to the right item) and that both items begin and end simultaneously.\nAs with stimuli design, control low-level visual features of the video clips such as luminance and color so they are the same across both sides of the screen.\nApply looping behavior by duplicating the composite clip in the video timeline. To minimize jerkiness between loops, attend to any differences in the start and end frames of the loop. If necessary, use a short video transition to provide a smoother transition between loops.\nExport the edited videos in a format appropriate for the eye tracking program and at the highest resolution possible.\nUse experimental presentation software, usually packaged with the eye tracker, to program and present the stimuli and to randomize the stimuli order. General-purpose experiment presentation software may also be used, provided they are able to control the eye tracker and record data from it.\nInsert attention-grabber images before each trial to maintain and redirect infants' attention to the center of the screen immediately before the trial begins (see Figure 2).",
    "NOTE: Examples include static or animated puppies, kittens, toys, smiling faces, or cartoon figures, as long as they are highly innteresting and of equal size. Although animations may be more effective, they are memory intensive, and we found that static images worked equally well. These images should be small (about 2 to 5 degrees) and centrally located on the monitor, so that the infant is looking at the center of the monitor before each trial starts.\nAt the beginning and end of the experimental sequence, insert a three-point calibration check procedure consisting of three slides, each with one target that appears in the upper-left corner, screen center, and lower-right corner (see Figure 2).\n4. Eyetracking apparatus\nUse a remote eye tracker which does not require any restraints or apparatus to secure the position of the head and is capable of a sampling rate of at least 50 Hz.\n\tNOTE: Remote eye trackers contain imperceptible, infrared light-emitting diodes (LEDs) that emit light onto the observer's eyes. The built-in infrared camera detects the positions of the pupils and the corneal reflections and applies algorithms to compute the observer's fixation point on the monitor as three-dimensional (x, y, z) coordinates. The coordinates are averaged across both eyes to produce a single binocular value. Usually only the (x, y) coordinates are analyzed, as z, distance from the monitor, is not relevant.\nUse a computer monitor 15\" or greater, with a resolution of at least 1024 x 728 pixels, to display the experimental stimuli.\nPosition the eye tracker directly under the stimuli monitor and at a low angle facing the infant's face as directly head-on as possible. Use rulers and a digital angle gauge to measure the placement and angle of the eyetracker and the monitor. If needed, enter these numbers into the eyetracking software.",
    "NOTE: A higher angle (e.g., the eye tracker is lower to the ground and therefore angled higher) may disrupt eye tracking due to occlusion of the eyes by the infant's cheeks and hands. For best practices in eye tracker position, consult the specific eye tracker model's guidelines. Furthermore, most eye tracker software can save this information to be loaded before each session. However, if there is the possibility of the eye tracker or the monitor moving even slightly in between experimental sessions, re-collect measurements before each session in order to achieve the most accurate calibration.\nPosition a separate webcamera, often called a user or scene camera, above the stimulus monitor to record the participant’s full face during the experiment. It provides a live feed during the experiment, and its recording is stored with the raw gaze data.\nSet up the experimental presentation software, usually commercially available with the eye tracker, to present the stimuli, record the eye movements, record the user or scene camera, display gaze points during the experiment, and, optionally, perform gaze data analysis.\n\tNOTE: A general-purpose experimental presentation software may also be used, provided it contains integrations permitting it to control the eye tracker and record data from it.\n5. Eyetracking procedure\nParticipant entry & background measures\n\t\nUpon arrival, explain the study, obtain signed consent in accordance with university IRB regulations. If the infant is alert, proceed with testing, and complete questionnaires after the experiment. If upon arrival, the infant is not ready (e.g., infant is fussy, sleeping, or needs to be fed), use this time for the parent to complete all background family and language questionnaires.",
    "Have the parent to complete any background family and language questionnaires. Collect standard demographic and medical information, and information about the infant’s language and technology environment (e.g., number of languages used at home; exposure to video, smartphones, tablets).\nSet-Up\n\t\nDim the lights in the experimental room and ensure there are no other obvious visual distractors in the room. Use curtains to occlude the infant’s field of view from all distractors in the room (see Figure 3). Make sure all background applications on the computer, including antivirus scanning and software updates, are not running during the experiment.\nInvite the parent to sit in the chair with the infant sitting on their lap. To provide more stability, the parent may strap the infant in a soft booster seat placed on the parent's lap.\n\t\tNOTE: Such booster seats preserve closeness with parents, but also prevents younger infants from leaning backwards or forwards too much (resulting in data loss) and older infants from crawling away.\nAccording to eye tracker guidelines, check that the infant's head is positioned at an optimal distance from the monitor and eye tracker. Confirm, using the eye tracker software, that the infant's eyes are visible to the eye tracker. If not visible, ask the parent gently sway the infant in all directions until the eyes are detected and within appropriate distance.\nProvide the parent with occluding glasses that prevent him or her from seeing the experimental stimuli.\n\t\tNOTE: Occluding glasses reduce the possibility of biasing the infant to particular stimuli or screen sides, and also prevent the eye tracker from inadvertently tracking the parent's eyes instead of the infant's.\nCalibration\n\t\nPerform the calibration procedure according to the eye tracker instructions.",
    "If supported by the eye tracker software, use a five-point calibration procedure corresponding to the four corners and the center of the monitor.\n\t\tNOTE: For calibration to work, infants must look at the calibration image. Therefore, the image must be highly interesting. A spinning-type of animation works well so that the \"center\" of the image remains stationary, as you want the infant's eyes to be as directed as possible to the center of the calibration point.\nDuring calibration, do not point towards the image, or have the parent direct attention to the calibration image, because that may draw infants' attention away from the screen and towards the person pointing to it.\nVerify that calibration is successful, using the eye tracker software. Repeat calibration if needed, especially if the parent or infant moves substantially (e.g., the parent standing up) during calibration.\n\t\tNOTE: The calibration process depends on it being novel, interesting, and brief. The more times infants need to undergo calibration, the less effective it may be.\nAfter calibration is confirmed to be successful, immediately begin the experiment.\nExperiment\n\t\nBegin the experiment with the three-point calibration check (see Figure 2). Manually control the duration of each target; when the infant fixates on the target in one slide, immediately proceed to the next target. If the eye gaze is consistently one degree or greater away from each target's center, abort the experiment and repeat calibration.\nContinue with the experiment, beginning with the attention-grabber before the first trial (see Figure 2). Manually control how long the attention-grabber is displayed. Begin the trial when the infant fixates on the attention-grabber. If the infant does not fixate on it after several seconds, use a squeaking toy or flashing light to redirect the infant's attention to the screen.",
    "After all trials have been shown, perform the same three-point calibration check procedure again to test for possible signal drift or calibration changes during the experiment. After the check, end the experiment.\nTerminate the experiment if the infant demonstrates irrecoverable fussiness or if the parent requests to stop.\nWrap-Up\n\t\nIf not already completed, have the parents fill out the background family and language questionnaires.\nProvide compensation and, if consented to, share additional flyers/materials for the parent to distribute among their peers to assist in recruitment.\n6. Data analysis\nFirst, assess the quality of the data by plotting a velocity chart or a trace of gaze position over time to examine whether the data is noisy (periods of high velocity peaks) for each subject. High velocity changes or systematic drifts in data position may be indicative of poor calibration or data acquisition errors.\nFilter out high-frequency information from the gaze data by using noise reduction algorithms or filters, such as using a moving average. These algorithms can also interpolate across short gaps in the data, typically caused by blinks and head movement.\n\tNOTE: Using common spatial-temporal filters to classify fixations and saccades is not recommended, because these algorithms are based on adult eye behavior and are not generalizable to infant eye behavior.\nDraw two areas of interest (AOIs), one for each side of the screen. Make sure the AOIs are slightly larger than the visual elements themselves (e.g., 25 pixels or 1º visual angle larger, all around the person) to accommodate any minor calibration inaccuracies or standard instrument error.",
    "NOTE: While the AOI is static, it encompasses a moving object in a video, so also make sure the AOI should be larger than the maximum dimensions of the moving object while it changes throughout the video. If desired and supported by the eye tracker software, you may use dynamic moving AOIs instead.\nMaintain a gap of about 25 pixels or larger in between the two AOIs, in the center of the screen.\nUsing the eye tracker software or a secondary analysis program, calculate total looking times for each AOI for each trial by summing up all gaze points falling within the AOI and multiplying this count by the sampling interval (e.g., if using a 120Hz eye tracker, the sampling interval is 8.33 ms).\nIf still using the eye tracker software, export the looking time data. Next, calculate total looking times for each infant, for each stimulus type, across the full experimental run. Exclude any infants who did not provide sufficient amount of gaze data (e.g., at least 25% of the maximum data possible).\n\tNOTE: In Stone, et al.7, 24% of all infants tested were excluded due to poor calibration or insufficient gaze data due to fussiness, looking away, occlusion of the eyes during recording, excessive blinking, droopy eyelids, instrument error, or experimenter error.\nCalculate a looking preference index for each infant. First, divide the total looking time for one stimulus type over the other.\n\tNOTE: This step allows infants to be directly compared with each other, regardless of whether the infants varied in how long they looked at the experiment overall.\nNormalize this value with a logarithmic transformation, which allows the looking preference index to be meaningfully interpreted across all infants where an index of -1.0 and 1.0 represent the same magnitude, but in opposite directions.",
    "Perform appropriate statistical testing to compare total looking times and looking preference indices across participant groups. Report statistical test results along with effect sizes and/or confidence intervals.\n\tNOTE: In Stone, et al.7, to test for age-related sensitivity to sonority-based phonological restrictions in sign language, an independent t-test was performed to compare sonority looking preference indices (the log of the quotient of looking time for well-formed items over ill-formed items) between younger and older infant groups.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Behavior"
  ],
  "bigAreas": [
    "Ecology & Environmental Biology"
  ]
}