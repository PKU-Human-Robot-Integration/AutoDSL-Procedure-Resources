{
  "id": 9096,
  "origin_website": "Jove",
  "title": "A Human-machine-interface Integrating Low-cost Sensors with a Neuromuscular Electrical Stimulation System for Post-stroke Balance Rehabilitation",
  "procedures": [
    "Note: The HMI software pipeline was developed based on freely available open-source software and off-the-shelf low-cost video game sensors (details available at: https://team.inria.fr/nphys4nrehab/software/ and https://github.com/NeuroPhys4NeuroRehab/JoVE). The HMI software pipeline is provided for data collection during a modified functional reach task (mFRT)21 in a VR based gaming platform for visuomotor balance therapy (VBT)8.\nFigure 2a shows the diagnostic eye tracker setup where the gaze features are extracted offline for the quantification of post-stroke residual function so that the visual feedback in VR can be customized accordingly.\nFigure 2b shows the experimental setup for VBT.\nimgsrc://cloudfront.jove.com/files/ftp_upload/52394/52394fig2.jpg\nFigure 2: (a) Schematic of the human-machine-interface for the evaluation of post-stroke pursuit eye movements. (b) Schematic of the human-machine-interface where the software interface integrates biosignal sensors and motion capture to record mobile brain/body imaging data with neuromuscular electrical stimulation system (NMES) and sensory electrical stimulation (SES) for post-stroke NMES/SES-assisted visuomotor balance therapy. NMES: Neuromuscular Electrical Stimulation, SES: Sensory Electrical Stimulation, EMG: Electromyogram, EEG: Electroencephalogram, EOG: Electrooculogram, CoP: Center of Pressure, PC: Personal Computer. Reproduced from 8 and 37​. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/52394/52394fig2large.jpg]\n1. Software Installation for Mobile Brain/Body Imaging During VBT\nInstall drivers for the Motion Capture (installation procedures provided at https://code.google.com/p/labstreaminglayer/wiki/KinectMocap)\n\t\nDownload and install Kinect Runtime from http://go.microsoft.com/fwlink/?LinkId=253187 (Motion Capture sensor should not be plugged into any of the USB ports on the computer).\nPlug in the powered Motion Capture Sensor into a USB port via the interface cable. The drivers will load automatically.\nInstall drivers for the Eye Tracker Sensor (installation procedures provided at http://github.com/esdalmaijer/EyeTribe-Toolbox-for-Matlab[href=http://github.com/esdalmaijer/EyeTribe-Toolbox-for-Matlab])\n\t\nDownload the software from http://theeyetribe.com, launch the application and launch the application to install the software (Eye Tracker sensor should not be plugged into any of the USB ports on the computer).",
    "Plug in the powered Eye Tracker Sensor and the drivers will load automatically.\nInstall drivers for the Balance Board (installation procedures provided at (installation procedures provided at http://www.colorado.edu/intphys/neuromechanics/cu_wii.html)\n\t\nDownload and extract CU_WiiBB.zip from http://www.colorado.edu/intphys/neuromechanics/CU_WiiBB.zip\nCopy the WiiLab folder to Microsoft Window operating system's standard Program Files directory.\nOpen the WiiLab folder in the Program Files directory and run as an administrator the InstallWiiLab.bat file to install the Balance Board.\nInstall drivers for EEG/EOG (installation procedures provided at http://openvibe.inria.fr/how-to-connect-emotiv-epoc-with-openvibe/ )\n\t\nDownload and install Emotiv SDK from http://www.emotiv.com/apps/sdk/209/\nDownload and install OpenViBE Acquisition Server with labstreaminglayer (LSL) from https://code.google.com/p/labstreaminglayer/downloads/detail?name=OVAS-withLSL-0.14.3-3350-svn.zip for distributed multi-sensor signal transport, time synchronization and data collection system (installation procedures provided at https://code.google.com/p/labstreaminglayer/).\nInstall the drivers for the commercial NMES stimulator (details at http://www.vivaltis.com/gammes/phenix/phenix-usb-neo-50-554-1.html#content).\n2. Low-cost Sensor Placement for Mobile Brain/Body Imaging (MoBI): The Open-source HMI Software Pipeline Provides Mobile Brain/Body Imaging (MoBI) 19 with Low-Cost Off-the-Shelf Sensors (Figure 2b) Which Can be Adapted for Other Agility Training Programs.\nVisual Feedback for MoBI:\n\t\nBegin by obtaining a projection screen to display the visual biofeedback at the one end of the room (recommended distance from subject 0.6 m).\nAdjust the height so that the center of the screen will be at the subjects' eye-level.\nMotion Capture for MoBI:\n\t\nPlace the motion capture sensor in front of the projection screen, and aim it at the volume of motion capture.\nConfirm that the volume of motion capture is 1.5 m to 2.5 m in front of the motion capture sensor.\nBalance Board Placement for MoBI:\n\t\nPlace the Balance Board on the floor, about 2.0 m away from the motion capture sensor.\nLeave enough room around the Balance Board to ensure full-body movement (i.e., during modified functional reach task21).\nEEG/EMG/EOG Sensor Placement for MoBI",
    "Ask the subject to sit on a chair facing the Motion Capture and with their feet on the Balance Board.\nPlace the recording (EMG) cum stimulation (NMES/SES) electrodes bilaterally on the Medial Gastrocnemius (MG) and Tibialis Anterior (TA) muscles of the subject. Then, connect them to the wireless electrical stimulator (NMES/SES) system.\nPlace the electroencephalogram (EEG) cap on the subjects head following the International 10 - 20 system. Then, place the EEG electrodes with conductive paste at -Fz, C3, Cz, C4, P3, Pz, P4, PO7, Oz, PO8 - before connecting them to the wireless EEG headset.\nPlace two EEG electrodes with conductive paste above and below one of eyes for vertical EOG and put two electrodes with conductive paste at the outer canthus of each eye for horizontal EOG. (Note: In case Eye Tracker sensor is not used in the post-stroke subject then bilateral EOG is preferable).\nPlace two EEG electrodes on earlobes as reference electrodes.\n3. Eye Tracker Based Evaluation of Post-stroke Pursuit Eye Movements\nAsk the subject to sit with the chin resting comfortably on the height-adjustable Chin-Rest. Then, raise the computer monitor to a convenient height such that the eyes are roughly facing the center of the computer monitor (Figure 2a).\nPlace the Eye Tracker roughly 50 cm from the Chin-Rest and ask the subject to look straight at the computer monitor for visual cues.\nRun EyeTribeWinUI.exe in the 'SmartEye' folder to calibrate the Eye Tracker sensor. The subject will be asked to look at various targets on the PC monitor for roughly 2 sec each. A typical user calibration process takes approximately 20 sec to complete. The (x, y) coordinates of the subject's gaze point are recorded for different cued targets for calibration.",
    "Run 'Visual_Stimulus.exe' in the SmartEye folder to execute the virtual reality based interface. Subsequently run the 'SmartEye.exe' program present in the 'SmartEye' folder to acquire the subjects' eye gaze data that is synchronized with the virtual reality based task. This data will be used for the evaluation of post-stroke pursuit eye movement.\nimgsrc://cloudfront.jove.com/files/ftp_upload/52394/52394fig3.jpg\nFigure 3: (a) Cursor representing the center of pressure (CoP) which needs to be volitionally driven to the cued target during visuomotor balance therapy , (b) Visuomotor balance therapy protocol where the subject steers the computer cursor to a peripheral target driven by volitionally generated CoP excursions. The Reset can be assisted with Neuromuscular Electrical Stimulation (NMES) and sensory electrical stimulation (SES), (c) Experimental setup for visually-cued visuomotor balance therapy. Reproduced from 8 and 37​. Please click here to view a larger version of this figure.[href=https://www.jove.com/files/ftp_upload/52394/52394fig3large.jpg]\n4. NMES/SES-Assisted Visuomotor Balance Therapy (VBT) under MoBI\nConnect the eye-tracker and balance board sensors to the visual feedback computer (Figure 2).\n\t\nMake sure that the Eye Tracker sensor is powered on, connected to computer, and that it has fully booted. Start the 'EyeTribe server.exe' and 'EyeTribeWinUI.exe' available in the 'VBT' folder (see steps 1.3).\nMake sure that the Balance Board sensor is powered on. Then, press the button on the Balance Board sensor to make the remote discoverable in the menu. Then, click on the show or hide icon in the system's taskbar and click on Bluetooth device icon. Then, click on the 'Add a Device' option and pair the Balance Board sensor as a Bluetooth device without using the code to the visual feedback computer. Once the Balance Board sensor is connected to the visual feedback computer, open the 'VBT' folder and run the WiiBBinterface.m file to establish Matlab- Balance Board sensor interface (see steps 1.6).",
    "Make sure that the Motion Capture sensor is powered on, connected to the computer and that it has fully booted (there is a green LED on the front). Open the LSL folder and start 'Mocap' software to begin streaming of the motion capture sensor data (see steps 1.6).\nMake sure that the EEG/EOG data acquisition systems are powered on. Then, double-click on the openvibe-acquisition-server-withlsl.cmd available in the LSL folder (see steps 1.6). From the menu, select the respective sensor hardware (i.e., 'Emotiv EPOC') and configure the module, if necessary, by clicking on the 'Driver Properties'. Then, click on 'Connect', and then click on 'Play' to start the acquisition server.\nCalibrate the Sensors for VBT\n\t\nAsk the post-stroke subject to stand on the Balance Board with safety harness (and partial body weight support, if necessary).\nSet a minimum baseline NMES level (pulse-width and current level) necessary for upright standing according to clinical observation (i.e., zero body weight support)22. For setting the minimum baseline NMES level, one can set the stimulation frequency at 20 Hz and then increase the pulse-width and/or current level until upright standing is achieved. Here, NMES of knee extensors is required to generate enough torque to prevent knee buckling.\nAsk the subject to perform various reach movements that affects CoM and CoP location.\nRun the 'CalibSensors.m' program available in the 'DataCollect' folder in order to collect multi-sensor calibration data while the subject performs various self-initiated maximal reach movements in different directions that affect center of mass (CoM) and center of pressure (CoP) location on the visual feedback.\n5. Multi-sensor Data Collection from Low-cost Sensors During VBT (Figure 2b)",
    "Run the 'CollectBaseline.m' program in the 'DataCollect' folder to collect baseline resting-state, eyes-open, multi-sensor data by asking the subject to stand still for 2 min while looking straight at the CoP target on the PC monitor (Figure 3a).\nConnect the visual feedback computer's video output to the projection screen and run the SmartEyeVRTasks.exe file in the 'VBT' folder in the visual feedback computer to launch the SmartEyeVRTasks GUI. Also, run 'CollectVBT.m' program in the 'DataCollect' folder to collect sensor data during VBT.\n\t\nFrom upright standing, called the 'Central hold' phase, ask the subject to steer the cursor, driven by the CoP, as fast as possible towards randomly presented peripheral target as cued by visual feedback (Figure 3b).\nFollowing this 'Move' phase, ask the subject to hold the cursor at the target location for 1 sec during the 'Peripheral hold' phase.\nFollowing the 'Peripheral hold' phase, the cursor will 'Reset' back to the center when the subject needs to return back to upright standing - the 'Central hold' position. NMES/SES is triggered for the muscle when its EMG level goes above a set threshold to assist the volitional effort required to return the CoP to the 'Central hold' position.\n\t\tNote: The difficulty of the mFRT can be increased by decreasing the gain, imgsrc://cloudfront.jove.com/files/ftp_upload/52394/52394eq1.jpg, or increasing the noise variance,imgsrc://cloudfront.jove.com/files/ftp_upload/52394/52394eq2.jpg, within subject-specific feasible range:\nimgsrc://cloudfront.jove.com/files/ftp_upload/52394/52394eq3.jpg\n\t\twhere the CoP excursions, imgsrc://cloudfront.jove.com/files/ftp_upload/52394/52394eq4.jpg, drive the computer cursor, imgsrc://cloudfront.jove.com/files/ftp_upload/52394/52394eq5.jpg, in discretized time, imgsrc://cloudfront.jove.com/files/ftp_upload/52394/52394eq6.jpg, with time-step, imgsrc://cloudfront.jove.com/files/ftp_upload/52394/52394eq7.jpg.\nSubscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Neuroscience"
  ],
  "bigAreas": [
    "Biomedical & Clinical Research"
  ]
}