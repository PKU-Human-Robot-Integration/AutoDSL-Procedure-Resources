{
  "id": 11276,
  "origin_website": "Jove",
  "title": "Lensless Fluorescent Microscopy on a Chip",
  "procedures": [
    "In this section, we will review the experimental methods of our lensless on-chip fluorescent microscopy platform1-4. To demonstrate the capabilities of this technique, we will show on-chip imaging results for fluorescent micro-particles and labeled white blood cells. Although not discussed here, the same lensfree fluorescent microscopy platform can also be used to image small model animals such as transgenic C. elegans samples3.\n1. Design of the Lensless On-Chip Imaging Platform\nOur lensless on-chip imaging platform comprises several optical components including a digital sensor array (e.g., a CCD chip), an incoherent illumination source, a prism, an absorption filter, a fiber-optic faceplate or a fiber-optic taper. As shown in Fig.1, these components are assembled with micro-fluidic devices to achieve fluorescent imaging of a large sample volume on a chip, without the use of any lenses, mechanical scanners or thin-film based interference filters.\nDigital Sensor Array: Our lensless imaging configuration utilizes an optoelectronic sensor array to record the fluorescent emission from target micro-objects. In this platform, for detection of the fluorescence signal, different types of sensor-arrays can be used, such as CCDs (e.g., Models: KAF-8300, KAI-11002, KAF-39000, all from KODAK) and complementary metal-oxide-semiconductor imagers (CMOS, e.g., Model: MT9T031C12STCD, from Micron Technologies). Key parameters of interest for these sensor-arrays include the pixel size (e.g., 5.4 μm, 9 μm, 6.8 μm and 3.2 μm for KAF-8300, KAI-11002, KAF-39000 and MT9T031C12STCD, respectively) and the active imaging area (e.g., 2.4 cm2, 8 cm2, 18 cm2 and 32 mm2 for KAF-8300, KAI-11002, KAF-39000 and MT9T031C12STCD, respectively). For lensfree on-chip imaging, CCD sensors can in general be preferred to achieve higher throughput (wider active area) and better sensitivity, while CMOS sensors can be preferred for relatively cheaper and lighter weight designs (e.g., for field use).",
    "Light Sources: In our platform, an incoherent light source, e.g., a simple light-emitting diode (LED, e.g., from Thorlabs, M455L2-C2 and LEDD1B), can be used for fluorescence excitation. In the experimental set-up shown in Fig. 1, a multi-mode fiber-optic cable (Thorlabs, BFH37-1000) with 1 mm core size is butt-coupled to an LED source (without the use of any lenses or coupling optics) and the excitation light is then delivered to the sample volume through the exit aperture of this fiber. In this system, the required power level of fluorescence excitation should be around ~ 0.2- 5 mW for an FOV of > 2-8 cm2 at the exit of the illumination fiber; however, the LEDs should be able to output ~ 5mW-1W power levels as the butt-coupling approach is considerably lossy which decreases the excitation power at the output of the fiber. To achieve excitation of various dyes, different color LEDs can also be multiplexed by using a fiber-optic coupler.",
    "In addition to on-chip fluorescent imaging, lensfree holographic transmission images of the same sample can also be obtained with this platform by utilizing a vertical illumination source as illustrated in Fig. 2. Unlike the fluorescence excitation fiber, for holographic image acquisition, a different fiber-optic cable with a smaller core size (e.g., ~50-400 μm) is butt coupled to another LED source (Mightex, FCS-0625-000). This vertical illumination light, after exiting the fiber-end, starts to acquire partial spatial coherence as it propagates toward the sample. The diameter of this spatially coherent region is proportional to the distance that the light travels and is inversely proportional to the exit aperture size of the fiber. As long as this spatial coherence diameter at the sample plane is larger than the diffraction size of each sample at the sensor plane, the scattered light from each object can faithfully interfere with the background light, creating a lensfree in-line hologram of the sample. These acquired lensfree holograms can then be rapidly processed using iterative phase recovery approaches to reconstruct a transmission bright-field image of the sample volume5-7. For this holographic illumination end, a longer wavelength LED (i.e., ~625-700 nm) is selected since the absorption filters that are used to block the excitation light are high-pass filters with typical cut-off wavelengths of e.g., 500-600nm, which permits acquisition of transmission in-line holograms of the samples without an issue.",
    "Other optical components: In this on-chip fluorescent microscopy platform, two different excitation filtering methods are used in parallel to create the required dark-field background as shown in Fig.2. First, a glass prism (e.g., Edmund Optics, rhomboid or dove prisms) or a glass hemi-sphere is used to create total-internal reflection (for the excitation light) at the bottom surface of the micro-fluidic chip which hosts the samples of interest. In parallel to this, an inexpensive absorption filter (e.g., from Roscolux) is used remove the weakly scattered excitation light that does not obey the TIR process. Upon successful rejection of the excitation using these two mechanisms, only the fluorescent emission of the samples is acquired at the detector plane. Note here that a certain fraction of the emitted fluorescent signal also experiences TIR at the same interface. However, this only limits the detection numerical aperture of this lensfree on-chip imaging approach to ~1.0, such that only the oblique rays above such a high detection numerical aperture remain trapped within the micro-chip while the rest of the fluorescent rays can still hit the active area of the sensor-array to be sampled by its pixels.",
    "Despite such a large detection numerical aperture, the raw fluorescent spots at the sensor-array become fairly wide (e.g., ~150-200 μm) since fluorescent emission is not directional and therefore rapidly diverges. To engineer and better control the spatial spreading of this fluorescent signal in our lensless platform, we utilized a planar optical component, i.e., a fiber-optic faceplate (e.g., Edmund Optics, NT55-142), that is placed between the object and the sensor planes. A fiber-optic faceplate is composed of a 2D array of fiber-optic cables which carry optical intensity information from one side of the device to the other. Its main function in our lensfree on-chip microscopy set-up is to couple the free-space modes of the fluorescent emission from the sample volume into guided optical waves traveling without spatial spreading within each fiber, which can partially narrow down the lensfree fluorescent point-spread function (PSF) between the object and the detector planes. This further increases our signal-to-noise ratio (SNR) as well as the spatial resolution that can be achieved using our lensless platform.\n\tAs an alternative to a regular faceplate, we can also utilize in our on-chip imaging platform a \"tapered\" fiber-optic faceplate which has a significantly larger density of fiber-optic cables on its top facet compared to the bottom one. Such a tapered faceplate does not only help us achieve a better PSF, but also can introduce magnification in our platform (e.g., >2-3X) which further helps us to improve our lensless resolution down to e.g., <4 μm. We should also note that the field-of-view of such a tapered design is reduced by at least the square of the introduced magnification factor when compared to a regular faceplate based imaging system, which can constitute a reduction of e.g., from ~8 cm2 FOV initially (CCD: KAI-11002) down to <2 cm2 with the taper.",
    "Finally, we should also note that the use of a fiber-optic faceplate or a taper distorts the lensfree holograms of the sample because of various optical modes of the fiber-optic array3. While such distorted lensfree patterns at the detector array can still be useful for certain cytometry relation applications, for holographic reconstruction of transmission images, the fiber-optic array (e.g., the faceplate or the taper) needs to be removed from the on-chip assembly at the cost of slightly reduced spatial resolution in the fluorescent mode3.\nMicro-fluidic Chips: The micro-fluidic chips that are used in our platform are fabricated using PDMS (Polydimethylsiloxane) walls placed on glass slides creating the micro-channels that are needed for on-chip imaging. To fabricate these micro-fluidic channels we pursue the following recipe:\n\t\nPDMS A and B elastomers are uniformly mixed and stirred with 1:10 volume ratio.\nOnce this heterogeneous solution is poured to a Petri dish, it is cured at 65 °C for 2 hours.\nUsing an X-acto knife, the required size and shape of the micro-fluidic channel wall is extracted from the Petri dish.\nThe device bonding is then achieved by using a high-frequency plasma generator (Electro-Technic Products Inc., BD-10AS), which needs to expose both the cover glass slides and PDMS bonding area.\nAfter this plasma treatment, the device is placed inside an oven for ~40-50 minutes at 70 °C to strengthen the bonding.\nAssembly and alignment of the lensless on-chip microscopy platform:\n\tThe assembly procedures for our lensfree on-chip imaging platform can be detailed as:\n\t\nCover glass of the opto-electronic sensor-array is removed.\nUsing a vacuum pen (Edmund Optics, NT57-636), a thin absorption filter is gently placed on the top of the detector active area.\nA fiber-optic faceplate or a taper is positioned on top of this absorption filter.",
    "The fabricated micro-fluidic chip is then directly placed on the top of the fiber-optic array.\nA glass prism or a hemi-sphere is assembled above the micro-fluidic chip using an index-matching oil (Cargille, Immersion Oil 300 Series) such that the refractive index of the interface is matched to the glass refractive index.\nSide illumination fiber is moved closer to the prism (or the hemi-sphere) and its angle is adjusted to ensure that total-internal reflection occurs at the glass-air interface corresponding to the micro-fluidic chip's bottom substrate. The vertical illumination (for lensfree transmission imaging) is aligned to be perpendicular to the detector-array and is centered to a desired field-of-view.\nSide and vertical light-sources are sequentially turned on/off to achieve both fluorescent imaging and bright-field transmission imaging using same on-chip platform.\nLensfree raw images are then acquired using a custom-developed Labview interface through a PC (e.g., 3.2 GHz Processor, Intel Core).\n2. Sample Preparation\nWe used fluorescent micro-beads (e.g., Invitrogen, Fluospheres) to calibrate our imaging platform, by measuring its lensfree system point-spread-function (PSF). After this initial PSF measurement is done, various cells or small model animals (e.g., transgenic C. elegans samples) can be imaged using the same on-chip platform.\nStarting with the next sub-section, we will provide further details of our sample preparation steps.\nFluorescent micro-beads:\nRaw fluorescent bead solutions are combined with DI water to optimize the concentration of the samples.\n~10 μL of fluorescent bead solution is mixed with 40 μL, 5 mL, and 20 mL of DI water for 10 μm, 4 μm and 2 μm diameter beads, respectively. Heterogeneous solutions of various beads (e.g., non-fluorescent and fluorescent) are prepared as needed by mixing different bead solutions with each other.",
    "The final sample solution is then injected into the micro-fluidic chip from the side PDMS walls using a sharp syringe needle (Fisher Scientific, BD PrecisionGlide Needles, 14-826 Series)\nWhite blood cell labeling:\nA volume of ~100 μL whole blood is mixed with ~1 mL of red blood cell lysing buffer (eBioscience).\nAfter incubation for ~3 min, the lysed blood solution is centrifuged and the pellet layer is resuspended in ~200 μL of PBS (Phosphate buffered saline).\nTo label the nucleic acid of the cells with fluorescence dyes, 5 μL of 1mM SYTO 16 is added to the 200 μL of resuspension, after which the sample is incubated for ~30 min in dark at room temperature.\nSecond centrifuging is applied to this labeled sample, where the supernatant is removed to decrease the background noise due to fluorescent emission from unbound dyes.\nWhite blood cell pellet layer is resuspended in PBS that can then be transferred to a micro-fluidic chip for lensfree on-chip fluorescent imaging (see e.g., Figure 7).\n3. Digital processing of the acquired lensless fluorescent images",
    "In this lensless imaging platform, two different algorithms are used to digitally increase the resolution of the system, namely the Lucy-Richardson deconvolution and Compressive sampling based decoding. Through the use of these digital processing methods, we quantified the resolution enhancement that can be achieved with each approach by resolving closely packed bead-pairs (see Figs. 5-6). The reconstructed lensfree fluorescent images can then be pseudocolored (if desired) to highlight the natural color of the micro-objects, which surely requires prior knowledge of the fluorescent signal wavelength, unless a color (e.g., an RGB: red-green-blue CCD/CMOS) sensor-chip is used. For these digital processing methods, custom-developed algorithms are used that only require a CPU (e.g., a 3.2 GHz Processor, Intel Core). Potentially, next-generation graphics processing units (GPUs) could also be used for faster processing. In addition to imaging, if needed, the decoded fluorescent objects can also be automatically counted using a custom-developed interface (see Fig. 8) for on-chip cytometry applications.\nMeasurement of the system Point -Spread Function (PSF):\n\tPrior to any digital processing for resolution improvement (such as deconvolution or compressive decoding), the incoherent point-spread function of the on-chip system needs to be estimated, which can be achieved by averaging several measured lensfree fluorescent patterns created by isolated small fluorescent beads located at a certain height from the sensor-chip. These individual fluorescent patterns are then aligned with respect to their center of mass coordinates to be averaged after appropriate intensity normalization1,2. This averaged lensfree pattern can be then used as the fluorescent point-spread function of our on-chip microscope.",
    "Lucy-Richardson Deconvolution1: To digitally improve the spatial resolution of our platform, we feed the raw acquired fluorescent image and the measured incoherent point-spread function into an accelerated Lucy-Richardson algorithm8-10. By applying the Bayes' theorem, the Lucy-Richardson algorithm uses the measured point-spread function to iteratively refine the maximum-likelihood estimation of the fluorescence source distribution at the object plane8,9. The iteration process is terminated typically after a few hundred cycles before the emergence of noise amplification to ensure minimal square error between the projected and the measured lensfree fluorescent patterns. The convergence of this deconvolution algorithm was also accelerated by a vector extrapolation method to shorten the computation time10. To give an idea: this algorithm provides an effective spatial resolution of ~20 μm (using a CCD/CMOS chip with a pixel size of e.g., ~9μm) and can deconvolve an FOV of ~ 8 cm2 within a few tens of minutes on a regular PC that is running Matlab1. Note that the same computation time drops to just a few seconds for e.g., ~1mm2 FOV which is comparable to the FOV of a typical 10X objective lens.",
    "Compressive sampling/sensing based sparse-signal decoding2: Further resolution improvement (down to <4 μm)4 can be achieved by using Compressive Sensing/Sampling based decoding algorithms11,12. Compressive Sampling/Sensing provides a recently emerging theoretical framework13-15 that aims to recover a sparse signal from much fewer samples than that is required according to the sampling theorem. While in general, signal recovery from under-sampled measurements is an ill-posed problem, for a specific class of functions (namely for sparse functions), the well-known sampling theorem and its representation basis is recently shown to be quite inefficient in terms of the number of measurements that are required, i.e., the same sparse signal can in general be uniquely recovered from very few samples compared to the classical sampling theory.\n\tLensless fluorescent images recorded by our on-chip microscope inherently satisfy an important requirement of Compressive Decoding: For the applications that are of interest to this work, such as wide-field fluorescent cytometry, rare cell analysis and high-throughput micro-array imaging, fluorescent objects of interest can be considered to be already sparse. Therefore, in our lensless fluorescent microscope, decoding of the distribution and the relative strengths of the fluorescent emitters located at the object plane can be modeled as a large-scale l1-Regularized Least Squares Problem which can be solved using e.g., an interior-point method2,12. This optimization problem can be mathematically expressed as:\nimgsrc://cloudfront.jove.com/files/ftp_upload/3181/3181eq1.jpg",
    "where ||u||k=(∑in |ui|k )(1/k) and ||u||∞=maxi |ui |. Therefore, we minimize l1-regularized l2-norm of the difference between the recorded/measured(y) and the estimated (Ax) lensfree images, where x and A represent the source distribution to be decoded and the measurement matrix formed using the experimental PSF of the system, respectively. We also use a constraint function forcing the source distribution at the object plane to be nonnegative. This iterative compressive decoding process ends when the value of the cost function reaches to a predetermined tolerance value. Regularization (β) and tolerance parameters are in general functions of the object sparsity and the measurement noise level, and are optimized in our system to ~βmax/10 and ~0.01, respectively.\n\tBased on the above outlined numerical scheme, compressive decoding of raw fluorescent images greatly improves our platform's ability to resolve sparse objects and exhibits a processing speed comparable to Lucy-Richardson Deconvolution2. In addition to imaging a single layer, fluorescent objects located at different depths can be also decoded and separated from each other simultaneously by running the same algorithm using all the PSFs corresponding to different depth layers2.",
    "Pseudocoloring: While not a fundamental limitation, the presented on-chip imaging platform mostly employs monochrome opto-electronic sensor arrays which in general provide better signal-to-noise ratio for biological sample imaging. Therefore, the raw fluorescent images are acquired in grayscale format, which does not contain the real color information of the samples. This could be mitigated by using color CCD/CMOS chips in our lensfree imaging architecture such that 3 color channels (red, green and blue) are acquired in each lensfree fluorescent measurement. On the other hand, if the labeling dye emission characteristics are already known, raw format grayscale fluorescent images of a monochrome sensor-chip and their decoded/deconvoled versions can also be artificially converted to color images using a pseudocoloring algorithm implemented in e.g., MATLAB. For this purpose, the acquired grayscale images can be expanded into 3-dimensional data-cubes, where any color of interest can be synthesized by using appropriate weighing factors at each pseudo channel of the data cube. As a result of this processing, monochrome lensfree fluorescent images can be converted (if desired) to multi-channel images that provide known color information of a given fluorescent object.",
    "Automated fluorescent cell counting: For cytometry applications, we have also developed a custom-designed user interface (see Fig. 8) that can automatically count the fluorescent objects/cells based on their lensfree images acquired with our on-chip microscopy platform. Toward this task, initially a soft threshold is applied to raw lensfree images to narrow down potential locations of fluorescent objects. Then, a series of functions (especially regionprops) are used to measure image properties of each sub-region of interest such as position, area, shape and intensity. Using these object data, binary objects are classified into subgroups, such as cells, dead pixels, as well as dust or background auto fluorescence. Once the final result of regionprops function is filtered to show only the cells of interest, the length of the resulting structure array can be used to get the cell count over the entire FOV of our lensfree on-chip imager.\n4. Representative Results:\nAn overview of our set-up is shown in Figure 1, with several optical components that are used in its assembly. Key features of our on-chip microscopy platform are explained in Figure 2, including fluorescent excitation and detection, total internal reflection as well as partially-coherent illumination for holographic transmission imaging on the same platform. Lensless fluorescent on-chip imaging results of a heterogeneous mixture containing various micro-particles (4 μm green and 10 μm green/red) are shown in Figures 3-4. Comparison of Lucy-Richardson deconvolution and Compressive Sampling/Sensing based decoding is provided in Figure 5 for digitally enhancing the resolution of raw lensless fluorescent images. Compressive decoding enabled spatial resolution (<4 μm) is quantified in Figure 6. Lensless on-chip microscopy of fluorescently labeled white blood cells is illustrated in Figure 7, which also provides comparison images taken with a conventional fluorescent microscope. Finally, our automated fluorescent object counting interface is shown in Figure 8.\nimgsrc://cloudfront.jove.com/files/ftp_upload/3181/3181fig1.jpg",
    "Figure 1. Overview of our lensless on-chip imaging set-up is shown with several optical components that are used in its assembly.\nimgsrc://cloudfront.jove.com/files/ftp_upload/3181/3181fig2.jpg\nFigure 2. The schematic diagram of on-chip lensfree fluorescent imaging platform is shown (left image). Fluorescence excitation is achieved through the side facet of a rhomboid prism using an incoherent source. The experimental set-up of our on-chip fluorescent imaging platform is also shown (right image). Whole blood sample within a microfluidic chip (dimensions: 2.5 x 3.5 x 0.3 cm) was excited through the prism interface, where index matching oil was used to assemble the chip and the prism. Upon rejection of the excitation light by TIR and the color filter, only the fluorescent emission from the labeled blood cells was recorded by our CCD sensor chip (KODAK 11002) over an FOV of ~2.5 x 3.5 cm.\nimgsrc://cloudfront.jove.com/files/ftp_upload/3181/3181fig3.jpg\nFigure 3. Wide-field lensless fluorescent on-chip imaging of a mixture containing 4 μm and 10 μm green fluorescent particles is illustrated. For comparison purposes, 10X microscope objective images are also provided, which agree well with our lensless fluorescent images.\nimgsrc://cloudfront.jove.com/files/ftp_upload/3181/3181fig4.jpg\nFigure 4. Wide-field lensless fluorescent imaging of a mixture containing 10 μm green and 10 μm red fluorescent particles is demonstrated. Our lensless fluorescent images provide a decent match to 10X microscope objective images of the same samples.\nimgsrc://cloudfront.jove.com/files/ftp_upload/3181/3181fig5.jpg",
    "Figure 5. Performance comparison of the Lucy-Richardson (LR) deconvolution and compressive sampling (CS) based decoding algorithms is provided, for imaging of various 10 μm bead-pairs. The top row illustrates the lensless raw fluorescent images. The inset images in the top row show the microscope comparisons of the same particles that are acquired using a 10X objective lens. The middle row demonstrates our compressive decoding results while the bottom row illustrates the Lucy-Richardson deconvolution results. d, dCS, and dLR refer to the center-to-center distances in microscope images, CS decoded lensless images, and LR deconvolved lensless images, respectively.\nimgsrc://cloudfront.jove.com/files/ftp_upload/3181/3181fig6.jpg\nFigure 6. Digital processing of lensless fluorescent raw images is illustrated. A Compressive Sampling based algorithm is used to achieve <4 μm spatial resolution by resolving closely packed 2 μm diameter bead pairs. The insets also show 40X microscope objective comparisons, which agree very well with the decoded fluorescent images. Here d refers to the center-to-center distances in microscope images, while dCS refers to the center-to-center distances in the CS decoded lensless fluorescent images.\nimgsrc://cloudfront.jove.com/files/ftp_upload/3181/3181fig7.jpg\nFigure 7. Lensless imaging of fluorescently (SYTO 16) labeled white blood cells is illustrated. The raw lensfree images are rapidly decoded using a CS based decoder, which agrees very well with a conventional microscope image of the same sample that is acquired with a 10X objective lens.\nimgsrc://cloudfront.jove.com/files/ftp_upload/3181/3181fig8.jpg\nFigure 8. A custom-designed automated fluorescent object counting interface (in MATLAB) is illustrated.Subscription Required. Please recommend JoVE to your librarian."
  ],
  "subjectAreas": [
    "Bioengineering"
  ],
  "bigAreas": [
    "Bioengineering & Technology"
  ]
}